{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy\n",
    "import importlib\n",
    "import torch.nn.functional as F\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import manifold\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/train_dist')\n",
    "sys.path.append('/workspace/GREAT_ASV_system/Model_exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResnetSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpeakerNetModel = importlib.import_module('models.'+'ResNetSE34V2').__getattribute__('MainModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetSE34V2.py, Embedding size is 192, Encoder ASP, Spec_aug False.\n"
     ]
    }
   ],
   "source": [
    "# RESNET34SE\n",
    "# (self, block, layers, num_filters, nOut, spec_aug, encoder_type='SAP', n_mels=40, log_input=True, **kwargs)\n",
    "# model = ResNetSE(SEBasicBlock, [3, 4, 6, 3], num_filters, nOut, spec_aug, **kwargs)\n",
    "S = SpeakerNetModel(n_mels=64, nOut=192, spec_aug=False, encoder_type='ASP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/workspace/LOGS_OUTPUT/tmp_logs/train_logs_201120/single_gpu_resnetsev2/model/model000000120.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state = torch.load(model_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#__L__.W is not in the model.\n"
     ]
    }
   ],
   "source": [
    "self_state = S.state_dict()\n",
    "\n",
    "for name, param in loaded_state['model'].items():\n",
    "    origname = name\n",
    "    if name not in self_state:\n",
    "        name = name.replace(\"__S__.\", \"\")\n",
    "\n",
    "        if name not in self_state:\n",
    "            print(\"#%s is not in the model.\"%origname)\n",
    "            continue\n",
    "\n",
    "    if self_state[name].size() != loaded_state['model'][origname].size():\n",
    "        print(\"#Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state['model'][origname].size()))\n",
    "        continue\n",
    "\n",
    "    self_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetSE(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (attention): Sequential(\n",
       "    (0): Conv1d(2048, 128, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv1d(128, 2048, kernel_size=(1,), stride=(1,))\n",
       "    (4): Softmax(dim=2)\n",
       "  )\n",
       "  (fc): Linear(in_features=4096, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWAV(filename):\n",
    "\n",
    "    # Maximum audio length\n",
    "    \n",
    "    max_audio = int(0*16000 + 240)\n",
    "\n",
    "    # Read wav file and convert to torch tensor\n",
    "    sample_rate, audio  = wavfile.read(filename)\n",
    "    \n",
    "    audiosize = audio.shape[0]\n",
    "\n",
    "    if audiosize <= max_audio:\n",
    "        shortage    = max_audio - audiosize + 1 \n",
    "        audio       = numpy.pad(audio, (0, shortage), 'wrap')\n",
    "        audiosize   = audio.shape[0]\n",
    "    \n",
    "    feats = []\n",
    "\n",
    "    feats.append(audio)\n",
    "\n",
    "    feat = numpy.stack(feats,axis=0).astype(numpy.float)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = '/workspace/DATASET/server9_ssd/voxceleb/vox_o_triallist.txt'\n",
    "test_path = '/workspace/DATASET/server9_ssd/voxceleb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "with open(test_list) as listfile:\n",
    "    while True:\n",
    "        line = listfile.readline()\n",
    "        if (not line):\n",
    "            break\n",
    "\n",
    "        data = line.split();\n",
    "\n",
    "        ## Append random label if missing\n",
    "        if len(data) == 2: data = [random.randint(0,1)] + data\n",
    "\n",
    "        files.append(data[1])\n",
    "        files.append(data[2])\n",
    "\n",
    "setfiles = list(set(files))\n",
    "setfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4708"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(setfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4298101341724396\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "for count, wavline in enumerate(setfiles[:200]):\n",
    "    wavline = os.path.join(test_path, wavline)\n",
    "    raw_inp = loadWAV(wavline)\n",
    "    raw_inp = torch.FloatTensor(raw_inp)\n",
    "    \n",
    "    ref_feat = S.forward(raw_inp).detach().cpu().numpy()\n",
    "    \n",
    "    print((count+1), end='\\r')\n",
    "endtime =time.time()\n",
    "print((endtime-starttime)/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetSE(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (attention): Sequential(\n",
       "    (0): Conv1d(2048, 128, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv1d(128, 2048, kernel_size=(1,), stride=(1,))\n",
       "    (4): Softmax(dim=2)\n",
       "  )\n",
       "  (fc): Linear(in_features=4096, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       PreEmphasis-1               [-1, 120000]               0\n",
      "       Spectrogram-2             [-1, 257, 751]               0\n",
      "          MelScale-3              [-1, 64, 751]               0\n",
      "    MelSpectrogram-4              [-1, 64, 751]               0\n",
      "    InstanceNorm1d-5              [-1, 64, 751]               0\n",
      "            Conv2d-6          [-1, 32, 64, 751]             320\n",
      "              ReLU-7          [-1, 32, 64, 751]               0\n",
      "       BatchNorm2d-8          [-1, 32, 64, 751]              64\n",
      "            Conv2d-9          [-1, 32, 64, 751]           9,216\n",
      "             ReLU-10          [-1, 32, 64, 751]               0\n",
      "      BatchNorm2d-11          [-1, 32, 64, 751]              64\n",
      "           Conv2d-12          [-1, 32, 64, 751]           9,216\n",
      "      BatchNorm2d-13          [-1, 32, 64, 751]              64\n",
      "AdaptiveAvgPool2d-14             [-1, 32, 1, 1]               0\n",
      "           Linear-15                    [-1, 4]             132\n",
      "             ReLU-16                    [-1, 4]               0\n",
      "           Linear-17                   [-1, 32]             160\n",
      "          Sigmoid-18                   [-1, 32]               0\n",
      "          SELayer-19          [-1, 32, 64, 751]               0\n",
      "             ReLU-20          [-1, 32, 64, 751]               0\n",
      "     SEBasicBlock-21          [-1, 32, 64, 751]               0\n",
      "           Conv2d-22          [-1, 32, 64, 751]           9,216\n",
      "             ReLU-23          [-1, 32, 64, 751]               0\n",
      "      BatchNorm2d-24          [-1, 32, 64, 751]              64\n",
      "           Conv2d-25          [-1, 32, 64, 751]           9,216\n",
      "      BatchNorm2d-26          [-1, 32, 64, 751]              64\n",
      "AdaptiveAvgPool2d-27             [-1, 32, 1, 1]               0\n",
      "           Linear-28                    [-1, 4]             132\n",
      "             ReLU-29                    [-1, 4]               0\n",
      "           Linear-30                   [-1, 32]             160\n",
      "          Sigmoid-31                   [-1, 32]               0\n",
      "          SELayer-32          [-1, 32, 64, 751]               0\n",
      "             ReLU-33          [-1, 32, 64, 751]               0\n",
      "     SEBasicBlock-34          [-1, 32, 64, 751]               0\n",
      "           Conv2d-35          [-1, 32, 64, 751]           9,216\n",
      "             ReLU-36          [-1, 32, 64, 751]               0\n",
      "      BatchNorm2d-37          [-1, 32, 64, 751]              64\n",
      "           Conv2d-38          [-1, 32, 64, 751]           9,216\n",
      "      BatchNorm2d-39          [-1, 32, 64, 751]              64\n",
      "AdaptiveAvgPool2d-40             [-1, 32, 1, 1]               0\n",
      "           Linear-41                    [-1, 4]             132\n",
      "             ReLU-42                    [-1, 4]               0\n",
      "           Linear-43                   [-1, 32]             160\n",
      "          Sigmoid-44                   [-1, 32]               0\n",
      "          SELayer-45          [-1, 32, 64, 751]               0\n",
      "             ReLU-46          [-1, 32, 64, 751]               0\n",
      "     SEBasicBlock-47          [-1, 32, 64, 751]               0\n",
      "           Conv2d-48          [-1, 64, 32, 376]          18,432\n",
      "             ReLU-49          [-1, 64, 32, 376]               0\n",
      "      BatchNorm2d-50          [-1, 64, 32, 376]             128\n",
      "           Conv2d-51          [-1, 64, 32, 376]          36,864\n",
      "      BatchNorm2d-52          [-1, 64, 32, 376]             128\n",
      "AdaptiveAvgPool2d-53             [-1, 64, 1, 1]               0\n",
      "           Linear-54                    [-1, 8]             520\n",
      "             ReLU-55                    [-1, 8]               0\n",
      "           Linear-56                   [-1, 64]             576\n",
      "          Sigmoid-57                   [-1, 64]               0\n",
      "          SELayer-58          [-1, 64, 32, 376]               0\n",
      "           Conv2d-59          [-1, 64, 32, 376]           2,048\n",
      "      BatchNorm2d-60          [-1, 64, 32, 376]             128\n",
      "             ReLU-61          [-1, 64, 32, 376]               0\n",
      "     SEBasicBlock-62          [-1, 64, 32, 376]               0\n",
      "           Conv2d-63          [-1, 64, 32, 376]          36,864\n",
      "             ReLU-64          [-1, 64, 32, 376]               0\n",
      "      BatchNorm2d-65          [-1, 64, 32, 376]             128\n",
      "           Conv2d-66          [-1, 64, 32, 376]          36,864\n",
      "      BatchNorm2d-67          [-1, 64, 32, 376]             128\n",
      "AdaptiveAvgPool2d-68             [-1, 64, 1, 1]               0\n",
      "           Linear-69                    [-1, 8]             520\n",
      "             ReLU-70                    [-1, 8]               0\n",
      "           Linear-71                   [-1, 64]             576\n",
      "          Sigmoid-72                   [-1, 64]               0\n",
      "          SELayer-73          [-1, 64, 32, 376]               0\n",
      "             ReLU-74          [-1, 64, 32, 376]               0\n",
      "     SEBasicBlock-75          [-1, 64, 32, 376]               0\n",
      "           Conv2d-76          [-1, 64, 32, 376]          36,864\n",
      "             ReLU-77          [-1, 64, 32, 376]               0\n",
      "      BatchNorm2d-78          [-1, 64, 32, 376]             128\n",
      "           Conv2d-79          [-1, 64, 32, 376]          36,864\n",
      "      BatchNorm2d-80          [-1, 64, 32, 376]             128\n",
      "AdaptiveAvgPool2d-81             [-1, 64, 1, 1]               0\n",
      "           Linear-82                    [-1, 8]             520\n",
      "             ReLU-83                    [-1, 8]               0\n",
      "           Linear-84                   [-1, 64]             576\n",
      "          Sigmoid-85                   [-1, 64]               0\n",
      "          SELayer-86          [-1, 64, 32, 376]               0\n",
      "             ReLU-87          [-1, 64, 32, 376]               0\n",
      "     SEBasicBlock-88          [-1, 64, 32, 376]               0\n",
      "           Conv2d-89          [-1, 64, 32, 376]          36,864\n",
      "             ReLU-90          [-1, 64, 32, 376]               0\n",
      "      BatchNorm2d-91          [-1, 64, 32, 376]             128\n",
      "           Conv2d-92          [-1, 64, 32, 376]          36,864\n",
      "      BatchNorm2d-93          [-1, 64, 32, 376]             128\n",
      "AdaptiveAvgPool2d-94             [-1, 64, 1, 1]               0\n",
      "           Linear-95                    [-1, 8]             520\n",
      "             ReLU-96                    [-1, 8]               0\n",
      "           Linear-97                   [-1, 64]             576\n",
      "          Sigmoid-98                   [-1, 64]               0\n",
      "          SELayer-99          [-1, 64, 32, 376]               0\n",
      "            ReLU-100          [-1, 64, 32, 376]               0\n",
      "    SEBasicBlock-101          [-1, 64, 32, 376]               0\n",
      "          Conv2d-102         [-1, 128, 16, 188]          73,728\n",
      "            ReLU-103         [-1, 128, 16, 188]               0\n",
      "     BatchNorm2d-104         [-1, 128, 16, 188]             256\n",
      "          Conv2d-105         [-1, 128, 16, 188]         147,456\n",
      "     BatchNorm2d-106         [-1, 128, 16, 188]             256\n",
      "AdaptiveAvgPool2d-107            [-1, 128, 1, 1]               0\n",
      "          Linear-108                   [-1, 16]           2,064\n",
      "            ReLU-109                   [-1, 16]               0\n",
      "          Linear-110                  [-1, 128]           2,176\n",
      "         Sigmoid-111                  [-1, 128]               0\n",
      "         SELayer-112         [-1, 128, 16, 188]               0\n",
      "          Conv2d-113         [-1, 128, 16, 188]           8,192\n",
      "     BatchNorm2d-114         [-1, 128, 16, 188]             256\n",
      "            ReLU-115         [-1, 128, 16, 188]               0\n",
      "    SEBasicBlock-116         [-1, 128, 16, 188]               0\n",
      "          Conv2d-117         [-1, 128, 16, 188]         147,456\n",
      "            ReLU-118         [-1, 128, 16, 188]               0\n",
      "     BatchNorm2d-119         [-1, 128, 16, 188]             256\n",
      "          Conv2d-120         [-1, 128, 16, 188]         147,456\n",
      "     BatchNorm2d-121         [-1, 128, 16, 188]             256\n",
      "AdaptiveAvgPool2d-122            [-1, 128, 1, 1]               0\n",
      "          Linear-123                   [-1, 16]           2,064\n",
      "            ReLU-124                   [-1, 16]               0\n",
      "          Linear-125                  [-1, 128]           2,176\n",
      "         Sigmoid-126                  [-1, 128]               0\n",
      "         SELayer-127         [-1, 128, 16, 188]               0\n",
      "            ReLU-128         [-1, 128, 16, 188]               0\n",
      "    SEBasicBlock-129         [-1, 128, 16, 188]               0\n",
      "          Conv2d-130         [-1, 128, 16, 188]         147,456\n",
      "            ReLU-131         [-1, 128, 16, 188]               0\n",
      "     BatchNorm2d-132         [-1, 128, 16, 188]             256\n",
      "          Conv2d-133         [-1, 128, 16, 188]         147,456\n",
      "     BatchNorm2d-134         [-1, 128, 16, 188]             256\n",
      "AdaptiveAvgPool2d-135            [-1, 128, 1, 1]               0\n",
      "          Linear-136                   [-1, 16]           2,064\n",
      "            ReLU-137                   [-1, 16]               0\n",
      "          Linear-138                  [-1, 128]           2,176\n",
      "         Sigmoid-139                  [-1, 128]               0\n",
      "         SELayer-140         [-1, 128, 16, 188]               0\n",
      "            ReLU-141         [-1, 128, 16, 188]               0\n",
      "    SEBasicBlock-142         [-1, 128, 16, 188]               0\n",
      "          Conv2d-143         [-1, 128, 16, 188]         147,456\n",
      "            ReLU-144         [-1, 128, 16, 188]               0\n",
      "     BatchNorm2d-145         [-1, 128, 16, 188]             256\n",
      "          Conv2d-146         [-1, 128, 16, 188]         147,456\n",
      "     BatchNorm2d-147         [-1, 128, 16, 188]             256\n",
      "AdaptiveAvgPool2d-148            [-1, 128, 1, 1]               0\n",
      "          Linear-149                   [-1, 16]           2,064\n",
      "            ReLU-150                   [-1, 16]               0\n",
      "          Linear-151                  [-1, 128]           2,176\n",
      "         Sigmoid-152                  [-1, 128]               0\n",
      "         SELayer-153         [-1, 128, 16, 188]               0\n",
      "            ReLU-154         [-1, 128, 16, 188]               0\n",
      "    SEBasicBlock-155         [-1, 128, 16, 188]               0\n",
      "          Conv2d-156         [-1, 128, 16, 188]         147,456\n",
      "            ReLU-157         [-1, 128, 16, 188]               0\n",
      "     BatchNorm2d-158         [-1, 128, 16, 188]             256\n",
      "          Conv2d-159         [-1, 128, 16, 188]         147,456\n",
      "     BatchNorm2d-160         [-1, 128, 16, 188]             256\n",
      "AdaptiveAvgPool2d-161            [-1, 128, 1, 1]               0\n",
      "          Linear-162                   [-1, 16]           2,064\n",
      "            ReLU-163                   [-1, 16]               0\n",
      "          Linear-164                  [-1, 128]           2,176\n",
      "         Sigmoid-165                  [-1, 128]               0\n",
      "         SELayer-166         [-1, 128, 16, 188]               0\n",
      "            ReLU-167         [-1, 128, 16, 188]               0\n",
      "    SEBasicBlock-168         [-1, 128, 16, 188]               0\n",
      "          Conv2d-169         [-1, 128, 16, 188]         147,456\n",
      "            ReLU-170         [-1, 128, 16, 188]               0\n",
      "     BatchNorm2d-171         [-1, 128, 16, 188]             256\n",
      "          Conv2d-172         [-1, 128, 16, 188]         147,456\n",
      "     BatchNorm2d-173         [-1, 128, 16, 188]             256\n",
      "AdaptiveAvgPool2d-174            [-1, 128, 1, 1]               0\n",
      "          Linear-175                   [-1, 16]           2,064\n",
      "            ReLU-176                   [-1, 16]               0\n",
      "          Linear-177                  [-1, 128]           2,176\n",
      "         Sigmoid-178                  [-1, 128]               0\n",
      "         SELayer-179         [-1, 128, 16, 188]               0\n",
      "            ReLU-180         [-1, 128, 16, 188]               0\n",
      "    SEBasicBlock-181         [-1, 128, 16, 188]               0\n",
      "          Conv2d-182           [-1, 256, 8, 94]         294,912\n",
      "            ReLU-183           [-1, 256, 8, 94]               0\n",
      "     BatchNorm2d-184           [-1, 256, 8, 94]             512\n",
      "          Conv2d-185           [-1, 256, 8, 94]         589,824\n",
      "     BatchNorm2d-186           [-1, 256, 8, 94]             512\n",
      "AdaptiveAvgPool2d-187            [-1, 256, 1, 1]               0\n",
      "          Linear-188                   [-1, 32]           8,224\n",
      "            ReLU-189                   [-1, 32]               0\n",
      "          Linear-190                  [-1, 256]           8,448\n",
      "         Sigmoid-191                  [-1, 256]               0\n",
      "         SELayer-192           [-1, 256, 8, 94]               0\n",
      "          Conv2d-193           [-1, 256, 8, 94]          32,768\n",
      "     BatchNorm2d-194           [-1, 256, 8, 94]             512\n",
      "            ReLU-195           [-1, 256, 8, 94]               0\n",
      "    SEBasicBlock-196           [-1, 256, 8, 94]               0\n",
      "          Conv2d-197           [-1, 256, 8, 94]         589,824\n",
      "            ReLU-198           [-1, 256, 8, 94]               0\n",
      "     BatchNorm2d-199           [-1, 256, 8, 94]             512\n",
      "          Conv2d-200           [-1, 256, 8, 94]         589,824\n",
      "     BatchNorm2d-201           [-1, 256, 8, 94]             512\n",
      "AdaptiveAvgPool2d-202            [-1, 256, 1, 1]               0\n",
      "          Linear-203                   [-1, 32]           8,224\n",
      "            ReLU-204                   [-1, 32]               0\n",
      "          Linear-205                  [-1, 256]           8,448\n",
      "         Sigmoid-206                  [-1, 256]               0\n",
      "         SELayer-207           [-1, 256, 8, 94]               0\n",
      "            ReLU-208           [-1, 256, 8, 94]               0\n",
      "    SEBasicBlock-209           [-1, 256, 8, 94]               0\n",
      "          Conv2d-210           [-1, 256, 8, 94]         589,824\n",
      "            ReLU-211           [-1, 256, 8, 94]               0\n",
      "     BatchNorm2d-212           [-1, 256, 8, 94]             512\n",
      "          Conv2d-213           [-1, 256, 8, 94]         589,824\n",
      "     BatchNorm2d-214           [-1, 256, 8, 94]             512\n",
      "AdaptiveAvgPool2d-215            [-1, 256, 1, 1]               0\n",
      "          Linear-216                   [-1, 32]           8,224\n",
      "            ReLU-217                   [-1, 32]               0\n",
      "          Linear-218                  [-1, 256]           8,448\n",
      "         Sigmoid-219                  [-1, 256]               0\n",
      "         SELayer-220           [-1, 256, 8, 94]               0\n",
      "            ReLU-221           [-1, 256, 8, 94]               0\n",
      "    SEBasicBlock-222           [-1, 256, 8, 94]               0\n",
      "          Conv1d-223              [-1, 128, 94]         262,272\n",
      "            ReLU-224              [-1, 128, 94]               0\n",
      "     BatchNorm1d-225              [-1, 128, 94]             256\n",
      "          Conv1d-226             [-1, 2048, 94]         264,192\n",
      "         Softmax-227             [-1, 2048, 94]               0\n",
      "          Linear-228                  [-1, 192]         786,624\n",
      "================================================================\n",
      "Total params: 6,717,452\n",
      "Trainable params: 6,717,452\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 708.39\n",
      "Params size (MB): 25.63\n",
      "Estimated Total Size (MB): 734.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(S, input_size=(120000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECAPA-TDNN1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpeakerNetModel = importlib.import_module('models.'+'EPACA-TDNN').__getattribute__('MainModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPACA-TDNN.py, Embedding size is 192, Channels 1024, Spec_aug False.\n"
     ]
    }
   ],
   "source": [
    "# RESNET34SE\n",
    "# (self, block, layers, num_filters, nOut, spec_aug, encoder_type='SAP', n_mels=40, log_input=True, **kwargs)\n",
    "# model = ResNetSE(SEBasicBlock, [3, 4, 6, 3], num_filters, nOut, spec_aug, **kwargs)\n",
    "S = SpeakerNetModel(n_mels=40, nOut=192, spec_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/workspace/LOGS_OUTPUT/tmp_logs/train_logs_201120/multi_gpu_epaca_tdnn/model/model000000060.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state = torch.load(model_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#__L__.W is not in the model.\n"
     ]
    }
   ],
   "source": [
    "self_state = S.state_dict()\n",
    "\n",
    "for name, param in loaded_state['model'].items():\n",
    "    origname = name\n",
    "    if name not in self_state:\n",
    "        name = name.replace(\"__S__.\", \"\")\n",
    "\n",
    "        if name not in self_state:\n",
    "            print(\"#%s is not in the model.\"%origname)\n",
    "            continue\n",
    "\n",
    "    if self_state[name].size() != loaded_state['model'][origname].size():\n",
    "        print(\"#Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state['model'][origname].size()))\n",
    "        continue\n",
    "\n",
    "    self_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECAPA_TDNN(\n",
       "  (instancenorm): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Conv1dReluBn(\n",
       "    (conv): Conv1d(40, 1024, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "    (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "  (pooling): AttentiveStatsPool(\n",
       "    (linear1): Conv1d(3072, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 3072, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=6144, out_features=192, bias=True)\n",
       "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWAV(filename):\n",
    "\n",
    "    # Maximum audio length\n",
    "    \n",
    "    max_audio = int(0*16000 + 240)\n",
    "\n",
    "    # Read wav file and convert to torch tensor\n",
    "    sample_rate, audio  = wavfile.read(filename)\n",
    "    \n",
    "    audiosize = audio.shape[0]\n",
    "\n",
    "    if audiosize <= max_audio:\n",
    "        shortage    = max_audio - audiosize + 1 \n",
    "        audio       = numpy.pad(audio, (0, shortage), 'wrap')\n",
    "        audiosize   = audio.shape[0]\n",
    "    \n",
    "    feats = []\n",
    "\n",
    "    feats.append(audio)\n",
    "\n",
    "    feat = numpy.stack(feats,axis=0).astype(numpy.float)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = '/workspace/DATASET/server9_ssd/voxceleb/vox_o_triallist.txt'\n",
    "test_path = '/workspace/DATASET/server9_ssd/voxceleb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "with open(test_list) as listfile:\n",
    "    while True:\n",
    "        line = listfile.readline()\n",
    "        if (not line):\n",
    "            break\n",
    "\n",
    "        data = line.split();\n",
    "\n",
    "        ## Append random label if missing\n",
    "        if len(data) == 2: data = [random.randint(0,1)] + data\n",
    "\n",
    "        files.append(data[1])\n",
    "        files.append(data[2])\n",
    "\n",
    "setfiles = list(set(files))\n",
    "setfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4708"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(setfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3624333930015564\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "for count, wavline in enumerate(setfiles[:200]):\n",
    "    wavline = os.path.join(test_path, wavline)\n",
    "    raw_inp = loadWAV(wavline)\n",
    "    raw_inp = torch.FloatTensor(raw_inp)\n",
    "    \n",
    "    ref_feat = S.forward(raw_inp).detach().cpu().numpy()\n",
    "    \n",
    "    print((count+1), end='\\r')\n",
    "endtime =time.time()\n",
    "print((endtime-starttime)/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECAPA_TDNN(\n",
       "  (instancenorm): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Conv1dReluBn(\n",
       "    (conv): Conv1d(40, 1024, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "    (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "  (pooling): AttentiveStatsPool(\n",
       "    (linear1): Conv1d(3072, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 3072, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=6144, out_features=192, bias=True)\n",
       "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       PreEmphasis-1               [-1, 120000]               0\n",
      "       Spectrogram-2             [-1, 257, 751]               0\n",
      "          MelScale-3              [-1, 40, 751]               0\n",
      "    MelSpectrogram-4              [-1, 40, 751]               0\n",
      "    InstanceNorm1d-5              [-1, 40, 751]               0\n",
      "            Conv1d-6            [-1, 1024, 751]         204,800\n",
      "       BatchNorm1d-7            [-1, 1024, 751]           2,048\n",
      "      Conv1dReluBn-8            [-1, 1024, 751]               0\n",
      "            Conv1d-9            [-1, 1024, 751]       1,048,576\n",
      "      BatchNorm1d-10            [-1, 1024, 751]           2,048\n",
      "     Conv1dReluBn-11            [-1, 1024, 751]               0\n",
      "           Conv1d-12             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-13             [-1, 128, 751]             256\n",
      "           Conv1d-14             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-15             [-1, 128, 751]             256\n",
      "           Conv1d-16             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-17             [-1, 128, 751]             256\n",
      "           Conv1d-18             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-19             [-1, 128, 751]             256\n",
      "           Conv1d-20             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-21             [-1, 128, 751]             256\n",
      "           Conv1d-22             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-23             [-1, 128, 751]             256\n",
      "           Conv1d-24             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-25             [-1, 128, 751]             256\n",
      " Res2Conv1dReluBn-26            [-1, 1024, 751]               0\n",
      "           Conv1d-27            [-1, 1024, 751]       1,048,576\n",
      "      BatchNorm1d-28            [-1, 1024, 751]           2,048\n",
      "     Conv1dReluBn-29            [-1, 1024, 751]               0\n",
      "           Linear-30                  [-1, 512]         524,800\n",
      "           Linear-31                 [-1, 1024]         525,312\n",
      "       SE_Connect-32            [-1, 1024, 751]               0\n",
      "           Conv1d-33            [-1, 1024, 751]       1,048,576\n",
      "      BatchNorm1d-34            [-1, 1024, 751]           2,048\n",
      "     Conv1dReluBn-35            [-1, 1024, 751]               0\n",
      "           Conv1d-36             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-37             [-1, 128, 751]             256\n",
      "           Conv1d-38             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-39             [-1, 128, 751]             256\n",
      "           Conv1d-40             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-41             [-1, 128, 751]             256\n",
      "           Conv1d-42             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-43             [-1, 128, 751]             256\n",
      "           Conv1d-44             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-45             [-1, 128, 751]             256\n",
      "           Conv1d-46             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-47             [-1, 128, 751]             256\n",
      "           Conv1d-48             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-49             [-1, 128, 751]             256\n",
      " Res2Conv1dReluBn-50            [-1, 1024, 751]               0\n",
      "           Conv1d-51            [-1, 1024, 751]       1,048,576\n",
      "      BatchNorm1d-52            [-1, 1024, 751]           2,048\n",
      "     Conv1dReluBn-53            [-1, 1024, 751]               0\n",
      "           Linear-54                  [-1, 512]         524,800\n",
      "           Linear-55                 [-1, 1024]         525,312\n",
      "       SE_Connect-56            [-1, 1024, 751]               0\n",
      "           Conv1d-57            [-1, 1024, 751]       1,048,576\n",
      "      BatchNorm1d-58            [-1, 1024, 751]           2,048\n",
      "     Conv1dReluBn-59            [-1, 1024, 751]               0\n",
      "           Conv1d-60             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-61             [-1, 128, 751]             256\n",
      "           Conv1d-62             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-63             [-1, 128, 751]             256\n",
      "           Conv1d-64             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-65             [-1, 128, 751]             256\n",
      "           Conv1d-66             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-67             [-1, 128, 751]             256\n",
      "           Conv1d-68             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-69             [-1, 128, 751]             256\n",
      "           Conv1d-70             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-71             [-1, 128, 751]             256\n",
      "           Conv1d-72             [-1, 128, 751]          49,152\n",
      "      BatchNorm1d-73             [-1, 128, 751]             256\n",
      " Res2Conv1dReluBn-74            [-1, 1024, 751]               0\n",
      "           Conv1d-75            [-1, 1024, 751]       1,048,576\n",
      "      BatchNorm1d-76            [-1, 1024, 751]           2,048\n",
      "     Conv1dReluBn-77            [-1, 1024, 751]               0\n",
      "           Linear-78                  [-1, 512]         524,800\n",
      "           Linear-79                 [-1, 1024]         525,312\n",
      "       SE_Connect-80            [-1, 1024, 751]               0\n",
      "           Conv1d-81            [-1, 3072, 751]       9,440,256\n",
      "           Conv1d-82             [-1, 128, 751]         393,344\n",
      "           Conv1d-83            [-1, 3072, 751]         396,288\n",
      "AttentiveStatsPool-84                 [-1, 6144]               0\n",
      "      BatchNorm1d-85                 [-1, 6144]          12,288\n",
      "           Linear-86                  [-1, 192]       1,179,840\n",
      "      BatchNorm1d-87                  [-1, 192]             384\n",
      "================================================================\n",
      "Total params: 22,120,896\n",
      "Trainable params: 22,120,896\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 228.36\n",
      "Params size (MB): 84.38\n",
      "Estimated Total Size (MB): 313.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(S, input_size=(120000,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECAPA-TDNN512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpeakerNetModel = importlib.import_module('models.'+'EPACA-TDNNL').__getattribute__('MainModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPACA-TDNNL.py, Embedding size is 192, Channels 512, Spec_aug False.\n"
     ]
    }
   ],
   "source": [
    "# RESNET34SE\n",
    "# (self, block, layers, num_filters, nOut, spec_aug, encoder_type='SAP', n_mels=40, log_input=True, **kwargs)\n",
    "# model = ResNetSE(SEBasicBlock, [3, 4, 6, 3], num_filters, nOut, spec_aug, **kwargs)\n",
    "S = SpeakerNetModel(n_mels=40, nOut=192, spec_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/workspace/LOGS_OUTPUT/tmp_logs/train_logs_201120/epaca_tdnnl_aldatest_beta0/model/model000000120.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state = torch.load(model_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#__L__.W is not in the model.\n",
      "#DA_module.backbone.torchfb.0.flipped_filter is not in the model.\n",
      "#DA_module.backbone.torchfb.1.spectrogram.window is not in the model.\n",
      "#DA_module.backbone.torchfb.1.mel_scale.fb is not in the model.\n",
      "#DA_module.backbone.layer1.conv.weight is not in the model.\n",
      "#DA_module.backbone.layer1.bn.weight is not in the model.\n",
      "#DA_module.backbone.layer1.bn.bias is not in the model.\n",
      "#DA_module.backbone.layer1.bn.running_mean is not in the model.\n",
      "#DA_module.backbone.layer1.bn.running_var is not in the model.\n",
      "#DA_module.backbone.layer1.bn.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer2.0.conv.weight is not in the model.\n",
      "#DA_module.backbone.layer2.0.bn.weight is not in the model.\n",
      "#DA_module.backbone.layer2.0.bn.bias is not in the model.\n",
      "#DA_module.backbone.layer2.0.bn.running_mean is not in the model.\n",
      "#DA_module.backbone.layer2.0.bn.running_var is not in the model.\n",
      "#DA_module.backbone.layer2.0.bn.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer2.1.convs.0.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.convs.1.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.convs.2.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.convs.3.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.convs.4.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.convs.5.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.convs.6.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.0.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.0.bias is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.0.running_mean is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.0.running_var is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.0.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.1.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.1.bias is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.1.running_mean is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.1.running_var is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.1.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.2.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.2.bias is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.2.running_mean is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.2.running_var is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.2.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.3.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.3.bias is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.3.running_mean is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.3.running_var is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.3.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.4.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.4.bias is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.4.running_mean is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.4.running_var is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.4.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.5.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.5.bias is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.5.running_mean is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.5.running_var is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.5.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.6.weight is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.6.bias is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.6.running_mean is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.6.running_var is not in the model.\n",
      "#DA_module.backbone.layer2.1.bns.6.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer2.2.conv.weight is not in the model.\n",
      "#DA_module.backbone.layer2.2.bn.weight is not in the model.\n",
      "#DA_module.backbone.layer2.2.bn.bias is not in the model.\n",
      "#DA_module.backbone.layer2.2.bn.running_mean is not in the model.\n",
      "#DA_module.backbone.layer2.2.bn.running_var is not in the model.\n",
      "#DA_module.backbone.layer2.2.bn.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer2.3.linear1.weight is not in the model.\n",
      "#DA_module.backbone.layer2.3.linear1.bias is not in the model.\n",
      "#DA_module.backbone.layer2.3.linear2.weight is not in the model.\n",
      "#DA_module.backbone.layer2.3.linear2.bias is not in the model.\n",
      "#DA_module.backbone.layer3.0.conv.weight is not in the model.\n",
      "#DA_module.backbone.layer3.0.bn.weight is not in the model.\n",
      "#DA_module.backbone.layer3.0.bn.bias is not in the model.\n",
      "#DA_module.backbone.layer3.0.bn.running_mean is not in the model.\n",
      "#DA_module.backbone.layer3.0.bn.running_var is not in the model.\n",
      "#DA_module.backbone.layer3.0.bn.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer3.1.convs.0.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.convs.1.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.convs.2.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.convs.3.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.convs.4.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.convs.5.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.convs.6.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.0.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.0.bias is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.0.running_mean is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.0.running_var is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.0.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.1.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.1.bias is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.1.running_mean is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.1.running_var is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.1.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.2.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.2.bias is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.2.running_mean is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.2.running_var is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.2.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.3.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.3.bias is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.3.running_mean is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.3.running_var is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.3.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.4.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.4.bias is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.4.running_mean is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.4.running_var is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.4.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.5.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.5.bias is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.5.running_mean is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.5.running_var is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.5.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.6.weight is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.6.bias is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.6.running_mean is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.6.running_var is not in the model.\n",
      "#DA_module.backbone.layer3.1.bns.6.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer3.2.conv.weight is not in the model.\n",
      "#DA_module.backbone.layer3.2.bn.weight is not in the model.\n",
      "#DA_module.backbone.layer3.2.bn.bias is not in the model.\n",
      "#DA_module.backbone.layer3.2.bn.running_mean is not in the model.\n",
      "#DA_module.backbone.layer3.2.bn.running_var is not in the model.\n",
      "#DA_module.backbone.layer3.2.bn.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer3.3.linear1.weight is not in the model.\n",
      "#DA_module.backbone.layer3.3.linear1.bias is not in the model.\n",
      "#DA_module.backbone.layer3.3.linear2.weight is not in the model.\n",
      "#DA_module.backbone.layer3.3.linear2.bias is not in the model.\n",
      "#DA_module.backbone.layer4.0.conv.weight is not in the model.\n",
      "#DA_module.backbone.layer4.0.bn.weight is not in the model.\n",
      "#DA_module.backbone.layer4.0.bn.bias is not in the model.\n",
      "#DA_module.backbone.layer4.0.bn.running_mean is not in the model.\n",
      "#DA_module.backbone.layer4.0.bn.running_var is not in the model.\n",
      "#DA_module.backbone.layer4.0.bn.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer4.1.convs.0.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.convs.1.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.convs.2.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.convs.3.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.convs.4.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.convs.5.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.convs.6.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.0.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.0.bias is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.0.running_mean is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.0.running_var is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.0.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.1.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.1.bias is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.1.running_mean is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.1.running_var is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.1.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.2.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.2.bias is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.2.running_mean is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.2.running_var is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.2.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.3.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.3.bias is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.3.running_mean is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.3.running_var is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.3.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.4.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.4.bias is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.4.running_mean is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.4.running_var is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.4.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.5.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.5.bias is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.5.running_mean is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.5.running_var is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.5.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.6.weight is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.6.bias is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.6.running_mean is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.6.running_var is not in the model.\n",
      "#DA_module.backbone.layer4.1.bns.6.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer4.2.conv.weight is not in the model.\n",
      "#DA_module.backbone.layer4.2.bn.weight is not in the model.\n",
      "#DA_module.backbone.layer4.2.bn.bias is not in the model.\n",
      "#DA_module.backbone.layer4.2.bn.running_mean is not in the model.\n",
      "#DA_module.backbone.layer4.2.bn.running_var is not in the model.\n",
      "#DA_module.backbone.layer4.2.bn.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.layer4.3.linear1.weight is not in the model.\n",
      "#DA_module.backbone.layer4.3.linear1.bias is not in the model.\n",
      "#DA_module.backbone.layer4.3.linear2.weight is not in the model.\n",
      "#DA_module.backbone.layer4.3.linear2.bias is not in the model.\n",
      "#DA_module.backbone.conv.weight is not in the model.\n",
      "#DA_module.backbone.conv.bias is not in the model.\n",
      "#DA_module.backbone.pooling.linear1.weight is not in the model.\n",
      "#DA_module.backbone.pooling.linear1.bias is not in the model.\n",
      "#DA_module.backbone.pooling.linear2.weight is not in the model.\n",
      "#DA_module.backbone.pooling.linear2.bias is not in the model.\n",
      "#DA_module.backbone.bn1.weight is not in the model.\n",
      "#DA_module.backbone.bn1.bias is not in the model.\n",
      "#DA_module.backbone.bn1.running_mean is not in the model.\n",
      "#DA_module.backbone.bn1.running_var is not in the model.\n",
      "#DA_module.backbone.bn1.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.linear.weight is not in the model.\n",
      "#DA_module.backbone.linear.bias is not in the model.\n",
      "#DA_module.backbone.bn2.weight is not in the model.\n",
      "#DA_module.backbone.bn2.bias is not in the model.\n",
      "#DA_module.backbone.bn2.running_mean is not in the model.\n",
      "#DA_module.backbone.bn2.running_var is not in the model.\n",
      "#DA_module.backbone.bn2.num_batches_tracked is not in the model.\n",
      "#DA_module.metrics.W is not in the model.\n",
      "#DA_module.layer_d1.linear.weight is not in the model.\n",
      "#DA_module.layer_d1.linear.bias is not in the model.\n",
      "#DA_module.layer_d1.batchnorm.weight is not in the model.\n",
      "#DA_module.layer_d1.batchnorm.bias is not in the model.\n",
      "#DA_module.layer_d1.batchnorm.running_mean is not in the model.\n",
      "#DA_module.layer_d1.batchnorm.running_var is not in the model.\n",
      "#DA_module.layer_d1.batchnorm.num_batches_tracked is not in the model.\n",
      "#DA_module.layer_d2.linear.weight is not in the model.\n",
      "#DA_module.layer_d2.linear.bias is not in the model.\n"
     ]
    }
   ],
   "source": [
    "self_state = S.state_dict()\n",
    "\n",
    "for name, param in loaded_state['model'].items():\n",
    "    origname = name\n",
    "    if name not in self_state:\n",
    "        name = name.replace(\"__S__.\", \"\")\n",
    "\n",
    "        if name not in self_state:\n",
    "            print(\"#%s is not in the model.\"%origname)\n",
    "            continue\n",
    "\n",
    "    if self_state[name].size() != loaded_state['model'][origname].size():\n",
    "        print(\"#Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state['model'][origname].size()))\n",
    "        continue\n",
    "\n",
    "    self_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECAPA_TDNN(\n",
       "  (instancenorm): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Conv1dReluBn(\n",
       "    (conv): Conv1d(40, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))\n",
       "  (pooling): AttentiveStatsPool(\n",
       "    (linear1): Conv1d(1536, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=3072, out_features=192, bias=True)\n",
       "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWAV(filename):\n",
    "\n",
    "    # Maximum audio length\n",
    "    \n",
    "    max_audio = int(0*16000 + 240)\n",
    "\n",
    "    # Read wav file and convert to torch tensor\n",
    "    sample_rate, audio  = wavfile.read(filename)\n",
    "    \n",
    "    audiosize = audio.shape[0]\n",
    "\n",
    "    if audiosize <= max_audio:\n",
    "        shortage    = max_audio - audiosize + 1 \n",
    "        audio       = numpy.pad(audio, (0, shortage), 'wrap')\n",
    "        audiosize   = audio.shape[0]\n",
    "    \n",
    "    feats = []\n",
    "\n",
    "    feats.append(audio)\n",
    "\n",
    "    feat = numpy.stack(feats,axis=0).astype(numpy.float)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = '/workspace/DATASET/server9_ssd/voxceleb/vox_o_triallist.txt'\n",
    "test_path = '/workspace/DATASET/server9_ssd/voxceleb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "with open(test_list) as listfile:\n",
    "    while True:\n",
    "        line = listfile.readline()\n",
    "        if (not line):\n",
    "            break\n",
    "\n",
    "        data = line.split();\n",
    "\n",
    "        ## Append random label if missing\n",
    "        if len(data) == 2: data = [random.randint(0,1)] + data\n",
    "\n",
    "        files.append(data[1])\n",
    "        files.append(data[2])\n",
    "\n",
    "setfiles = list(set(files))\n",
    "setfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4708"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(setfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0166996669769288\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "for count, wavline in enumerate(setfiles[:200]):\n",
    "    wavline = os.path.join(test_path, wavline)\n",
    "    raw_inp = loadWAV(wavline)\n",
    "    raw_inp = torch.FloatTensor(raw_inp)\n",
    "    \n",
    "    ref_feat = S.forward(raw_inp).detach().cpu().numpy()\n",
    "    \n",
    "    print((count+1), end='\\r')\n",
    "endtime =time.time()\n",
    "print((endtime-starttime)/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECAPA_TDNN(\n",
       "  (instancenorm): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Conv1dReluBn(\n",
       "    (conv): Conv1d(40, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))\n",
       "  (pooling): AttentiveStatsPool(\n",
       "    (linear1): Conv1d(1536, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=3072, out_features=192, bias=True)\n",
       "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       PreEmphasis-1               [-1, 120000]               0\n",
      "       Spectrogram-2             [-1, 257, 751]               0\n",
      "          MelScale-3              [-1, 40, 751]               0\n",
      "    MelSpectrogram-4              [-1, 40, 751]               0\n",
      "    InstanceNorm1d-5              [-1, 40, 751]               0\n",
      "            Conv1d-6             [-1, 512, 751]         102,400\n",
      "       BatchNorm1d-7             [-1, 512, 751]           1,024\n",
      "      Conv1dReluBn-8             [-1, 512, 751]               0\n",
      "            Conv1d-9             [-1, 512, 751]         262,144\n",
      "      BatchNorm1d-10             [-1, 512, 751]           1,024\n",
      "     Conv1dReluBn-11             [-1, 512, 751]               0\n",
      "           Conv1d-12              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-13              [-1, 64, 751]             128\n",
      "           Conv1d-14              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-15              [-1, 64, 751]             128\n",
      "           Conv1d-16              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-17              [-1, 64, 751]             128\n",
      "           Conv1d-18              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-19              [-1, 64, 751]             128\n",
      "           Conv1d-20              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-21              [-1, 64, 751]             128\n",
      "           Conv1d-22              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-23              [-1, 64, 751]             128\n",
      "           Conv1d-24              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-25              [-1, 64, 751]             128\n",
      " Res2Conv1dReluBn-26             [-1, 512, 751]               0\n",
      "           Conv1d-27             [-1, 512, 751]         262,144\n",
      "      BatchNorm1d-28             [-1, 512, 751]           1,024\n",
      "     Conv1dReluBn-29             [-1, 512, 751]               0\n",
      "           Linear-30                  [-1, 256]         131,328\n",
      "           Linear-31                  [-1, 512]         131,584\n",
      "       SE_Connect-32             [-1, 512, 751]               0\n",
      "           Conv1d-33             [-1, 512, 751]         262,144\n",
      "      BatchNorm1d-34             [-1, 512, 751]           1,024\n",
      "     Conv1dReluBn-35             [-1, 512, 751]               0\n",
      "           Conv1d-36              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-37              [-1, 64, 751]             128\n",
      "           Conv1d-38              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-39              [-1, 64, 751]             128\n",
      "           Conv1d-40              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-41              [-1, 64, 751]             128\n",
      "           Conv1d-42              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-43              [-1, 64, 751]             128\n",
      "           Conv1d-44              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-45              [-1, 64, 751]             128\n",
      "           Conv1d-46              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-47              [-1, 64, 751]             128\n",
      "           Conv1d-48              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-49              [-1, 64, 751]             128\n",
      " Res2Conv1dReluBn-50             [-1, 512, 751]               0\n",
      "           Conv1d-51             [-1, 512, 751]         262,144\n",
      "      BatchNorm1d-52             [-1, 512, 751]           1,024\n",
      "     Conv1dReluBn-53             [-1, 512, 751]               0\n",
      "           Linear-54                  [-1, 256]         131,328\n",
      "           Linear-55                  [-1, 512]         131,584\n",
      "       SE_Connect-56             [-1, 512, 751]               0\n",
      "           Conv1d-57             [-1, 512, 751]         262,144\n",
      "      BatchNorm1d-58             [-1, 512, 751]           1,024\n",
      "     Conv1dReluBn-59             [-1, 512, 751]               0\n",
      "           Conv1d-60              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-61              [-1, 64, 751]             128\n",
      "           Conv1d-62              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-63              [-1, 64, 751]             128\n",
      "           Conv1d-64              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-65              [-1, 64, 751]             128\n",
      "           Conv1d-66              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-67              [-1, 64, 751]             128\n",
      "           Conv1d-68              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-69              [-1, 64, 751]             128\n",
      "           Conv1d-70              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-71              [-1, 64, 751]             128\n",
      "           Conv1d-72              [-1, 64, 751]          12,288\n",
      "      BatchNorm1d-73              [-1, 64, 751]             128\n",
      " Res2Conv1dReluBn-74             [-1, 512, 751]               0\n",
      "           Conv1d-75             [-1, 512, 751]         262,144\n",
      "      BatchNorm1d-76             [-1, 512, 751]           1,024\n",
      "     Conv1dReluBn-77             [-1, 512, 751]               0\n",
      "           Linear-78                  [-1, 256]         131,328\n",
      "           Linear-79                  [-1, 512]         131,584\n",
      "       SE_Connect-80             [-1, 512, 751]               0\n",
      "           Conv1d-81            [-1, 1536, 751]       2,360,832\n",
      "           Conv1d-82             [-1, 128, 751]         196,736\n",
      "           Conv1d-83            [-1, 1536, 751]         198,144\n",
      "AttentiveStatsPool-84                 [-1, 3072]               0\n",
      "      BatchNorm1d-85                 [-1, 3072]           6,144\n",
      "           Linear-86                  [-1, 192]         590,016\n",
      "      BatchNorm1d-87                  [-1, 192]             384\n",
      "================================================================\n",
      "Total params: 6,084,160\n",
      "Trainable params: 6,084,160\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 116.09\n",
      "Params size (MB): 23.21\n",
      "Estimated Total Size (MB): 139.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(S, input_size=(120000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpeakerNetModel = importlib.import_module('models.'+'X_vector').__getattribute__('MainModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_vector.py, Embedding size is 192,  Spec_aug False.\n"
     ]
    }
   ],
   "source": [
    "# RESNET34SE\n",
    "# (self, block, layers, num_filters, nOut, spec_aug, encoder_type='SAP', n_mels=40, log_input=True, **kwargs)\n",
    "# model = ResNetSE(SEBasicBlock, [3, 4, 6, 3], num_filters, nOut, spec_aug, **kwargs)\n",
    "S = SpeakerNetModel(n_mels=40, nOut=192, spec_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/workspace/LOGS_OUTPUT/tmp_logs/train_logs_201120/Xvecor_alda_0.0/model/model000000123.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state = torch.load(model_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#__L__.W is not in the model.\n",
      "#DA_module.backbone.torchfb.0.flipped_filter is not in the model.\n",
      "#DA_module.backbone.torchfb.1.spectrogram.window is not in the model.\n",
      "#DA_module.backbone.torchfb.1.mel_scale.fb is not in the model.\n",
      "#DA_module.backbone.tdnn1.0.weight is not in the model.\n",
      "#DA_module.backbone.tdnn1.0.bias is not in the model.\n",
      "#DA_module.backbone.tdnn1.2.weight is not in the model.\n",
      "#DA_module.backbone.tdnn1.2.bias is not in the model.\n",
      "#DA_module.backbone.tdnn1.2.running_mean is not in the model.\n",
      "#DA_module.backbone.tdnn1.2.running_var is not in the model.\n",
      "#DA_module.backbone.tdnn1.2.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.tdnn2.0.weight is not in the model.\n",
      "#DA_module.backbone.tdnn2.0.bias is not in the model.\n",
      "#DA_module.backbone.tdnn2.2.weight is not in the model.\n",
      "#DA_module.backbone.tdnn2.2.bias is not in the model.\n",
      "#DA_module.backbone.tdnn2.2.running_mean is not in the model.\n",
      "#DA_module.backbone.tdnn2.2.running_var is not in the model.\n",
      "#DA_module.backbone.tdnn2.2.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.tdnn3.0.weight is not in the model.\n",
      "#DA_module.backbone.tdnn3.0.bias is not in the model.\n",
      "#DA_module.backbone.tdnn3.2.weight is not in the model.\n",
      "#DA_module.backbone.tdnn3.2.bias is not in the model.\n",
      "#DA_module.backbone.tdnn3.2.running_mean is not in the model.\n",
      "#DA_module.backbone.tdnn3.2.running_var is not in the model.\n",
      "#DA_module.backbone.tdnn3.2.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.tdnn4.0.weight is not in the model.\n",
      "#DA_module.backbone.tdnn4.0.bias is not in the model.\n",
      "#DA_module.backbone.tdnn4.2.weight is not in the model.\n",
      "#DA_module.backbone.tdnn4.2.bias is not in the model.\n",
      "#DA_module.backbone.tdnn4.2.running_mean is not in the model.\n",
      "#DA_module.backbone.tdnn4.2.running_var is not in the model.\n",
      "#DA_module.backbone.tdnn4.2.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.tdnn5.0.weight is not in the model.\n",
      "#DA_module.backbone.tdnn5.0.bias is not in the model.\n",
      "#DA_module.backbone.tdnn5.2.weight is not in the model.\n",
      "#DA_module.backbone.tdnn5.2.bias is not in the model.\n",
      "#DA_module.backbone.tdnn5.2.running_mean is not in the model.\n",
      "#DA_module.backbone.tdnn5.2.running_var is not in the model.\n",
      "#DA_module.backbone.tdnn5.2.num_batches_tracked is not in the model.\n",
      "#DA_module.backbone.pooling.linear1.weight is not in the model.\n",
      "#DA_module.backbone.pooling.linear1.bias is not in the model.\n",
      "#DA_module.backbone.pooling.linear2.weight is not in the model.\n",
      "#DA_module.backbone.pooling.linear2.bias is not in the model.\n",
      "#DA_module.backbone.embedding_layer1.linear.weight is not in the model.\n",
      "#DA_module.backbone.embedding_layer1.linear.bias is not in the model.\n",
      "#DA_module.backbone.embedding_layer1.batchnorm.weight is not in the model.\n",
      "#DA_module.backbone.embedding_layer1.batchnorm.bias is not in the model.\n",
      "#DA_module.backbone.embedding_layer1.batchnorm.running_mean is not in the model.\n",
      "#DA_module.backbone.embedding_layer1.batchnorm.running_var is not in the model.\n",
      "#DA_module.backbone.embedding_layer1.batchnorm.num_batches_tracked is not in the model.\n",
      "#DA_module.metrics.W is not in the model.\n",
      "#DA_module.layer_d1.linear.weight is not in the model.\n",
      "#DA_module.layer_d1.linear.bias is not in the model.\n",
      "#DA_module.layer_d1.batchnorm.weight is not in the model.\n",
      "#DA_module.layer_d1.batchnorm.bias is not in the model.\n",
      "#DA_module.layer_d1.batchnorm.running_mean is not in the model.\n",
      "#DA_module.layer_d1.batchnorm.running_var is not in the model.\n",
      "#DA_module.layer_d1.batchnorm.num_batches_tracked is not in the model.\n",
      "#DA_module.layer_d2.linear.weight is not in the model.\n",
      "#DA_module.layer_d2.linear.bias is not in the model.\n"
     ]
    }
   ],
   "source": [
    "self_state = S.state_dict()\n",
    "\n",
    "for name, param in loaded_state['model'].items():\n",
    "    origname = name\n",
    "    if name not in self_state:\n",
    "        name = name.replace(\"__S__.\", \"\")\n",
    "\n",
    "        if name not in self_state:\n",
    "            print(\"#%s is not in the model.\"%origname)\n",
    "            continue\n",
    "\n",
    "    if self_state[name].size() != loaded_state['model'][origname].size():\n",
    "        print(\"#Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state['model'][origname].size()))\n",
    "        continue\n",
    "\n",
    "    self_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xvector_1L(\n",
       "  (instancenorm): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (tdnn1): Sequential(\n",
       "    (0): Conv1d(40, 512, kernel_size=(5,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (tdnn2): Sequential(\n",
       "    (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(2,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (tdnn3): Sequential(\n",
       "    (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(3,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (tdnn4): Sequential(\n",
       "    (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (tdnn5): Sequential(\n",
       "    (0): Conv1d(512, 1500, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(1500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pooling): AttentiveStatsPool(\n",
       "    (linear1): Conv1d(1500, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 1500, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (embedding_layer1): Sequential(\n",
       "    (linear): Linear(in_features=3000, out_features=192, bias=True)\n",
       "    (batchnorm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWAV(filename):\n",
    "\n",
    "    # Maximum audio length\n",
    "    \n",
    "    max_audio = int(0*16000 + 240)\n",
    "\n",
    "    # Read wav file and convert to torch tensor\n",
    "    sample_rate, audio  = wavfile.read(filename)\n",
    "    \n",
    "    audiosize = audio.shape[0]\n",
    "\n",
    "    if audiosize <= max_audio:\n",
    "        shortage    = max_audio - audiosize + 1 \n",
    "        audio       = numpy.pad(audio, (0, shortage), 'wrap')\n",
    "        audiosize   = audio.shape[0]\n",
    "    \n",
    "    feats = []\n",
    "\n",
    "    feats.append(audio)\n",
    "\n",
    "    feat = numpy.stack(feats,axis=0).astype(numpy.float)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = '/workspace/DATASET/server9_ssd/voxceleb/vox_o_triallist.txt'\n",
    "test_path = '/workspace/DATASET/server9_ssd/voxceleb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "with open(test_list) as listfile:\n",
    "    while True:\n",
    "        line = listfile.readline()\n",
    "        if (not line):\n",
    "            break\n",
    "\n",
    "        data = line.split();\n",
    "\n",
    "        ## Append random label if missing\n",
    "        if len(data) == 2: data = [random.randint(0,1)] + data\n",
    "\n",
    "        files.append(data[1])\n",
    "        files.append(data[2])\n",
    "\n",
    "setfiles = list(set(files))\n",
    "setfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4708"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(setfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2526428437232971\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "for count, wavline in enumerate(setfiles[:200]):\n",
    "    wavline = os.path.join(test_path, wavline)\n",
    "    raw_inp = loadWAV(wavline)\n",
    "    raw_inp = torch.FloatTensor(raw_inp)\n",
    "    \n",
    "    ref_feat = S.forward(raw_inp).detach().cpu().numpy()\n",
    "    \n",
    "    print((count+1), end='\\r')\n",
    "endtime =time.time()\n",
    "print((endtime-starttime)/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xvector_1L(\n",
       "  (instancenorm): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (tdnn1): Sequential(\n",
       "    (0): Conv1d(40, 512, kernel_size=(5,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (tdnn2): Sequential(\n",
       "    (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(2,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (tdnn3): Sequential(\n",
       "    (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(3,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (tdnn4): Sequential(\n",
       "    (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (tdnn5): Sequential(\n",
       "    (0): Conv1d(512, 1500, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(1500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pooling): AttentiveStatsPool(\n",
       "    (linear1): Conv1d(1500, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 1500, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (embedding_layer1): Sequential(\n",
       "    (linear): Linear(in_features=3000, out_features=192, bias=True)\n",
       "    (batchnorm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       PreEmphasis-1               [-1, 120000]               0\n",
      "       Spectrogram-2             [-1, 257, 751]               0\n",
      "          MelScale-3              [-1, 40, 751]               0\n",
      "    MelSpectrogram-4              [-1, 40, 751]               0\n",
      "    InstanceNorm1d-5              [-1, 40, 751]               0\n",
      "            Conv1d-6             [-1, 512, 747]         102,912\n",
      "              ReLU-7             [-1, 512, 747]               0\n",
      "       BatchNorm1d-8             [-1, 512, 747]           1,024\n",
      "            Conv1d-9             [-1, 512, 743]         786,944\n",
      "             ReLU-10             [-1, 512, 743]               0\n",
      "      BatchNorm1d-11             [-1, 512, 743]           1,024\n",
      "           Conv1d-12             [-1, 512, 737]         786,944\n",
      "             ReLU-13             [-1, 512, 737]               0\n",
      "      BatchNorm1d-14             [-1, 512, 737]           1,024\n",
      "           Conv1d-15             [-1, 512, 737]         262,656\n",
      "             ReLU-16             [-1, 512, 737]               0\n",
      "      BatchNorm1d-17             [-1, 512, 737]           1,024\n",
      "           Conv1d-18            [-1, 1500, 737]         769,500\n",
      "             ReLU-19            [-1, 1500, 737]               0\n",
      "      BatchNorm1d-20            [-1, 1500, 737]           3,000\n",
      "           Conv1d-21             [-1, 128, 737]         192,128\n",
      "           Conv1d-22            [-1, 1500, 737]         193,500\n",
      "AttentiveStatsPool-23                 [-1, 3000]               0\n",
      "           Linear-24                  [-1, 192]         576,192\n",
      "      BatchNorm1d-25                  [-1, 192]             384\n",
      "================================================================\n",
      "Total params: 3,678,256\n",
      "Trainable params: 3,678,256\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 72.29\n",
      "Params size (MB): 14.03\n",
      "Estimated Total Size (MB): 86.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(S, input_size=(120000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResnetSEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpeakerNetModel = importlib.import_module('models.'+'ResNetSE34L').__getattribute__('MainModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size is 192, encoder ASP.\n"
     ]
    }
   ],
   "source": [
    "# RESNET34SE\n",
    "# (self, block, layers, num_filters, nOut, spec_aug, encoder_type='SAP', n_mels=40, log_input=True, **kwargs)\n",
    "# (self, block, layers, num_filters, nOut, encoder_type='SAP', n_mels=40, log_input=True, **kwargs)\n",
    "# model = ResNetSE(SEBasicBlock, [3, 4, 6, 3], num_filters, nOut, spec_aug, **kwargs)\n",
    "S = SpeakerNetModel(n_mels=64, nOut=192, encoder_type='ASP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = '/workspace/LOGS_OUTPUT/tmp_logs/train_logs_201120/single_gpu_resnetsev2/model/model000000120.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_state = torch.load(model_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#__L__.W is not in the model.\n"
     ]
    }
   ],
   "source": [
    "# self_state = S.state_dict()\n",
    "\n",
    "# for name, param in loaded_state['model'].items():\n",
    "#     origname = name\n",
    "#     if name not in self_state:\n",
    "#         name = name.replace(\"__S__.\", \"\")\n",
    "\n",
    "#         if name not in self_state:\n",
    "#             print(\"#%s is not in the model.\"%origname)\n",
    "#             continue\n",
    "\n",
    "#     if self_state[name].size() != loaded_state['model'][origname].size():\n",
    "#         print(\"#Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state['model'][origname].size()))\n",
    "#         continue\n",
    "\n",
    "#     self_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetSE(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(7, 7), stride=(2, 1), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=2, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=2, out_features=16, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=2, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=2, out_features=16, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=2, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=2, out_features=16, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): MelSpectrogram(\n",
       "    (spectrogram): Spectrogram()\n",
       "    (mel_scale): MelScale()\n",
       "  )\n",
       "  (sap_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc): Linear(in_features=256, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWAV(filename):\n",
    "\n",
    "    # Maximum audio length\n",
    "    \n",
    "    max_audio = int(0*16000 + 240)\n",
    "\n",
    "    # Read wav file and convert to torch tensor\n",
    "    sample_rate, audio  = wavfile.read(filename)\n",
    "    \n",
    "    audiosize = audio.shape[0]\n",
    "\n",
    "    if audiosize <= max_audio:\n",
    "        shortage    = max_audio - audiosize + 1 \n",
    "        audio       = numpy.pad(audio, (0, shortage), 'wrap')\n",
    "        audiosize   = audio.shape[0]\n",
    "    \n",
    "    feats = []\n",
    "\n",
    "    feats.append(audio)\n",
    "\n",
    "    feat = numpy.stack(feats,axis=0).astype(numpy.float)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = '/workspace/DATASET/server9_ssd/voxceleb/vox_o_triallist.txt'\n",
    "test_path = '/workspace/DATASET/server9_ssd/voxceleb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "with open(test_list) as listfile:\n",
    "    while True:\n",
    "        line = listfile.readline()\n",
    "        if (not line):\n",
    "            break\n",
    "\n",
    "        data = line.split();\n",
    "\n",
    "        ## Append random label if missing\n",
    "        if len(data) == 2: data = [random.randint(0,1)] + data\n",
    "\n",
    "        files.append(data[1])\n",
    "        files.append(data[2])\n",
    "\n",
    "setfiles = list(set(files))\n",
    "setfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4708"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(setfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0989412236213685\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "for count, wavline in enumerate(setfiles[:200]):\n",
    "    wavline = os.path.join(test_path, wavline)\n",
    "    raw_inp = loadWAV(wavline)\n",
    "    raw_inp = torch.FloatTensor(raw_inp)\n",
    "    \n",
    "    ref_feat = S.forward(raw_inp).detach().cpu().numpy()\n",
    "    \n",
    "    print((count+1), end='\\r')\n",
    "endtime =time.time()\n",
    "print((endtime-starttime)/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetSE(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(7, 7), stride=(2, 1), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=2, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=2, out_features=16, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=2, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=2, out_features=16, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=2, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=2, out_features=16, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): MelSpectrogram(\n",
       "    (spectrogram): Spectrogram()\n",
       "    (mel_scale): MelScale()\n",
       "  )\n",
       "  (sap_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc): Linear(in_features=256, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       Spectrogram-1             [-1, 257, 751]               0\n",
      "          MelScale-2              [-1, 64, 751]               0\n",
      "    MelSpectrogram-3              [-1, 64, 751]               0\n",
      "    InstanceNorm1d-4              [-1, 64, 751]               0\n",
      "            Conv2d-5          [-1, 16, 32, 751]             784\n",
      "       BatchNorm2d-6          [-1, 16, 32, 751]              32\n",
      "              ReLU-7          [-1, 16, 32, 751]               0\n",
      "            Conv2d-8          [-1, 16, 32, 751]           2,304\n",
      "              ReLU-9          [-1, 16, 32, 751]               0\n",
      "      BatchNorm2d-10          [-1, 16, 32, 751]              32\n",
      "           Conv2d-11          [-1, 16, 32, 751]           2,304\n",
      "      BatchNorm2d-12          [-1, 16, 32, 751]              32\n",
      "AdaptiveAvgPool2d-13             [-1, 16, 1, 1]               0\n",
      "           Linear-14                    [-1, 2]              34\n",
      "             ReLU-15                    [-1, 2]               0\n",
      "           Linear-16                   [-1, 16]              48\n",
      "          Sigmoid-17                   [-1, 16]               0\n",
      "          SELayer-18          [-1, 16, 32, 751]               0\n",
      "             ReLU-19          [-1, 16, 32, 751]               0\n",
      "     SEBasicBlock-20          [-1, 16, 32, 751]               0\n",
      "           Conv2d-21          [-1, 16, 32, 751]           2,304\n",
      "             ReLU-22          [-1, 16, 32, 751]               0\n",
      "      BatchNorm2d-23          [-1, 16, 32, 751]              32\n",
      "           Conv2d-24          [-1, 16, 32, 751]           2,304\n",
      "      BatchNorm2d-25          [-1, 16, 32, 751]              32\n",
      "AdaptiveAvgPool2d-26             [-1, 16, 1, 1]               0\n",
      "           Linear-27                    [-1, 2]              34\n",
      "             ReLU-28                    [-1, 2]               0\n",
      "           Linear-29                   [-1, 16]              48\n",
      "          Sigmoid-30                   [-1, 16]               0\n",
      "          SELayer-31          [-1, 16, 32, 751]               0\n",
      "             ReLU-32          [-1, 16, 32, 751]               0\n",
      "     SEBasicBlock-33          [-1, 16, 32, 751]               0\n",
      "           Conv2d-34          [-1, 16, 32, 751]           2,304\n",
      "             ReLU-35          [-1, 16, 32, 751]               0\n",
      "      BatchNorm2d-36          [-1, 16, 32, 751]              32\n",
      "           Conv2d-37          [-1, 16, 32, 751]           2,304\n",
      "      BatchNorm2d-38          [-1, 16, 32, 751]              32\n",
      "AdaptiveAvgPool2d-39             [-1, 16, 1, 1]               0\n",
      "           Linear-40                    [-1, 2]              34\n",
      "             ReLU-41                    [-1, 2]               0\n",
      "           Linear-42                   [-1, 16]              48\n",
      "          Sigmoid-43                   [-1, 16]               0\n",
      "          SELayer-44          [-1, 16, 32, 751]               0\n",
      "             ReLU-45          [-1, 16, 32, 751]               0\n",
      "     SEBasicBlock-46          [-1, 16, 32, 751]               0\n",
      "           Conv2d-47          [-1, 32, 16, 376]           4,608\n",
      "             ReLU-48          [-1, 32, 16, 376]               0\n",
      "      BatchNorm2d-49          [-1, 32, 16, 376]              64\n",
      "           Conv2d-50          [-1, 32, 16, 376]           9,216\n",
      "      BatchNorm2d-51          [-1, 32, 16, 376]              64\n",
      "AdaptiveAvgPool2d-52             [-1, 32, 1, 1]               0\n",
      "           Linear-53                    [-1, 4]             132\n",
      "             ReLU-54                    [-1, 4]               0\n",
      "           Linear-55                   [-1, 32]             160\n",
      "          Sigmoid-56                   [-1, 32]               0\n",
      "          SELayer-57          [-1, 32, 16, 376]               0\n",
      "           Conv2d-58          [-1, 32, 16, 376]             512\n",
      "      BatchNorm2d-59          [-1, 32, 16, 376]              64\n",
      "             ReLU-60          [-1, 32, 16, 376]               0\n",
      "     SEBasicBlock-61          [-1, 32, 16, 376]               0\n",
      "           Conv2d-62          [-1, 32, 16, 376]           9,216\n",
      "             ReLU-63          [-1, 32, 16, 376]               0\n",
      "      BatchNorm2d-64          [-1, 32, 16, 376]              64\n",
      "           Conv2d-65          [-1, 32, 16, 376]           9,216\n",
      "      BatchNorm2d-66          [-1, 32, 16, 376]              64\n",
      "AdaptiveAvgPool2d-67             [-1, 32, 1, 1]               0\n",
      "           Linear-68                    [-1, 4]             132\n",
      "             ReLU-69                    [-1, 4]               0\n",
      "           Linear-70                   [-1, 32]             160\n",
      "          Sigmoid-71                   [-1, 32]               0\n",
      "          SELayer-72          [-1, 32, 16, 376]               0\n",
      "             ReLU-73          [-1, 32, 16, 376]               0\n",
      "     SEBasicBlock-74          [-1, 32, 16, 376]               0\n",
      "           Conv2d-75          [-1, 32, 16, 376]           9,216\n",
      "             ReLU-76          [-1, 32, 16, 376]               0\n",
      "      BatchNorm2d-77          [-1, 32, 16, 376]              64\n",
      "           Conv2d-78          [-1, 32, 16, 376]           9,216\n",
      "      BatchNorm2d-79          [-1, 32, 16, 376]              64\n",
      "AdaptiveAvgPool2d-80             [-1, 32, 1, 1]               0\n",
      "           Linear-81                    [-1, 4]             132\n",
      "             ReLU-82                    [-1, 4]               0\n",
      "           Linear-83                   [-1, 32]             160\n",
      "          Sigmoid-84                   [-1, 32]               0\n",
      "          SELayer-85          [-1, 32, 16, 376]               0\n",
      "             ReLU-86          [-1, 32, 16, 376]               0\n",
      "     SEBasicBlock-87          [-1, 32, 16, 376]               0\n",
      "           Conv2d-88          [-1, 32, 16, 376]           9,216\n",
      "             ReLU-89          [-1, 32, 16, 376]               0\n",
      "      BatchNorm2d-90          [-1, 32, 16, 376]              64\n",
      "           Conv2d-91          [-1, 32, 16, 376]           9,216\n",
      "      BatchNorm2d-92          [-1, 32, 16, 376]              64\n",
      "AdaptiveAvgPool2d-93             [-1, 32, 1, 1]               0\n",
      "           Linear-94                    [-1, 4]             132\n",
      "             ReLU-95                    [-1, 4]               0\n",
      "           Linear-96                   [-1, 32]             160\n",
      "          Sigmoid-97                   [-1, 32]               0\n",
      "          SELayer-98          [-1, 32, 16, 376]               0\n",
      "             ReLU-99          [-1, 32, 16, 376]               0\n",
      "    SEBasicBlock-100          [-1, 32, 16, 376]               0\n",
      "          Conv2d-101           [-1, 64, 8, 188]          18,432\n",
      "            ReLU-102           [-1, 64, 8, 188]               0\n",
      "     BatchNorm2d-103           [-1, 64, 8, 188]             128\n",
      "          Conv2d-104           [-1, 64, 8, 188]          36,864\n",
      "     BatchNorm2d-105           [-1, 64, 8, 188]             128\n",
      "AdaptiveAvgPool2d-106             [-1, 64, 1, 1]               0\n",
      "          Linear-107                    [-1, 8]             520\n",
      "            ReLU-108                    [-1, 8]               0\n",
      "          Linear-109                   [-1, 64]             576\n",
      "         Sigmoid-110                   [-1, 64]               0\n",
      "         SELayer-111           [-1, 64, 8, 188]               0\n",
      "          Conv2d-112           [-1, 64, 8, 188]           2,048\n",
      "     BatchNorm2d-113           [-1, 64, 8, 188]             128\n",
      "            ReLU-114           [-1, 64, 8, 188]               0\n",
      "    SEBasicBlock-115           [-1, 64, 8, 188]               0\n",
      "          Conv2d-116           [-1, 64, 8, 188]          36,864\n",
      "            ReLU-117           [-1, 64, 8, 188]               0\n",
      "     BatchNorm2d-118           [-1, 64, 8, 188]             128\n",
      "          Conv2d-119           [-1, 64, 8, 188]          36,864\n",
      "     BatchNorm2d-120           [-1, 64, 8, 188]             128\n",
      "AdaptiveAvgPool2d-121             [-1, 64, 1, 1]               0\n",
      "          Linear-122                    [-1, 8]             520\n",
      "            ReLU-123                    [-1, 8]               0\n",
      "          Linear-124                   [-1, 64]             576\n",
      "         Sigmoid-125                   [-1, 64]               0\n",
      "         SELayer-126           [-1, 64, 8, 188]               0\n",
      "            ReLU-127           [-1, 64, 8, 188]               0\n",
      "    SEBasicBlock-128           [-1, 64, 8, 188]               0\n",
      "          Conv2d-129           [-1, 64, 8, 188]          36,864\n",
      "            ReLU-130           [-1, 64, 8, 188]               0\n",
      "     BatchNorm2d-131           [-1, 64, 8, 188]             128\n",
      "          Conv2d-132           [-1, 64, 8, 188]          36,864\n",
      "     BatchNorm2d-133           [-1, 64, 8, 188]             128\n",
      "AdaptiveAvgPool2d-134             [-1, 64, 1, 1]               0\n",
      "          Linear-135                    [-1, 8]             520\n",
      "            ReLU-136                    [-1, 8]               0\n",
      "          Linear-137                   [-1, 64]             576\n",
      "         Sigmoid-138                   [-1, 64]               0\n",
      "         SELayer-139           [-1, 64, 8, 188]               0\n",
      "            ReLU-140           [-1, 64, 8, 188]               0\n",
      "    SEBasicBlock-141           [-1, 64, 8, 188]               0\n",
      "          Conv2d-142           [-1, 64, 8, 188]          36,864\n",
      "            ReLU-143           [-1, 64, 8, 188]               0\n",
      "     BatchNorm2d-144           [-1, 64, 8, 188]             128\n",
      "          Conv2d-145           [-1, 64, 8, 188]          36,864\n",
      "     BatchNorm2d-146           [-1, 64, 8, 188]             128\n",
      "AdaptiveAvgPool2d-147             [-1, 64, 1, 1]               0\n",
      "          Linear-148                    [-1, 8]             520\n",
      "            ReLU-149                    [-1, 8]               0\n",
      "          Linear-150                   [-1, 64]             576\n",
      "         Sigmoid-151                   [-1, 64]               0\n",
      "         SELayer-152           [-1, 64, 8, 188]               0\n",
      "            ReLU-153           [-1, 64, 8, 188]               0\n",
      "    SEBasicBlock-154           [-1, 64, 8, 188]               0\n",
      "          Conv2d-155           [-1, 64, 8, 188]          36,864\n",
      "            ReLU-156           [-1, 64, 8, 188]               0\n",
      "     BatchNorm2d-157           [-1, 64, 8, 188]             128\n",
      "          Conv2d-158           [-1, 64, 8, 188]          36,864\n",
      "     BatchNorm2d-159           [-1, 64, 8, 188]             128\n",
      "AdaptiveAvgPool2d-160             [-1, 64, 1, 1]               0\n",
      "          Linear-161                    [-1, 8]             520\n",
      "            ReLU-162                    [-1, 8]               0\n",
      "          Linear-163                   [-1, 64]             576\n",
      "         Sigmoid-164                   [-1, 64]               0\n",
      "         SELayer-165           [-1, 64, 8, 188]               0\n",
      "            ReLU-166           [-1, 64, 8, 188]               0\n",
      "    SEBasicBlock-167           [-1, 64, 8, 188]               0\n",
      "          Conv2d-168           [-1, 64, 8, 188]          36,864\n",
      "            ReLU-169           [-1, 64, 8, 188]               0\n",
      "     BatchNorm2d-170           [-1, 64, 8, 188]             128\n",
      "          Conv2d-171           [-1, 64, 8, 188]          36,864\n",
      "     BatchNorm2d-172           [-1, 64, 8, 188]             128\n",
      "AdaptiveAvgPool2d-173             [-1, 64, 1, 1]               0\n",
      "          Linear-174                    [-1, 8]             520\n",
      "            ReLU-175                    [-1, 8]               0\n",
      "          Linear-176                   [-1, 64]             576\n",
      "         Sigmoid-177                   [-1, 64]               0\n",
      "         SELayer-178           [-1, 64, 8, 188]               0\n",
      "            ReLU-179           [-1, 64, 8, 188]               0\n",
      "    SEBasicBlock-180           [-1, 64, 8, 188]               0\n",
      "          Conv2d-181          [-1, 128, 8, 188]          73,728\n",
      "            ReLU-182          [-1, 128, 8, 188]               0\n",
      "     BatchNorm2d-183          [-1, 128, 8, 188]             256\n",
      "          Conv2d-184          [-1, 128, 8, 188]         147,456\n",
      "     BatchNorm2d-185          [-1, 128, 8, 188]             256\n",
      "AdaptiveAvgPool2d-186            [-1, 128, 1, 1]               0\n",
      "          Linear-187                   [-1, 16]           2,064\n",
      "            ReLU-188                   [-1, 16]               0\n",
      "          Linear-189                  [-1, 128]           2,176\n",
      "         Sigmoid-190                  [-1, 128]               0\n",
      "         SELayer-191          [-1, 128, 8, 188]               0\n",
      "          Conv2d-192          [-1, 128, 8, 188]           8,192\n",
      "     BatchNorm2d-193          [-1, 128, 8, 188]             256\n",
      "            ReLU-194          [-1, 128, 8, 188]               0\n",
      "    SEBasicBlock-195          [-1, 128, 8, 188]               0\n",
      "          Conv2d-196          [-1, 128, 8, 188]         147,456\n",
      "            ReLU-197          [-1, 128, 8, 188]               0\n",
      "     BatchNorm2d-198          [-1, 128, 8, 188]             256\n",
      "          Conv2d-199          [-1, 128, 8, 188]         147,456\n",
      "     BatchNorm2d-200          [-1, 128, 8, 188]             256\n",
      "AdaptiveAvgPool2d-201            [-1, 128, 1, 1]               0\n",
      "          Linear-202                   [-1, 16]           2,064\n",
      "            ReLU-203                   [-1, 16]               0\n",
      "          Linear-204                  [-1, 128]           2,176\n",
      "         Sigmoid-205                  [-1, 128]               0\n",
      "         SELayer-206          [-1, 128, 8, 188]               0\n",
      "            ReLU-207          [-1, 128, 8, 188]               0\n",
      "    SEBasicBlock-208          [-1, 128, 8, 188]               0\n",
      "          Conv2d-209          [-1, 128, 8, 188]         147,456\n",
      "            ReLU-210          [-1, 128, 8, 188]               0\n",
      "     BatchNorm2d-211          [-1, 128, 8, 188]             256\n",
      "          Conv2d-212          [-1, 128, 8, 188]         147,456\n",
      "     BatchNorm2d-213          [-1, 128, 8, 188]             256\n",
      "AdaptiveAvgPool2d-214            [-1, 128, 1, 1]               0\n",
      "          Linear-215                   [-1, 16]           2,064\n",
      "            ReLU-216                   [-1, 16]               0\n",
      "          Linear-217                  [-1, 128]           2,176\n",
      "         Sigmoid-218                  [-1, 128]               0\n",
      "         SELayer-219          [-1, 128, 8, 188]               0\n",
      "            ReLU-220          [-1, 128, 8, 188]               0\n",
      "    SEBasicBlock-221          [-1, 128, 8, 188]               0\n",
      "          Linear-222             [-1, 188, 128]          16,512\n",
      "          Linear-223                  [-1, 192]          49,344\n",
      "================================================================\n",
      "Total params: 1,420,246\n",
      "Trainable params: 1,420,246\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 206.83\n",
      "Params size (MB): 5.42\n",
      "Estimated Total Size (MB): 212.71\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(S, input_size=(120000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
