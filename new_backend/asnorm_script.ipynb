{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import torch\n",
    "import numpy\n",
    "import torch.nn.functional as F\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from asnorm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make cohort set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/train_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from DatasetLoader import loadWAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpeakerNetModel = importlib.import_module('models.'+'EPACA-TDNN').__getattribute__('MainModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPACA-TDNN.py, Embedding size is 192, Channels 1024, Spec_aug False.\n"
     ]
    }
   ],
   "source": [
    "# EPACA-TDNN\n",
    "S = SpeakerNetModel(n_mels=40, nOut=192, spec_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/workspace/LOGS_OUTPUT/tmp_logs/train_logs_201120/multi_gpu_epaca_tdnn_soxaug/model/model000000034.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = '/workspace/DATASET/server9_ssd/voxceleb/vox2_trainlist.txt'\n",
    "train_path = '/workspace/DATASET/server9_ssd/voxceleb'\n",
    "test_list = '/workspace/DATASET/server9_ssd/voxceleb/vox_o_triallist.txt'\n",
    "test_path = '/workspace/DATASET/server9_ssd/voxceleb'\n",
    "score_file = '/workspace/LOGS_OUTPUT/tmp_logs/train_logs_201120/multi_gpu_epaca_tdnn_soxaug/result/model000000034.vox1osc'\n",
    "out_path_1 = 'as1.txt'\n",
    "out_path_2 = 'as2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECAPA_TDNN(\n",
       "  (instancenorm): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Conv1dReluBn(\n",
       "    (conv): Conv1d(40, 1024, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "    (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "  (pooling): AttentiveStatsPool(\n",
       "    (linear1): Conv1d(3072, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 3072, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=6144, out_features=192, bias=True)\n",
       "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state = torch.load(model_path, map_location=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#__L__.W is not in the model.\n"
     ]
    }
   ],
   "source": [
    "self_state = S.state_dict()\n",
    "\n",
    "for name, param in loaded_state['model'].items():\n",
    "    origname = name\n",
    "    if name not in self_state:\n",
    "        name = name.replace(\"__S__.\", \"\")\n",
    "\n",
    "        if name not in self_state:\n",
    "            print(\"#%s is not in the model.\"%origname)\n",
    "            continue\n",
    "\n",
    "    if self_state[name].size() != loaded_state['model'][origname].size():\n",
    "        print(\"#Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state[origname].size()))\n",
    "        continue\n",
    "\n",
    "    self_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECAPA_TDNN(\n",
       "  (instancenorm): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Conv1dReluBn(\n",
       "    (conv): Conv1d(40, 1024, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "    (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "  (pooling): AttentiveStatsPool(\n",
       "    (linear1): Conv1d(3072, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 3072, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=6144, out_features=192, bias=True)\n",
       "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWAV(filename, max_frames):\n",
    "\n",
    "    # Maximum audio length\n",
    "    max_audio = max_frames * 160 + 240\n",
    "\n",
    "    # Read wav file and convert to torch tensor\n",
    "    sample_rate, audio  = wavfile.read(filename)\n",
    "\n",
    "    audiosize = audio.shape[0]\n",
    "\n",
    "    if audiosize <= max_audio:\n",
    "        shortage    = max_audio - audiosize + 1 \n",
    "        audio       = numpy.pad(audio, (0, shortage), 'wrap')\n",
    "        audiosize   = audio.shape[0]\n",
    "\n",
    "    \n",
    "    feats = []\n",
    "\n",
    "    feats.append(audio)\n",
    "\n",
    "    feat = numpy.stack(feats,axis=0).astype(numpy.float)\n",
    "\n",
    "    return feat;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_list, 'r') as f:\n",
    "    train_list_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1092009"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092\r"
     ]
    }
   ],
   "source": [
    "cohort_spk_dict = {}\n",
    "for count, line in enumerate(train_list_list):\n",
    "    label, wavline = line[:-1].split(' ')\n",
    "    wavline = os.path.join(train_path, wavline)\n",
    "    raw_inp = loadWAV(wavline, max_frames=0)\n",
    "    raw_inp = torch.FloatTensor(raw_inp).cuda()\n",
    "    \n",
    "    ref_feat = S.forward(raw_inp).detach().cpu()\n",
    "    if label not in cohort_spk_dict.keys():\n",
    "        cohort_spk_dict[label] = ref_feat\n",
    "    else:\n",
    "        cohort_spk_dict[label] = torch.cat([cohort_spk_dict[label], ref_feat], dim=0)\n",
    "    if ((count+1) % 1000) == 0:\n",
    "        print((count+1)//1000, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_spk_dict_mean = {}\n",
    "for i in cohort_spk_dict:\n",
    "    cohort_spk_dict_mean[i] = torch.mean(cohort_spk_dict[i], dim=0, keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_spk_dict_mean_nm = {}\n",
    "for i in cohort_spk_dict_mean:\n",
    "    cohort_spk_dict_mean_nm[i] = F.normalize(cohort_spk_dict_mean[i], p=2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract vox-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "listfilename = test_list\n",
    "files = []\n",
    "with open(listfilename) as listfile:\n",
    "    while True:\n",
    "        line = listfile.readline()\n",
    "        if (not line):\n",
    "            break\n",
    "\n",
    "        data = line.split()\n",
    "\n",
    "        files.append(data[1])\n",
    "        files.append(data[2])\n",
    "\n",
    "setfiles = list(set(files))\n",
    "setfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4708"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(setfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\r"
     ]
    }
   ],
   "source": [
    "for count, line in enumerate(setfiles):\n",
    "    wavline = line\n",
    "    wavline = os.path.join(train_path, wavline)\n",
    "    raw_inp = loadWAV(wavline, max_frames=0)\n",
    "    raw_inp = torch.FloatTensor(raw_inp).cuda()\n",
    "    \n",
    "    ref_feat = S.forward(raw_inp).detach().cpu()\n",
    "\n",
    "    test_dict[line] = ref_feat\n",
    "    \n",
    "    if ((count+1) % 1000) == 0:\n",
    "        print((count+1)//1000, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4708"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict_nm = {}\n",
    "for i in test_dict:\n",
    "    test_dict_nm[i] = F.normalize(test_dict[i].squeeze(0), p=2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### optional\n",
    "# import pickle\n",
    "# with open('tmp_chort_dict', 'wb') as f:\n",
    "#     pickle.dump(cohort_spk_dict, f)\n",
    "# import pickle\n",
    "# with open('tmp_test_dict', 'wb') as f:\n",
    "#     pickle.dump(test_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28219752\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "cohort2test = {}\n",
    "for i in cohort_spk_dict_mean_nm:\n",
    "    cohort_emb = cohort_spk_dict_mean_nm[i]\n",
    "    for j in test_dict_nm:\n",
    "        test_emb = test_dict_nm[j]\n",
    "        score = F.cosine_similarity(cohort_emb, test_emb, dim=0).cpu().numpy()\n",
    "        cohort2test[i+\" \"+j] = score\n",
    "\n",
    "        count += 1\n",
    "        if (count % 100000) == 0:\n",
    "            print(count // 100000, end='\\r')\n",
    "                \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input score_file; enroll_audio; test_audio; cohort_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score norm operation start, method: Adaptive_score_norm_type_1\n",
      "calculate all statistics\n",
      "Scoring...\n",
      "Adaptive_score_norm_type_1 is finished\n"
     ]
    }
   ],
   "source": [
    "as_norm_1(score_file, out_path_1, cohort2test, cohort2test, top_num=2000, hold_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score norm operation start, method: Adaptive_score_norm_type_2\n",
      "Scoring...\n",
      "Adaptive_score_norm_type_2 is finished\n"
     ]
    }
   ],
   "source": [
    "as_norm_2(score_file, out_path_2, cohort2test, cohort2test, top_num=2000, hold_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get asnormed score_file & scoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
