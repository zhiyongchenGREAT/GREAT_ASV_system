{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import torch\n",
    "import numpy\n",
    "import torch.nn.functional as F\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '/workspace/DATASET/server9_ssd/PVTC20/task1/spk_scores.txt'\n",
    "trials = '/workspace/DATASET/server9_ssd/PVTC20/task1/trials_competitor'\n",
    "test_path = '/workspace/DATASET/server9_ssd/PVTC20/task1/wav_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/train_dist')\n",
    "sys.path.append('/workspace/GREAT_ASV_system/PVTC20')\n",
    "sys.path.append('/workspace/GREAT_ASV_system/new_backend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tuneThreshold_pvtc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from DatasetLoader import loadWAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpeakerNetModel = importlib.import_module('models.'+'EPACA-TDNN').__getattribute__('MainModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPACA-TDNN.py, Embedding size is 192, Channels 1024, Spec_aug False.\n"
     ]
    }
   ],
   "source": [
    "# EPACA-TDNN\n",
    "S = SpeakerNetModel(n_mels=40, nOut=192, spec_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/workspace/LOGS_OUTPUT/tmp_logs/train_logs_201120/multi_gpu_epaca_tdnn_soxaug/model/model000000034.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECAPA_TDNN(\n",
       "  (instancenorm): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Conv1dReluBn(\n",
       "    (conv): Conv1d(40, 1024, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "    (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "  (pooling): AttentiveStatsPool(\n",
       "    (linear1): Conv1d(3072, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 3072, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=6144, out_features=192, bias=True)\n",
       "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state = torch.load(model_path, map_location=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#__L__.W is not in the model.\n"
     ]
    }
   ],
   "source": [
    "self_state = S.state_dict()\n",
    "\n",
    "for name, param in loaded_state['model'].items():\n",
    "    origname = name\n",
    "    if name not in self_state:\n",
    "        name = name.replace(\"__S__.\", \"\")\n",
    "\n",
    "        if name not in self_state:\n",
    "            print(\"#%s is not in the model.\"%origname)\n",
    "            continue\n",
    "\n",
    "    if self_state[name].size() != loaded_state['model'][origname].size():\n",
    "        print(\"#Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state[origname].size()))\n",
    "        continue\n",
    "\n",
    "    self_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECAPA_TDNN(\n",
       "  (instancenorm): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Conv1dReluBn(\n",
       "    (conv): Conv1d(40, 1024, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "    (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Res2Conv1dReluBn(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "        (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "      )\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Conv1dReluBn(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): SE_Connect(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv): Conv1d(3072, 3072, kernel_size=(1,), stride=(1,))\n",
       "  (pooling): AttentiveStatsPool(\n",
       "    (linear1): Conv1d(3072, 128, kernel_size=(1,), stride=(1,))\n",
       "    (linear2): Conv1d(128, 3072, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=6144, out_features=192, bias=True)\n",
       "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWAV(filename, last_seconds):\n",
    "\n",
    "    # Maximum audio length\n",
    "    \n",
    "    max_audio = int(last_seconds*16000 + 240)\n",
    "\n",
    "    # Read wav file and convert to torch tensor\n",
    "    sample_rate, audio  = wavfile.read(filename)\n",
    "    \n",
    "    audio = audio[-max_audio:]\n",
    "\n",
    "    audiosize = audio.shape[0]\n",
    "\n",
    "    if audiosize <= max_audio:\n",
    "        shortage    = max_audio - audiosize + 1 \n",
    "        audio       = numpy.pad(audio, (0, shortage), 'wrap')\n",
    "        audiosize   = audio.shape[0]\n",
    "    \n",
    "    feats = []\n",
    "\n",
    "    feats.append(audio)\n",
    "\n",
    "    feat = numpy.stack(feats,axis=0).astype(numpy.float)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "listfilename = trials\n",
    "files = []\n",
    "with open(listfilename, 'r') as listfile:\n",
    "    while True:\n",
    "        line = listfile.readline()\n",
    "        if (not line):\n",
    "            break\n",
    "\n",
    "        data = line.split()\n",
    "\n",
    "        files.append(data[0])\n",
    "        files.append(data[1])\n",
    "        files.append(data[2])\n",
    "        files.append(data[3])\n",
    "\n",
    "setfiles = list(set(files))\n",
    "setfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162413"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(setfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\r"
     ]
    }
   ],
   "source": [
    "test_dict = {}\n",
    "for count, line in enumerate(setfiles):\n",
    "    wavline = line\n",
    "    wavline = os.path.join(test_path, wavline)\n",
    "    raw_inp = loadWAV(wavline, last_seconds=1.0)\n",
    "    raw_inp = torch.FloatTensor(raw_inp).cuda()\n",
    "    \n",
    "    ref_feat = S.forward(raw_inp).detach().cpu()\n",
    "\n",
    "    test_dict[line] = ref_feat\n",
    "    \n",
    "    if ((count+1) % 1000) == 0:\n",
    "        print((count+1)//1000, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162413"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "listfilename = trials\n",
    "enroll_files = []\n",
    "with open(listfilename, 'r') as listfile:\n",
    "    while True:\n",
    "        line = listfile.readline()\n",
    "        if (not line):\n",
    "            break\n",
    "\n",
    "        data = line.split()\n",
    "\n",
    "        enroll_files.append(data[0]+' '+data[1]+' '+data[2])\n",
    "\n",
    "enroll_files = list(set(enroll_files))\n",
    "enroll_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1070"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enroll_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_dict_mean_nm = {}\n",
    "for i in enroll_files:\n",
    "    data1, data2, data3 = i.split(' ')\n",
    "    emb1, emb2, emb3 = test_dict[data1], test_dict[data2], test_dict[data3]\n",
    "    emb = torch.cat([emb1, emb2, emb3], dim=0)\n",
    "    emb = torch.mean(emb, dim=0, keepdim=False)\n",
    "    emb = F.normalize(emb, p=2, dim=0)\n",
    "    enroll_dict_mean_nm[i] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1070"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enroll_dict_mean_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict_nm = {}\n",
    "for i in test_dict:\n",
    "    emb = test_dict[i]\n",
    "    emb = F.normalize(emb.squeeze(0), p=2, dim=0)\n",
    "    test_dict_nm[i] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162413"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dict_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trials, 'r') as f:\n",
    "    trial_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\r"
     ]
    }
   ],
   "source": [
    "with open(out_path, 'w') as f:\n",
    "    for count, line in enumerate(trial_lines):\n",
    "        line = line[:-1]\n",
    "        data = line.split(' ')\n",
    "        enroll_label = data[0]+' '+data[1]+' '+data[2]\n",
    "        test_label = data[-1]\n",
    "        \n",
    "        enroll_emb = enroll_dict_mean_nm[enroll_label]\n",
    "        test_emb = test_dict_nm[test_label]\n",
    "        \n",
    "        score = F.cosine_similarity(enroll_emb, test_emb, dim=0).cpu().numpy()\n",
    "        f.write('%s %s %.4f\\n'%(enroll_label, test_label, score))\n",
    "        \n",
    "        if ((count+1) % 10000) == 0:\n",
    "            print((count+1) // 10000, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\r"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "for count, line in enumerate(trial_lines):\n",
    "    line = line[:-1]\n",
    "    data = line.split(' ')\n",
    "    enroll_label = data[0]+' '+data[1]+' '+data[2]\n",
    "    test_label = data[-1]\n",
    "\n",
    "    enroll_emb = enroll_dict_mean_nm[enroll_label]\n",
    "    test_emb = test_dict_nm[test_label]\n",
    "\n",
    "    score = F.cosine_similarity(enroll_emb, test_emb, dim=0).cpu().numpy()\n",
    "    score_list.append(score)\n",
    "\n",
    "    if ((count+1) % 10000) == 0:\n",
    "        print((count+1) // 10000, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 0.000e+00,\n",
       "        0.000e+00, 3.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 1.000e+00,\n",
       "        2.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 3.000e+00, 4.000e+00,\n",
       "        2.000e+00, 3.000e+00, 5.000e+00, 7.000e+00, 5.000e+00, 2.000e+00,\n",
       "        4.000e+00, 7.000e+00, 3.000e+00, 1.600e+01, 1.300e+01, 1.800e+01,\n",
       "        1.500e+01, 1.100e+01, 1.100e+01, 1.700e+01, 2.200e+01, 2.100e+01,\n",
       "        1.400e+01, 1.900e+01, 3.700e+01, 2.700e+01, 2.900e+01, 2.600e+01,\n",
       "        3.900e+01, 4.200e+01, 5.200e+01, 4.700e+01, 6.000e+01, 7.700e+01,\n",
       "        6.900e+01, 7.800e+01, 9.000e+01, 7.800e+01, 9.800e+01, 1.040e+02,\n",
       "        1.000e+02, 1.430e+02, 1.550e+02, 1.460e+02, 1.500e+02, 1.700e+02,\n",
       "        2.100e+02, 2.040e+02, 2.470e+02, 2.350e+02, 2.730e+02, 2.840e+02,\n",
       "        3.310e+02, 3.220e+02, 3.550e+02, 3.890e+02, 4.100e+02, 4.770e+02,\n",
       "        4.870e+02, 5.270e+02, 5.450e+02, 5.940e+02, 6.160e+02, 6.670e+02,\n",
       "        6.780e+02, 7.140e+02, 8.050e+02, 8.360e+02, 8.430e+02, 9.410e+02,\n",
       "        1.029e+03, 1.022e+03, 1.052e+03, 1.196e+03, 1.204e+03, 1.225e+03,\n",
       "        1.331e+03, 1.423e+03, 1.468e+03, 1.524e+03, 1.600e+03, 1.709e+03,\n",
       "        1.725e+03, 1.828e+03, 1.988e+03, 1.986e+03, 2.170e+03, 2.076e+03,\n",
       "        2.311e+03, 2.440e+03, 2.398e+03, 2.574e+03, 2.643e+03, 2.776e+03,\n",
       "        2.842e+03, 2.926e+03, 3.023e+03, 3.122e+03, 3.336e+03, 3.357e+03,\n",
       "        3.444e+03, 3.490e+03, 3.745e+03, 3.786e+03, 3.742e+03, 3.890e+03,\n",
       "        4.010e+03, 4.124e+03, 4.241e+03, 4.340e+03, 4.489e+03, 4.578e+03,\n",
       "        4.507e+03, 4.782e+03, 4.688e+03, 4.984e+03, 5.006e+03, 5.213e+03,\n",
       "        5.382e+03, 5.375e+03, 5.270e+03, 5.505e+03, 5.591e+03, 5.559e+03,\n",
       "        5.710e+03, 5.810e+03, 6.079e+03, 6.038e+03, 5.969e+03, 6.131e+03,\n",
       "        6.143e+03, 6.384e+03, 6.272e+03, 6.377e+03, 6.593e+03, 6.574e+03,\n",
       "        6.493e+03, 6.511e+03, 6.648e+03, 6.770e+03, 6.630e+03, 6.762e+03,\n",
       "        6.961e+03, 6.767e+03, 6.848e+03, 6.978e+03, 6.876e+03, 6.828e+03,\n",
       "        6.896e+03, 6.938e+03, 6.880e+03, 6.911e+03, 6.860e+03, 7.014e+03,\n",
       "        7.025e+03, 6.907e+03, 6.982e+03, 7.063e+03, 6.846e+03, 6.771e+03,\n",
       "        6.844e+03, 6.845e+03, 6.711e+03, 6.677e+03, 6.547e+03, 6.662e+03,\n",
       "        6.692e+03, 6.509e+03, 6.424e+03, 6.535e+03, 6.313e+03, 6.308e+03,\n",
       "        6.187e+03, 6.159e+03, 6.163e+03, 6.064e+03, 6.026e+03, 5.861e+03,\n",
       "        5.826e+03, 5.883e+03, 5.545e+03, 5.573e+03, 5.522e+03, 5.510e+03,\n",
       "        5.502e+03, 5.391e+03, 5.271e+03, 5.218e+03, 5.170e+03, 5.032e+03,\n",
       "        5.011e+03, 5.112e+03, 4.890e+03, 4.856e+03, 4.650e+03, 4.742e+03,\n",
       "        4.385e+03, 4.552e+03, 4.416e+03, 4.460e+03, 4.229e+03, 4.244e+03,\n",
       "        4.156e+03, 3.979e+03, 3.940e+03, 3.831e+03, 3.798e+03, 3.803e+03,\n",
       "        3.836e+03, 3.596e+03, 3.631e+03, 3.425e+03, 3.366e+03, 3.378e+03,\n",
       "        3.305e+03, 3.266e+03, 3.202e+03, 3.146e+03, 3.094e+03, 3.003e+03,\n",
       "        2.898e+03, 2.840e+03, 2.909e+03, 2.888e+03, 2.782e+03, 2.768e+03,\n",
       "        2.693e+03, 2.673e+03, 2.582e+03, 2.505e+03, 2.391e+03, 2.422e+03,\n",
       "        2.363e+03, 2.206e+03, 2.172e+03, 2.187e+03, 2.094e+03, 2.106e+03,\n",
       "        2.056e+03, 1.997e+03, 1.885e+03, 1.940e+03, 1.880e+03, 1.802e+03,\n",
       "        1.754e+03, 1.759e+03, 1.701e+03, 1.705e+03, 1.640e+03, 1.529e+03,\n",
       "        1.438e+03, 1.451e+03, 1.499e+03, 1.364e+03, 1.364e+03, 1.329e+03,\n",
       "        1.325e+03, 1.306e+03, 1.214e+03, 1.289e+03, 1.223e+03, 1.217e+03,\n",
       "        1.126e+03, 1.100e+03, 1.036e+03, 1.043e+03, 1.059e+03, 1.012e+03,\n",
       "        9.940e+02, 9.870e+02, 8.540e+02, 8.750e+02, 7.490e+02, 8.710e+02,\n",
       "        8.480e+02, 7.670e+02, 7.780e+02, 7.240e+02, 7.380e+02, 7.230e+02,\n",
       "        7.380e+02, 7.140e+02, 6.100e+02, 6.180e+02, 6.430e+02, 6.330e+02,\n",
       "        5.710e+02, 6.350e+02, 5.470e+02, 5.530e+02, 4.800e+02, 5.510e+02,\n",
       "        5.190e+02, 4.820e+02, 5.000e+02, 4.710e+02, 4.500e+02, 4.350e+02,\n",
       "        4.660e+02, 3.920e+02, 4.510e+02, 4.810e+02, 4.380e+02, 3.960e+02,\n",
       "        4.070e+02, 3.430e+02, 3.660e+02, 3.890e+02, 3.850e+02, 3.720e+02,\n",
       "        3.430e+02, 3.740e+02, 3.700e+02, 3.650e+02, 3.480e+02, 3.140e+02,\n",
       "        3.590e+02, 3.490e+02, 3.530e+02, 3.470e+02, 3.200e+02, 3.410e+02,\n",
       "        3.770e+02, 3.430e+02, 3.190e+02, 3.630e+02, 3.800e+02, 3.750e+02,\n",
       "        3.250e+02, 3.370e+02, 3.780e+02, 3.330e+02, 3.540e+02, 3.580e+02,\n",
       "        4.350e+02, 3.380e+02, 3.460e+02, 4.100e+02, 3.360e+02, 3.780e+02,\n",
       "        3.510e+02, 3.970e+02, 3.510e+02, 3.870e+02, 3.960e+02, 3.860e+02,\n",
       "        3.630e+02, 3.770e+02, 3.960e+02, 3.880e+02, 3.460e+02, 4.200e+02,\n",
       "        3.770e+02, 4.140e+02, 3.900e+02, 3.850e+02, 3.830e+02, 4.290e+02,\n",
       "        4.050e+02, 4.380e+02, 3.960e+02, 3.840e+02, 4.570e+02, 4.350e+02,\n",
       "        4.160e+02, 4.370e+02, 4.140e+02, 4.320e+02, 4.270e+02, 4.070e+02,\n",
       "        4.050e+02, 3.740e+02, 4.170e+02, 4.180e+02, 3.660e+02, 4.010e+02,\n",
       "        3.930e+02, 3.960e+02, 4.160e+02, 3.860e+02, 3.590e+02, 3.750e+02,\n",
       "        3.770e+02, 3.290e+02, 3.660e+02, 3.790e+02, 3.380e+02, 3.450e+02,\n",
       "        3.270e+02, 3.300e+02, 3.320e+02, 3.440e+02, 3.210e+02, 2.920e+02,\n",
       "        2.540e+02, 3.080e+02, 3.070e+02, 2.890e+02, 2.490e+02, 2.730e+02,\n",
       "        2.350e+02, 2.640e+02, 2.510e+02, 2.360e+02, 2.620e+02, 2.200e+02,\n",
       "        2.070e+02, 1.980e+02, 1.640e+02, 1.960e+02, 1.450e+02, 1.480e+02,\n",
       "        1.320e+02, 1.350e+02, 1.690e+02, 1.380e+02, 1.270e+02, 1.070e+02,\n",
       "        1.200e+02, 1.090e+02, 1.040e+02, 9.500e+01, 7.800e+01, 5.800e+01,\n",
       "        9.000e+01, 6.000e+01, 9.200e+01, 5.800e+01, 7.300e+01, 4.800e+01,\n",
       "        4.300e+01, 5.800e+01, 4.800e+01, 3.100e+01, 4.400e+01, 3.900e+01,\n",
       "        2.600e+01, 3.000e+01, 3.300e+01, 1.100e+01, 9.000e+00, 1.600e+01,\n",
       "        8.000e+00, 1.400e+01, 7.000e+00, 9.000e+00, 1.100e+01, 2.000e+00,\n",
       "        8.000e+00, 2.000e+00, 8.000e+00, 1.000e+00, 1.000e+00, 4.000e+00,\n",
       "        3.000e+00, 1.000e+00, 4.000e+00, 3.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 2.000e+00, 2.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        4.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 2.000e+00]),\n",
       " array([-2.66988993e-01, -2.64498532e-01, -2.62008071e-01, -2.59517640e-01,\n",
       "        -2.57027179e-01, -2.54536718e-01, -2.52046257e-01, -2.49555811e-01,\n",
       "        -2.47065365e-01, -2.44574904e-01, -2.42084458e-01, -2.39593998e-01,\n",
       "        -2.37103552e-01, -2.34613091e-01, -2.32122645e-01, -2.29632184e-01,\n",
       "        -2.27141738e-01, -2.24651277e-01, -2.22160831e-01, -2.19670370e-01,\n",
       "        -2.17179924e-01, -2.14689463e-01, -2.12199017e-01, -2.09708557e-01,\n",
       "        -2.07218111e-01, -2.04727650e-01, -2.02237204e-01, -1.99746743e-01,\n",
       "        -1.97256297e-01, -1.94765836e-01, -1.92275390e-01, -1.89784929e-01,\n",
       "        -1.87294483e-01, -1.84804022e-01, -1.82313576e-01, -1.79823115e-01,\n",
       "        -1.77332669e-01, -1.74842209e-01, -1.72351763e-01, -1.69861302e-01,\n",
       "        -1.67370856e-01, -1.64880395e-01, -1.62389949e-01, -1.59899488e-01,\n",
       "        -1.57409042e-01, -1.54918581e-01, -1.52428135e-01, -1.49937674e-01,\n",
       "        -1.47447228e-01, -1.44956768e-01, -1.42466322e-01, -1.39975861e-01,\n",
       "        -1.37485415e-01, -1.34994954e-01, -1.32504508e-01, -1.30014047e-01,\n",
       "        -1.27523601e-01, -1.25033140e-01, -1.22542694e-01, -1.20052241e-01,\n",
       "        -1.17561787e-01, -1.15071334e-01, -1.12580881e-01, -1.10090420e-01,\n",
       "        -1.07599966e-01, -1.05109513e-01, -1.02619059e-01, -1.00128606e-01,\n",
       "        -9.76381525e-02, -9.51476991e-02, -9.26572457e-02, -9.01667923e-02,\n",
       "        -8.76763389e-02, -8.51858854e-02, -8.26954320e-02, -8.02049786e-02,\n",
       "        -7.77145252e-02, -7.52240717e-02, -7.27336183e-02, -7.02431649e-02,\n",
       "        -6.77527115e-02, -6.52622581e-02, -6.27718046e-02, -6.02813549e-02,\n",
       "        -5.77909015e-02, -5.53004481e-02, -5.28099947e-02, -5.03195412e-02,\n",
       "        -4.78290878e-02, -4.53386344e-02, -4.28481810e-02, -4.03577276e-02,\n",
       "        -3.78672741e-02, -3.53768207e-02, -3.28863636e-02, -3.03959120e-02,\n",
       "        -2.79054586e-02, -2.54150052e-02, -2.29245517e-02, -2.04340983e-02,\n",
       "        -1.79436449e-02, -1.54531915e-02, -1.29627371e-02, -1.04722837e-02,\n",
       "        -7.98183028e-03, -5.49137732e-03, -3.00092367e-03, -5.10470127e-04,\n",
       "         1.97998341e-03,  4.47043683e-03,  6.96089026e-03,  9.45134368e-03,\n",
       "         1.19417971e-02,  1.44322505e-02,  1.69227049e-02,  1.94131583e-02,\n",
       "         2.19036117e-02,  2.43940651e-02,  2.68845186e-02,  2.93749720e-02,\n",
       "         3.18654254e-02,  3.43558788e-02,  3.68463323e-02,  3.93367857e-02,\n",
       "         4.18272391e-02,  4.43176925e-02,  4.68081459e-02,  4.92985994e-02,\n",
       "         5.17890528e-02,  5.42795062e-02,  5.67699596e-02,  5.92604131e-02,\n",
       "         6.17508665e-02,  6.42413199e-02,  6.67317733e-02,  6.92222267e-02,\n",
       "         7.17126802e-02,  7.42031336e-02,  7.66935870e-02,  7.91840404e-02,\n",
       "         8.16744938e-02,  8.41649473e-02,  8.66554007e-02,  8.91458541e-02,\n",
       "         9.16363075e-02,  9.41267610e-02,  9.66172144e-02,  9.91076678e-02,\n",
       "         1.01598121e-01,  1.04088575e-01,  1.06579028e-01,  1.09069481e-01,\n",
       "         1.11559935e-01,  1.14050388e-01,  1.16540842e-01,  1.19031295e-01,\n",
       "         1.21521749e-01,  1.24012202e-01,  1.26502663e-01,  1.28993109e-01,\n",
       "         1.31483570e-01,  1.33974016e-01,  1.36464477e-01,  1.38954923e-01,\n",
       "         1.41445383e-01,  1.43935829e-01,  1.46426290e-01,  1.48916736e-01,\n",
       "         1.51407197e-01,  1.53897643e-01,  1.56388104e-01,  1.58878550e-01,\n",
       "         1.61369011e-01,  1.63859457e-01,  1.66349918e-01,  1.68840364e-01,\n",
       "         1.71330824e-01,  1.73821270e-01,  1.76311731e-01,  1.78802177e-01,\n",
       "         1.81292638e-01,  1.83783084e-01,  1.86273545e-01,  1.88763991e-01,\n",
       "         1.91254452e-01,  1.93744898e-01,  1.96235359e-01,  1.98725805e-01,\n",
       "         2.01216266e-01,  2.03706712e-01,  2.06197172e-01,  2.08687618e-01,\n",
       "         2.11178079e-01,  2.13668525e-01,  2.16158986e-01,  2.18649432e-01,\n",
       "         2.21139893e-01,  2.23630339e-01,  2.26120800e-01,  2.28611246e-01,\n",
       "         2.31101707e-01,  2.33592153e-01,  2.36082613e-01,  2.38573059e-01,\n",
       "         2.41063520e-01,  2.43553966e-01,  2.46044427e-01,  2.48534873e-01,\n",
       "         2.51025319e-01,  2.53515780e-01,  2.56006241e-01,  2.58496702e-01,\n",
       "         2.60987133e-01,  2.63477594e-01,  2.65968055e-01,  2.68458515e-01,\n",
       "         2.70948946e-01,  2.73439407e-01,  2.75929868e-01,  2.78420329e-01,\n",
       "         2.80910760e-01,  2.83401221e-01,  2.85891682e-01,  2.88382143e-01,\n",
       "         2.90872574e-01,  2.93363035e-01,  2.95853496e-01,  2.98343956e-01,\n",
       "         3.00834388e-01,  3.03324848e-01,  3.05815309e-01,  3.08305770e-01,\n",
       "         3.10796201e-01,  3.13286662e-01,  3.15777123e-01,  3.18267584e-01,\n",
       "         3.20758015e-01,  3.23248476e-01,  3.25738937e-01,  3.28229398e-01,\n",
       "         3.30719829e-01,  3.33210289e-01,  3.35700750e-01,  3.38191211e-01,\n",
       "         3.40681642e-01,  3.43172103e-01,  3.45662564e-01,  3.48153025e-01,\n",
       "         3.50643456e-01,  3.53133917e-01,  3.55624378e-01,  3.58114839e-01,\n",
       "         3.60605299e-01,  3.63095731e-01,  3.65586191e-01,  3.68076652e-01,\n",
       "         3.70567113e-01,  3.73057544e-01,  3.75548005e-01,  3.78038466e-01,\n",
       "         3.80528927e-01,  3.83019358e-01,  3.85509819e-01,  3.88000280e-01,\n",
       "         3.90490741e-01,  3.92981172e-01,  3.95471632e-01,  3.97962093e-01,\n",
       "         4.00452554e-01,  4.02942985e-01,  4.05433446e-01,  4.07923907e-01,\n",
       "         4.10414368e-01,  4.12904799e-01,  4.15395260e-01,  4.17885721e-01,\n",
       "         4.20376182e-01,  4.22866613e-01,  4.25357074e-01,  4.27847534e-01,\n",
       "         4.30337995e-01,  4.32828426e-01,  4.35318887e-01,  4.37809348e-01,\n",
       "         4.40299809e-01,  4.42790240e-01,  4.45280701e-01,  4.47771162e-01,\n",
       "         4.50261623e-01,  4.52752054e-01,  4.55242515e-01,  4.57732975e-01,\n",
       "         4.60223436e-01,  4.62713867e-01,  4.65204328e-01,  4.67694789e-01,\n",
       "         4.70185250e-01,  4.72675681e-01,  4.75166142e-01,  4.77656603e-01,\n",
       "         4.80147064e-01,  4.82637495e-01,  4.85127956e-01,  4.87618417e-01,\n",
       "         4.90108877e-01,  4.92599308e-01,  4.95089769e-01,  4.97580230e-01,\n",
       "         5.00070691e-01,  5.02561152e-01,  5.05051613e-01,  5.07542014e-01,\n",
       "         5.10032475e-01,  5.12522936e-01,  5.15013397e-01,  5.17503858e-01,\n",
       "         5.19994318e-01,  5.22484779e-01,  5.24975240e-01,  5.27465641e-01,\n",
       "         5.29956102e-01,  5.32446563e-01,  5.34937024e-01,  5.37427485e-01,\n",
       "         5.39917946e-01,  5.42408407e-01,  5.44898868e-01,  5.47389269e-01,\n",
       "         5.49879730e-01,  5.52370191e-01,  5.54860651e-01,  5.57351112e-01,\n",
       "         5.59841573e-01,  5.62332034e-01,  5.64822495e-01,  5.67312896e-01,\n",
       "         5.69803357e-01,  5.72293818e-01,  5.74784279e-01,  5.77274740e-01,\n",
       "         5.79765201e-01,  5.82255661e-01,  5.84746122e-01,  5.87236524e-01,\n",
       "         5.89726985e-01,  5.92217445e-01,  5.94707906e-01,  5.97198367e-01,\n",
       "         5.99688828e-01,  6.02179289e-01,  6.04669750e-01,  6.07160151e-01,\n",
       "         6.09650612e-01,  6.12141073e-01,  6.14631534e-01,  6.17121994e-01,\n",
       "         6.19612455e-01,  6.22102916e-01,  6.24593377e-01,  6.27083778e-01,\n",
       "         6.29574239e-01,  6.32064700e-01,  6.34555161e-01,  6.37045622e-01,\n",
       "         6.39536083e-01,  6.42026544e-01,  6.44517004e-01,  6.47007406e-01,\n",
       "         6.49497867e-01,  6.51988328e-01,  6.54478788e-01,  6.56969249e-01,\n",
       "         6.59459710e-01,  6.61950171e-01,  6.64440632e-01,  6.66931033e-01,\n",
       "         6.69421494e-01,  6.71911955e-01,  6.74402416e-01,  6.76892877e-01,\n",
       "         6.79383337e-01,  6.81873798e-01,  6.84364259e-01,  6.86854720e-01,\n",
       "         6.89345121e-01,  6.91835582e-01,  6.94326043e-01,  6.96816504e-01,\n",
       "         6.99306965e-01,  7.01797426e-01,  7.04287887e-01,  7.06778347e-01,\n",
       "         7.09268749e-01,  7.11759210e-01,  7.14249671e-01,  7.16740131e-01,\n",
       "         7.19230592e-01,  7.21721053e-01,  7.24211514e-01,  7.26701975e-01,\n",
       "         7.29192376e-01,  7.31682837e-01,  7.34173298e-01,  7.36663759e-01,\n",
       "         7.39154220e-01,  7.41644681e-01,  7.44135141e-01,  7.46625602e-01,\n",
       "         7.49116004e-01,  7.51606464e-01,  7.54096925e-01,  7.56587386e-01,\n",
       "         7.59077847e-01,  7.61568308e-01,  7.64058769e-01,  7.66549230e-01,\n",
       "         7.69039631e-01,  7.71530092e-01,  7.74020553e-01,  7.76511014e-01,\n",
       "         7.79001474e-01,  7.81491935e-01,  7.83982396e-01,  7.86472857e-01,\n",
       "         7.88963258e-01,  7.91453719e-01,  7.93944180e-01,  7.96434641e-01,\n",
       "         7.98925102e-01,  8.01415563e-01,  8.03906024e-01,  8.06396484e-01,\n",
       "         8.08886886e-01,  8.11377347e-01,  8.13867807e-01,  8.16358268e-01,\n",
       "         8.18848729e-01,  8.21339190e-01,  8.23829651e-01,  8.26320112e-01,\n",
       "         8.28810513e-01,  8.31300974e-01,  8.33791435e-01,  8.36281896e-01,\n",
       "         8.38772357e-01,  8.41262817e-01,  8.43753278e-01,  8.46243739e-01,\n",
       "         8.48734140e-01,  8.51224601e-01,  8.53715062e-01,  8.56205523e-01,\n",
       "         8.58695984e-01,  8.61186445e-01,  8.63676906e-01,  8.66167367e-01,\n",
       "         8.68657768e-01,  8.71148229e-01,  8.73638690e-01,  8.76129150e-01,\n",
       "         8.78619611e-01,  8.81110072e-01,  8.83600533e-01,  8.86090994e-01,\n",
       "         8.88581395e-01,  8.91071856e-01,  8.93562317e-01,  8.96052778e-01,\n",
       "         8.98543239e-01,  9.01033700e-01,  9.03524160e-01,  9.06014621e-01,\n",
       "         9.08505023e-01,  9.10995483e-01,  9.13485944e-01,  9.15976405e-01,\n",
       "         9.18466866e-01,  9.20957327e-01,  9.23447788e-01,  9.25938249e-01,\n",
       "         9.28428650e-01,  9.30919111e-01,  9.33409572e-01,  9.35900033e-01,\n",
       "         9.38390493e-01,  9.40880954e-01,  9.43371415e-01,  9.45861876e-01,\n",
       "         9.48352277e-01,  9.50842738e-01,  9.53333199e-01,  9.55823660e-01,\n",
       "         9.58314121e-01,  9.60804582e-01,  9.63295043e-01,  9.65785503e-01,\n",
       "         9.68275905e-01,  9.70766366e-01,  9.73256826e-01,  9.75747287e-01,\n",
       "         9.78237748e-01], dtype=float32),\n",
       " <a list of 500 Patch objects>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(score_list, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_spk_out = '/workspace/DATASET/server9_ssd/PVTC20/task1/spk_out.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\r"
     ]
    }
   ],
   "source": [
    "TH = 0.47\n",
    "with open(final_spk_out, 'w') as f:\n",
    "    for count, line in enumerate(trial_lines):\n",
    "        line = line[:-1]\n",
    "        data = line.split(' ')\n",
    "        enroll_label = data[0]+' '+data[1]+' '+data[2]\n",
    "        test_label = data[-1]\n",
    "        \n",
    "        enroll_emb = enroll_dict_mean_nm[enroll_label]\n",
    "        test_emb = test_dict_nm[test_label]\n",
    "        \n",
    "        score = F.cosine_similarity(enroll_emb, test_emb, dim=0).cpu().numpy()\n",
    "        \n",
    "        if score >= TH:\n",
    "            score = 1\n",
    "        else:\n",
    "            score = 0\n",
    "        \n",
    "        f.write('%s %s %d\\n'%(enroll_label, test_label, score))\n",
    "        \n",
    "        if ((count+1) % 10000) == 0:\n",
    "            print((count+1) // 10000, end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_kws_out = '/workspace/DATASET/server9_ssd/PVTC20/task1/kws_output.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(final_kws_out, 'r') as f:\n",
    "    kws_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kws_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_spk_out = '/workspace/DATASET/server9_ssd/PVTC20/task1/spk_out.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(final_spk_out, 'r') as f:\n",
    "    spk_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spk_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_out = '/workspace/DATASET/server9_ssd/PVTC20/task1/baseline_output.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\r"
     ]
    }
   ],
   "source": [
    "with open(final_out, 'w') as f:\n",
    "    for count, [k_line, s_line] in enumerate(zip(kws_lines, spk_lines)):\n",
    "        k_line = k_line[:-1]\n",
    "        s_line = s_line[:-1]\n",
    "        \n",
    "        k_data = k_line.split(' ')\n",
    "        s_data = s_line.split(' ')\n",
    "        \n",
    "        k = k_data[0]+' '+k_data[1]+' '+k_data[2]+' '+k_data[3]\n",
    "        s = s_data[0]+' '+s_data[1]+' '+s_data[2]+' '+s_data[3]\n",
    "        \n",
    "        assert k == s\n",
    "        \n",
    "        score = int(int(k_data[-1]) and int(s_data[-1]))\n",
    "        \n",
    "        f.write('%s %d\\n'%(k, score))\n",
    "        \n",
    "        if ((count+1) % 10000) == 0:\n",
    "            print((count+1) // 10000, end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev tune only on speech with 'xiaolexiaole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_trials = '/workspace/DATASET/server9_ssd/PVTC20/dev/task1/trials'\n",
    "dev_kws = '/workspace/DATASET/server9_ssd/PVTC20/dev/task1/trials_for_wake'\n",
    "dev_path = '/workspace/DATASET/server9_ssd/PVTC20/dev/task1/wav_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dev_kws, 'r') as f:\n",
    "    kws_keys = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kws_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kws_pos = []\n",
    "for i in kws_keys:\n",
    "    i = i[:-1]\n",
    "    data, label = i.split(' ')\n",
    "    if label == 'positive':\n",
    "        kws_pos.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kws_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dev_trials, 'r') as f:\n",
    "    trial_keys = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\r"
     ]
    }
   ],
   "source": [
    "target_trials = []\n",
    "for count, i in enumerate(trial_keys):\n",
    "    i = i[:-1]\n",
    "    test_wav = i.split(' ')[-2]\n",
    "    if test_wav in kws_pos:\n",
    "        target_trials.append(i)\n",
    "    if ((count+1) % 1000) ==0:\n",
    "        print((count+1)//1000, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "devfiles = []\n",
    "\n",
    "for line in target_trials:\n",
    "\n",
    "    data = line.split(' ')\n",
    "\n",
    "    devfiles.append(data[0])\n",
    "    devfiles.append(data[1])\n",
    "    devfiles.append(data[2])\n",
    "    devfiles.append(data[3])\n",
    "\n",
    "devfiles = list(set(devfiles))\n",
    "devfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16834"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(devfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\r"
     ]
    }
   ],
   "source": [
    "dev_dict = {}\n",
    "for count, line in enumerate(devfiles):\n",
    "    wavline = line\n",
    "    wavline = os.path.join(dev_path, wavline)\n",
    "    raw_inp = loadWAV(wavline, last_seconds=1.0)\n",
    "    raw_inp = torch.FloatTensor(raw_inp).cuda()\n",
    "    \n",
    "    ref_feat = S.forward(raw_inp).detach().cpu()\n",
    "\n",
    "    dev_dict[line] = ref_feat\n",
    "    \n",
    "    if ((count+1) % 1000) == 0:\n",
    "        print((count+1)//1000, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16834"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_enroll_files = []\n",
    "for line in target_trials:\n",
    "    data = line.split()\n",
    "    \n",
    "    dev_enroll_files.append(data[0]+' '+data[1]+' '+data[2])\n",
    "\n",
    "dev_enroll_files = list(set(dev_enroll_files))\n",
    "dev_enroll_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_enroll_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_enroll_dict_mean_nm = {}\n",
    "for i in dev_enroll_files:\n",
    "    data1, data2, data3 = i.split(' ')\n",
    "    emb1, emb2, emb3 = dev_dict[data1], dev_dict[data2], dev_dict[data3]\n",
    "    emb = torch.cat([emb1, emb2, emb3], dim=0)\n",
    "    emb = torch.mean(emb, dim=0, keepdim=False)\n",
    "    emb = F.normalize(emb, p=2, dim=0)\n",
    "    dev_enroll_dict_mean_nm[i] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_enroll_dict_mean_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in target_trials:\n",
    "    if i.split(' ')[-1] == 'positive':\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dict_nm = {}\n",
    "for i in dev_dict:\n",
    "    emb = dev_dict[i]\n",
    "    emb = F.normalize(emb.squeeze(0), p=2, dim=0)\n",
    "    dev_dict_nm[i] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16834"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_dict_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\r"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "key_list = []\n",
    "for count, line in enumerate(target_trials):\n",
    "    data = line.split(' ')\n",
    "    enroll_label = data[0]+' '+data[1]+' '+data[2]\n",
    "    test_label = data[3]\n",
    "    key = 1 if data[-1]=='positive' else 0\n",
    "\n",
    "    enroll_emb = dev_enroll_dict_mean_nm[enroll_label]\n",
    "    test_emb = dev_dict_nm[test_label]\n",
    "\n",
    "    score = F.cosine_similarity(enroll_emb, test_emb, dim=0).cpu().numpy()\n",
    "    score_list.append(score)\n",
    "    \n",
    "    key_list.append(key)\n",
    "    \n",
    "\n",
    "    if ((count+1) % 10000) == 0:\n",
    "        print((count+1) // 10000, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tuneThresholdfromScore_pvtc20_minc(score_list, key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2299999999999995"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## eer\n",
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20771666666666666"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## minc@0.05\n",
    "result[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.58206385, 0.20166666666666666, 16.939999999999998]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TH\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev tune only on speech with all (regardless of kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_trials = '/workspace/DATASET/server9_ssd/PVTC20/dev/task1/trials'\n",
    "dev_path = '/workspace/DATASET/server9_ssd/PVTC20/dev/task1/wav_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dev_trials, 'r') as f:\n",
    "    trial_keys = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r",
      "2\r",
      "3\r",
      "4\r",
      "5\r",
      "6\r",
      "7\r",
      "8\r",
      "9\r",
      "10\r",
      "11\r",
      "12\r",
      "13\r",
      "14\r",
      "15\r",
      "16\r",
      "17\r",
      "18\r",
      "19\r",
      "20\r",
      "21\r",
      "22\r",
      "23\r",
      "24\r",
      "25\r",
      "26\r",
      "27\r",
      "28\r",
      "29\r",
      "30\r",
      "31\r",
      "32\r",
      "33\r",
      "34\r",
      "35\r",
      "36\r",
      "37\r",
      "38\r",
      "39\r",
      "40\r",
      "41\r",
      "42\r",
      "43\r",
      "44\r",
      "45\r",
      "46\r",
      "47\r",
      "48\r",
      "49\r",
      "50\r",
      "51\r",
      "52\r",
      "53\r",
      "54\r",
      "55\r",
      "56\r",
      "57\r",
      "58\r",
      "59\r",
      "60\r",
      "61\r",
      "62\r",
      "63\r",
      "64\r",
      "65\r",
      "66\r",
      "67\r",
      "68\r",
      "69\r",
      "70\r",
      "71\r",
      "72\r",
      "73\r",
      "74\r",
      "75\r",
      "76\r",
      "77\r",
      "78\r",
      "79\r",
      "80\r",
      "81\r",
      "82\r",
      "83\r",
      "84\r",
      "85\r",
      "86\r",
      "87\r",
      "88\r",
      "89\r",
      "90\r",
      "91\r",
      "92\r",
      "93\r",
      "94\r",
      "95\r",
      "96\r",
      "97\r",
      "98\r",
      "99\r",
      "100\r",
      "101\r",
      "102\r",
      "103\r",
      "104\r",
      "105\r"
     ]
    }
   ],
   "source": [
    "target_trials = []\n",
    "for count, i in enumerate(trial_keys):\n",
    "    i = i[:-1]\n",
    "\n",
    "    target_trials.append(i)\n",
    "    if ((count+1) % 1000) ==0:\n",
    "        print((count+1)//1000, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "devfiles = []\n",
    "\n",
    "for line in target_trials:\n",
    "\n",
    "    data = line.split(' ')\n",
    "\n",
    "    devfiles.append(data[0])\n",
    "    devfiles.append(data[1])\n",
    "    devfiles.append(data[2])\n",
    "    devfiles.append(data[3])\n",
    "\n",
    "devfiles = list(set(devfiles))\n",
    "devfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26529"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(devfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\r"
     ]
    }
   ],
   "source": [
    "dev_dict = {}\n",
    "for count, line in enumerate(devfiles):\n",
    "    wavline = line\n",
    "    wavline = os.path.join(dev_path, wavline)\n",
    "    raw_inp = loadWAV(wavline, last_seconds=1.0)\n",
    "    raw_inp = torch.FloatTensor(raw_inp).cuda()\n",
    "    \n",
    "    ref_feat = S.forward(raw_inp).detach().cpu()\n",
    "\n",
    "    dev_dict[line] = ref_feat\n",
    "    \n",
    "    if ((count+1) % 1000) == 0:\n",
    "        print((count+1)//1000, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26529"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_enroll_files = []\n",
    "for line in target_trials:\n",
    "    data = line.split()\n",
    "    \n",
    "    dev_enroll_files.append(data[0]+' '+data[1]+' '+data[2])\n",
    "\n",
    "dev_enroll_files = list(set(dev_enroll_files))\n",
    "dev_enroll_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_enroll_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_enroll_dict_mean_nm = {}\n",
    "for i in dev_enroll_files:\n",
    "    data1, data2, data3 = i.split(' ')\n",
    "    emb1, emb2, emb3 = dev_dict[data1], dev_dict[data2], dev_dict[data3]\n",
    "    emb = torch.cat([emb1, emb2, emb3], dim=0)\n",
    "    emb = torch.mean(emb, dim=0, keepdim=False)\n",
    "    emb = F.normalize(emb, p=2, dim=0)\n",
    "    dev_enroll_dict_mean_nm[i] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_enroll_dict_mean_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in target_trials:\n",
    "    if i.split(' ')[-1] == 'positive':\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dict_nm = {}\n",
    "for i in dev_dict:\n",
    "    emb = dev_dict[i]\n",
    "    emb = F.normalize(emb.squeeze(0), p=2, dim=0)\n",
    "    dev_dict_nm[i] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26529"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_dict_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\r"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "key_list = []\n",
    "for count, line in enumerate(target_trials):\n",
    "    data = line.split(' ')\n",
    "    enroll_label = data[0]+' '+data[1]+' '+data[2]\n",
    "    test_label = data[3]\n",
    "    key = 1 if data[-1]=='positive' else 0\n",
    "\n",
    "    enroll_emb = dev_enroll_dict_mean_nm[enroll_label]\n",
    "    test_emb = dev_dict_nm[test_label]\n",
    "\n",
    "    score = F.cosine_similarity(enroll_emb, test_emb, dim=0).cpu().numpy()\n",
    "    score_list.append(score)\n",
    "    \n",
    "    key_list.append(key)\n",
    "    \n",
    "\n",
    "    if ((count+1) % 10000) == 0:\n",
    "        print((count+1) // 10000, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tuneThresholdfromScore_pvtc20_minc(score_list, key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.927"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## eer\n",
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19288999999999992"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## minc@0.05\n",
    "result[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.56074214, 0.291, 13.759999999999994]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TH\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use dev TH to set testing TH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "TH = 0.5607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_spk_out = '/workspace/DATASET/server9_ssd/PVTC20/task1/spk_scores.txt'\n",
    "final_spk_out_tune = '/workspace/DATASET/server9_ssd/PVTC20/task1/spk_tune_out.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(final_spk_out, 'r') as f:\n",
    "    ori_out = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PVTC_task1_0001.wav PVTC_task1_0002.wav PVTC_task1_0003.wav PVTC_task1_0004.wav 0.5597\\n'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(final_spk_out_tune, 'w') as f:\n",
    "    for line in ori_out:\n",
    "        line = line[:-1]\n",
    "        score = float(line.split(' ')[-1])\n",
    "        if score > TH:\n",
    "            score = 1\n",
    "        else:\n",
    "            score = 0\n",
    "        data = line.split(' ')\n",
    "        f.write(data[0]+' '+data[1]+' '+data[2]+' '+data[3]+' '+str(score)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## socre norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trials, 'r') as f:\n",
    "    trial_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_test_list = []\n",
    "for i in trial_list:\n",
    "    pure_test_list.append(i[:-1].split(' ')[-1])\n",
    "pure_test_list = list(set(pure_test_list))\n",
    "pure_test_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159235"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pure_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_enroll_dict_mean_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1070"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enroll_dict_mean_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_test_dict_nm = {}\n",
    "for i in pure_test_list:\n",
    "    pure_test_dict_nm[i] = test_dict_nm[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159235"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pure_test_dict_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\r"
     ]
    }
   ],
   "source": [
    "cohort2enroll = {}\n",
    "for count, i in enumerate(dev_enroll_dict_mean_nm):\n",
    "    chort = dev_enroll_dict_mean_nm[i]\n",
    "    for j in enroll_dict_mean_nm:\n",
    "        enroll = enroll_dict_mean_nm[j]\n",
    "        cohort2enroll[i+'|'+j] = F.cosine_similarity(chort, enroll, dim=0).cpu().numpy()\n",
    "    print(count+1, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598130"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cohort2enroll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\r"
     ]
    }
   ],
   "source": [
    "cohort2test = {}\n",
    "for count, i in enumerate(dev_enroll_dict_mean_nm):\n",
    "    chort = dev_enroll_dict_mean_nm[i]\n",
    "    for j in pure_test_dict_nm:\n",
    "        test = pure_test_dict_nm[j]\n",
    "        cohort2test[i+'|'+j] = F.cosine_similarity(chort, test, dim=0).cpu().numpy()\n",
    "    print(count+1, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89012365"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cohort2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89012365"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "159235 * 559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '/workspace/DATASET/server9_ssd/PVTC20/task1/spk_scores_as2.txt'\n",
    "file_score_path = '/workspace/DATASET/server9_ssd/PVTC20/task1/spk_scores.txt'\n",
    "top_num=400\n",
    "hold_name=True\n",
    "dict_sep='|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_norm_2(file_score_path, out_path, cohort2enroll, cohort2test, top_num=200, hold_name=True, dict_sep=' '):\n",
    "# operation: norm_score = 0.5* ((score-mean_e_t)/str_e_t+(score-mean_t_e)/str_t_e)\n",
    "    print('Score norm operation start, method: Adaptive_score_norm_type_2')\n",
    "\n",
    "    file_scores_as_norm_path = out_path\n",
    "    enroll_dict = defaultdict(dict)\n",
    "    test_dict = defaultdict(dict)\n",
    "\n",
    "    for count, i in enumerate(cohort2enroll):\n",
    "        cohort_utt = i.split(dict_sep)[0]\n",
    "        enroll_utt = i.split(dict_sep)[1]\n",
    "        score = float(cohort2enroll[i])\n",
    "        enroll_dict[enroll_utt][cohort_utt] = score \n",
    "\n",
    "        if ((count+1) % 100000) == 0:\n",
    "            print('read c2e:', (count+1)//100000, end='\\r')      \n",
    "\n",
    "    for count, i in enumerate(cohort2test):\n",
    "        cohort_utt = i.split(dict_sep)[0]\n",
    "        test_utt = i.split(dict_sep)[1]\n",
    "        score = float(cohort2test[i])\n",
    "        test_dict[test_utt][cohort_utt] = score\n",
    "\n",
    "        if ((count+1) % 100000) == 0:\n",
    "            print('read c2t:', (count+1)//100000, end='\\r')\n",
    "\n",
    "    for key in enroll_dict:\n",
    "        tmp_tuple = sorted(enroll_dict[key].items(),key=lambda x:x[1], reverse = True)\n",
    "        tmplist1 = []\n",
    "        tmplist2 = []\n",
    "        for i,j in tmp_tuple:\n",
    "            tmplist1.append(i)\n",
    "            tmplist2.append(j)\n",
    "        enroll_dict[key] = dict(zip(tmplist1,tmplist2))\n",
    "\n",
    "    for key in test_dict:\n",
    "        tmp_tuple = sorted(test_dict[key].items(),key=lambda x:x[1], reverse = True)\n",
    "        tmplist1 = []\n",
    "        tmplist2 = []\n",
    "        for i,j in tmp_tuple:\n",
    "            tmplist1.append(i)\n",
    "            tmplist2.append(j)\n",
    "        test_dict[key] = dict(zip(tmplist1,tmplist2))\n",
    "\n",
    "    print('Scoring...')\n",
    "\n",
    "    file_scores = open(file_score_path)\n",
    "    with open(file_scores_as_norm_path,'w') as f:\n",
    "        for count, line in enumerate(file_scores):\n",
    "\n",
    "            enroll_utt = line.split(' ')[0].strip()+' '+line.split(' ')[1].strip()+' '+line.split(' ')[2].strip()\n",
    "            test_utt = line.split(' ')[3].strip()\n",
    "            score = float(line.split(' ')[-1].strip())\n",
    "\n",
    "            cor_cohort_utt = []\n",
    "            for num,(cor_cohort_utt_tmp) in enumerate(enroll_dict[enroll_utt]):\n",
    "                if num<top_num:\n",
    "                    cor_cohort_utt.append(cor_cohort_utt_tmp)\n",
    "                else:\n",
    "                    break\n",
    "            tmp_score_list = []\n",
    "            for tmp_utt in cor_cohort_utt:\n",
    "                tmp_score_list.append(test_dict[test_utt][tmp_utt])\n",
    "            mean_e_t = numpy.mean(tmp_score_list)\n",
    "            str_e_t = numpy.std(tmp_score_list, ddof=1)\n",
    "\n",
    "            cor_cohort_utt = []\n",
    "            for num,(cor_cohort_utt_tmp) in enumerate(test_dict[test_utt]):\n",
    "                if num<top_num:\n",
    "                    cor_cohort_utt.append(cor_cohort_utt_tmp)\n",
    "                else:\n",
    "                    break\n",
    "            tmp_score_list = []\n",
    "            for tmp_utt in cor_cohort_utt:\n",
    "                tmp_score_list.append(enroll_dict[enroll_utt][tmp_utt])\n",
    "            mean_t_e = numpy.mean(tmp_score_list)\n",
    "            str_t_e = numpy.std(tmp_score_list, ddof=1)\n",
    "\n",
    "            norm_score = 0.5* ((score-mean_e_t)/str_e_t+(score-mean_t_e)/str_t_e)\n",
    "            if hold_name:\n",
    "                f.write('%s %s %.4f\\n'%(enroll_utt, test_utt, norm_score))\n",
    "            else:\n",
    "                f.write('%.4f\\n'%(norm_score))\n",
    "\n",
    "            if ((count+1) % 10000) == 0:\n",
    "                print((count+1)//10000, end='\\r')\n",
    "\n",
    "    print('Adaptive_score_norm_type_2 is finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score norm operation start, method: Adaptive_score_norm_type_2\n",
      "Scoring...890\n",
      "Adaptive_score_norm_type_2 is finished\n"
     ]
    }
   ],
   "source": [
    "out_path = '/workspace/DATASET/server9_ssd/PVTC20/task1/spk_scores_as2.txt'\n",
    "final_spk_out = '/workspace/DATASET/server9_ssd/PVTC20/task1/spk_scores.txt'\n",
    "as_norm_2(final_spk_out, out_path, cohort2enroll, cohort2test, top_num=400, hold_name=True, dict_sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_path, 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PVTC_task1_0001.wav PVTC_task1_0002.wav PVTC_task1_0003.wav PVTC_task1_0004.wav 3.6198\\n'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list\n",
    "for i in lines:\n",
    "    i = i[:-1]\n",
    "    score_list.append(float(i.split(' ')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 2.0000e+00, 1.0000e+00,\n",
       "        3.0000e+00, 1.0000e+00, 1.0000e+00, 3.0000e+00, 0.0000e+00,\n",
       "        4.0000e+00, 1.0000e+00, 8.0000e+00, 4.0000e+00, 3.0000e+00,\n",
       "        5.0000e+00, 6.0000e+00, 2.0000e+00, 6.0000e+00, 8.0000e+00,\n",
       "        1.0000e+01, 1.2000e+01, 8.0000e+00, 1.1000e+01, 2.1000e+01,\n",
       "        1.3000e+01, 2.1000e+01, 1.4000e+01, 1.7000e+01, 2.4000e+01,\n",
       "        1.8000e+01, 3.4000e+01, 4.3000e+01, 3.2000e+01, 4.5000e+01,\n",
       "        4.4000e+01, 5.3000e+01, 6.2000e+01, 7.3000e+01, 8.0000e+01,\n",
       "        9.3000e+01, 1.0000e+02, 1.0900e+02, 1.2700e+02, 1.2300e+02,\n",
       "        1.4700e+02, 1.7300e+02, 1.9100e+02, 1.9400e+02, 2.2600e+02,\n",
       "        2.9000e+02, 2.7500e+02, 2.8300e+02, 3.0500e+02, 3.4000e+02,\n",
       "        4.0600e+02, 4.6500e+02, 5.2300e+02, 5.1800e+02, 6.0900e+02,\n",
       "        5.9600e+02, 7.1200e+02, 7.5700e+02, 8.6800e+02, 8.9800e+02,\n",
       "        1.0620e+03, 1.1200e+03, 1.2090e+03, 1.2590e+03, 1.4070e+03,\n",
       "        1.5310e+03, 1.6060e+03, 1.8140e+03, 1.9290e+03, 2.0700e+03,\n",
       "        2.3640e+03, 2.4320e+03, 2.6520e+03, 2.7890e+03, 3.1100e+03,\n",
       "        3.1590e+03, 3.3720e+03, 3.8150e+03, 4.0140e+03, 4.1220e+03,\n",
       "        4.4520e+03, 4.7640e+03, 5.1110e+03, 5.3900e+03, 5.5610e+03,\n",
       "        6.0670e+03, 6.3490e+03, 6.6230e+03, 6.9880e+03, 7.5210e+03,\n",
       "        7.6950e+03, 8.0970e+03, 8.3660e+03, 8.7070e+03, 8.8630e+03,\n",
       "        9.3820e+03, 9.8350e+03, 1.0043e+04, 1.0194e+04, 1.0760e+04,\n",
       "        1.0811e+04, 1.1301e+04, 1.1517e+04, 1.1862e+04, 1.1997e+04,\n",
       "        1.2416e+04, 1.2351e+04, 1.2732e+04, 1.2804e+04, 1.2878e+04,\n",
       "        1.3026e+04, 1.2794e+04, 1.3191e+04, 1.3016e+04, 1.2631e+04,\n",
       "        1.2604e+04, 1.2951e+04, 1.2558e+04, 1.2625e+04, 1.2600e+04,\n",
       "        1.2459e+04, 1.2040e+04, 1.1962e+04, 1.1664e+04, 1.1549e+04,\n",
       "        1.1223e+04, 1.0850e+04, 1.0894e+04, 1.0599e+04, 1.0882e+04,\n",
       "        1.1560e+04, 1.2767e+04, 1.4623e+04, 1.6406e+04, 1.8027e+04,\n",
       "        1.9168e+04, 1.8800e+04, 1.8546e+04, 1.7117e+04, 1.5577e+04,\n",
       "        1.3521e+04, 1.2009e+04, 1.0735e+04, 9.2770e+03, 8.4540e+03,\n",
       "        7.5140e+03, 7.0140e+03, 6.3890e+03, 5.9660e+03, 5.7870e+03,\n",
       "        5.4920e+03, 5.6630e+03, 5.3110e+03, 5.1110e+03, 4.9440e+03,\n",
       "        4.7060e+03, 4.2290e+03, 4.0720e+03, 3.6710e+03, 3.5560e+03,\n",
       "        3.4760e+03, 3.2790e+03, 3.2850e+03, 3.0250e+03, 2.8910e+03,\n",
       "        2.8020e+03, 2.5320e+03, 2.5300e+03, 2.5320e+03, 2.2760e+03,\n",
       "        2.1650e+03, 2.1420e+03, 2.0230e+03, 1.9210e+03, 1.8440e+03,\n",
       "        1.7630e+03, 1.6900e+03, 1.5890e+03, 1.5970e+03, 1.4740e+03,\n",
       "        1.3810e+03, 1.4110e+03, 1.2680e+03, 1.1690e+03, 1.1830e+03,\n",
       "        1.1620e+03, 1.0460e+03, 1.0350e+03, 9.7200e+02, 9.4700e+02,\n",
       "        9.1100e+02, 8.3400e+02, 7.1600e+02, 7.4200e+02, 7.5300e+02,\n",
       "        7.6200e+02, 7.0300e+02, 6.3100e+02, 6.4900e+02, 6.5500e+02,\n",
       "        6.4000e+02, 5.8800e+02, 6.0200e+02, 5.8400e+02, 5.8000e+02,\n",
       "        4.9800e+02, 4.7800e+02, 5.0800e+02, 5.2600e+02, 5.0300e+02,\n",
       "        4.6600e+02, 4.8900e+02, 5.0700e+02, 4.9200e+02, 5.0300e+02,\n",
       "        4.2200e+02, 4.6800e+02, 4.9400e+02, 4.7800e+02, 4.1300e+02,\n",
       "        4.6800e+02, 4.4300e+02, 4.6500e+02, 4.7200e+02, 5.2400e+02,\n",
       "        5.1200e+02, 4.7000e+02, 4.3300e+02, 4.8100e+02, 5.2100e+02,\n",
       "        4.5500e+02, 4.9800e+02, 5.0900e+02, 4.5500e+02, 4.4900e+02,\n",
       "        5.0700e+02, 4.6500e+02, 4.6500e+02, 4.2000e+02, 4.4500e+02,\n",
       "        4.3000e+02, 4.9500e+02, 4.7000e+02, 4.1600e+02, 4.8800e+02,\n",
       "        4.5300e+02, 4.5500e+02, 4.1600e+02, 4.9100e+02, 4.4600e+02,\n",
       "        4.7300e+02, 3.9100e+02, 4.6500e+02, 4.2500e+02, 4.3800e+02,\n",
       "        4.1900e+02, 4.1500e+02, 4.2300e+02, 4.3500e+02, 3.9400e+02,\n",
       "        4.0100e+02, 3.7500e+02, 4.0700e+02, 3.2600e+02, 3.5400e+02,\n",
       "        3.6300e+02, 3.9400e+02, 3.8000e+02, 3.4900e+02, 3.8300e+02,\n",
       "        3.6900e+02, 3.6100e+02, 3.6000e+02, 3.0800e+02, 3.4500e+02,\n",
       "        3.3200e+02, 3.4700e+02, 3.4600e+02, 3.1000e+02, 3.3400e+02,\n",
       "        3.2000e+02, 3.0700e+02, 2.8900e+02, 2.6700e+02, 2.9600e+02,\n",
       "        2.5900e+02, 2.8700e+02, 3.1000e+02, 2.3300e+02, 2.5000e+02,\n",
       "        2.3600e+02, 2.4200e+02, 2.5400e+02, 2.1900e+02, 2.5500e+02,\n",
       "        2.3500e+02, 1.8200e+02, 2.3700e+02, 2.1100e+02, 1.9500e+02,\n",
       "        2.2500e+02, 1.9700e+02, 1.8200e+02, 1.7700e+02, 2.0200e+02,\n",
       "        1.8500e+02, 2.0800e+02, 2.0000e+02, 1.8400e+02, 2.0800e+02,\n",
       "        1.8700e+02, 1.6100e+02, 1.7300e+02, 1.6100e+02, 1.5200e+02,\n",
       "        1.2400e+02, 1.2000e+02, 1.6600e+02, 1.4100e+02, 1.2000e+02,\n",
       "        1.6500e+02, 1.4100e+02, 1.5100e+02, 1.3400e+02, 1.1000e+02,\n",
       "        1.1300e+02, 1.1100e+02, 1.0400e+02, 1.2400e+02, 1.2200e+02,\n",
       "        1.2000e+02, 9.3000e+01, 9.9000e+01, 1.1800e+02, 8.7000e+01,\n",
       "        1.2900e+02, 9.9000e+01, 9.1000e+01, 8.9000e+01, 7.9000e+01,\n",
       "        8.5000e+01, 7.9000e+01, 5.1000e+01, 7.0000e+01, 7.4000e+01,\n",
       "        7.5000e+01, 6.9000e+01, 5.7000e+01, 7.2000e+01, 6.4000e+01,\n",
       "        5.0000e+01, 5.8000e+01, 7.1000e+01, 6.0000e+01, 4.7000e+01,\n",
       "        4.3000e+01, 6.4000e+01, 4.2000e+01, 3.7000e+01, 4.7000e+01,\n",
       "        4.2000e+01, 4.1000e+01, 4.1000e+01, 3.4000e+01, 4.0000e+01,\n",
       "        3.7000e+01, 3.4000e+01, 2.9000e+01, 2.3000e+01, 4.3000e+01,\n",
       "        2.4000e+01, 2.3000e+01, 3.6000e+01, 2.5000e+01, 2.6000e+01,\n",
       "        2.6000e+01, 1.8000e+01, 2.8000e+01, 3.2000e+01, 1.4000e+01,\n",
       "        2.4000e+01, 2.3000e+01, 2.0000e+01, 2.0000e+01, 1.8000e+01,\n",
       "        8.0000e+00, 1.2000e+01, 2.4000e+01, 1.2000e+01, 1.2000e+01,\n",
       "        1.9000e+01, 8.0000e+00, 1.0000e+01, 1.4000e+01, 9.0000e+00,\n",
       "        1.9000e+01, 8.0000e+00, 1.8000e+01, 1.0000e+01, 1.3000e+01,\n",
       "        7.0000e+00, 7.0000e+00, 9.0000e+00, 5.0000e+00, 1.3000e+01,\n",
       "        0.0000e+00, 1.0000e+01, 5.0000e+00, 2.0000e+00, 8.0000e+00,\n",
       "        3.0000e+00, 5.0000e+00, 2.0000e+00, 7.0000e+00, 3.0000e+00,\n",
       "        5.0000e+00, 1.0000e+00, 1.0000e+00, 2.0000e+00, 2.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 5.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        2.0000e+00, 4.0000e+00, 5.0000e+00, 5.0000e+00, 3.0000e+00,\n",
       "        4.0000e+00, 2.0000e+00, 0.0000e+00, 3.0000e+00, 7.0000e+00,\n",
       "        1.0000e+00, 2.0000e+00, 3.0000e+00, 5.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([-4.94370000e+00, -4.91102380e+00, -4.87834760e+00, -4.84567140e+00,\n",
       "        -4.81299520e+00, -4.78031900e+00, -4.74764280e+00, -4.71496660e+00,\n",
       "        -4.68229040e+00, -4.64961420e+00, -4.61693800e+00, -4.58426180e+00,\n",
       "        -4.55158560e+00, -4.51890940e+00, -4.48623320e+00, -4.45355700e+00,\n",
       "        -4.42088080e+00, -4.38820460e+00, -4.35552840e+00, -4.32285220e+00,\n",
       "        -4.29017600e+00, -4.25749980e+00, -4.22482360e+00, -4.19214740e+00,\n",
       "        -4.15947120e+00, -4.12679500e+00, -4.09411880e+00, -4.06144260e+00,\n",
       "        -4.02876640e+00, -3.99609020e+00, -3.96341400e+00, -3.93073780e+00,\n",
       "        -3.89806160e+00, -3.86538540e+00, -3.83270920e+00, -3.80003300e+00,\n",
       "        -3.76735680e+00, -3.73468060e+00, -3.70200440e+00, -3.66932820e+00,\n",
       "        -3.63665200e+00, -3.60397580e+00, -3.57129960e+00, -3.53862340e+00,\n",
       "        -3.50594720e+00, -3.47327100e+00, -3.44059480e+00, -3.40791860e+00,\n",
       "        -3.37524240e+00, -3.34256620e+00, -3.30989000e+00, -3.27721380e+00,\n",
       "        -3.24453760e+00, -3.21186140e+00, -3.17918520e+00, -3.14650900e+00,\n",
       "        -3.11383280e+00, -3.08115660e+00, -3.04848040e+00, -3.01580420e+00,\n",
       "        -2.98312800e+00, -2.95045180e+00, -2.91777560e+00, -2.88509940e+00,\n",
       "        -2.85242320e+00, -2.81974700e+00, -2.78707080e+00, -2.75439460e+00,\n",
       "        -2.72171840e+00, -2.68904220e+00, -2.65636600e+00, -2.62368980e+00,\n",
       "        -2.59101360e+00, -2.55833740e+00, -2.52566120e+00, -2.49298500e+00,\n",
       "        -2.46030880e+00, -2.42763260e+00, -2.39495640e+00, -2.36228020e+00,\n",
       "        -2.32960400e+00, -2.29692780e+00, -2.26425160e+00, -2.23157540e+00,\n",
       "        -2.19889920e+00, -2.16622300e+00, -2.13354680e+00, -2.10087060e+00,\n",
       "        -2.06819440e+00, -2.03551820e+00, -2.00284200e+00, -1.97016580e+00,\n",
       "        -1.93748960e+00, -1.90481340e+00, -1.87213720e+00, -1.83946100e+00,\n",
       "        -1.80678480e+00, -1.77410860e+00, -1.74143240e+00, -1.70875620e+00,\n",
       "        -1.67608000e+00, -1.64340380e+00, -1.61072760e+00, -1.57805140e+00,\n",
       "        -1.54537520e+00, -1.51269900e+00, -1.48002280e+00, -1.44734660e+00,\n",
       "        -1.41467040e+00, -1.38199420e+00, -1.34931800e+00, -1.31664180e+00,\n",
       "        -1.28396560e+00, -1.25128940e+00, -1.21861320e+00, -1.18593700e+00,\n",
       "        -1.15326080e+00, -1.12058460e+00, -1.08790840e+00, -1.05523220e+00,\n",
       "        -1.02255600e+00, -9.89879800e-01, -9.57203600e-01, -9.24527400e-01,\n",
       "        -8.91851200e-01, -8.59175000e-01, -8.26498800e-01, -7.93822600e-01,\n",
       "        -7.61146400e-01, -7.28470200e-01, -6.95794000e-01, -6.63117800e-01,\n",
       "        -6.30441600e-01, -5.97765400e-01, -5.65089200e-01, -5.32413000e-01,\n",
       "        -4.99736800e-01, -4.67060600e-01, -4.34384400e-01, -4.01708200e-01,\n",
       "        -3.69032000e-01, -3.36355800e-01, -3.03679600e-01, -2.71003400e-01,\n",
       "        -2.38327200e-01, -2.05651000e-01, -1.72974800e-01, -1.40298600e-01,\n",
       "        -1.07622400e-01, -7.49462000e-02, -4.22700000e-02, -9.59380000e-03,\n",
       "         2.30824000e-02,  5.57586000e-02,  8.84348000e-02,  1.21111000e-01,\n",
       "         1.53787200e-01,  1.86463400e-01,  2.19139600e-01,  2.51815800e-01,\n",
       "         2.84492000e-01,  3.17168200e-01,  3.49844400e-01,  3.82520600e-01,\n",
       "         4.15196800e-01,  4.47873000e-01,  4.80549200e-01,  5.13225400e-01,\n",
       "         5.45901600e-01,  5.78577800e-01,  6.11254000e-01,  6.43930200e-01,\n",
       "         6.76606400e-01,  7.09282600e-01,  7.41958800e-01,  7.74635000e-01,\n",
       "         8.07311200e-01,  8.39987400e-01,  8.72663600e-01,  9.05339800e-01,\n",
       "         9.38016000e-01,  9.70692200e-01,  1.00336840e+00,  1.03604460e+00,\n",
       "         1.06872080e+00,  1.10139700e+00,  1.13407320e+00,  1.16674940e+00,\n",
       "         1.19942560e+00,  1.23210180e+00,  1.26477800e+00,  1.29745420e+00,\n",
       "         1.33013040e+00,  1.36280660e+00,  1.39548280e+00,  1.42815900e+00,\n",
       "         1.46083520e+00,  1.49351140e+00,  1.52618760e+00,  1.55886380e+00,\n",
       "         1.59154000e+00,  1.62421620e+00,  1.65689240e+00,  1.68956860e+00,\n",
       "         1.72224480e+00,  1.75492100e+00,  1.78759720e+00,  1.82027340e+00,\n",
       "         1.85294960e+00,  1.88562580e+00,  1.91830200e+00,  1.95097820e+00,\n",
       "         1.98365440e+00,  2.01633060e+00,  2.04900680e+00,  2.08168300e+00,\n",
       "         2.11435920e+00,  2.14703540e+00,  2.17971160e+00,  2.21238780e+00,\n",
       "         2.24506400e+00,  2.27774020e+00,  2.31041640e+00,  2.34309260e+00,\n",
       "         2.37576880e+00,  2.40844500e+00,  2.44112120e+00,  2.47379740e+00,\n",
       "         2.50647360e+00,  2.53914980e+00,  2.57182600e+00,  2.60450220e+00,\n",
       "         2.63717840e+00,  2.66985460e+00,  2.70253080e+00,  2.73520700e+00,\n",
       "         2.76788320e+00,  2.80055940e+00,  2.83323560e+00,  2.86591180e+00,\n",
       "         2.89858800e+00,  2.93126420e+00,  2.96394040e+00,  2.99661660e+00,\n",
       "         3.02929280e+00,  3.06196900e+00,  3.09464520e+00,  3.12732140e+00,\n",
       "         3.15999760e+00,  3.19267380e+00,  3.22535000e+00,  3.25802620e+00,\n",
       "         3.29070240e+00,  3.32337860e+00,  3.35605480e+00,  3.38873100e+00,\n",
       "         3.42140720e+00,  3.45408340e+00,  3.48675960e+00,  3.51943580e+00,\n",
       "         3.55211200e+00,  3.58478820e+00,  3.61746440e+00,  3.65014060e+00,\n",
       "         3.68281680e+00,  3.71549300e+00,  3.74816920e+00,  3.78084540e+00,\n",
       "         3.81352160e+00,  3.84619780e+00,  3.87887400e+00,  3.91155020e+00,\n",
       "         3.94422640e+00,  3.97690260e+00,  4.00957880e+00,  4.04225500e+00,\n",
       "         4.07493120e+00,  4.10760740e+00,  4.14028360e+00,  4.17295980e+00,\n",
       "         4.20563600e+00,  4.23831220e+00,  4.27098840e+00,  4.30366460e+00,\n",
       "         4.33634080e+00,  4.36901700e+00,  4.40169320e+00,  4.43436940e+00,\n",
       "         4.46704560e+00,  4.49972180e+00,  4.53239800e+00,  4.56507420e+00,\n",
       "         4.59775040e+00,  4.63042660e+00,  4.66310280e+00,  4.69577900e+00,\n",
       "         4.72845520e+00,  4.76113140e+00,  4.79380760e+00,  4.82648380e+00,\n",
       "         4.85916000e+00,  4.89183620e+00,  4.92451240e+00,  4.95718860e+00,\n",
       "         4.98986480e+00,  5.02254100e+00,  5.05521720e+00,  5.08789340e+00,\n",
       "         5.12056960e+00,  5.15324580e+00,  5.18592200e+00,  5.21859820e+00,\n",
       "         5.25127440e+00,  5.28395060e+00,  5.31662680e+00,  5.34930300e+00,\n",
       "         5.38197920e+00,  5.41465540e+00,  5.44733160e+00,  5.48000780e+00,\n",
       "         5.51268400e+00,  5.54536020e+00,  5.57803640e+00,  5.61071260e+00,\n",
       "         5.64338880e+00,  5.67606500e+00,  5.70874120e+00,  5.74141740e+00,\n",
       "         5.77409360e+00,  5.80676980e+00,  5.83944600e+00,  5.87212220e+00,\n",
       "         5.90479840e+00,  5.93747460e+00,  5.97015080e+00,  6.00282700e+00,\n",
       "         6.03550320e+00,  6.06817940e+00,  6.10085560e+00,  6.13353180e+00,\n",
       "         6.16620800e+00,  6.19888420e+00,  6.23156040e+00,  6.26423660e+00,\n",
       "         6.29691280e+00,  6.32958900e+00,  6.36226520e+00,  6.39494140e+00,\n",
       "         6.42761760e+00,  6.46029380e+00,  6.49297000e+00,  6.52564620e+00,\n",
       "         6.55832240e+00,  6.59099860e+00,  6.62367480e+00,  6.65635100e+00,\n",
       "         6.68902720e+00,  6.72170340e+00,  6.75437960e+00,  6.78705580e+00,\n",
       "         6.81973200e+00,  6.85240820e+00,  6.88508440e+00,  6.91776060e+00,\n",
       "         6.95043680e+00,  6.98311300e+00,  7.01578920e+00,  7.04846540e+00,\n",
       "         7.08114160e+00,  7.11381780e+00,  7.14649400e+00,  7.17917020e+00,\n",
       "         7.21184640e+00,  7.24452260e+00,  7.27719880e+00,  7.30987500e+00,\n",
       "         7.34255120e+00,  7.37522740e+00,  7.40790360e+00,  7.44057980e+00,\n",
       "         7.47325600e+00,  7.50593220e+00,  7.53860840e+00,  7.57128460e+00,\n",
       "         7.60396080e+00,  7.63663700e+00,  7.66931320e+00,  7.70198940e+00,\n",
       "         7.73466560e+00,  7.76734180e+00,  7.80001800e+00,  7.83269420e+00,\n",
       "         7.86537040e+00,  7.89804660e+00,  7.93072280e+00,  7.96339900e+00,\n",
       "         7.99607520e+00,  8.02875140e+00,  8.06142760e+00,  8.09410380e+00,\n",
       "         8.12678000e+00,  8.15945620e+00,  8.19213240e+00,  8.22480860e+00,\n",
       "         8.25748480e+00,  8.29016100e+00,  8.32283720e+00,  8.35551340e+00,\n",
       "         8.38818960e+00,  8.42086580e+00,  8.45354200e+00,  8.48621820e+00,\n",
       "         8.51889440e+00,  8.55157060e+00,  8.58424680e+00,  8.61692300e+00,\n",
       "         8.64959920e+00,  8.68227540e+00,  8.71495160e+00,  8.74762780e+00,\n",
       "         8.78030400e+00,  8.81298020e+00,  8.84565640e+00,  8.87833260e+00,\n",
       "         8.91100880e+00,  8.94368500e+00,  8.97636120e+00,  9.00903740e+00,\n",
       "         9.04171360e+00,  9.07438980e+00,  9.10706600e+00,  9.13974220e+00,\n",
       "         9.17241840e+00,  9.20509460e+00,  9.23777080e+00,  9.27044700e+00,\n",
       "         9.30312320e+00,  9.33579940e+00,  9.36847560e+00,  9.40115180e+00,\n",
       "         9.43382800e+00,  9.46650420e+00,  9.49918040e+00,  9.53185660e+00,\n",
       "         9.56453280e+00,  9.59720900e+00,  9.62988520e+00,  9.66256140e+00,\n",
       "         9.69523760e+00,  9.72791380e+00,  9.76059000e+00,  9.79326620e+00,\n",
       "         9.82594240e+00,  9.85861860e+00,  9.89129480e+00,  9.92397100e+00,\n",
       "         9.95664720e+00,  9.98932340e+00,  1.00219996e+01,  1.00546758e+01,\n",
       "         1.00873520e+01,  1.01200282e+01,  1.01527044e+01,  1.01853806e+01,\n",
       "         1.02180568e+01,  1.02507330e+01,  1.02834092e+01,  1.03160854e+01,\n",
       "         1.03487616e+01,  1.03814378e+01,  1.04141140e+01,  1.04467902e+01,\n",
       "         1.04794664e+01,  1.05121426e+01,  1.05448188e+01,  1.05774950e+01,\n",
       "         1.06101712e+01,  1.06428474e+01,  1.06755236e+01,  1.07081998e+01,\n",
       "         1.07408760e+01,  1.07735522e+01,  1.08062284e+01,  1.08389046e+01,\n",
       "         1.08715808e+01,  1.09042570e+01,  1.09369332e+01,  1.09696094e+01,\n",
       "         1.10022856e+01,  1.10349618e+01,  1.10676380e+01,  1.11003142e+01,\n",
       "         1.11329904e+01,  1.11656666e+01,  1.11983428e+01,  1.12310190e+01,\n",
       "         1.12636952e+01,  1.12963714e+01,  1.13290476e+01,  1.13617238e+01,\n",
       "         1.13944000e+01]),\n",
       " <a list of 500 Patch objects>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "len(score_list)\n",
    "\n",
    "plt.hist(score_list, bins=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use asnorm TH to set testing TH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "TH = 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_spk_out = '/workspace/DATASET/server9_ssd/PVTC20/task1/spk_scores_as2.txt'\n",
    "final_spk_out_tune = '/workspace/DATASET/server9_ssd/PVTC20/task1/spk_tune_out_as.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(final_spk_out, 'r') as f:\n",
    "    ori_out = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PVTC_task1_0001.wav PVTC_task1_0002.wav PVTC_task1_0003.wav PVTC_task1_0004.wav 3.6198\\n'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(final_spk_out_tune, 'w') as f:\n",
    "    for line in ori_out:\n",
    "        line = line[:-1]\n",
    "        score = float(line.split(' ')[-1])\n",
    "        if score > TH:\n",
    "            score = 1\n",
    "        else:\n",
    "            score = 0\n",
    "        data = line.split(' ')\n",
    "        f.write(data[0]+' '+data[1]+' '+data[2]+' '+data[3]+' '+str(score)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
