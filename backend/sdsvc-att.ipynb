{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import traceback\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fft = librosa.get_fftlib()\n",
    "class VoxIterableDataset(object):\n",
    "    def __init__(self, data_dir_dict, data_len_dict, config):        \n",
    "        with open(data_dir_dict['spk2utt_train_dict'], 'rb') as handle:\n",
    "            self.spk2utt_train_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['music_dict'], 'rb') as handle:\n",
    "            self.music_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['noise_dict'], 'rb') as handle:\n",
    "            self.noise_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['babble_dict'], 'rb') as handle:\n",
    "            self.babble_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['rir_dict'], 'rb') as handle:\n",
    "            self.rir_dict = pickle.load(handle)\n",
    "            \n",
    "        with open(data_len_dict['spk2utt_train_len'], 'rb') as handle:\n",
    "            self.spk2utt_train_len = pickle.load(handle)\n",
    "        with open(data_len_dict['music_len'], 'rb') as handle:\n",
    "            self.music_len = pickle.load(handle)\n",
    "        with open(data_len_dict['noise_len'], 'rb') as handle:\n",
    "            self.noise_len = pickle.load(handle)\n",
    "        with open(data_len_dict['babble_len'], 'rb') as handle:\n",
    "            self.babble_len = pickle.load(handle)\n",
    "        \n",
    "        \n",
    "        self.random_spkrs_batchlist = None\n",
    "        self.ramdom_batch_len = None\n",
    "        self.random_noise_type = None\n",
    "        \n",
    "        \n",
    "        self.possible_babble_num = [3, 4, 5, 6, 7]\n",
    "        self.possible_babble_snr = [13, 15, 17, 20]\n",
    "        self.possible_noise_snr = [0, 5, 10, 15]\n",
    "        self.possible_music_snr = [5, 8, 10, 15]\n",
    "        \n",
    "        self.sr = config['sr']\n",
    "        self.repeats = config['repeats']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.extended_prefectch = config['extended_prefectch']\n",
    "        \n",
    "        self.mfcc_dim = 30\n",
    "        \n",
    "        # Auxiliary paras\n",
    "        self.multi_read_count = 0\n",
    "        self.preload_mem = False\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        assert len(self.ramdom_batch_len) == len(self.random_spkrs_batchlist)\n",
    "        try:\n",
    "            batch_frame_len = self.ramdom_batch_len.pop(0)\n",
    "            batch_spkrs = self.random_spkrs_batchlist.pop(0)\n",
    "            batch_noise_type = self.random_noise_type.pop(0)\n",
    "            batched_feats = np.zeros([self.batch_size, batch_frame_len, self.mfcc_dim])\n",
    "            batched_labels = np.zeros(self.batch_size)\n",
    "            \n",
    "            for batch_index, (spkr, noise_type) in enumerate(zip(batch_spkrs, batch_noise_type)):\n",
    "                \n",
    "                concat_wav, VAD_result = self._colleting_and_slicing(spkr, batch_frame_len,\\\n",
    "                hop_len=160, extended_prefectch=self.extended_prefectch)\n",
    "            \n",
    "                \n",
    "                if noise_type == 0:\n",
    "                    aug_wav = concat_wav\n",
    "                \n",
    "                elif noise_type == 1:\n",
    "                    aug_wav = self._add_rebverb(concat_wav)\n",
    "                   \n",
    "                elif noise_type == 2:\n",
    "                    aug_wav = self._add_noise(concat_wav)\n",
    "                    \n",
    "                elif noise_type == 3:\n",
    "                    aug_wav = self._add_music(concat_wav)\n",
    "                  \n",
    "                elif noise_type == 4:\n",
    "                    aug_wav = self._add_babble(concat_wav)\n",
    "             \n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                    \n",
    "            \n",
    "                single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "                dct_type=2, n_fft=512, hop_length=160, \\\n",
    "                win_length=None, window='hann', power=2.0, \\\n",
    "                center=True, pad_mode='reflect', n_mels=30, \\\n",
    "                fmin=20, fmax=7600)\n",
    "                # Note single_feats needs transpose\n",
    "                out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "                # Apply VAD\n",
    "                assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "                out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "                batched_feats[batch_index] = out_feats[:batch_frame_len]\n",
    "                batched_labels[batch_index] = spkr\n",
    "                \n",
    "            return batched_feats, batched_labels\n",
    "        \n",
    "        except IndexError:\n",
    "            raise StopIteration\n",
    "\n",
    "    def process_one_utt(self, utt_dir):\n",
    "        try:\n",
    "            concat_wav, _ = librosa.load(utt_dir, sr=self.sr)\n",
    "            \n",
    "            VAD_result = self._VAD_detection(concat_wav)\n",
    "            \n",
    "            aug_wav = concat_wav\n",
    "\n",
    "            single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "            dct_type=2, n_fft=512, hop_length=160, \\\n",
    "            win_length=None, window='hann', power=2.0, \\\n",
    "            center=True, pad_mode='reflect', n_mels=30, \\\n",
    "            fmin=20, fmax=7600)\n",
    "            # Note single_feats needs transpose\n",
    "            out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "            # Apply VAD\n",
    "            assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "            out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "            \n",
    "            batched_feats = out_feats[None, :, :]\n",
    "                \n",
    "            return batched_feats\n",
    "        \n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def process_one_utt_noVAD(self, utt_dir):\n",
    "        try:\n",
    "            concat_wav, _ = librosa.load(utt_dir, sr=self.sr)\n",
    "            \n",
    "            aug_wav = concat_wav\n",
    "\n",
    "            single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "            dct_type=2, n_fft=512, hop_length=160, \\\n",
    "            win_length=None, window='hann', power=2.0, \\\n",
    "            center=True, pad_mode='reflect', n_mels=30, \\\n",
    "            fmin=20, fmax=7600)\n",
    "            # Note single_feats needs transpose\n",
    "            out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "            \n",
    "            batched_feats = out_feats[None, :, :]\n",
    "                \n",
    "            return batched_feats\n",
    "        \n",
    "        except Exception:\n",
    "            traceback.print_exc()            \n",
    "    \n",
    "    def noise_data_preload(self):\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            _, _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            _, _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            _, _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "    \n",
    "    def noise_data_preload2mem(self):\n",
    "        print('preloading to memory')\n",
    "        \n",
    "        self.music_preload_dict = {}\n",
    "        self.noise_preload_dict = {}\n",
    "        self.babble_preload_dict = {}\n",
    "        self.preload_mem = True\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            self.music_preload_dict[i], _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            self.noise_preload_dict[i], _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            self.babble_preload_dict[i], _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)       \n",
    "        \n",
    "        \n",
    "    def get_random_list(self):\n",
    "        spkrs_list = self.repeats * list(self.spk2utt_train_dict.keys())\n",
    "        random.shuffle(spkrs_list)\n",
    "        len_spkrs_list = len(spkrs_list)\n",
    "        self.random_spkrs_batchlist = [spkrs_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        self.ramdom_batch_len = [random.randint(200, 400) for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        noise_type_list = [i%5 for i in range(len_spkrs_list)]\n",
    "\n",
    "        random.shuffle(noise_type_list)\n",
    "        self.random_noise_type = [noise_type_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        assert len(self.random_spkrs_batchlist) == len(self.ramdom_batch_len)\\\n",
    "        == len(self.random_noise_type)\n",
    "        \n",
    "    def _colleting_and_slicing(self, spkr, batch_frame_len, hop_len=160, extended_prefectch=2.0):\n",
    "        \n",
    "        least_wav_len = (batch_frame_len - 1) * hop_len\n",
    "        concat_utt = np.zeros(0)\n",
    "        valid_frames_len = 0\n",
    "        \n",
    "        # Use to count multi_read_count\n",
    "        get_count = 0\n",
    "\n",
    "        while valid_frames_len < batch_frame_len:\n",
    "            concat_utt = np.zeros(0)\n",
    "\n",
    "            utt_dir = self._get_random_spk_utt(spkr, self.spk2utt_train_dict)\n",
    "            utt_len = self.spk2utt_train_len[utt_dir]\n",
    "#             off = self._get_random_offset(least_wav_len, utt_len) / self.sr\n",
    "            off = self._get_random_offset(least_wav_len+extended_prefectch*self.sr, utt_len) / self.sr\n",
    "            dur = least_wav_len / self.sr + extended_prefectch\n",
    "            \n",
    "            utt_part, _ = librosa.load(utt_dir, sr=self.sr, offset=off, duration=dur)\n",
    "            \n",
    "            concat_utt = np.append(concat_utt, utt_part)\n",
    "            detected_frames = self._VAD_detection(concat_utt)\n",
    "            valid_frames_len = np.sum(detected_frames)\n",
    "\n",
    "            get_count += 1\n",
    "\n",
    "        if get_count > 1:\n",
    "            self.multi_read_count += 1\n",
    "\n",
    "        VAD_result = detected_frames\n",
    "        return concat_utt, VAD_result\n",
    "    \n",
    "    def _add_rebverb(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = in_wav\n",
    "        filter_dir = self._get_random_noise(self.rir_dict)\n",
    "        filter, _ = librosa.load(filter_dir, sr=self.sr)\n",
    "        \n",
    "        signal_length = len(signal)\n",
    "        filter_length = len(filter)\n",
    "        output_length = signal_length + filter_length - 1\n",
    "        output = np.zeros(output_length)\n",
    "\n",
    "        fft_length = 2**np.ceil(np.log2(4 * filter_length)).astype(np.int)\n",
    "        block_length = fft_length - filter_length + 1\n",
    "\n",
    "\n",
    "        filter_padded = np.zeros(fft_length)\n",
    "        filter_padded[0:filter_length] = filter\n",
    "        filter_padded = fft.rfft(filter_padded)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(signal_length//block_length + 1):\n",
    "            process_length = min(block_length, signal_length - i * block_length);\n",
    "            signal_block_padded = np.zeros(fft_length)\n",
    "            signal_block_padded[0:process_length] = signal[i * block_length : i * block_length + process_length]\n",
    "            signal_block_padded = fft.rfft(signal_block_padded)\n",
    "\n",
    "            signal_block_padded = filter_padded * signal_block_padded\n",
    "\n",
    "            signal_block_padded = fft.irfft(signal_block_padded, n=fft_length)\n",
    "\n",
    "            if (i*block_length + fft_length) <= output_length:\n",
    "                output[i*block_length : i*block_length + fft_length] += signal_block_padded\n",
    "            else:\n",
    "                output[i*block_length : output_length] += signal_block_padded[:output_length-i*block_length]\n",
    "        \n",
    "        # shift with max index of filter\n",
    "        shift_index = np.argmax(filter)\n",
    "        \n",
    "        final_out = output[shift_index:shift_index+signal_length]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_noise(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.noise_dict, return_index=True)\n",
    "            noise_len = self.noise_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "                \n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_noise_snr[random.randint(0, len(self.possible_noise_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_music(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.music_dict, return_index=True)\n",
    "            noise_len = self.music_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_music_snr[random.randint(0, len(self.possible_music_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_babble(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        signal_off = 0\n",
    "        bg_spks_num = self.possible_babble_num[random.randint(0, len(self.possible_babble_num)-1)]    \n",
    "        for _ in range(bg_spks_num):            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.babble_dict, return_index=True)\n",
    "            noise_len = self.babble_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_babble_snr[random.randint(0, len(self.possible_babble_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_db(self, in_wav, noise, signal_off, snr_db, power_before_reverb):\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "\n",
    "        noise_power = noise.dot(noise) / len(noise)\n",
    "        scale_factor = np.sqrt(10**(-snr_db / 10) * power_before_reverb / noise_power)\n",
    "        noise = scale_factor * noise\n",
    "\n",
    "        add_length = min(len(noise), len(signal)-signal_off)\n",
    "        signal[signal_off:signal_off+add_length] += noise[:add_length]\n",
    "        out_wav = signal      \n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _CMVN(self, in_feat, cmn_window = 300, normalize_variance = False):             \n",
    "        num_frames = in_feat.shape[0]\n",
    "        dim = in_feat.shape[1]\n",
    "        last_window_start = -1\n",
    "        last_window_end = -1\n",
    "        cur_sum = np.zeros(dim)\n",
    "        cur_sumsq = np.zeros(dim)\n",
    "\n",
    "        out_feat = np.zeros([num_frames, dim])\n",
    "\n",
    "        for t in range(num_frames):\n",
    "            window_start = 0\n",
    "            window_end = 0\n",
    "\n",
    "            window_start = t - int(cmn_window / 2)\n",
    "            window_end = window_start + cmn_window\n",
    "\n",
    "            if (window_start < 0):\n",
    "                window_end -= window_start\n",
    "                window_start = 0\n",
    "\n",
    "            if (window_end > num_frames):\n",
    "                window_start -= (window_end - num_frames)\n",
    "                window_end = num_frames\n",
    "                if (window_start < 0):\n",
    "                    window_start = 0\n",
    "\n",
    "            if (last_window_start == -1):\n",
    "                input_part = in_feat[window_start:window_end]\n",
    "                cur_sum = np.sum(input_part, axis=0, keepdims=False)\n",
    "                if normalize_variance:\n",
    "                    cur_sumsq = np.sum(input_part**2, axis=0, keepdims=False)\n",
    "            else:\n",
    "                if (window_start > last_window_start):\n",
    "                    frame_to_remove = in_feat[last_window_start]\n",
    "                    cur_sum -= frame_to_remove\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq -= frame_to_remove**2\n",
    "\n",
    "                if (window_end > last_window_end):\n",
    "                    frame_to_add = in_feat[last_window_end]\n",
    "                    cur_sum += frame_to_add\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq += frame_to_add**2\n",
    "\n",
    "            window_frames = window_end - window_start\n",
    "            last_window_start = window_start\n",
    "            last_window_end = window_end\n",
    "\n",
    "            out_feat[t] = in_feat[t] - (1.0 / window_frames) * cur_sum\n",
    "\n",
    "\n",
    "            if normalize_variance:\n",
    "                if (window_frames == 1):\n",
    "                    out_feat[t] = 0.0\n",
    "                else:\n",
    "                    variance = (1.0 / window_frames) * cur_sumsq - (1.0 / window_frames**2) * cur_sum**2\n",
    "                    variance = np.maximum(1.0e-10, variance)\n",
    "                    out_feat[t] /= variance**(0.5)\n",
    "                    \n",
    "        return out_feat\n",
    "\n",
    "    def _get_random_noise(self, noise_dict, return_index=False):\n",
    "        dict_len = len(noise_dict)\n",
    "        i = random.randint(0, dict_len-1)\n",
    "        noise_dir = noise_dict[i]\n",
    "        \n",
    "        if return_index:\n",
    "            return noise_dir, i\n",
    "        else:\n",
    "            return noise_dir\n",
    "    \n",
    "    def _get_random_spk_utt(self, spkr, spk2utt):\n",
    "        this_utts = spk2utt[spkr]\n",
    "        this_num_utts = len(this_utts)\n",
    "        i = random.randint(0, this_num_utts-1)\n",
    "        utt_dir = this_utts[i]\n",
    "        return utt_dir\n",
    "\n",
    "    def _get_random_offset(self, expected_length, utt_len):\n",
    "        if expected_length > utt_len:\n",
    "            return 0\n",
    "        \n",
    "        free_length = utt_len - expected_length\n",
    "        offset = random.randint(0, free_length)\n",
    "        return offset\n",
    "        \n",
    "    @property\n",
    "    def _VAD_config(self):\n",
    "        vad_energy_threshold = -3.0\n",
    "        vad_energy_mean_scale = 1.0\n",
    "        vad_frames_context = 0\n",
    "        vad_proportion_threshold = 0.12\n",
    "        \n",
    "        return vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold\n",
    "        \n",
    "        \n",
    "    def _VAD_detection(self, wav):\n",
    "        vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold = self._VAD_config\n",
    "        \n",
    "        y_tmp = np.pad(wav, int(512 // 2), mode='reflect')\n",
    "        y_tmp = librosa.util.frame(y_tmp, frame_length=512, hop_length=160)\n",
    "        y_log_energy = np.log(np.maximum(np.sum(y_tmp**2, axis=0), 1e-15))\n",
    "\n",
    "        T = len(y_log_energy)\n",
    "        output_voiced = np.zeros(T)\n",
    "        if (T == 0):\n",
    "            raise Exception(\"zero wave length\")\n",
    "\n",
    "        energy_threshold = vad_energy_threshold\n",
    "        if (vad_energy_mean_scale != 0.0):\n",
    "            assert(vad_energy_mean_scale > 0.0)\n",
    "            energy_threshold += vad_energy_mean_scale * np.sum(y_log_energy) / T\n",
    "\n",
    "\n",
    "        assert(vad_frames_context >= 0)\n",
    "        assert(vad_proportion_threshold > 0.0 and vad_proportion_threshold < 1.0);\n",
    "\n",
    "        for t in range(T):\n",
    "            num_count = 0\n",
    "            den_count = 0\n",
    "            context = vad_frames_context\n",
    "            for t2 in range(t - context, t + context+1):\n",
    "                if (t2 >= 0 and t2 < T):\n",
    "                    den_count+=1\n",
    "                    if (y_log_energy[t2] > energy_threshold):\n",
    "                        num_count+=1\n",
    "\n",
    "            if (num_count >= den_count * vad_proportion_threshold):\n",
    "                output_voiced[t] = 1.0\n",
    "            else:\n",
    "                output_voiced[t] = 0.0\n",
    "        \n",
    "        return output_voiced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "data_dir_dict = {}\n",
    "\n",
    "# val\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(OPT_INDEX, 'spk2utt_val_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(OPT_INDEX, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(OPT_INDEX, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(OPT_INDEX, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(OPT_INDEX, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(OPT_INDEX, 'spk2utt_val_len')\n",
    "data_len_dict['music_len'] = os.path.join(OPT_INDEX, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(OPT_INDEX, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(OPT_INDEX, 'babble_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/task2_train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = {}\n",
    "with open('/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/docs/train_labels.txt', 'r') as f:\n",
    "    for count, line in enumerate(f):\n",
    "        if count == 0:\n",
    "            continue\n",
    "        line = line[:-1]\n",
    "        utt, label = line.split(' ')\n",
    "        train_labels[utt] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "1779.1428241729736\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = None\n",
    "config['batch_size'] = None\n",
    "config['extended_prefectch'] = None\n",
    "\n",
    "# trial_dict_dir = '/Lun0/zhiyong/dataset/trial_dict'\n",
    "\n",
    "def trial_data_preload(dataset, i, train_list, train_labels):\n",
    "        \n",
    "    for i, line in enumerate(train_list):\n",
    "        data = dataset.process_one_utt(line)\n",
    "        utt_label = line.split('/')[-1][:-4]\n",
    "        label = train_labels[utt_label]\n",
    "        with open('/Lun0/zhiyong/SdSV_2020_deepmine/train_mfcc/'+utt_label, 'wb') as handle:\n",
    "            pickle.dump((data.astype(np.float16), [label]), handle)\n",
    "        if ((i+1) % 1000) == 0:    \n",
    "            print(i+1)\n",
    "\n",
    "dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, train_list, train_labels)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process_enr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "data_dir_dict = {}\n",
    "\n",
    "# val\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(OPT_INDEX, 'spk2utt_val_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(OPT_INDEX, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(OPT_INDEX, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(OPT_INDEX, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(OPT_INDEX, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(OPT_INDEX, 'spk2utt_val_len')\n",
    "data_len_dict['music_len'] = os.path.join(OPT_INDEX, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(OPT_INDEX, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(OPT_INDEX, 'babble_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enr_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/wav/enrollment/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "1779.1428241729736\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = None\n",
    "config['batch_size'] = None\n",
    "config['extended_prefectch'] = None\n",
    "\n",
    "# trial_dict_dir = '/Lun0/zhiyong/dataset/trial_dict'\n",
    "\n",
    "def trial_data_preload(dataset, i, enr_list):\n",
    "        \n",
    "    for i, line in enumerate(enr_list):\n",
    "        data = dataset.process_one_utt(line)\n",
    "        label = line.split('/')[-1][:-4]\n",
    "        with open('/Lun0/zhiyong/SdSV_2020_deepmine/enr_mfcc/'+label, 'wb') as handle:\n",
    "            pickle.dump((data.astype(np.float16), [label]), handle)\n",
    "        if ((i+1) % 1000) == 0:    \n",
    "            print(i+1)\n",
    "\n",
    "dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, enr_list)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process_evl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "data_dir_dict = {}\n",
    "\n",
    "# val\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(OPT_INDEX, 'spk2utt_val_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(OPT_INDEX, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(OPT_INDEX, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(OPT_INDEX, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(OPT_INDEX, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(OPT_INDEX, 'spk2utt_val_len')\n",
    "data_len_dict['music_len'] = os.path.join(OPT_INDEX, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(OPT_INDEX, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(OPT_INDEX, 'babble_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evl_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/evaluation/wav/evaluation/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "502.18626618385315\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = None\n",
    "config['batch_size'] = None\n",
    "config['extended_prefectch'] = None\n",
    "\n",
    "# trial_dict_dir = '/Lun0/zhiyong/dataset/trial_dict'\n",
    "\n",
    "def trial_data_preload(dataset, i, evl_list):\n",
    "        \n",
    "    for i, line in enumerate(evl_list):\n",
    "        data = dataset.process_one_utt(line)\n",
    "        label = line.split('/')[-1][:-4]\n",
    "        with open('/Lun0/zhiyong/SdSV_2020_deepmine/evl_mfcc/'+label, 'wb') as handle:\n",
    "            pickle.dump((data.astype(np.float16), [label]), handle)\n",
    "        if ((i+1) % 1000) == 0:    \n",
    "            print(i+1)\n",
    "\n",
    "dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, evl_list)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = '/Lun0/zhiyong/SdSV_2020_deepmine/train_mfcc'\n",
    "expected_len = 85764\n",
    "workers = 1\n",
    "single_worker_len = int(expected_len / workers)\n",
    "output = '/Lun0/zhiyong/SdSV_2020_deepmine/train_mfcc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mfcc_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/train_mfcc/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert expected_len == len(train_mfcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(output, 'w') as f:\n",
    "    for i in train_mfcc_list:\n",
    "        path = i\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85764"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make enr index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = '/Lun0/zhiyong/SdSV_2020_deepmine/enr_mfcc'\n",
    "expected_len = 110673\n",
    "workers = 1\n",
    "single_worker_len = int(expected_len / workers)\n",
    "output = '/Lun0/zhiyong/SdSV_2020_deepmine/enr_mfcc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enr_mfcc_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/enr_mfcc/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert expected_len == len(enr_mfcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(output, 'w') as f:\n",
    "    for i in enr_mfcc_list:\n",
    "        path = i\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make evl index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = '/Lun0/zhiyong/SdSV_2020_deepmine/evl_mfcc'\n",
    "expected_len = 69542\n",
    "workers = 1\n",
    "single_worker_len = int(expected_len / workers)\n",
    "output = '/Lun0/zhiyong/SdSV_2020_deepmine/evl_mfcc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evl_mfcc_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/evl_mfcc/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert expected_len == len(evl_mfcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(output, 'w') as f:\n",
    "    for i in evl_mfcc_list:\n",
    "        path = i\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./train')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# import vox_model_bank\n",
    "from train import train_model_new\n",
    "from train.read_data import *\n",
    "from train.my_dataloader import *\n",
    "# from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = '/Lun2/rzz/kaldi-master/egs/zhiyong/sre19/exp/Standard_ETDNN/ckpt/e3s120106end.model'\n",
    "model_id = 'Standard_ETDNN'\n",
    "model_metric = 'AM_normfree_softmax_anneal_ce_head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "component_dir = './sdsvc_fullmix_etdnn3e'\n",
    "PLDA_DIM = 370\n",
    "PLDA_DATA_NAME = 'plda_data'\n",
    "TEST_DATA_NAME = 'test_data_370'\n",
    "PLDA_PARA_NAME = 'plda_para_370'\n",
    "SCORING_PLDA_NAME = 'score_plda_370'\n",
    "SCORING_COSINE_NAME = 'score_cosine_370'\n",
    "ENR_DATA_NAME = 'enr_data'\n",
    "EVL_DATA_NAME = 'evl_data'\n",
    "TRAIN_DATA_NAME = 'train_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(component_dir):\n",
    "    os.makedirs(component_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU multiprocess for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_p = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/plda_full_data.csv'\n",
    "train_list = '/Lun0/zhiyong/SdSV_2020_deepmine/train_mfcc.csv'\n",
    "# train_data = CSVDataSet(train_list)\n",
    "train_data = PickleDataSet(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_len = len(train_data)\n",
    "num_per_process = (85764 // num_p) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "class_list_new_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8571\n"
     ]
    }
   ],
   "source": [
    "data_m = []\n",
    "# class_list_new_m = []\n",
    "for i in range(num_p):\n",
    "    data = torch.utils.data.Subset(train_data, np.arange(i*num_per_process, min((i+1)*num_per_process, train_data_len)))\n",
    "    data_m.append(data)\n",
    "    class_list_new_m.append({})\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_m(i, train_data, class_list_new_m):\n",
    "#     train_list = '/Lun0/zhiyong/dataset/vox12_kaldi_train_data/vox12_kaldi_train_data.csv'\n",
    "    model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if i < 26:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(i%2)\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     torch.cuda.set_device(i%2)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     train_data = CSVDataSet(train_list)\n",
    "#     train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=False)\n",
    "\n",
    "    train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "    batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "    pin_memory=False, drop_last=False, timeout=0,\\\n",
    "    worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "    model = train_model_new.get_model(model_id, model_metric, None, model_settings, None)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    class_list_new = {}\n",
    "\n",
    "    for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = batch_x.to(device)\n",
    "        label = batch_y[0].split('-')[0]\n",
    "        batch_y = torch.tensor([0]).to(device)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "        except:\n",
    "            print('Proc', str(i), 'EER:', label)\n",
    "            continue\n",
    "    #     _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "        emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "        if label not in class_list_new.keys():\n",
    "            class_list_new[label] = emb[None, :]\n",
    "        else:\n",
    "            class_list_new[label] = np.append(class_list_new[label], emb[None, :], axis=0)\n",
    "\n",
    "        if (count+1) % 10000 == 0:\n",
    "            print('Proc '+ str(i) + ':' + str((count+1) // 10000))\n",
    "    \n",
    "    class_list_new_m[i] = class_list_new\n",
    "    del model, batch_x, batch_y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = [Process(target = extract_feature_m, args = (i, data_m[i], class_list_new_m)) for i in range(num_p)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new_m:\n",
    "    for j in i:\n",
    "        count += len(i[j])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_list_new = class_list_new_m[0]\n",
    "\n",
    "for count, this_list in enumerate(class_list_new_m):\n",
    "    if count == 0:\n",
    "        continue\n",
    "    for this_label in this_list:\n",
    "        if this_label not in class_list_new.keys():\n",
    "            class_list_new[this_label] = this_list[this_label]\n",
    "        else:\n",
    "            class_list_new[this_label] = np.append(class_list_new[this_label], this_list[this_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nanlist = []\n",
    "for i in class_list_new:\n",
    "    if np.isnan(class_list_new[i]).any():\n",
    "        print(i)\n",
    "        nanlist.append(i)\n",
    "for i in nanlist:\n",
    "    class_list_new.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85764"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+TRAIN_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(class_list_new, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU multiprocess for enr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_p = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/plda_full_data.csv'\n",
    "train_list = '/Lun0/zhiyong/SdSV_2020_deepmine/enr_mfcc.csv'\n",
    "# train_data = CSVDataSet(train_list)\n",
    "train_data = PickleDataSet(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_len = len(train_data)\n",
    "num_per_process = (110673 // num_p) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "class_list_new_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55337\n",
      "55336\n"
     ]
    }
   ],
   "source": [
    "data_m = []\n",
    "# class_list_new_m = []\n",
    "for i in range(num_p):\n",
    "    data = torch.utils.data.Subset(train_data, np.arange(i*num_per_process, min((i+1)*num_per_process, train_data_len)))\n",
    "    data_m.append(data)\n",
    "    class_list_new_m.append({})\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_m(i, train_data, class_list_new_m):\n",
    "#     train_list = '/Lun0/zhiyong/dataset/vox12_kaldi_train_data/vox12_kaldi_train_data.csv'\n",
    "    model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 10249, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if i < 26:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(i%2)\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     torch.cuda.set_device(i%2)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     train_data = CSVDataSet(train_list)\n",
    "#     train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=False)\n",
    "\n",
    "    train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "    batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "    pin_memory=False, drop_last=False, timeout=0,\\\n",
    "    worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "    model = train_model_new.get_model(model_id, model_metric, None, model_settings, None)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    class_list_new = {}\n",
    "\n",
    "    for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = batch_x.to(device)\n",
    "        label = batch_y[0].split('-')[0]\n",
    "        batch_y = torch.tensor([0]).to(device)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "        except:\n",
    "            print('Proc', str(i), 'EER:', label)\n",
    "            continue\n",
    "    #     _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "        emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "        if label not in class_list_new.keys():\n",
    "            class_list_new[label] = emb[None, :]\n",
    "        else:\n",
    "            class_list_new[label] = np.append(class_list_new[label], emb[None, :], axis=0)\n",
    "\n",
    "        if (count+1) % 10000 == 0:\n",
    "            print('Proc '+ str(i) + ':' + str((count+1) // 10000))\n",
    "    \n",
    "    class_list_new_m[i] = class_list_new\n",
    "    del model, batch_x, batch_y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Proc 4:1\n",
      "Proc 8:1\n",
      "Proc 0:1\n",
      "Proc 6:1\n",
      "Proc 2:1\n",
      "Proc 5:1\n",
      "Proc 7:1\n",
      "Proc 3:1\n",
      "Proc 9:1\n",
      "Proc 1:1\n"
     ]
    }
   ],
   "source": [
    "processes = [Process(target = extract_feature_m, args = (i, data_m[i], class_list_new_m)) for i in range(num_p)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new_m:\n",
    "    for j in i:\n",
    "        count += len(i[j])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_list_new = class_list_new_m[0]\n",
    "\n",
    "for count, this_list in enumerate(class_list_new_m):\n",
    "    if count == 0:\n",
    "        continue\n",
    "    for this_label in this_list:\n",
    "        if this_label not in class_list_new.keys():\n",
    "            class_list_new[this_label] = this_list[this_label]\n",
    "        else:\n",
    "            class_list_new[this_label] = np.append(class_list_new[this_label], this_list[this_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nanlist = []\n",
    "for i in class_list_new:\n",
    "    if np.isnan(class_list_new[i]).any():\n",
    "        print(i)\n",
    "        nanlist.append(i)\n",
    "for i in nanlist:\n",
    "    class_list_new.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+ENR_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(class_list_new, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU multiprocess for evl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_p = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/plda_full_data.csv'\n",
    "train_list = '/Lun0/zhiyong/SdSV_2020_deepmine/evl_mfcc.csv'\n",
    "# train_data = CSVDataSet(train_list)\n",
    "train_data = PickleDataSet(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_len = len(train_data)\n",
    "num_per_process = (69542 // num_p) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "class_list_new_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6947\n"
     ]
    }
   ],
   "source": [
    "data_m = []\n",
    "# class_list_new_m = []\n",
    "for i in range(num_p):\n",
    "    data = torch.utils.data.Subset(train_data, np.arange(i*num_per_process, min((i+1)*num_per_process, train_data_len)))\n",
    "    data_m.append(data)\n",
    "    class_list_new_m.append({})\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_m(i, train_data, class_list_new_m):\n",
    "#     train_list = '/Lun0/zhiyong/dataset/vox12_kaldi_train_data/vox12_kaldi_train_data.csv'\n",
    "    model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 10249, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if i < 26:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(i%2)\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     torch.cuda.set_device(i%2)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     train_data = CSVDataSet(train_list)\n",
    "#     train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=False)\n",
    "\n",
    "    train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "    batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "    pin_memory=False, drop_last=False, timeout=0,\\\n",
    "    worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "    model = train_model_new.get_model(model_id, model_metric, None, model_settings, None)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    class_list_new = {}\n",
    "\n",
    "    for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = batch_x.to(device)\n",
    "        label = batch_y[0].split('-')[0]\n",
    "        batch_y = torch.tensor([0]).to(device)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "        except:\n",
    "            print('Proc', str(i), 'EER:', label)\n",
    "            continue\n",
    "    #     _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "        emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "        if label not in class_list_new.keys():\n",
    "            class_list_new[label] = emb[None, :]\n",
    "        else:\n",
    "            class_list_new[label] = np.append(class_list_new[label], emb[None, :], axis=0)\n",
    "\n",
    "        if (count+1) % 10000 == 0:\n",
    "            print('Proc '+ str(i) + ':' + str((count+1) // 10000))\n",
    "    \n",
    "    class_list_new_m[i] = class_list_new\n",
    "    del model, batch_x, batch_y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n"
     ]
    }
   ],
   "source": [
    "processes = [Process(target = extract_feature_m, args = (i, data_m[i], class_list_new_m)) for i in range(num_p)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new_m:\n",
    "    for j in i:\n",
    "        count += len(i[j])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_list_new = class_list_new_m[0]\n",
    "\n",
    "for count, this_list in enumerate(class_list_new_m):\n",
    "    if count == 0:\n",
    "        continue\n",
    "    for this_label in this_list:\n",
    "        if this_label not in class_list_new.keys():\n",
    "            class_list_new[this_label] = this_list[this_label]\n",
    "        else:\n",
    "            class_list_new[this_label] = np.append(class_list_new[this_label], this_list[this_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nanlist = []\n",
    "for i in class_list_new:\n",
    "    if np.isnan(class_list_new[i]).any():\n",
    "        print(i)\n",
    "        nanlist.append(i)\n",
    "for i in nanlist:\n",
    "    class_list_new.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+EVL_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(class_list_new, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU multiprocess for plda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_p = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list = '/Lun0/zhiyong/dataset/plda_full_data.csv'\n",
    "# train_list = '/Lun0/zhiyong/dataset/plda_full_data_noVAD.csv'\n",
    "# train_data = CSVDataSet(train_list)\n",
    "train_data = PickleDataSet(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_len = len(train_data)\n",
    "num_per_process = (1276888 // num_p) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "class_list_new_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45580\n"
     ]
    }
   ],
   "source": [
    "data_m = []\n",
    "# class_list_new_m = []\n",
    "for i in range(num_p):\n",
    "    data = torch.utils.data.Subset(train_data, np.arange(i*num_per_process, min((i+1)*num_per_process, train_data_len)))\n",
    "    data_m.append(data)\n",
    "    class_list_new_m.append({})\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_m(i, train_data, class_list_new_m):\n",
    "#     train_list = '/Lun0/zhiyong/dataset/vox12_kaldi_train_data/vox12_kaldi_train_data.csv'\n",
    "    model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if i < 26:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(i%2)\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     torch.cuda.set_device(i%2)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     train_data = CSVDataSet(train_list)\n",
    "#     train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=False)\n",
    "\n",
    "    train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "    batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "    pin_memory=False, drop_last=False, timeout=0,\\\n",
    "    worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "    model = train_model_new.get_model(model_id, model_metric, None, model_settings, None)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    class_list_new = {}\n",
    "\n",
    "    for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = batch_x.to(device)\n",
    "        label = batch_y[0].split('-')[0]\n",
    "        batch_y = torch.tensor([0]).to(device)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "        except:\n",
    "            print('Proc', str(i), 'EER:', label)\n",
    "            continue\n",
    "    #     _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "        emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "        if label not in class_list_new.keys():\n",
    "            class_list_new[label] = emb[None, :]\n",
    "        else:\n",
    "            class_list_new[label] = np.append(class_list_new[label], emb[None, :], axis=0)\n",
    "\n",
    "        if (count+1) % 10000 == 0:\n",
    "            print('Proc '+ str(i) + ':' + str((count+1) // 10000))\n",
    "    \n",
    "    class_list_new_m[i] = class_list_new\n",
    "    del model, batch_x, batch_y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Proc 27:1\n",
      "Proc 24:1\n",
      "Proc 26:1\n",
      "Proc 22:1\n",
      "Proc 20:1\n",
      "Proc 16:1\n",
      "Proc 10:1\n",
      "Proc 6:1\n",
      "Proc 8:1\n",
      "Proc 18:1\n",
      "Proc 4:1\n",
      "Proc 25:1\n",
      "Proc 2:1\n",
      "Proc 12:1\n",
      "Proc 14:1\n",
      "Proc 21:1\n",
      "Proc 19:1\n",
      "Proc 0:1\n",
      "Proc 11:1\n",
      "Proc 23:1\n",
      "Proc 9:1\n",
      "Proc 15:1\n",
      "Proc 5:1\n",
      "Proc 7:1\n",
      "Proc 13:1\n",
      "Proc 3:1\n",
      "Proc 17:1\n",
      "Proc 1:1\n",
      "Proc 24:2\n",
      "Proc 27:2\n",
      "Proc 26:2\n",
      "Proc 20:2\n",
      "Proc 22:2\n",
      "Proc 18:2\n",
      "Proc 16:2\n",
      "Proc 8:2\n",
      "Proc 14:2\n",
      "Proc 12:2\n",
      "Proc 25:2\n",
      "Proc 10:2\n",
      "Proc 4:2\n",
      "Proc 6:2\n",
      "Proc 2:2\n",
      "Proc 21:2\n",
      "Proc 0:2\n",
      "Proc 19:2\n",
      "Proc 9:2\n",
      "Proc 11:2\n",
      "Proc 23:2\n",
      "Proc 17:2\n",
      "Proc 15:2\n",
      "Proc 7:2\n",
      "Proc 13:2\n",
      "Proc 5:2\n",
      "Proc 3:2\n",
      "Proc 1:2\n",
      "Proc 24:3\n",
      "Proc 26:3\n",
      "Proc 27:3\n",
      "Proc 22:3\n",
      "Proc 18:3\n",
      "Proc 20:3\n",
      "Proc 16:3\n",
      "Proc 14:3\n",
      "Proc 8:3\n",
      "Proc 12:3\n",
      "Proc 10:3\n",
      "Proc 4:3\n",
      "Proc 25:3\n",
      "Proc 6:3\n",
      "Proc 2:3\n",
      "Proc 0:3\n",
      "Proc 19:3\n",
      "Proc 21:3\n",
      "Proc 9:3\n",
      "Proc 23:3\n",
      "Proc 11:3\n",
      "Proc 15:3\n",
      "Proc 17:3\n",
      "Proc 7:3\n",
      "Proc 13:3\n",
      "Proc 5:3\n",
      "Proc 3:3\n",
      "Proc 1:3\n",
      "Proc 26:4\n",
      "Proc 24:4\n",
      "Proc 27:4\n",
      "Proc 22:4\n",
      "Proc 20:4\n",
      "Proc 18:4\n",
      "Proc 16:4\n",
      "Proc 14:4\n",
      "Proc 12:4\n",
      "Proc 8:4\n",
      "Proc 10:4\n",
      "Proc 25:4\n",
      "Proc 6:4\n",
      "Proc 4:4\n",
      "Proc 2:4\n",
      "Proc 0:4\n",
      "Proc 19:4\n",
      "Proc 21:4\n",
      "Proc 23:4\n",
      "Proc 15:4\n",
      "Proc 9:4\n",
      "Proc 11:4\n",
      "Proc 7:4\n",
      "Proc 13:4\n",
      "Proc 5:4\n",
      "Proc 17:4\n",
      "Proc 3:4\n",
      "Proc 1:4\n"
     ]
    }
   ],
   "source": [
    "processes = [Process(target = extract_feature_m, args = (i, data_m[i], class_list_new_m)) for i in range(num_p)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new_m:\n",
    "    for j in i:\n",
    "        count += len(i[j])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_list_new = class_list_new_m[0]\n",
    "\n",
    "for count, this_list in enumerate(class_list_new_m):\n",
    "    if count == 0:\n",
    "        continue\n",
    "    for this_label in this_list:\n",
    "        if this_label not in class_list_new.keys():\n",
    "            class_list_new[this_label] = this_list[this_label]\n",
    "        else:\n",
    "            class_list_new[this_label] = np.append(class_list_new[this_label], this_list[this_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nanlist = []\n",
    "for i in class_list_new:\n",
    "    if np.isnan(class_list_new[i]).any():\n",
    "        print(i)\n",
    "        nanlist.append(i)\n",
    "for i in nanlist:\n",
    "    class_list_new.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7323"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+PLDA_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(class_list_new, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_list_new = {}\n",
    "# for i in class_list:\n",
    "#     class_list_new[i[:-1]] = class_list[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLDA_FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./train')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# import vox_model_bank\n",
    "from train import train_model_new\n",
    "from train.read_data import *\n",
    "from train.my_dataloader import *\n",
    "# from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kaldi_plda import *\n",
    "from kaldi_lda import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Lun2/rzz/kaldi-master/egs/zhiyong/sre19/new_testbench'+'/'+PLDA_DATA_NAME, 'rb') as handle:\n",
    "    class_list_new = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of mean: 1.9705881360946418\n"
     ]
    }
   ],
   "source": [
    "# Substract global mean\n",
    "global_mean = np.zeros(512)\n",
    "num_utt = 0\n",
    "for count, i in enumerate(class_list_new):\n",
    "    num_utt += class_list_new[i].shape[0]\n",
    "    global_mean += class_list_new[i].shape[0] * np.mean(class_list_new[i], axis=0)\n",
    "    \n",
    "global_mean = (1.0 / num_utt) * global_mean\n",
    "print('Norm of mean:', np.linalg.norm(global_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in class_list_new:\n",
    "    class_list_new[i] = class_list_new[i] - global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # normlize to sqrt(dim)\n",
    "# for i in class_list_new:\n",
    "#     scale = np.sqrt(512) / np.linalg.norm(class_list_new[i], axis=1, keepdims=True)\n",
    "#     class_list_new[i] = scale * class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda norm of global mean: 9.641873606430675e-08\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(lda_dim=PLDA_DIM, ivector_dim=512)\n",
    "for i in class_list_new:\n",
    "    lda.AccStats(class_list_new[i])\n",
    "print('lda norm of global mean:', lda.GetGlobalMean()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input data has norm of mean 9.641873606430675e-08\n",
      "[7.01190490e+00 6.75681662e+00 6.53853053e+00 6.25568993e+00\n",
      " 6.11248365e+00 5.95853316e+00 5.76067349e+00 5.64741497e+00\n",
      " 5.57487744e+00 5.41990231e+00 5.38111534e+00 5.31902969e+00\n",
      " 5.23789065e+00 5.19969617e+00 5.15591191e+00 5.06367837e+00\n",
      " 4.95002558e+00 4.87409618e+00 4.84840474e+00 4.74871468e+00\n",
      " 4.71036534e+00 4.62632340e+00 4.59444607e+00 4.53859824e+00\n",
      " 4.50825004e+00 4.44792223e+00 4.42513736e+00 4.34977219e+00\n",
      " 4.28159505e+00 4.25209140e+00 4.19223498e+00 4.16862494e+00\n",
      " 4.06981441e+00 4.06355494e+00 4.03968798e+00 3.96515890e+00\n",
      " 3.92289551e+00 3.89805072e+00 3.86241858e+00 3.79790583e+00\n",
      " 3.72304290e+00 3.67162826e+00 3.64237800e+00 3.57782648e+00\n",
      " 3.55594916e+00 3.51338202e+00 3.48159699e+00 3.44671244e+00\n",
      " 3.38799819e+00 3.37222889e+00 3.31932983e+00 3.26479589e+00\n",
      " 3.23583721e+00 3.18890552e+00 3.16877421e+00 3.13774669e+00\n",
      " 3.09139334e+00 3.04371133e+00 3.00723616e+00 2.97468080e+00\n",
      " 2.93475707e+00 2.91202466e+00 2.88878275e+00 2.87596840e+00\n",
      " 2.86439953e+00 2.80306845e+00 2.76811226e+00 2.75282091e+00\n",
      " 2.73265968e+00 2.70924597e+00 2.66613388e+00 2.63483158e+00\n",
      " 2.61028253e+00 2.58592747e+00 2.53934771e+00 2.51142099e+00\n",
      " 2.49924999e+00 2.49027539e+00 2.47251919e+00 2.42728511e+00\n",
      " 2.39750196e+00 2.37405700e+00 2.35193609e+00 2.32716667e+00\n",
      " 2.30830347e+00 2.25238815e+00 2.22747853e+00 2.19589194e+00\n",
      " 2.18315646e+00 2.16168723e+00 2.14473982e+00 2.13666842e+00\n",
      " 2.11730956e+00 2.09368117e+00 2.07249359e+00 2.02863364e+00\n",
      " 2.00766347e+00 1.98834752e+00 1.97887775e+00 1.94679614e+00\n",
      " 1.93039694e+00 1.86316743e+00 1.83820799e+00 1.80521765e+00\n",
      " 1.80025135e+00 1.73680036e+00 1.72558673e+00 1.69926713e+00\n",
      " 1.68113125e+00 1.64568037e+00 1.64385487e+00 1.61517082e+00\n",
      " 1.59876115e+00 1.58277031e+00 1.56115538e+00 1.55320346e+00\n",
      " 1.51243525e+00 1.49619275e+00 1.47218505e+00 1.43834861e+00\n",
      " 1.40241336e+00 1.39010490e+00 1.35986172e+00 1.34133043e+00\n",
      " 1.30430106e+00 1.27390776e+00 1.26693302e+00 1.24963291e+00\n",
      " 1.22605047e+00 1.20930857e+00 1.17516276e+00 1.15928254e+00\n",
      " 1.10827155e+00 1.10579309e+00 1.08143299e+00 1.04990833e+00\n",
      " 1.02459246e+00 1.02341005e+00 9.85720533e-01 9.61891596e-01\n",
      " 9.42982519e-01 9.21998780e-01 8.82967456e-01 8.72463017e-01\n",
      " 8.44555158e-01 8.17005973e-01 7.93647028e-01 7.76731812e-01\n",
      " 7.45476639e-01 7.08294780e-01 6.86481937e-01 6.57690591e-01\n",
      " 6.51422345e-01 5.97619248e-01 5.42989137e-01 5.23422102e-01\n",
      " 4.98348925e-01 4.77149980e-01 4.23471134e-01 3.70797065e-01\n",
      " 3.59415774e-01 3.00606079e-01 2.58306813e-01 2.28607677e-01\n",
      " 1.95625143e-01 1.75367642e-01 1.46014513e-01 1.28691052e-01\n",
      " 8.98530433e-02 8.07634505e-02 5.95855167e-02 5.23992103e-02\n",
      " 4.70815083e-02 4.34232852e-02 3.61298754e-02 2.98530038e-02\n",
      " 2.48705681e-02 2.35851227e-02 1.95286451e-02 1.69957990e-02\n",
      " 1.46860880e-02 1.21079527e-02 1.10980698e-02 9.93992518e-03\n",
      " 8.83581804e-03 7.61617126e-03 7.20521993e-03 6.65891856e-03\n",
      " 6.43155722e-03 5.94651053e-03 5.82038515e-03 5.57402635e-03\n",
      " 5.16710101e-03 5.06908641e-03 4.74478140e-03 4.38495356e-03\n",
      " 4.16813362e-03 4.08939712e-03 3.65184440e-03 3.47949909e-03\n",
      " 3.29645439e-03 3.24561828e-03 3.09080106e-03 2.96960479e-03\n",
      " 2.84422802e-03 2.66636480e-03 2.60714860e-03 2.44392856e-03\n",
      " 2.28607000e-03 2.16064731e-03 2.13101155e-03 2.09523859e-03\n",
      " 2.02501915e-03 1.94251359e-03 1.92125743e-03 1.86249722e-03\n",
      " 1.83413055e-03 1.74571568e-03 1.71652971e-03 1.67846122e-03\n",
      " 1.57774025e-03 1.54048222e-03 1.50385920e-03 1.46617952e-03\n",
      " 1.44405312e-03 1.42015405e-03 1.38468954e-03 1.35962379e-03\n",
      " 1.32311004e-03 1.29079373e-03 1.28130524e-03 1.26447037e-03\n",
      " 1.21417661e-03 1.18156807e-03 1.17149410e-03 1.15402245e-03\n",
      " 1.13138434e-03 1.11139484e-03 1.08723355e-03 1.06463934e-03\n",
      " 1.05900574e-03 1.03875135e-03 1.01130509e-03 9.94422771e-04\n",
      " 9.77763215e-04 9.61645653e-04 9.40291655e-04 9.31481056e-04\n",
      " 9.17237684e-04 9.09895749e-04 9.00540358e-04 8.82440489e-04\n",
      " 8.77600637e-04 8.64681170e-04 8.49183888e-04 8.47919815e-04\n",
      " 8.36188645e-04 8.13606259e-04 8.06461647e-04 7.91656685e-04\n",
      " 7.87537605e-04 7.69919355e-04 7.60725888e-04 7.44501528e-04\n",
      " 7.39846716e-04 7.30456784e-04 7.16250308e-04 7.08588571e-04\n",
      " 6.99920974e-04 6.96945088e-04 6.95438919e-04 6.76953446e-04\n",
      " 6.70633304e-04 6.55723181e-04 6.46802028e-04 6.42673428e-04\n",
      " 6.36047590e-04 6.24363606e-04 6.18873107e-04 6.14856934e-04\n",
      " 6.06837331e-04 6.00400230e-04 5.95799374e-04 5.88649844e-04\n",
      " 5.87224146e-04 5.73575076e-04 5.68754828e-04 5.60811273e-04\n",
      " 5.59500017e-04 5.54052382e-04 5.43516854e-04 5.40823128e-04\n",
      " 5.38010822e-04 5.35647654e-04 5.31539068e-04 5.22636787e-04\n",
      " 5.15352779e-04 5.13604532e-04 5.08347723e-04 5.03630612e-04\n",
      " 4.95788463e-04 4.93156317e-04 4.89114666e-04 4.86122788e-04\n",
      " 4.77366778e-04 4.74588437e-04 4.69555699e-04 4.66400719e-04\n",
      " 4.60788245e-04 4.55495115e-04 4.51422460e-04 4.48002291e-04\n",
      " 4.45603325e-04 4.43398202e-04 4.35994025e-04 4.33107565e-04\n",
      " 4.27534264e-04 4.24282181e-04 4.20404387e-04 4.12010008e-04\n",
      " 4.10059373e-04 4.07764398e-04 4.02257420e-04 4.00794722e-04\n",
      " 3.99235784e-04 3.97516295e-04 3.90868507e-04 3.89592037e-04\n",
      " 3.87512351e-04 3.84632269e-04 3.77020784e-04 3.73522364e-04\n",
      " 3.72927493e-04 3.66062967e-04 3.63919240e-04 3.60036860e-04\n",
      " 3.59354962e-04 3.55639701e-04 3.52414461e-04 3.50360789e-04\n",
      " 3.47156264e-04 3.46141020e-04 3.44457453e-04 3.40093148e-04\n",
      " 3.36950601e-04 3.32473051e-04 3.30968644e-04 3.27108307e-04\n",
      " 3.24586611e-04 3.21917088e-04 3.18269984e-04 3.16201073e-04\n",
      " 3.13593124e-04 3.11225940e-04 3.09161930e-04 3.06719205e-04\n",
      " 3.03768834e-04 3.02202086e-04 2.99985008e-04 2.97486014e-04\n",
      " 2.92276651e-04 2.89988534e-04 2.87571679e-04 2.86359582e-04\n",
      " 2.81954368e-04 2.81530935e-04 2.81018894e-04 2.77104065e-04\n",
      " 2.76333412e-04 2.73608658e-04 2.70526215e-04 2.69865961e-04\n",
      " 2.66358817e-04 2.64890279e-04 2.62616183e-04 2.60694146e-04\n",
      " 2.59875665e-04 2.56800500e-04 2.55723048e-04 2.52834586e-04\n",
      " 2.49502489e-04 2.48174272e-04 2.45265661e-04 2.43736249e-04\n",
      " 2.42852404e-04 2.40490233e-04 2.38602052e-04 2.35357983e-04\n",
      " 2.34692255e-04 2.33321361e-04 2.32322432e-04 2.30155091e-04\n",
      " 2.26614611e-04 2.25580995e-04 2.23635578e-04 2.22122875e-04\n",
      " 2.20987783e-04 2.17813711e-04 2.17153065e-04 2.15398017e-04\n",
      " 2.13744459e-04 2.12653408e-04 2.10804164e-04 2.08537320e-04\n",
      " 2.07026353e-04 2.05859286e-04 2.01086440e-04 2.00153275e-04\n",
      " 1.99297855e-04 1.96561414e-04 1.95738365e-04 1.94750089e-04\n",
      " 1.92496281e-04 1.91086155e-04 1.89591196e-04 1.88202819e-04\n",
      " 1.87796557e-04 1.85246885e-04 1.84971438e-04 1.82974150e-04\n",
      " 1.79982109e-04 1.77720238e-04 1.76297165e-04 1.74962580e-04\n",
      " 1.73266720e-04 1.72189163e-04 1.71349523e-04 1.68583511e-04\n",
      " 1.67095673e-04 1.66706061e-04 1.65429352e-04 1.63860504e-04\n",
      " 1.61517146e-04 1.60526333e-04 1.59672788e-04 1.58419226e-04\n",
      " 1.58171467e-04 1.55307888e-04 1.54088931e-04 1.52555335e-04\n",
      " 1.51569923e-04 1.49823879e-04 1.48722874e-04 1.46846461e-04\n",
      " 1.45928812e-04 1.44227513e-04 1.42827932e-04 1.42422769e-04\n",
      " 1.41577243e-04 1.40021808e-04 1.38648701e-04 1.37590029e-04\n",
      " 1.36614973e-04 1.35292333e-04 1.34186086e-04 1.33206958e-04\n",
      " 1.31995798e-04 1.31523648e-04 1.30158084e-04 1.27797622e-04\n",
      " 1.26682466e-04 1.25518742e-04 1.24519029e-04 1.23284655e-04\n",
      " 1.22379661e-04 1.21245636e-04 1.19842088e-04 1.19038137e-04\n",
      " 1.18275595e-04 1.16979033e-04 1.15074766e-04 1.14196537e-04\n",
      " 1.12435868e-04 1.12123236e-04 1.10683549e-04 1.09457730e-04\n",
      " 1.08649877e-04 1.07591438e-04 1.06707342e-04 1.05470747e-04\n",
      " 1.04458549e-04 1.04075350e-04 1.01826185e-04 1.00874041e-04\n",
      " 9.97529951e-05 9.74343900e-05 9.67193363e-05 9.56367751e-05\n",
      " 9.43077499e-05 9.39990215e-05 9.30565845e-05 9.24288979e-05\n",
      " 9.03165224e-05 8.92649220e-05 8.81987869e-05 8.78416478e-05\n",
      " 8.69982863e-05 8.49103057e-05 8.46237219e-05 8.36127361e-05\n",
      " 8.24187036e-05 8.07262356e-05 7.96919998e-05 7.84922378e-05\n",
      " 7.69550140e-05 7.64413830e-05 7.55467501e-05 7.33162343e-05\n",
      " 7.19422311e-05 6.99753625e-05 6.89090799e-05 6.60633110e-05]\n",
      "[8.07989212 7.21778079 5.8904341  5.15080362 4.7302275  4.15403744\n",
      " 3.99383618 3.63447651 3.45939434 3.26295624 3.09979301 2.92855832\n",
      " 2.766262   2.66294305 2.45968911 2.41496127 2.30625234 2.28097716\n",
      " 2.21707954 2.12541285 2.08638457 2.02445998 1.9207608  1.85233115\n",
      " 1.83030956 1.77017587 1.72893062 1.6800222  1.65788071 1.64865859\n",
      " 1.59416565 1.54173326 1.50551477 1.49379866 1.47077623 1.44007072\n",
      " 1.43503925 1.41225207 1.35746827 1.35251838 1.34165387 1.28122493\n",
      " 1.27735732 1.26357575 1.24789799 1.2214984  1.21076324 1.19255159\n",
      " 1.17280037 1.13948023 1.13265809 1.10888312 1.10369793 1.08125672\n",
      " 1.07617833 1.05045515 1.0391252  1.01341374 0.99338571 0.98656491\n",
      " 0.97869527 0.95530038 0.95392633 0.93146179 0.91417809 0.91268754\n",
      " 0.87907744 0.86789281 0.85874722 0.85502889 0.85347226 0.84578537\n",
      " 0.83173277 0.82486657 0.8106771  0.80710072 0.80109976 0.79207146\n",
      " 0.78734789 0.76356117 0.75587216 0.74953435 0.7474362  0.73049122\n",
      " 0.7189019  0.71471786 0.70995011 0.70406988 0.68918971 0.68602996\n",
      " 0.6833013  0.67423361 0.67049552 0.66103874 0.65037413 0.63932224\n",
      " 0.62896356 0.62343266 0.61738815 0.61439185 0.60949894 0.59989343\n",
      " 0.59958939 0.5857487  0.58392853 0.57904407 0.57456792 0.56843072\n",
      " 0.55810519 0.55683323 0.5532243  0.55067637 0.53851161 0.53386454\n",
      " 0.53075318 0.52869247 0.52634416 0.51644044 0.50726647 0.50477602\n",
      " 0.49912914 0.49445388 0.49055227 0.48441464 0.48217132 0.47757698\n",
      " 0.46904246 0.46659346 0.46236693 0.45720133 0.45227449 0.44645786\n",
      " 0.4444343  0.43780789 0.43680809 0.43297653 0.423705   0.4218169\n",
      " 0.41903232 0.41481185 0.41405362 0.40494594 0.40469628 0.39985704\n",
      " 0.39843701 0.39606697 0.3911775  0.38805297 0.38216937 0.38022075\n",
      " 0.37755298 0.37269182 0.37007154 0.36565206 0.36176019 0.35753188\n",
      " 0.35578668 0.35193261 0.35070508 0.34737981 0.34454358 0.3388367\n",
      " 0.33863949 0.33459946 0.3336774  0.33183251 0.32789808 0.32647415\n",
      " 0.32592259 0.32237441 0.31637409 0.31372686 0.31201727 0.30482254\n",
      " 0.30388643 0.30169647 0.2974982  0.29594709 0.29506593 0.29375336\n",
      " 0.28974838 0.28801212 0.28482747 0.2836286  0.2818503  0.27891988\n",
      " 0.27838278 0.27682383 0.27200709 0.27129536 0.26727033 0.26461642\n",
      " 0.26403644 0.26157223 0.2604338  0.259145   0.25689346 0.25412449\n",
      " 0.25350082 0.25163316 0.24835969 0.24733146 0.24404851 0.2425684\n",
      " 0.24150114 0.24019939 0.23905432 0.23738063 0.23686145 0.23276144\n",
      " 0.2310249  0.23038843 0.2290578  0.22742108 0.2253748  0.22484911\n",
      " 0.22187404 0.22056203 0.21903139 0.21817682 0.21658152 0.21564012\n",
      " 0.21493852 0.21210916 0.21100692 0.20996156 0.20782289 0.20643705\n",
      " 0.20559318 0.20371382 0.20289415 0.20206833 0.20116705 0.1992312\n",
      " 0.19808919 0.19706301 0.19419877 0.19348785 0.19239982 0.19174974\n",
      " 0.18997559 0.18813382 0.18812502 0.18766022 0.18529333 0.1833955\n",
      " 0.18312428 0.18128784 0.18025426 0.1789808  0.17783074 0.17610201\n",
      " 0.17564822 0.17375023 0.17182501 0.17086856 0.1707359  0.16986276\n",
      " 0.16832063 0.16798238 0.1659075  0.16535979 0.16471135 0.16332534\n",
      " 0.1621863  0.1615834  0.16110781 0.16014143 0.15954723 0.1587706\n",
      " 0.1582445  0.15665406 0.1556928  0.15531613 0.15376159 0.15328592\n",
      " 0.15302539 0.15042259 0.14977105 0.14915626 0.14852998 0.14758656\n",
      " 0.14660305 0.14491418 0.14446801 0.14386448 0.1424858  0.14144041\n",
      " 0.14098812 0.14021829 0.13897126 0.13843321 0.13773188 0.13763475\n",
      " 0.1368068  0.13573002 0.13505031 0.13403234 0.13302153 0.13271824\n",
      " 0.13215002 0.13107409 0.13082587 0.13016891 0.12954823 0.12807304\n",
      " 0.12747434 0.12649877 0.12578351 0.12500611 0.12449423 0.12391431\n",
      " 0.12339993 0.12295074 0.12201023 0.12125907 0.12112258 0.12035917\n",
      " 0.11989001 0.11861018 0.11815517 0.11804501 0.11720293 0.11634543\n",
      " 0.11519189 0.11413366 0.11380629 0.11270697 0.11193176 0.1119134\n",
      " 0.11147394 0.11131063 0.11007806 0.10948133 0.1093358  0.10859516\n",
      " 0.10797899 0.10781655 0.10735588 0.10664047 0.10614305 0.10574216\n",
      " 0.10432027 0.10399609 0.10350405 0.10329433 0.10260413 0.10237036\n",
      " 0.10134805 0.10108374 0.10033099 0.0999897  0.09942819 0.09860755\n",
      " 0.09834159 0.09761178 0.09748906 0.09652309 0.09593176 0.09534164\n",
      " 0.09516967 0.0949915  0.09457686 0.09318571 0.09291288 0.09258333\n",
      " 0.09239241 0.09166779 0.09128559 0.09093116 0.09031224 0.08960646\n",
      " 0.08925803 0.08909865 0.08898745 0.08851138 0.08828639 0.08795674\n",
      " 0.08723435 0.08683665 0.08616122 0.08572696 0.08562319 0.08517968\n",
      " 0.08470571 0.08397655 0.08321457 0.08309559 0.08281906 0.08222881\n",
      " 0.0818812  0.08124221 0.08087179 0.08070997 0.07987393 0.07951544\n",
      " 0.0793106  0.07885681 0.07842391 0.07764536 0.07753069 0.07729064\n",
      " 0.07714349 0.07658481 0.07640514 0.07634881 0.07562464 0.07522812\n",
      " 0.07491424 0.07391117 0.07375727 0.07355642 0.07313947 0.07262619\n",
      " 0.07203453 0.07187752 0.07153159 0.07134193 0.07094547 0.07043055\n",
      " 0.07027685 0.06983851 0.06974232 0.06934114 0.06862795 0.06840831\n",
      " 0.0681071  0.06787347 0.06715175 0.06681515 0.06659    0.06604506\n",
      " 0.06565256 0.06521825 0.0651241  0.06470717 0.06434369 0.06395644\n",
      " 0.06381314 0.06319551 0.06280488 0.06247117 0.06241157 0.061875\n",
      " 0.06137653 0.06119032 0.06052294 0.06044267 0.05993094 0.05975454\n",
      " 0.05955295 0.05924133 0.05882579 0.05841201 0.05805264 0.05775289\n",
      " 0.0571914  0.05686684 0.05676489 0.05658737 0.05646609 0.05613059\n",
      " 0.05576556 0.05524215 0.05501878 0.05472768 0.05440597 0.05413196\n",
      " 0.05395726 0.05362115 0.05322859 0.05296836 0.05246933 0.05210337\n",
      " 0.05170617 0.05145475 0.05116211 0.05097581 0.05053852 0.05036981\n",
      " 0.04995901 0.0495593  0.04909031 0.04878364 0.04853368 0.04835259\n",
      " 0.04814556 0.0477073  0.04733175 0.04685652 0.04668761 0.04647637\n",
      " 0.04601069 0.0458273  0.04547564 0.04533526 0.04500185 0.04465502\n",
      " 0.0439594  0.0437539  0.04335692 0.04310528 0.04241455 0.0423697\n",
      " 0.04182014 0.04164885 0.04097891 0.04054367 0.03988333 0.03907085\n",
      " 0.03804346 0.03785201]\n"
     ]
    }
   ],
   "source": [
    "transform = lda.ComputeLdaTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # normlize to sqrt(dim)\n",
    "# for i in class_list_new:\n",
    "#     scale = np.sqrt(512) / np.linalg.norm(class_list_new[i], axis=1, keepdims=True)\n",
    "#     class_list_new[i] = scale * class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in class_list_new:\n",
    "    class_list_new[i] = class_list_new[i].dot(transform.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normlize to sqrt(dim)\n",
    "for i in class_list_new:\n",
    "    scale = np.sqrt(PLDA_DIM) / np.linalg.norm(class_list_new[i], axis=1, keepdims=True)\n",
    "    class_list_new[i] = scale * class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plda_stats = PldaStats(PLDA_DIM)\n",
    "for i in class_list_new:\n",
    "    plda_stats.add_samples(class_list_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plda_stats.sort()\n",
    "plda_stats.is_sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "nllr_x: 411.3536651606943\n",
      "nllr_y: -371.394730264205\n",
      "normalized_nllr: 39.95893489648931\n",
      "nllr_m: 412.13621538628524\n",
      "nllr_m_2: 412.13621538628604\n",
      "part1_residual -455.29228631886446\n",
      "part2_mean -412.13621538628524\n",
      "normlized_obj -455.04478465275184\n",
      "2 5\n",
      "nllr_x: 240.15276805056112\n",
      "nllr_y: -458.94205476522495\n",
      "normalized_nllr: -218.7892867146638\n",
      "nllr_m: 246.5813414941023\n",
      "nllr_m_2: 246.5813414941021\n",
      "part1_residual -437.3886274503415\n",
      "part2_mean -246.5813414941023\n",
      "normlized_obj -436.294340594284\n",
      "3 5\n",
      "nllr_x: 237.46553834505684\n",
      "nllr_y: -458.8741951366892\n",
      "normalized_nllr: -221.40865679163232\n",
      "nllr_m: 245.48345787472775\n",
      "nllr_m_2: 245.48345787472786\n",
      "part1_residual -437.3910096499305\n",
      "part2_mean -245.48345787472775\n",
      "normlized_obj -436.2904127286267\n",
      "4 5\n",
      "nllr_x: 237.20065986248494\n",
      "nllr_y: -458.7576755590343\n",
      "normalized_nllr: -221.55701569654934\n",
      "nllr_m: 245.46150954196784\n",
      "nllr_m_2: 245.4615095419679\n",
      "part1_residual -437.3910074823672\n",
      "part2_mean -245.46150954196784\n",
      "normlized_obj -436.2902846989926\n",
      "5 5\n",
      "nllr_x: 237.16177247008068\n",
      "nllr_y: -458.73833011962114\n",
      "normalized_nllr: -221.57655764954046\n",
      "nllr_m: 245.46090097759316\n",
      "nllr_m_2: 245.46090097759335\n",
      "part1_residual -437.3910038566896\n",
      "part2_mean -245.46090097759313\n",
      "normlized_obj -436.2902776039693\n"
     ]
    }
   ],
   "source": [
    "# test_fin_prior\n",
    "plda_estimator = PldaEstimation(plda_stats)\n",
    "plda_paras = plda_estimator.estimate(iteration=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+ PLDA_PARA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(plda_paras, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PLDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+ PLDA_PARA_NAME, 'rb') as handle:\n",
    "    plda_paras = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plda = PLDA(plda_paras[0], plda_paras[1], plda_paras[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TRAIN_DATA_NAME, 'rb') as handle:\n",
    "    train_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_list = np.zeros([0, 512])\n",
    "for i in train_data:\n",
    "    unlabeled_list = np.append(unlabeled_list, train_data[i], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "major_mean = np.mean(unlabeled_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# out = component_dir+'/major_mean'\n",
    "# with open(out, 'wb') as handle:\n",
    "#     pickle.dump(major_mean, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_list = unlabeled_list - major_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_list = unlabeled_list.dot(transform.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normlize to sqrt(dim)\n",
    "scale = np.sqrt(PLDA_DIM) / np.linalg.norm(unlabeled_list, axis=1, keepdims=True)\n",
    "unlabeled_list = scale * unlabeled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adaptor = PldaUnsupervisedAdaptor(dim=PLDA_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(unlabeled_list.shape[0]):\n",
    "    adaptor.add_stats(unlabeled_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_plda_paras = adaptor.update_plda(plda_paras[0], plda_paras[1], plda_paras[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/new_plda_paras'\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(new_plda_paras, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plda = PLDA(new_plda_paras[0], new_plda_paras[1], new_plda_paras[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enroll models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+ENR_DATA_NAME, 'rb') as handle:\n",
    "    enr_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enr_list = {}\n",
    "num_utt = {}\n",
    "with open('/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/docs/model_enrollment.txt', 'r') as f:\n",
    "    for count, line in enumerate(f):\n",
    "        if count == 0:\n",
    "            continue\n",
    "        info = line[:-1].split(' ')\n",
    "        model_label = info[0]\n",
    "        num_utt[model_label] = len(info)-1\n",
    "        for i in range(1, len(info)):\n",
    "            if model_label not in enr_list.keys():\n",
    "                enr_list[model_label] = enr_data[info[i]]\n",
    "            else:\n",
    "                enr_list[model_label] = np.append(enr_list[model_label], enr_data[info[i]], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+EVL_DATA_NAME, 'rb') as handle:\n",
    "    evl_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/docs/trials.txt'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enr_list:\n",
    "    enr_list[i] = np.mean(enr_list[i], axis=0).squeeze()\n",
    "    enr_list[i] = enr_list[i] - global_mean\n",
    "    enr_list[i] = transform.dot(enr_list[i])\n",
    "    enr_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(enr_list[i])) * enr_list[i]\n",
    "    num = num_utt[i]\n",
    "    enr_list[i] = plda.transform_ivector(enr_list[i], num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in evl_data:\n",
    "    evl_data[i] = evl_data[i].squeeze()\n",
    "    evl_data[i] = evl_data[i] - global_mean\n",
    "    evl_data[i] = transform.dot(evl_data[i])\n",
    "    evl_data[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(evl_data[i])) * evl_data[i]\n",
    "    evl_data[i] = plda.transform_ivector(evl_data[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            line = line[:-1]\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "                continue\n",
    "            enroll_emb = enr_list[line.split(' ')[0]].squeeze()\n",
    "            num = num_utt[line.split(' ')[0]]\n",
    "            test_emb = evl_data[line.split(' ')[1]].squeeze()\n",
    "\n",
    "            cosine = plda.log_likelihood_ratio(enroll_emb, num, test_emb)\n",
    "            \n",
    "            of.write(str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13198024"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scoring adapt plda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/docs/trials.txt'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME+'adapt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in enr_list:\n",
    "    enr_list[i] = np.mean(enr_list[i], axis=0).squeeze()\n",
    "    enr_list[i] = enr_list[i] - major_mean\n",
    "    enr_list[i] = transform.dot(enr_list[i])\n",
    "    enr_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(enr_list[i])) * enr_list[i]\n",
    "    num = num_utt[i]\n",
    "    enr_list[i] = plda.transform_ivector(enr_list[i], num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in evl_data:\n",
    "    evl_data[i] = evl_data[i].squeeze()\n",
    "    evl_data[i] = evl_data[i] - major_mean\n",
    "    evl_data[i] = transform.dot(evl_data[i])\n",
    "    evl_data[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(evl_data[i])) * evl_data[i]\n",
    "    evl_data[i] = plda.transform_ivector(evl_data[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-id evaluation-file-id\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n",
      "20.0\n",
      "21.0\n",
      "22.0\n",
      "23.0\n",
      "24.0\n",
      "25.0\n",
      "26.0\n",
      "27.0\n",
      "28.0\n",
      "29.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "33.0\n",
      "34.0\n",
      "35.0\n",
      "36.0\n",
      "37.0\n",
      "38.0\n",
      "39.0\n",
      "40.0\n",
      "41.0\n",
      "42.0\n",
      "43.0\n",
      "44.0\n",
      "45.0\n",
      "46.0\n",
      "47.0\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "51.0\n",
      "52.0\n",
      "53.0\n",
      "54.0\n",
      "55.0\n",
      "56.0\n",
      "57.0\n",
      "58.0\n",
      "59.0\n",
      "60.0\n",
      "61.0\n",
      "62.0\n",
      "63.0\n",
      "64.0\n",
      "65.0\n",
      "66.0\n",
      "67.0\n",
      "68.0\n",
      "69.0\n",
      "70.0\n",
      "71.0\n",
      "72.0\n",
      "73.0\n",
      "74.0\n",
      "75.0\n",
      "76.0\n",
      "77.0\n",
      "78.0\n",
      "79.0\n",
      "80.0\n",
      "81.0\n",
      "82.0\n",
      "83.0\n",
      "84.0\n",
      "85.0\n",
      "86.0\n",
      "87.0\n",
      "88.0\n",
      "89.0\n",
      "90.0\n",
      "91.0\n",
      "92.0\n",
      "93.0\n",
      "94.0\n",
      "95.0\n",
      "96.0\n",
      "97.0\n",
      "98.0\n",
      "99.0\n",
      "100.0\n",
      "101.0\n",
      "102.0\n",
      "103.0\n",
      "104.0\n",
      "105.0\n",
      "106.0\n",
      "107.0\n",
      "108.0\n",
      "109.0\n",
      "110.0\n",
      "111.0\n",
      "112.0\n",
      "113.0\n",
      "114.0\n",
      "115.0\n",
      "116.0\n",
      "117.0\n",
      "118.0\n",
      "119.0\n",
      "120.0\n",
      "121.0\n",
      "122.0\n",
      "123.0\n",
      "124.0\n",
      "125.0\n",
      "126.0\n",
      "127.0\n",
      "128.0\n",
      "129.0\n",
      "130.0\n",
      "131.0\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            line = line[:-1]\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "                continue\n",
    "            enroll_emb = enr_list[line.split(' ')[0]].squeeze()\n",
    "            num = num_utt[line.split(' ')[0]]\n",
    "            test_emb = evl_data[line.split(' ')[1]].squeeze()\n",
    "\n",
    "            cosine = plda.log_likelihood_ratio(enroll_emb, num, test_emb)\n",
    "            \n",
    "            of.write(str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 100000 == 0:\n",
    "                print((count+1) // 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13198024"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/docs/trials.txt'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in enr_list:\n",
    "    enr_list[i] = np.mean(enr_list[i], axis=0).squeeze()\n",
    "    enr_list[i] = (1.0 / np.linalg.norm(enr_list[i])) * enr_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in evl_data:\n",
    "    evl_data[i] = evl_data[i].squeeze()\n",
    "    evl_data[i] = (1.0 / np.linalg.norm(evl_data[i])) * evl_data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-id evaluation-file-id\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            line = line[:-1]\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "                continue\n",
    "            enroll_emb = enr_list[line.split(' ')[0]].squeeze()\n",
    "            test_emb = evl_data[line.split(' ')[1]].squeeze()\n",
    "\n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write('{:.3f}'.format(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 100000 == 0:\n",
    "                print((count+1) // 100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
