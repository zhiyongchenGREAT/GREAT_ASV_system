{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../train')\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "import training_utils\n",
    "from torch.utils.data import *\n",
    "from my_dataloader import *\n",
    "from read_data import *\n",
    "\n",
    "from model_bank import *\n",
    "from models import *\n",
    "\n",
    "import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = '/Lun2/rzz/kaldi-master/egs/zhiyong/sdsvc_exp/train_exp/new_pipe_test_fullmix 1L/ckpt/vox1test_metric_saver_MINC.model'\n",
    "# model_id = 'Xvector_SAP_1L'\n",
    "# model_metric = 'AM_normfree_softmax_anneal_ce_head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = '/Lun2/rzz/kaldi-master/egs/zhiyong/sdsvc_exp/train_exp/new_pipe_test_fullvoxonly/ckpt/vox1test_metric_saver_MINC.model'\n",
    "# model_id = 'Xvector_SAP_1L'\n",
    "# model_metric = 'AM_normfree_softmax_anneal_ce_head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Lun2/rzz/kaldi-master/egs/zhiyong/sdsvc_exp/train_exp/full mix 1L FOCAL_ALDA_OPT e_lr2/ckpt/sdsvc_metric_saver_MINC.model'\n",
    "model_id = ''\n",
    "model_metric = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "\n",
    "    train_list = '/Lun0/zhiyong/sdsvc_libri_full_dataset/mix_8983_fulltrain_fixed.csv'\n",
    "    vox_val_list = '/Lun0/zhiyong/sdsvc_libri_full_dataset/source_vox_7323_fullval.csv'\n",
    "    libri_val_list = '/Lun0/zhiyong/sdsvc_libri_full_dataset/source_libri_1172_fullval.csv'\n",
    "    sdsvc_val_list = '/Lun0/zhiyong/sdsvc_libri_full_dataset/target_sdsvc_488_fullval.csv'\n",
    "    sdsvc_trial_list = '/Lun0/zhiyong/sdsvc_libri_full_dataset/sdsvc_trial_list.csv'\n",
    "    sdsvc_trial_keys = '/Lun0/zhiyong/sdsvc_libri_full_dataset/sdsvc_trial_keys.csv'\n",
    "    vox1test_trial_list = '/Lun0/zhiyong/sdsvc_libri_full_dataset/vox1test_trial_list.csv'\n",
    "    vox1test_trial_keys = '/Lun0/zhiyong/sdsvc_libri_full_dataset/vox1test_trial_keys.csv'\n",
    "    libri_trial_list = '/Lun0/zhiyong/sdsvc_libri_full_dataset/libri_trial_list.csv'\n",
    "    libri_trial_keys = '/Lun0/zhiyong/sdsvc_libri_full_dataset/libri_trial_keys.csv'\n",
    "    # vox1test_aux_list = '/home/great10/sdsvc_libri_full_dataset/vox1test_aux_list.csv'\n",
    "    # vox1test_aux_keys = '/home/great10/sdsvc_libri_full_dataset/vox1test_aux_keys.csv'\n",
    "\n",
    "    scoring_config = {'p_target': [0.01], 'c_miss': 10, 'c_fa': 1}\n",
    "\n",
    "    num_workers = 32  # how many workers for loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Config()\n",
    "total_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7811, \\\n",
    "# 's': 50, 'm': 0.2, 'anneal_steps': 10000}\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = str(3)\n",
    "\n",
    "# device = torch.device(\"cuda:0\")\n",
    "\n",
    "# model = get_model(model_id, model_metric, model_settings, None)\n",
    "# checkpoint = torch.load(model_path, map_location='cpu')\n",
    "# model.load_state_dict(checkpoint['model'], strict=True)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7811, 'source_class_num': 7323, \\\n",
    "'s': 50, 'm': 0.2, 'anneal_steps': 10000, 'weight': 15, 'focal_d_gamma': 0, 'focal_al_gamma': 0}\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(3)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "model = FOCAL_ALDA.FOCAL_ALDA_2DO_OPT_FAST(model_settings)\n",
    "checkpoint = torch.load(model_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.benchmark = False\n",
    "# model.eval()\n",
    "\n",
    "# train_data = PickleDataSet(opt.vox1test_trial_list)\n",
    "# train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "# batch_sampler=None, num_workers=opt.num_workers, collate_fn=None,\\\n",
    "# pin_memory=False, drop_last=False, timeout=0,\\\n",
    "# worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "# test_list = {}\n",
    "\n",
    "# for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "#     batch_x = batch_x.to(device)\n",
    "#     label = batch_y[0]\n",
    "\n",
    "#     batch_y = torch.tensor([0]).to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "#     emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "#     if label not in test_list.keys():\n",
    "#         test_list[label] = emb[None, :]\n",
    "#     else:\n",
    "#         print('repeat eer:', label)\n",
    "#         break\n",
    "\n",
    "# msg = \"vox1test_ASV_eval Step: {:} Embcount: {:}\".format(total_step, (count + 1))\n",
    "# print(msg)\n",
    "\n",
    "# out_dir = './'\n",
    "# f_out = open(os.path.join(out_dir, 'scores'), 'w')   \n",
    "\n",
    "# for i in test_list:\n",
    "#     test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "\n",
    "# with open(opt.vox1test_trial_keys, 'r') as f:\n",
    "#     for count, line in enumerate(f):\n",
    "#         if count == 0:\n",
    "#             pass\n",
    "#             # print(line)\n",
    "\n",
    "#         enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "#         test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "#         cosine = np.dot(enroll_emb, test_emb)\n",
    "\n",
    "#         f_out.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "\n",
    "# f_out.close()\n",
    "\n",
    "# msg = \"vox1test_ASV_eval Step: {:} Trialcount: {:}\".format(total_step, (count + 1))\n",
    "# print(msg)\n",
    "\n",
    "\n",
    "# eer, minc, actc = score.scoring(os.path.join(out_dir, 'scores'), opt.vox1test_trial_keys, opt.scoring_config)\n",
    "\n",
    "# current_lr = 0.0\n",
    "# msg = \"vox1test_ASV_eval Step: {:} EER: {:.4f} MINC: {:.4f} ACTC: {:.4f} Lr: {:.5f}\"\\\n",
    "# .format(total_step, eer, minc, actc, current_lr)\n",
    "# print(msg)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.benchmark = False\n",
    "# model.eval()\n",
    "\n",
    "# train_data = PickleDataSet(opt.sdsvc_trial_list)\n",
    "# train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "# batch_sampler=None, num_workers=opt.num_workers, collate_fn=None,\\\n",
    "# pin_memory=False, drop_last=False, timeout=0,\\\n",
    "# worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "# test_list = {}\n",
    "\n",
    "# for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "#     batch_x = batch_x.to(device)\n",
    "#     label = batch_y[0]\n",
    "\n",
    "#     batch_y = torch.tensor([0]).to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "#     emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "#     if label not in test_list.keys():\n",
    "#         test_list[label] = emb[None, :]\n",
    "#     else:\n",
    "#         print('repeat eer:', label)\n",
    "#         break        \n",
    "\n",
    "# msg = \"sdsvc_ASV_eval Step: {:} Embcount: {:}\".format(total_step, (count + 1))\n",
    "# print(msg)\n",
    "\n",
    "# out_dir = './'\n",
    "# f_out = open(os.path.join(out_dir, 'scores'), 'w')   \n",
    "\n",
    "# for i in test_list:\n",
    "#     test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "\n",
    "# with open(opt.sdsvc_trial_keys, 'r') as f:\n",
    "#     for count, line in enumerate(f):\n",
    "#         if count == 0:\n",
    "#             pass\n",
    "#             # print(line)\n",
    "\n",
    "#         enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "#         test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "#         cosine = np.dot(enroll_emb, test_emb)\n",
    "\n",
    "#         f_out.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "\n",
    "# f_out.close()\n",
    "\n",
    "# msg = \"sdsvc_trial_keys Step: {:} Trialcount: {:}\".format(total_step, (count + 1))\n",
    "# print(msg)\n",
    "\n",
    "# eer, minc, actc = score.scoring(os.path.join(out_dir, 'scores'), opt.sdsvc_trial_keys, opt.scoring_config)\n",
    "\n",
    "# current_lr = 0.0\n",
    "# msg = \"sdsvc_ASV_eval Step: {:} EER: {:.4f} MINC: {:.4f} ACTC: {:.4f} Lr: {:.5f}\"\\\n",
    "# .format(total_step, eer, minc, actc, current_lr)\n",
    "# print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libri_ASV_eval Step: 0 Embcount: 2703\n",
      "libri_trial_keys Step: 0 Trialcount: 32436\n",
      "libri_ASV_eval Step: 0 EER: 0.0220 MINC: 0.1265 ACTC: 1.0000 Lr: 0.00000\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = False\n",
    "model.eval()\n",
    "\n",
    "train_data = PickleDataSet(opt.libri_trial_list)\n",
    "train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "batch_sampler=None, num_workers=opt.num_workers, collate_fn=None,\\\n",
    "pin_memory=False, drop_last=False, timeout=0,\\\n",
    "worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "test_list = {}\n",
    "\n",
    "for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "    batch_x = batch_x.to(device)\n",
    "    label = batch_y[0]\n",
    "\n",
    "    batch_y = torch.tensor([0]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "    emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "    if label not in test_list.keys():\n",
    "        test_list[label] = emb[None, :]\n",
    "    else:\n",
    "        print('repeat eer:', label)\n",
    "        break        \n",
    "\n",
    "msg = \"libri_ASV_eval Step: {:} Embcount: {:}\".format(total_step, (count + 1))\n",
    "print(msg)\n",
    "\n",
    "out_dir = './'\n",
    "f_out = open(os.path.join(out_dir, 'scores'), 'w')   \n",
    "\n",
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "\n",
    "with open(opt.libri_trial_keys, 'r') as f:\n",
    "    for count, line in enumerate(f):\n",
    "        if count == 0:\n",
    "            pass\n",
    "            # print(line)\n",
    "\n",
    "        enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "        test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "        cosine = np.dot(enroll_emb, test_emb)\n",
    "\n",
    "        f_out.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "\n",
    "f_out.close()\n",
    "\n",
    "msg = \"libri_trial_keys Step: {:} Trialcount: {:}\".format(total_step, (count + 1))\n",
    "print(msg)\n",
    "\n",
    "eer, minc, actc = score.scoring(os.path.join(out_dir, 'scores'), opt.libri_trial_keys, opt.scoring_config)\n",
    "\n",
    "current_lr = 0.0\n",
    "msg = \"libri_ASV_eval Step: {:} EER: {:.4f} MINC: {:.4f} ACTC: {:.4f} Lr: {:.5f}\"\\\n",
    ".format(total_step, eer, minc, actc, current_lr)\n",
    "print(msg) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
