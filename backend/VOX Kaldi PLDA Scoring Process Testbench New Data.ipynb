{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n",
      "/home/dell/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./train')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# import vox_model_bank\n",
    "from train import train_model_new\n",
    "from train.read_data import *\n",
    "from train.my_dataloader import *\n",
    "# from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = '/Lun2/rzz/kaldi-master/egs/zhiyong/sre19/exp/Xvector_SAP_nodilate_1L_long_cosanel_newloader_newdata_2(test)/ckpt/min_eer.model'\n",
    "model_id = 'Xvector_SAP_nodilate_1L'\n",
    "model_metric = 'AM_normfree_softmax_anneal_ce_head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "component_dir = './new_testbench'\n",
    "PLDA_DIM = 370\n",
    "PLDA_DATA_NAME = 'plda_data'\n",
    "TEST_DATA_NAME = 'test_data_370'\n",
    "PLDA_PARA_NAME = 'plda_para_370'\n",
    "SCORING_PLDA_NAME = 'score_plda_370'\n",
    "SCORING_COSINE_NAME = 'score_cosine_370'\n",
    "AUX_DATA_NAME = 'aux_data_370'\n",
    "SCORING_AUX_COSINE = 'score_aux_cosine_370'\n",
    "SCORING_AUX_PLDA = 'score_aux_plda_370'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(component_dir):\n",
    "    os.makedirs(component_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_p = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/plda_full_data.csv'\n",
    "train_list = '/Lun0/zhiyong/dataset/plda_full_data_noVAD.csv'\n",
    "# train_data = CSVDataSet(train_list)\n",
    "train_data = PickleDataSet(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_len = len(train_data)\n",
    "num_per_process = (1276888 // num_p) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "class_list_new_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45580\n"
     ]
    }
   ],
   "source": [
    "data_m = []\n",
    "# class_list_new_m = []\n",
    "for i in range(num_p):\n",
    "    data = torch.utils.data.Subset(train_data, np.arange(i*num_per_process, min((i+1)*num_per_process, train_data_len)))\n",
    "    data_m.append(data)\n",
    "    class_list_new_m.append({})\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_m(i, train_data, class_list_new_m):\n",
    "#     train_list = '/Lun0/zhiyong/dataset/vox12_kaldi_train_data/vox12_kaldi_train_data.csv'\n",
    "    model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if i < 26:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(i%2)\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     torch.cuda.set_device(i%2)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     train_data = CSVDataSet(train_list)\n",
    "#     train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=False)\n",
    "\n",
    "    train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "    batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "    pin_memory=False, drop_last=False, timeout=0,\\\n",
    "    worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "    model = train_model_new.get_model(model_id, model_metric, None, model_settings, None)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    class_list_new = {}\n",
    "\n",
    "    for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = batch_x.to(device)\n",
    "        label = batch_y[0].split('-')[0]\n",
    "        batch_y = torch.tensor([0]).to(device)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "        except:\n",
    "            print('Proc', str(i), 'EER:', label)\n",
    "            continue\n",
    "    #     _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "        emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "        if label not in class_list_new.keys():\n",
    "            class_list_new[label] = emb[None, :]\n",
    "        else:\n",
    "            class_list_new[label] = np.append(class_list_new[label], emb[None, :], axis=0)\n",
    "\n",
    "        if (count+1) % 10000 == 0:\n",
    "            print('Proc '+ str(i) + ':' + str((count+1) // 10000))\n",
    "    \n",
    "    class_list_new_m[i] = class_list_new\n",
    "    del model, batch_x, batch_y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Proc 27:1\n",
      "Proc 24:1\n",
      "Proc 26:1\n",
      "Proc 22:1\n",
      "Proc 20:1\n",
      "Proc 16:1\n",
      "Proc 10:1\n",
      "Proc 6:1\n",
      "Proc 8:1\n",
      "Proc 18:1\n",
      "Proc 4:1\n",
      "Proc 25:1\n",
      "Proc 2:1\n",
      "Proc 12:1\n",
      "Proc 14:1\n",
      "Proc 21:1\n",
      "Proc 19:1\n",
      "Proc 0:1\n",
      "Proc 11:1\n",
      "Proc 23:1\n",
      "Proc 9:1\n",
      "Proc 15:1\n",
      "Proc 5:1\n",
      "Proc 7:1\n",
      "Proc 13:1\n",
      "Proc 3:1\n",
      "Proc 17:1\n",
      "Proc 1:1\n",
      "Proc 24:2\n",
      "Proc 27:2\n",
      "Proc 26:2\n",
      "Proc 20:2\n",
      "Proc 22:2\n",
      "Proc 18:2\n",
      "Proc 16:2\n",
      "Proc 8:2\n",
      "Proc 14:2\n",
      "Proc 12:2\n",
      "Proc 25:2\n",
      "Proc 10:2\n",
      "Proc 4:2\n",
      "Proc 6:2\n",
      "Proc 2:2\n",
      "Proc 21:2\n",
      "Proc 0:2\n",
      "Proc 19:2\n",
      "Proc 9:2\n",
      "Proc 11:2\n",
      "Proc 23:2\n",
      "Proc 17:2\n",
      "Proc 15:2\n",
      "Proc 7:2\n",
      "Proc 13:2\n",
      "Proc 5:2\n",
      "Proc 3:2\n",
      "Proc 1:2\n",
      "Proc 24:3\n",
      "Proc 26:3\n",
      "Proc 27:3\n",
      "Proc 22:3\n",
      "Proc 18:3\n",
      "Proc 20:3\n",
      "Proc 16:3\n",
      "Proc 14:3\n",
      "Proc 8:3\n",
      "Proc 12:3\n",
      "Proc 10:3\n",
      "Proc 4:3\n",
      "Proc 25:3\n",
      "Proc 6:3\n",
      "Proc 2:3\n",
      "Proc 0:3\n",
      "Proc 19:3\n",
      "Proc 21:3\n",
      "Proc 9:3\n",
      "Proc 23:3\n",
      "Proc 11:3\n",
      "Proc 15:3\n",
      "Proc 17:3\n",
      "Proc 7:3\n",
      "Proc 13:3\n",
      "Proc 5:3\n",
      "Proc 3:3\n",
      "Proc 1:3\n",
      "Proc 26:4\n",
      "Proc 24:4\n",
      "Proc 27:4\n",
      "Proc 22:4\n",
      "Proc 20:4\n",
      "Proc 18:4\n",
      "Proc 16:4\n",
      "Proc 14:4\n",
      "Proc 12:4\n",
      "Proc 8:4\n",
      "Proc 10:4\n",
      "Proc 25:4\n",
      "Proc 6:4\n",
      "Proc 4:4\n",
      "Proc 2:4\n",
      "Proc 0:4\n",
      "Proc 19:4\n",
      "Proc 21:4\n",
      "Proc 23:4\n",
      "Proc 15:4\n",
      "Proc 9:4\n",
      "Proc 11:4\n",
      "Proc 7:4\n",
      "Proc 13:4\n",
      "Proc 5:4\n",
      "Proc 17:4\n",
      "Proc 3:4\n",
      "Proc 1:4\n"
     ]
    }
   ],
   "source": [
    "processes = [Process(target = extract_feature_m, args = (i, data_m[i], class_list_new_m)) for i in range(num_p)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new_m:\n",
    "    for j in i:\n",
    "        count += len(i[j])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_list_new = class_list_new_m[0]\n",
    "\n",
    "for count, this_list in enumerate(class_list_new_m):\n",
    "    if count == 0:\n",
    "        continue\n",
    "    for this_label in this_list:\n",
    "        if this_label not in class_list_new.keys():\n",
    "            class_list_new[this_label] = this_list[this_label]\n",
    "        else:\n",
    "            class_list_new[this_label] = np.append(class_list_new[this_label], this_list[this_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nanlist = []\n",
    "for i in class_list_new:\n",
    "    if np.isnan(class_list_new[i]).any():\n",
    "        print(i)\n",
    "        nanlist.append(i)\n",
    "for i in nanlist:\n",
    "    class_list_new.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7323"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+PLDA_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(class_list_new, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_list_new = {}\n",
    "# for i in class_list:\n",
    "#     class_list_new[i[:-1]] = class_list[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLDA_FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./train')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# import vox_model_bank\n",
    "from train import train_model_new\n",
    "from train.read_data import *\n",
    "from train.my_dataloader import *\n",
    "# from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kaldi_plda import *\n",
    "from kaldi_lda import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+PLDA_DATA_NAME, 'rb') as handle:\n",
    "    class_list_new = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of mean: 1.9705881360946418\n"
     ]
    }
   ],
   "source": [
    "# Substract global mean\n",
    "global_mean = np.zeros(512)\n",
    "num_utt = 0\n",
    "for count, i in enumerate(class_list_new):\n",
    "    num_utt += class_list_new[i].shape[0]\n",
    "    global_mean += class_list_new[i].shape[0] * np.mean(class_list_new[i], axis=0)\n",
    "    \n",
    "global_mean = (1.0 / num_utt) * global_mean\n",
    "print('Norm of mean:', np.linalg.norm(global_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in class_list_new:\n",
    "    class_list_new[i] = class_list_new[i] - global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # normlize to sqrt(dim)\n",
    "# for i in class_list_new:\n",
    "#     scale = np.sqrt(512) / np.linalg.norm(class_list_new[i], axis=1, keepdims=True)\n",
    "#     class_list_new[i] = scale * class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda norm of global mean: 9.641873606430675e-08\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(lda_dim=PLDA_DIM, ivector_dim=512)\n",
    "for i in class_list_new:\n",
    "    lda.AccStats(class_list_new[i])\n",
    "print('lda norm of global mean:', lda.GetGlobalMean()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input data has norm of mean 9.641873606430675e-08\n",
      "[7.01190490e+00 6.75681662e+00 6.53853053e+00 6.25568993e+00\n",
      " 6.11248365e+00 5.95853316e+00 5.76067349e+00 5.64741497e+00\n",
      " 5.57487744e+00 5.41990231e+00 5.38111534e+00 5.31902969e+00\n",
      " 5.23789065e+00 5.19969617e+00 5.15591191e+00 5.06367837e+00\n",
      " 4.95002558e+00 4.87409618e+00 4.84840474e+00 4.74871468e+00\n",
      " 4.71036534e+00 4.62632340e+00 4.59444607e+00 4.53859824e+00\n",
      " 4.50825004e+00 4.44792223e+00 4.42513736e+00 4.34977219e+00\n",
      " 4.28159505e+00 4.25209140e+00 4.19223498e+00 4.16862494e+00\n",
      " 4.06981441e+00 4.06355494e+00 4.03968798e+00 3.96515890e+00\n",
      " 3.92289551e+00 3.89805072e+00 3.86241858e+00 3.79790583e+00\n",
      " 3.72304290e+00 3.67162826e+00 3.64237800e+00 3.57782648e+00\n",
      " 3.55594916e+00 3.51338202e+00 3.48159699e+00 3.44671244e+00\n",
      " 3.38799819e+00 3.37222889e+00 3.31932983e+00 3.26479589e+00\n",
      " 3.23583721e+00 3.18890552e+00 3.16877421e+00 3.13774669e+00\n",
      " 3.09139334e+00 3.04371133e+00 3.00723616e+00 2.97468080e+00\n",
      " 2.93475707e+00 2.91202466e+00 2.88878275e+00 2.87596840e+00\n",
      " 2.86439953e+00 2.80306845e+00 2.76811226e+00 2.75282091e+00\n",
      " 2.73265968e+00 2.70924597e+00 2.66613388e+00 2.63483158e+00\n",
      " 2.61028253e+00 2.58592747e+00 2.53934771e+00 2.51142099e+00\n",
      " 2.49924999e+00 2.49027539e+00 2.47251919e+00 2.42728511e+00\n",
      " 2.39750196e+00 2.37405700e+00 2.35193609e+00 2.32716667e+00\n",
      " 2.30830347e+00 2.25238815e+00 2.22747853e+00 2.19589194e+00\n",
      " 2.18315646e+00 2.16168723e+00 2.14473982e+00 2.13666842e+00\n",
      " 2.11730956e+00 2.09368117e+00 2.07249359e+00 2.02863364e+00\n",
      " 2.00766347e+00 1.98834752e+00 1.97887775e+00 1.94679614e+00\n",
      " 1.93039694e+00 1.86316743e+00 1.83820799e+00 1.80521765e+00\n",
      " 1.80025135e+00 1.73680036e+00 1.72558673e+00 1.69926713e+00\n",
      " 1.68113125e+00 1.64568037e+00 1.64385487e+00 1.61517082e+00\n",
      " 1.59876115e+00 1.58277031e+00 1.56115538e+00 1.55320346e+00\n",
      " 1.51243525e+00 1.49619275e+00 1.47218505e+00 1.43834861e+00\n",
      " 1.40241336e+00 1.39010490e+00 1.35986172e+00 1.34133043e+00\n",
      " 1.30430106e+00 1.27390776e+00 1.26693302e+00 1.24963291e+00\n",
      " 1.22605047e+00 1.20930857e+00 1.17516276e+00 1.15928254e+00\n",
      " 1.10827155e+00 1.10579309e+00 1.08143299e+00 1.04990833e+00\n",
      " 1.02459246e+00 1.02341005e+00 9.85720533e-01 9.61891596e-01\n",
      " 9.42982519e-01 9.21998780e-01 8.82967456e-01 8.72463017e-01\n",
      " 8.44555158e-01 8.17005973e-01 7.93647028e-01 7.76731812e-01\n",
      " 7.45476639e-01 7.08294780e-01 6.86481937e-01 6.57690591e-01\n",
      " 6.51422345e-01 5.97619248e-01 5.42989137e-01 5.23422102e-01\n",
      " 4.98348925e-01 4.77149980e-01 4.23471134e-01 3.70797065e-01\n",
      " 3.59415774e-01 3.00606079e-01 2.58306813e-01 2.28607677e-01\n",
      " 1.95625143e-01 1.75367642e-01 1.46014513e-01 1.28691052e-01\n",
      " 8.98530433e-02 8.07634505e-02 5.95855167e-02 5.23992103e-02\n",
      " 4.70815083e-02 4.34232852e-02 3.61298754e-02 2.98530038e-02\n",
      " 2.48705681e-02 2.35851227e-02 1.95286451e-02 1.69957990e-02\n",
      " 1.46860880e-02 1.21079527e-02 1.10980698e-02 9.93992518e-03\n",
      " 8.83581804e-03 7.61617126e-03 7.20521993e-03 6.65891856e-03\n",
      " 6.43155722e-03 5.94651053e-03 5.82038515e-03 5.57402635e-03\n",
      " 5.16710101e-03 5.06908641e-03 4.74478140e-03 4.38495356e-03\n",
      " 4.16813362e-03 4.08939712e-03 3.65184440e-03 3.47949909e-03\n",
      " 3.29645439e-03 3.24561828e-03 3.09080106e-03 2.96960479e-03\n",
      " 2.84422802e-03 2.66636480e-03 2.60714860e-03 2.44392856e-03\n",
      " 2.28607000e-03 2.16064731e-03 2.13101155e-03 2.09523859e-03\n",
      " 2.02501915e-03 1.94251359e-03 1.92125743e-03 1.86249722e-03\n",
      " 1.83413055e-03 1.74571568e-03 1.71652971e-03 1.67846122e-03\n",
      " 1.57774025e-03 1.54048222e-03 1.50385920e-03 1.46617952e-03\n",
      " 1.44405312e-03 1.42015405e-03 1.38468954e-03 1.35962379e-03\n",
      " 1.32311004e-03 1.29079373e-03 1.28130524e-03 1.26447037e-03\n",
      " 1.21417661e-03 1.18156807e-03 1.17149410e-03 1.15402245e-03\n",
      " 1.13138434e-03 1.11139484e-03 1.08723355e-03 1.06463934e-03\n",
      " 1.05900574e-03 1.03875135e-03 1.01130509e-03 9.94422771e-04\n",
      " 9.77763215e-04 9.61645653e-04 9.40291655e-04 9.31481056e-04\n",
      " 9.17237684e-04 9.09895749e-04 9.00540358e-04 8.82440489e-04\n",
      " 8.77600637e-04 8.64681170e-04 8.49183888e-04 8.47919815e-04\n",
      " 8.36188645e-04 8.13606259e-04 8.06461647e-04 7.91656685e-04\n",
      " 7.87537605e-04 7.69919355e-04 7.60725888e-04 7.44501528e-04\n",
      " 7.39846716e-04 7.30456784e-04 7.16250308e-04 7.08588571e-04\n",
      " 6.99920974e-04 6.96945088e-04 6.95438919e-04 6.76953446e-04\n",
      " 6.70633304e-04 6.55723181e-04 6.46802028e-04 6.42673428e-04\n",
      " 6.36047590e-04 6.24363606e-04 6.18873107e-04 6.14856934e-04\n",
      " 6.06837331e-04 6.00400230e-04 5.95799374e-04 5.88649844e-04\n",
      " 5.87224146e-04 5.73575076e-04 5.68754828e-04 5.60811273e-04\n",
      " 5.59500017e-04 5.54052382e-04 5.43516854e-04 5.40823128e-04\n",
      " 5.38010822e-04 5.35647654e-04 5.31539068e-04 5.22636787e-04\n",
      " 5.15352779e-04 5.13604532e-04 5.08347723e-04 5.03630612e-04\n",
      " 4.95788463e-04 4.93156317e-04 4.89114666e-04 4.86122788e-04\n",
      " 4.77366778e-04 4.74588437e-04 4.69555699e-04 4.66400719e-04\n",
      " 4.60788245e-04 4.55495115e-04 4.51422460e-04 4.48002291e-04\n",
      " 4.45603325e-04 4.43398202e-04 4.35994025e-04 4.33107565e-04\n",
      " 4.27534264e-04 4.24282181e-04 4.20404387e-04 4.12010008e-04\n",
      " 4.10059373e-04 4.07764398e-04 4.02257420e-04 4.00794722e-04\n",
      " 3.99235784e-04 3.97516295e-04 3.90868507e-04 3.89592037e-04\n",
      " 3.87512351e-04 3.84632269e-04 3.77020784e-04 3.73522364e-04\n",
      " 3.72927493e-04 3.66062967e-04 3.63919240e-04 3.60036860e-04\n",
      " 3.59354962e-04 3.55639701e-04 3.52414461e-04 3.50360789e-04\n",
      " 3.47156264e-04 3.46141020e-04 3.44457453e-04 3.40093148e-04\n",
      " 3.36950601e-04 3.32473051e-04 3.30968644e-04 3.27108307e-04\n",
      " 3.24586611e-04 3.21917088e-04 3.18269984e-04 3.16201073e-04\n",
      " 3.13593124e-04 3.11225940e-04 3.09161930e-04 3.06719205e-04\n",
      " 3.03768834e-04 3.02202086e-04 2.99985008e-04 2.97486014e-04\n",
      " 2.92276651e-04 2.89988534e-04 2.87571679e-04 2.86359582e-04\n",
      " 2.81954368e-04 2.81530935e-04 2.81018894e-04 2.77104065e-04\n",
      " 2.76333412e-04 2.73608658e-04 2.70526215e-04 2.69865961e-04\n",
      " 2.66358817e-04 2.64890279e-04 2.62616183e-04 2.60694146e-04\n",
      " 2.59875665e-04 2.56800500e-04 2.55723048e-04 2.52834586e-04\n",
      " 2.49502489e-04 2.48174272e-04 2.45265661e-04 2.43736249e-04\n",
      " 2.42852404e-04 2.40490233e-04 2.38602052e-04 2.35357983e-04\n",
      " 2.34692255e-04 2.33321361e-04 2.32322432e-04 2.30155091e-04\n",
      " 2.26614611e-04 2.25580995e-04 2.23635578e-04 2.22122875e-04\n",
      " 2.20987783e-04 2.17813711e-04 2.17153065e-04 2.15398017e-04\n",
      " 2.13744459e-04 2.12653408e-04 2.10804164e-04 2.08537320e-04\n",
      " 2.07026353e-04 2.05859286e-04 2.01086440e-04 2.00153275e-04\n",
      " 1.99297855e-04 1.96561414e-04 1.95738365e-04 1.94750089e-04\n",
      " 1.92496281e-04 1.91086155e-04 1.89591196e-04 1.88202819e-04\n",
      " 1.87796557e-04 1.85246885e-04 1.84971438e-04 1.82974150e-04\n",
      " 1.79982109e-04 1.77720238e-04 1.76297165e-04 1.74962580e-04\n",
      " 1.73266720e-04 1.72189163e-04 1.71349523e-04 1.68583511e-04\n",
      " 1.67095673e-04 1.66706061e-04 1.65429352e-04 1.63860504e-04\n",
      " 1.61517146e-04 1.60526333e-04 1.59672788e-04 1.58419226e-04\n",
      " 1.58171467e-04 1.55307888e-04 1.54088931e-04 1.52555335e-04\n",
      " 1.51569923e-04 1.49823879e-04 1.48722874e-04 1.46846461e-04\n",
      " 1.45928812e-04 1.44227513e-04 1.42827932e-04 1.42422769e-04\n",
      " 1.41577243e-04 1.40021808e-04 1.38648701e-04 1.37590029e-04\n",
      " 1.36614973e-04 1.35292333e-04 1.34186086e-04 1.33206958e-04\n",
      " 1.31995798e-04 1.31523648e-04 1.30158084e-04 1.27797622e-04\n",
      " 1.26682466e-04 1.25518742e-04 1.24519029e-04 1.23284655e-04\n",
      " 1.22379661e-04 1.21245636e-04 1.19842088e-04 1.19038137e-04\n",
      " 1.18275595e-04 1.16979033e-04 1.15074766e-04 1.14196537e-04\n",
      " 1.12435868e-04 1.12123236e-04 1.10683549e-04 1.09457730e-04\n",
      " 1.08649877e-04 1.07591438e-04 1.06707342e-04 1.05470747e-04\n",
      " 1.04458549e-04 1.04075350e-04 1.01826185e-04 1.00874041e-04\n",
      " 9.97529951e-05 9.74343900e-05 9.67193363e-05 9.56367751e-05\n",
      " 9.43077499e-05 9.39990215e-05 9.30565845e-05 9.24288979e-05\n",
      " 9.03165224e-05 8.92649220e-05 8.81987869e-05 8.78416478e-05\n",
      " 8.69982863e-05 8.49103057e-05 8.46237219e-05 8.36127361e-05\n",
      " 8.24187036e-05 8.07262356e-05 7.96919998e-05 7.84922378e-05\n",
      " 7.69550140e-05 7.64413830e-05 7.55467501e-05 7.33162343e-05\n",
      " 7.19422311e-05 6.99753625e-05 6.89090799e-05 6.60633110e-05]\n",
      "[8.07989212 7.21778079 5.8904341  5.15080362 4.7302275  4.15403744\n",
      " 3.99383618 3.63447651 3.45939434 3.26295624 3.09979301 2.92855832\n",
      " 2.766262   2.66294305 2.45968911 2.41496127 2.30625234 2.28097716\n",
      " 2.21707954 2.12541285 2.08638457 2.02445998 1.9207608  1.85233115\n",
      " 1.83030956 1.77017587 1.72893062 1.6800222  1.65788071 1.64865859\n",
      " 1.59416565 1.54173326 1.50551477 1.49379866 1.47077623 1.44007072\n",
      " 1.43503925 1.41225207 1.35746827 1.35251838 1.34165387 1.28122493\n",
      " 1.27735732 1.26357575 1.24789799 1.2214984  1.21076324 1.19255159\n",
      " 1.17280037 1.13948023 1.13265809 1.10888312 1.10369793 1.08125672\n",
      " 1.07617833 1.05045515 1.0391252  1.01341374 0.99338571 0.98656491\n",
      " 0.97869527 0.95530038 0.95392633 0.93146179 0.91417809 0.91268754\n",
      " 0.87907744 0.86789281 0.85874722 0.85502889 0.85347226 0.84578537\n",
      " 0.83173277 0.82486657 0.8106771  0.80710072 0.80109976 0.79207146\n",
      " 0.78734789 0.76356117 0.75587216 0.74953435 0.7474362  0.73049122\n",
      " 0.7189019  0.71471786 0.70995011 0.70406988 0.68918971 0.68602996\n",
      " 0.6833013  0.67423361 0.67049552 0.66103874 0.65037413 0.63932224\n",
      " 0.62896356 0.62343266 0.61738815 0.61439185 0.60949894 0.59989343\n",
      " 0.59958939 0.5857487  0.58392853 0.57904407 0.57456792 0.56843072\n",
      " 0.55810519 0.55683323 0.5532243  0.55067637 0.53851161 0.53386454\n",
      " 0.53075318 0.52869247 0.52634416 0.51644044 0.50726647 0.50477602\n",
      " 0.49912914 0.49445388 0.49055227 0.48441464 0.48217132 0.47757698\n",
      " 0.46904246 0.46659346 0.46236693 0.45720133 0.45227449 0.44645786\n",
      " 0.4444343  0.43780789 0.43680809 0.43297653 0.423705   0.4218169\n",
      " 0.41903232 0.41481185 0.41405362 0.40494594 0.40469628 0.39985704\n",
      " 0.39843701 0.39606697 0.3911775  0.38805297 0.38216937 0.38022075\n",
      " 0.37755298 0.37269182 0.37007154 0.36565206 0.36176019 0.35753188\n",
      " 0.35578668 0.35193261 0.35070508 0.34737981 0.34454358 0.3388367\n",
      " 0.33863949 0.33459946 0.3336774  0.33183251 0.32789808 0.32647415\n",
      " 0.32592259 0.32237441 0.31637409 0.31372686 0.31201727 0.30482254\n",
      " 0.30388643 0.30169647 0.2974982  0.29594709 0.29506593 0.29375336\n",
      " 0.28974838 0.28801212 0.28482747 0.2836286  0.2818503  0.27891988\n",
      " 0.27838278 0.27682383 0.27200709 0.27129536 0.26727033 0.26461642\n",
      " 0.26403644 0.26157223 0.2604338  0.259145   0.25689346 0.25412449\n",
      " 0.25350082 0.25163316 0.24835969 0.24733146 0.24404851 0.2425684\n",
      " 0.24150114 0.24019939 0.23905432 0.23738063 0.23686145 0.23276144\n",
      " 0.2310249  0.23038843 0.2290578  0.22742108 0.2253748  0.22484911\n",
      " 0.22187404 0.22056203 0.21903139 0.21817682 0.21658152 0.21564012\n",
      " 0.21493852 0.21210916 0.21100692 0.20996156 0.20782289 0.20643705\n",
      " 0.20559318 0.20371382 0.20289415 0.20206833 0.20116705 0.1992312\n",
      " 0.19808919 0.19706301 0.19419877 0.19348785 0.19239982 0.19174974\n",
      " 0.18997559 0.18813382 0.18812502 0.18766022 0.18529333 0.1833955\n",
      " 0.18312428 0.18128784 0.18025426 0.1789808  0.17783074 0.17610201\n",
      " 0.17564822 0.17375023 0.17182501 0.17086856 0.1707359  0.16986276\n",
      " 0.16832063 0.16798238 0.1659075  0.16535979 0.16471135 0.16332534\n",
      " 0.1621863  0.1615834  0.16110781 0.16014143 0.15954723 0.1587706\n",
      " 0.1582445  0.15665406 0.1556928  0.15531613 0.15376159 0.15328592\n",
      " 0.15302539 0.15042259 0.14977105 0.14915626 0.14852998 0.14758656\n",
      " 0.14660305 0.14491418 0.14446801 0.14386448 0.1424858  0.14144041\n",
      " 0.14098812 0.14021829 0.13897126 0.13843321 0.13773188 0.13763475\n",
      " 0.1368068  0.13573002 0.13505031 0.13403234 0.13302153 0.13271824\n",
      " 0.13215002 0.13107409 0.13082587 0.13016891 0.12954823 0.12807304\n",
      " 0.12747434 0.12649877 0.12578351 0.12500611 0.12449423 0.12391431\n",
      " 0.12339993 0.12295074 0.12201023 0.12125907 0.12112258 0.12035917\n",
      " 0.11989001 0.11861018 0.11815517 0.11804501 0.11720293 0.11634543\n",
      " 0.11519189 0.11413366 0.11380629 0.11270697 0.11193176 0.1119134\n",
      " 0.11147394 0.11131063 0.11007806 0.10948133 0.1093358  0.10859516\n",
      " 0.10797899 0.10781655 0.10735588 0.10664047 0.10614305 0.10574216\n",
      " 0.10432027 0.10399609 0.10350405 0.10329433 0.10260413 0.10237036\n",
      " 0.10134805 0.10108374 0.10033099 0.0999897  0.09942819 0.09860755\n",
      " 0.09834159 0.09761178 0.09748906 0.09652309 0.09593176 0.09534164\n",
      " 0.09516967 0.0949915  0.09457686 0.09318571 0.09291288 0.09258333\n",
      " 0.09239241 0.09166779 0.09128559 0.09093116 0.09031224 0.08960646\n",
      " 0.08925803 0.08909865 0.08898745 0.08851138 0.08828639 0.08795674\n",
      " 0.08723435 0.08683665 0.08616122 0.08572696 0.08562319 0.08517968\n",
      " 0.08470571 0.08397655 0.08321457 0.08309559 0.08281906 0.08222881\n",
      " 0.0818812  0.08124221 0.08087179 0.08070997 0.07987393 0.07951544\n",
      " 0.0793106  0.07885681 0.07842391 0.07764536 0.07753069 0.07729064\n",
      " 0.07714349 0.07658481 0.07640514 0.07634881 0.07562464 0.07522812\n",
      " 0.07491424 0.07391117 0.07375727 0.07355642 0.07313947 0.07262619\n",
      " 0.07203453 0.07187752 0.07153159 0.07134193 0.07094547 0.07043055\n",
      " 0.07027685 0.06983851 0.06974232 0.06934114 0.06862795 0.06840831\n",
      " 0.0681071  0.06787347 0.06715175 0.06681515 0.06659    0.06604506\n",
      " 0.06565256 0.06521825 0.0651241  0.06470717 0.06434369 0.06395644\n",
      " 0.06381314 0.06319551 0.06280488 0.06247117 0.06241157 0.061875\n",
      " 0.06137653 0.06119032 0.06052294 0.06044267 0.05993094 0.05975454\n",
      " 0.05955295 0.05924133 0.05882579 0.05841201 0.05805264 0.05775289\n",
      " 0.0571914  0.05686684 0.05676489 0.05658737 0.05646609 0.05613059\n",
      " 0.05576556 0.05524215 0.05501878 0.05472768 0.05440597 0.05413196\n",
      " 0.05395726 0.05362115 0.05322859 0.05296836 0.05246933 0.05210337\n",
      " 0.05170617 0.05145475 0.05116211 0.05097581 0.05053852 0.05036981\n",
      " 0.04995901 0.0495593  0.04909031 0.04878364 0.04853368 0.04835259\n",
      " 0.04814556 0.0477073  0.04733175 0.04685652 0.04668761 0.04647637\n",
      " 0.04601069 0.0458273  0.04547564 0.04533526 0.04500185 0.04465502\n",
      " 0.0439594  0.0437539  0.04335692 0.04310528 0.04241455 0.0423697\n",
      " 0.04182014 0.04164885 0.04097891 0.04054367 0.03988333 0.03907085\n",
      " 0.03804346 0.03785201]\n"
     ]
    }
   ],
   "source": [
    "transform = lda.ComputeLdaTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # normlize to sqrt(dim)\n",
    "# for i in class_list_new:\n",
    "#     scale = np.sqrt(512) / np.linalg.norm(class_list_new[i], axis=1, keepdims=True)\n",
    "#     class_list_new[i] = scale * class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in class_list_new:\n",
    "    class_list_new[i] = class_list_new[i].dot(transform.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normlize to sqrt(dim)\n",
    "for i in class_list_new:\n",
    "    scale = np.sqrt(PLDA_DIM) / np.linalg.norm(class_list_new[i], axis=1, keepdims=True)\n",
    "    class_list_new[i] = scale * class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plda_stats = PldaStats(PLDA_DIM)\n",
    "for i in class_list_new:\n",
    "    plda_stats.add_samples(class_list_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plda_stats.sort()\n",
    "plda_stats.is_sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "nllr_x: 411.3536651606943\n",
      "nllr_y: -371.394730264205\n",
      "normalized_nllr: 39.95893489648931\n",
      "nllr_m: 412.13621538628524\n",
      "nllr_m_2: 412.13621538628604\n",
      "part1_residual -455.29228631886446\n",
      "part2_mean -412.13621538628524\n",
      "normlized_obj -455.04478465275184\n",
      "2 5\n",
      "nllr_x: 240.15276805056112\n",
      "nllr_y: -458.94205476522495\n",
      "normalized_nllr: -218.7892867146638\n",
      "nllr_m: 246.5813414941023\n",
      "nllr_m_2: 246.5813414941021\n",
      "part1_residual -437.3886274503415\n",
      "part2_mean -246.5813414941023\n",
      "normlized_obj -436.294340594284\n",
      "3 5\n",
      "nllr_x: 237.46553834505684\n",
      "nllr_y: -458.8741951366892\n",
      "normalized_nllr: -221.40865679163232\n",
      "nllr_m: 245.48345787472775\n",
      "nllr_m_2: 245.48345787472786\n",
      "part1_residual -437.3910096499305\n",
      "part2_mean -245.48345787472775\n",
      "normlized_obj -436.2904127286267\n",
      "4 5\n",
      "nllr_x: 237.20065986248494\n",
      "nllr_y: -458.7576755590343\n",
      "normalized_nllr: -221.55701569654934\n",
      "nllr_m: 245.46150954196784\n",
      "nllr_m_2: 245.4615095419679\n",
      "part1_residual -437.3910074823672\n",
      "part2_mean -245.46150954196784\n",
      "normlized_obj -436.2902846989926\n",
      "5 5\n",
      "nllr_x: 237.16177247008068\n",
      "nllr_y: -458.73833011962114\n",
      "normalized_nllr: -221.57655764954046\n",
      "nllr_m: 245.46090097759316\n",
      "nllr_m_2: 245.46090097759335\n",
      "part1_residual -437.3910038566896\n",
      "part2_mean -245.46090097759313\n",
      "normlized_obj -436.2902776039693\n"
     ]
    }
   ],
   "source": [
    "# test_fin_prior\n",
    "plda_estimator = PldaEstimation(plda_stats)\n",
    "plda_paras = plda_estimator.estimate(iteration=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+ PLDA_PARA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(plda_paras, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+ PLDA_PARA_NAME, 'rb') as handle:\n",
    "    plda_paras = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plda = PLDA(plda_paras[0], plda_paras[1], plda_paras[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new training model bank\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n"
     ]
    }
   ],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/vox1_kaldi_test/vox1_kaldi_test.csv'\n",
    "train_list = '/Lun0/zhiyong/dataset/trial_data_csv.csv'\n",
    "test_list = {}\n",
    "model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# train_data = CSVDataSet(train_list)\n",
    "# train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=True)\n",
    "train_data = PickleDataSet(train_list)\n",
    "train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "pin_memory=False, drop_last=False, timeout=0,\\\n",
    "worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "model = train_model_new.get_model(model_id, model_metric, _, model_settings, _)\n",
    "checkpoint = torch.load(model_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "    batch_x = batch_x.to(device)\n",
    "    label = batch_y[0]\n",
    "\n",
    "    batch_y = torch.tensor([0]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "    emb = emb.squeeze().data.cpu().numpy()\n",
    "    \n",
    "    if label not in test_list.keys():\n",
    "        test_list[label] = emb[None, :]\n",
    "    else:\n",
    "        print('repeat eer:', label)\n",
    "        break\n",
    "#         test_list[label] = np.append(test_list[label], emb[None, :], axis=0)\n",
    "    \n",
    "    if (count+1) % 500 == 0:\n",
    "        print(count+1)\n",
    "\n",
    "del model, batch_x, batch_y\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4874"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4874"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+TEST_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(test_list, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aux trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new training model bank\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n"
     ]
    }
   ],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/vox1_kaldi_test/vox1_kaldi_test.csv'\n",
    "train_list = '/Lun0/zhiyong/dataset/trial_aux_data.csv'\n",
    "test_list = {}\n",
    "model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# train_data = CSVDataSet(train_list)\n",
    "# train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=True)\n",
    "train_data = PickleDataSet(train_list)\n",
    "train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "pin_memory=False, drop_last=False, timeout=0,\\\n",
    "worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "model = train_model_new.get_model(model_id, model_metric, _, model_settings, _)\n",
    "checkpoint = torch.load(model_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "    batch_x = batch_x.to(device)\n",
    "    label = batch_y[0]\n",
    "\n",
    "    batch_y = torch.tensor([0]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "    emb = emb.squeeze().data.cpu().numpy()\n",
    "    \n",
    "    if label not in test_list.keys():\n",
    "        test_list[label] = emb[None, :]\n",
    "    else:\n",
    "        print('repeat eer:', label)\n",
    "        break\n",
    "#         test_list[label] = np.append(test_list[label], emb[None, :], axis=0)\n",
    "    \n",
    "    if (count+1) % 500 == 0:\n",
    "        print(count+1)\n",
    "\n",
    "del model, batch_x, batch_y\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36237"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36237"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+AUX_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(test_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sdsvc dev trial & cos scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new training model bank\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n"
     ]
    }
   ],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/vox1_kaldi_test/vox1_kaldi_test.csv'\n",
    "train_list = '/Lun0/zhiyong/sdsvc_t2_small_sparse/trial_data_small_csv.csv'\n",
    "test_list = {}\n",
    "model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# train_data = CSVDataSet(train_list)\n",
    "# train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=True)\n",
    "train_data = PickleDataSet(train_list)\n",
    "train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "pin_memory=False, drop_last=False, timeout=0,\\\n",
    "worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "model = train_model_new.get_model(model_id, model_metric, _, model_settings, _)\n",
    "checkpoint = torch.load(model_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "    batch_x = batch_x.to(device)\n",
    "    label = batch_y[0]\n",
    "\n",
    "    batch_y = torch.tensor([0]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "    emb = emb.squeeze().data.cpu().numpy()\n",
    "    \n",
    "    if label not in test_list.keys():\n",
    "        test_list[label] = emb[None, :]\n",
    "    else:\n",
    "        print('repeat eer:', label)\n",
    "        break\n",
    "#         test_list[label] = np.append(test_list[label], emb[None, :], axis=0)\n",
    "    \n",
    "    if (count+1) % 500 == 0:\n",
    "        print(count+1)\n",
    "\n",
    "del model, batch_x, batch_y\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14490"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14490"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+'sdscv_trial_data'\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(test_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/sdsvc_t2_small_sparse/small_tiral_list'\n",
    "score_out_path = component_dir+'/'+'sdsvc_cos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+'sdscv_trial_data', 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t04.68\t0.389\t1.000\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+'sdsvc_cos'\n",
    "key_file = '/Lun0/zhiyong/sdsvc_t2_small_sparse/small_tiral_list'\n",
    "\n",
    "_ = scoring(score_file, key_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aux scoring PLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/dataset/aux_tiral_list'\n",
    "score_out_path = component_dir+'/'+SCORING_AUX_PLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+AUX_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id00562-X7FJ3M3bz3c-00127.wav id00562-9tqfxnIUShw-00071.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "155000\n",
      "160000\n",
      "165000\n",
      "170000\n",
      "175000\n",
      "180000\n",
      "185000\n",
      "190000\n",
      "195000\n",
      "200000\n",
      "205000\n",
      "210000\n",
      "215000\n",
      "220000\n",
      "225000\n",
      "230000\n",
      "235000\n",
      "240000\n",
      "245000\n",
      "250000\n",
      "255000\n",
      "260000\n",
      "265000\n",
      "270000\n",
      "275000\n",
      "280000\n",
      "285000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aux scoring cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/dataset/aux_tiral_list'\n",
    "score_out_path = component_dir+'/'+SCORING_AUX_COSINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+AUX_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id00562-X7FJ3M3bz3c-00127.wav id00562-9tqfxnIUShw-00071.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "155000\n",
      "160000\n",
      "165000\n",
      "170000\n",
      "175000\n",
      "180000\n",
      "185000\n",
      "190000\n",
      "195000\n",
      "200000\n",
      "205000\n",
      "210000\n",
      "215000\n",
      "220000\n",
      "225000\n",
      "230000\n",
      "235000\n",
      "240000\n",
      "245000\n",
      "250000\n",
      "255000\n",
      "260000\n",
      "265000\n",
      "270000\n",
      "275000\n",
      "280000\n",
      "285000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# scoring aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.98\t0.216\t0.303\n",
      "Starting point for CLLR is 0.703163\n",
      "Converged linear model with loss 0.12720251288238166\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.98\t0.216\t0.328\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "aux_score_file = component_dir+'/'+ SCORING_AUX_PLDA\n",
    "aux_key_file = '/Lun0/zhiyong/dataset/aux_tiral_list'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, aux_key_file, [aux_score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t02.18\t0.231\t1.000\n",
      "Starting point for CLLR is 0.844346\n",
      "Converged linear model with loss 0.13304337922710377\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t02.18\t0.231\t0.263\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "aux_score_file = component_dir+'/'+ SCORING_AUX_COSINE\n",
    "aux_key_file = '/Lun0/zhiyong/dataset/aux_tiral_list'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, aux_key_file, [aux_score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting point for CLLR is 0.773755\n",
      "Converged linear model with loss 0.1185242436564276\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.75\t0.205\t0.264\n"
     ]
    }
   ],
   "source": [
    "score_file_1_aux = component_dir+'/'+SCORING_AUX_PLDA\n",
    "score_file_2_aux = component_dir+'/'+SCORING_AUX_COSINE\n",
    "score_file_1 = component_dir+'/'+SCORING_PLDA_NAME\n",
    "score_file_2 = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "aux_key_file = '/Lun0/zhiyong/dataset/aux_tiral_list'\n",
    "calib_score_file = component_dir+'/'+'fuse_aux'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "# _ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, aux_key_file, [score_file_1_aux, score_file_2_aux])\n",
    "applying(linear_model_pth, [score_file_1, score_file_2], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting point for CLLR is 0.704718\n",
      "Converged linear model with loss 0.23705743394532688\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.66\t0.285\t0.454\n"
     ]
    }
   ],
   "source": [
    "score_file_1_aux = component_dir+'/'+SCORING_AUX_PLDA+'_norm'\n",
    "score_file_2_aux = component_dir+'/'+SCORING_AUX_COSINE+'_norm'\n",
    "score_file_1 = component_dir+'/'+SCORING_PLDA_NAME+'_norm'\n",
    "score_file_2 = component_dir+'/'+SCORING_COSINE_NAME+'_norm'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "aux_key_file = '/Lun0/zhiyong/dataset/aux_tiral_list'\n",
    "calib_score_file = component_dir+'/'+'fuse_aux_norm'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "# _ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, aux_key_file, [score_file_1_aux, score_file_2_aux])\n",
    "applying(linear_model_pth, [score_file_1, score_file_2], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting point for CLLR is 0.739236\n",
      "Converged linear model with loss 0.09995077823341468\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.61\t0.185\t0.195\n"
     ]
    }
   ],
   "source": [
    "score_file_1_aux = component_dir+'/'+SCORING_AUX_PLDA\n",
    "score_file_2_aux = component_dir+'/'+SCORING_AUX_COSINE\n",
    "score_file_3_aux = component_dir+'/'+SCORING_AUX_PLDA+'_norm'\n",
    "score_file_4_aux = component_dir+'/'+SCORING_AUX_COSINE+'_norm'\n",
    "score_file_1 = component_dir+'/'+SCORING_PLDA_NAME\n",
    "score_file_2 = component_dir+'/'+SCORING_COSINE_NAME\n",
    "score_file_3 = component_dir+'/'+SCORING_PLDA_NAME+'_norm'\n",
    "score_file_4 = component_dir+'/'+SCORING_COSINE_NAME+'_norm'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "aux_key_file = '/Lun0/zhiyong/dataset/aux_tiral_list'\n",
    "calib_score_file = component_dir+'/'+'fuse_aux_4'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "# _ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, aux_key_file, [score_file_1_aux, score_file_2_aux, score_file_3_aux, score_file_4_aux])\n",
    "applying(linear_model_pth, [score_file_1, score_file_2, score_file_3, score_file_4], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score norm aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from score_norm_1 import score_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "ori_score = component_dir+'/'+SCORING_PLDA_NAME\n",
    "norm_score = component_dir+'/'+SCORING_PLDA_NAME+'_norm'\n",
    "score_norm(ori_score, norm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "ori_score = component_dir+'/'+SCORING_AUX_PLDA\n",
    "norm_score = component_dir+'/'+SCORING_AUX_PLDA+'_norm'\n",
    "score_norm(ori_score, norm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.88\t0.312\t1.000\n",
      "Starting point for CLLR is 0.698849\n",
      "Converged linear model with loss 0.24405807569514407\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.88\t0.312\t0.524\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME+'_norm'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "aux_score_file = component_dir+'/'+ SCORING_AUX_PLDA+'_norm'\n",
    "aux_key_file = '/Lun0/zhiyong/dataset/aux_tiral_list'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, aux_key_file, [aux_score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "ori_score = component_dir+'/'+SCORING_COSINE_NAME\n",
    "norm_score = component_dir+'/'+SCORING_COSINE_NAME+'_norm'\n",
    "score_norm(ori_score, norm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "ori_score = component_dir+'/'+SCORING_AUX_COSINE\n",
    "norm_score = component_dir+'/'+SCORING_AUX_COSINE+'_norm'\n",
    "score_norm(ori_score, norm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.81\t0.311\t1.000\n",
      "Starting point for CLLR is 0.710586\n",
      "Converged linear model with loss 0.26639713490619543\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.81\t0.311\t0.635\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME+'_norm'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "aux_score_file = component_dir+'/'+ SCORING_AUX_COSINE+'_norm'\n",
    "aux_key_file = '/Lun0/zhiyong/dataset/aux_tiral_list'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, aux_key_file, [aux_score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.98\t0.216\t0.303\n",
      "Starting point for CLLR is 0.320928\n",
      "Converged linear model with loss 0.08190182800917162\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.98\t0.216\t0.258\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t02.18\t0.231\t1.000\n",
      "Starting point for CLLR is 0.842448\n",
      "Converged linear model with loss 0.08916190600896338\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t02.18\t0.231\t0.260\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score_norm_1 import score_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "ori_score = component_dir+'/'+SCORING_PLDA_NAME\n",
    "norm_score = component_dir+'/'+SCORING_PLDA_NAME+'_norm'\n",
    "score_norm(ori_score, norm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.88\t0.312\t1.000\n",
      "Starting point for CLLR is 0.538934\n",
      "Converged linear model with loss 0.07954009941343457\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.88\t0.312\t0.334\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME+'_norm'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "ori_score = component_dir+'/'+SCORING_COSINE_NAME\n",
    "norm_score = component_dir+'/'+SCORING_COSINE_NAME+'_norm'\n",
    "score_norm(ori_score, norm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.81\t0.311\t1.000\n",
      "Starting point for CLLR is 0.536303\n",
      "Converged linear model with loss 0.07717334626909308\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.81\t0.311\t0.331\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME+'_norm'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting point for CLLR is 0.581688\n",
      "Converged linear model with loss 0.074283602014203\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.74\t0.204\t0.221\n"
     ]
    }
   ],
   "source": [
    "score_file_1 = component_dir+'/'+SCORING_PLDA_NAME\n",
    "score_file_2 = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = component_dir+'/'+'fuse'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "# _ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file_1, score_file_2])\n",
    "applying(linear_model_pth, [score_file_1, score_file_2], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting point for CLLR is 0.537618\n",
      "Converged linear model with loss 0.0694378887070766\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.61\t0.266\t0.291\n"
     ]
    }
   ],
   "source": [
    "score_file_1 = component_dir+'/'+SCORING_PLDA_NAME+'_norm'\n",
    "score_file_2 = component_dir+'/'+SCORING_COSINE_NAME+'_norm'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = component_dir+'/'+'fuse_norm'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "# _ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file_1, score_file_2])\n",
    "applying(linear_model_pth, [score_file_1, score_file_2], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
