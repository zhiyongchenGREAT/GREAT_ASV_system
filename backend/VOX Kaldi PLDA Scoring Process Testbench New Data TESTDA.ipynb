{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/workspace/GREAT_ASV_system/train/')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# import vox_model_bank\n",
    "import model_bank\n",
    "from read_data import *\n",
    "from my_dataloader import *\n",
    "# from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/workspace/LOGS_OUTPUT/backup_server5/train_exp/new_pipe_test_fullvoxonly 1L sparse fixed/ckpt/vox1test_metric_saver_MINC.model'\n",
    "model_id = 'Xvector_SAP_1L'\n",
    "model_metric = 'AM_normfree_softmax_anneal_ce_head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_dir = '/workspace/LOGS_OUTPUT/std_server5/backend/testbench'\n",
    "PLDA_DIM = 370\n",
    "PLDA_DATA_NAME = 'plda_data'\n",
    "TEST_DATA_NAME = 'test_data_370'\n",
    "PLDA_PARA_NAME = 'plda_para_370'\n",
    "SCORING_PLDA_NAME = 'score_plda_370'\n",
    "SCORING_COSINE_NAME = 'score_cosine_370'\n",
    "# AUX_DATA_NAME = 'aux_data_370'\n",
    "# SCORING_AUX_COSINE = 'score_aux_cosine_370'\n",
    "# SCORING_AUX_PLDA = 'score_aux_plda_370'\n",
    "PLDA_DATA_sdsv_NAME = 'plda_data_sdsv'\n",
    "TEST_DATA_sdsv_NAME = 'test_data_sdsv'\n",
    "PLDA_PARA_sdsv_NAME = 'plda_para_sdsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(component_dir):\n",
    "    os.makedirs(component_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_p = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = '/workspace/DATASET/std/vox_full_plda.csv'\n",
    "# train_list = '/Lun0/zhiyong/dataset/plda_full_data_noVAD.csv'\n",
    "# train_data = CSVDataSet(train_list)\n",
    "train_data = PickleDataSet(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_len = len(train_data)\n",
    "num_per_process = (1276888 // num_p) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "class_list_new_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45580\n"
     ]
    }
   ],
   "source": [
    "data_m = []\n",
    "# class_list_new_m = []\n",
    "for i in range(num_p):\n",
    "    data = torch.utils.data.Subset(train_data, np.arange(i*num_per_process, min((i+1)*num_per_process, train_data_len)))\n",
    "    data_m.append(data)\n",
    "    class_list_new_m.append({})\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_m(i, train_data, class_list_new_m):\n",
    "#     train_list = '/Lun0/zhiyong/dataset/vox12_kaldi_train_data/vox12_kaldi_train_data.csv'\n",
    "    model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if i < 26:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(i%2)\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     torch.cuda.set_device(i%2)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     train_data = CSVDataSet(train_list)\n",
    "#     train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=False)\n",
    "\n",
    "    train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "    batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "    pin_memory=False, drop_last=False, timeout=0,\\\n",
    "    worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "    model = model_bank.get_model(model_id, model_metric, model_settings, None)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    class_list_new = {}\n",
    "\n",
    "    for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = batch_x.to(device)\n",
    "        label = batch_y[0].split('-')[0]\n",
    "        batch_y = torch.tensor([0]).to(device)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "        except:\n",
    "            print('Proc', str(i), 'EER:', label)\n",
    "            continue\n",
    "    #     _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "        emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "        if label not in class_list_new.keys():\n",
    "            class_list_new[label] = emb[None, :]\n",
    "        else:\n",
    "            class_list_new[label] = np.append(class_list_new[label], emb[None, :], axis=0)\n",
    "\n",
    "        if (count+1) % 10000 == 0:\n",
    "            print('Proc '+ str(i) + ':' + str((count+1) // 10000))\n",
    "    \n",
    "    class_list_new_m[i] = class_list_new\n",
    "    del model, batch_x, batch_y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = [Process(target = extract_feature_m, args = (i, data_m[i], class_list_new_m)) for i in range(num_p)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new_m:\n",
    "    for j in i:\n",
    "        count += len(i[j])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list_new = class_list_new_m[0]\n",
    "\n",
    "for count, this_list in enumerate(class_list_new_m):\n",
    "    if count == 0:\n",
    "        continue\n",
    "    for this_label in this_list:\n",
    "        if this_label not in class_list_new.keys():\n",
    "            class_list_new[this_label] = this_list[this_label]\n",
    "        else:\n",
    "            class_list_new[this_label] = np.append(class_list_new[this_label], this_list[this_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanlist = []\n",
    "for i in class_list_new:\n",
    "    if np.isnan(class_list_new[i]).any():\n",
    "        print(i)\n",
    "        nanlist.append(i)\n",
    "for i in nanlist:\n",
    "    class_list_new.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7323"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+PLDA_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(class_list_new, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_list_new = {}\n",
    "# for i in class_list:\n",
    "#     class_list_new[i[:-1]] = class_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU multiprocess SDSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_p = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = '/workspace/DATASET/std/sdsv_full.csv'\n",
    "# train_list = '/Lun0/zhiyong/dataset/plda_full_data_noVAD.csv'\n",
    "# train_data = CSVDataSet(train_list)\n",
    "train_data = PickleDataSet(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85764"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_len = len(train_data)\n",
    "num_per_process = (85764 // num_p) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "class_list_new_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3064\n",
      "3036\n"
     ]
    }
   ],
   "source": [
    "data_m = []\n",
    "# class_list_new_m = []\n",
    "for i in range(num_p):\n",
    "    data = torch.utils.data.Subset(train_data, np.arange(i*num_per_process, min((i+1)*num_per_process, train_data_len)))\n",
    "    data_m.append(data)\n",
    "    class_list_new_m.append({})\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_m(i, train_data, class_list_new_m):\n",
    "#     train_list = '/Lun0/zhiyong/dataset/vox12_kaldi_train_data/vox12_kaldi_train_data.csv'\n",
    "    model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if i < 26:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(i%2)\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     torch.cuda.set_device(i%2)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     train_data = CSVDataSet(train_list)\n",
    "#     train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=False)\n",
    "\n",
    "    train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "    batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "    pin_memory=False, drop_last=False, timeout=0,\\\n",
    "    worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "    model = model_bank.get_model(model_id, model_metric, model_settings, None)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    class_list_new = {}\n",
    "\n",
    "    for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = batch_x.to(device)\n",
    "        label = batch_y[0].split('-')[0]\n",
    "        batch_y = torch.tensor([0]).to(device)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "        except:\n",
    "            print('Proc', str(i), 'EER:', label)\n",
    "            continue\n",
    "    #     _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "        emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "        if label not in class_list_new.keys():\n",
    "            class_list_new[label] = emb[None, :]\n",
    "        else:\n",
    "            class_list_new[label] = np.append(class_list_new[label], emb[None, :], axis=0)\n",
    "\n",
    "        if (count+1) % 10000 == 0:\n",
    "            print('Proc '+ str(i) + ':' + str((count+1) // 10000))\n",
    "    \n",
    "    class_list_new_m[i] = class_list_new\n",
    "    del model, batch_x, batch_y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bankUsing model bank\n",
      "\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bankUsing model bankUsing model bankUsing model bank\n",
      "\n",
      "\n",
      "\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bankUsing model bank\n",
      "\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n",
      "Using model bank\n"
     ]
    }
   ],
   "source": [
    "processes = [Process(target = extract_feature_m, args = (i, data_m[i], class_list_new_m)) for i in range(num_p)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85764"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new_m:\n",
    "    for j in i:\n",
    "        count += len(i[j])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list_new = class_list_new_m[0]\n",
    "\n",
    "for count, this_list in enumerate(class_list_new_m):\n",
    "    if count == 0:\n",
    "        continue\n",
    "    for this_label in this_list:\n",
    "        if this_label not in class_list_new.keys():\n",
    "            class_list_new[this_label] = this_list[this_label]\n",
    "        else:\n",
    "            class_list_new[this_label] = np.append(class_list_new[this_label], this_list[this_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85764"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanlist = []\n",
    "for i in class_list_new:\n",
    "    if np.isnan(class_list_new[i]).any():\n",
    "        print(i)\n",
    "        nanlist.append(i)\n",
    "for i in nanlist:\n",
    "    class_list_new.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85764"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_label = np.sort(list(class_list_new.keys()))[0:488]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list_new_f = {}\n",
    "for i in filtered_label:\n",
    "    class_list_new_f[i] = class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+PLDA_DATA_sdsv_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(class_list_new_f, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLDA_FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# sys.path.append('./train')\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "\n",
    "# # import vox_model_bank\n",
    "# from train import train_model_new\n",
    "# from train.read_data import *\n",
    "# from train.my_dataloader import *\n",
    "# # from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaldi_plda import *\n",
    "from kaldi_plda_new import *\n",
    "from kaldi_lda import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+PLDA_DATA_NAME, 'rb') as handle:\n",
    "    class_list_new = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of mean: 1.904665238314247\n"
     ]
    }
   ],
   "source": [
    "# Substract global mean\n",
    "global_mean = np.zeros(512)\n",
    "num_utt = 0\n",
    "for count, i in enumerate(class_list_new):\n",
    "    num_utt += class_list_new[i].shape[0]\n",
    "    global_mean += class_list_new[i].shape[0] * np.mean(class_list_new[i], axis=0)\n",
    "    \n",
    "global_mean = (1.0 / num_utt) * global_mean\n",
    "print('Norm of mean:', np.linalg.norm(global_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_list_new:\n",
    "    class_list_new[i] = class_list_new[i] - global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda norm of global mean: 1.0221362319457326e-07\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(lda_dim=PLDA_DIM, ivector_dim=512)\n",
    "for i in class_list_new:\n",
    "    lda.AccStats(class_list_new[i])\n",
    "print('lda norm of global mean:', lda.GetGlobalMean()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input data has norm of mean 1.0221362319457326e-07\n",
      "[7.05680318e+00 6.83084110e+00 6.49589130e+00 6.25103781e+00\n",
      " 6.02699328e+00 5.93644421e+00 5.74553620e+00 5.71113328e+00\n",
      " 5.52863863e+00 5.48530371e+00 5.33798738e+00 5.29171180e+00\n",
      " 5.19417991e+00 5.13465376e+00 5.07992271e+00 5.03656835e+00\n",
      " 4.94590764e+00 4.87222457e+00 4.86027973e+00 4.83695617e+00\n",
      " 4.67446231e+00 4.62048504e+00 4.56140204e+00 4.53129694e+00\n",
      " 4.49590328e+00 4.46416332e+00 4.37204092e+00 4.31959085e+00\n",
      " 4.31300552e+00 4.24568159e+00 4.22761656e+00 4.13339006e+00\n",
      " 4.09174010e+00 4.06669643e+00 4.00950966e+00 3.98957290e+00\n",
      " 3.92033707e+00 3.90857520e+00 3.83256738e+00 3.74048687e+00\n",
      " 3.67952474e+00 3.63867904e+00 3.60639986e+00 3.55344168e+00\n",
      " 3.53629863e+00 3.48462131e+00 3.43491949e+00 3.41205987e+00\n",
      " 3.38153426e+00 3.36127220e+00 3.34227493e+00 3.30985634e+00\n",
      " 3.22345557e+00 3.20170408e+00 3.17643705e+00 3.10434679e+00\n",
      " 3.08763803e+00 3.05436367e+00 3.01382095e+00 2.98352146e+00\n",
      " 2.93198022e+00 2.90411634e+00 2.89903466e+00 2.83804975e+00\n",
      " 2.83351883e+00 2.78605764e+00 2.76421916e+00 2.74960267e+00\n",
      " 2.72184671e+00 2.69137132e+00 2.66338311e+00 2.63234074e+00\n",
      " 2.60219784e+00 2.57916201e+00 2.54094251e+00 2.50943206e+00\n",
      " 2.49625883e+00 2.47388711e+00 2.43530830e+00 2.42782802e+00\n",
      " 2.40034032e+00 2.38407741e+00 2.35199631e+00 2.31963590e+00\n",
      " 2.29363615e+00 2.28313650e+00 2.23608657e+00 2.21853409e+00\n",
      " 2.19684043e+00 2.14596213e+00 2.13420261e+00 2.12014413e+00\n",
      " 2.10439291e+00 2.06883039e+00 2.05822375e+00 2.01022595e+00\n",
      " 1.99369039e+00 1.97317591e+00 1.94283417e+00 1.90353871e+00\n",
      " 1.87266091e+00 1.82212012e+00 1.79120874e+00 1.77931542e+00\n",
      " 1.76385932e+00 1.73636444e+00 1.72209424e+00 1.68983678e+00\n",
      " 1.68067125e+00 1.63594565e+00 1.62080880e+00 1.60219155e+00\n",
      " 1.57460791e+00 1.55914501e+00 1.54711486e+00 1.52296514e+00\n",
      " 1.49303048e+00 1.48645691e+00 1.46302605e+00 1.44177406e+00\n",
      " 1.41063840e+00 1.39109357e+00 1.34906669e+00 1.33973311e+00\n",
      " 1.30432705e+00 1.25813219e+00 1.24786896e+00 1.22109354e+00\n",
      " 1.17852543e+00 1.16385927e+00 1.15515713e+00 1.12614338e+00\n",
      " 1.09951167e+00 1.08985197e+00 1.07348132e+00 1.05523889e+00\n",
      " 1.02161995e+00 1.00762190e+00 9.93792060e-01 9.45702369e-01\n",
      " 9.44586199e-01 9.26228945e-01 8.83398926e-01 8.28087345e-01\n",
      " 8.18886626e-01 7.83129310e-01 7.68436026e-01 7.61940351e-01\n",
      " 7.41613533e-01 7.18352937e-01 6.87489149e-01 6.78282083e-01\n",
      " 6.63211061e-01 5.89789159e-01 5.64599335e-01 5.62415737e-01\n",
      " 5.15598158e-01 4.95816375e-01 4.66256690e-01 3.96909883e-01\n",
      " 3.69744427e-01 3.40163152e-01 3.16658055e-01 2.20342006e-01\n",
      " 1.77412807e-01 1.62348963e-01 1.13433408e-01 1.04143794e-01\n",
      " 9.23012515e-02 6.58251454e-02 5.03778839e-02 4.32825786e-02\n",
      " 3.96143481e-02 2.39915614e-02 2.07418059e-02 1.94120242e-02\n",
      " 1.83273528e-02 1.66401563e-02 1.37179018e-02 1.31433994e-02\n",
      " 1.09389968e-02 1.00937527e-02 9.10398464e-03 8.41884768e-03\n",
      " 8.21084741e-03 7.02544367e-03 6.67112735e-03 5.74895556e-03\n",
      " 5.05565115e-03 4.69090728e-03 4.35393488e-03 4.18306941e-03\n",
      " 3.75041347e-03 3.69952198e-03 3.66422388e-03 3.35833611e-03\n",
      " 3.19666180e-03 3.05606799e-03 2.99444263e-03 2.78763446e-03\n",
      " 2.66529292e-03 2.49253493e-03 2.40373173e-03 2.28956599e-03\n",
      " 2.26859062e-03 2.24107159e-03 2.18416341e-03 2.15291719e-03\n",
      " 2.04664334e-03 1.94030304e-03 1.82721200e-03 1.77794011e-03\n",
      " 1.66097870e-03 1.65769693e-03 1.62021493e-03 1.60019356e-03\n",
      " 1.53859557e-03 1.53278112e-03 1.46885077e-03 1.41467815e-03\n",
      " 1.38346137e-03 1.37021374e-03 1.33519086e-03 1.28631320e-03\n",
      " 1.27506176e-03 1.26278431e-03 1.23741163e-03 1.21681072e-03\n",
      " 1.18913923e-03 1.15499244e-03 1.12259513e-03 1.10034376e-03\n",
      " 1.05677072e-03 1.04647519e-03 1.03127828e-03 1.02111508e-03\n",
      " 1.00223998e-03 9.85524920e-04 9.80106346e-04 9.68459414e-04\n",
      " 9.33999160e-04 9.23698519e-04 9.20974378e-04 9.17141524e-04\n",
      " 8.84159561e-04 8.74858006e-04 8.55983514e-04 8.48933289e-04\n",
      " 8.28119220e-04 8.18546170e-04 8.15102568e-04 8.08212287e-04\n",
      " 7.99599182e-04 7.68249256e-04 7.61137218e-04 7.55893982e-04\n",
      " 7.48146979e-04 7.40816173e-04 7.27943518e-04 7.15833339e-04\n",
      " 7.10598456e-04 7.03241478e-04 7.02368637e-04 6.90800849e-04\n",
      " 6.80590705e-04 6.72903526e-04 6.57635388e-04 6.49746893e-04\n",
      " 6.45237338e-04 6.42866221e-04 6.34058605e-04 6.28318514e-04\n",
      " 6.22107773e-04 6.11596017e-04 5.99638318e-04 5.93325326e-04\n",
      " 5.88482681e-04 5.82386306e-04 5.75183602e-04 5.67868522e-04\n",
      " 5.61815773e-04 5.56771509e-04 5.50629977e-04 5.46127168e-04\n",
      " 5.39479533e-04 5.37195523e-04 5.29377517e-04 5.25238151e-04\n",
      " 5.20466755e-04 5.15755587e-04 5.13007013e-04 5.04392696e-04\n",
      " 4.98673374e-04 4.92546028e-04 4.83500338e-04 4.79392882e-04\n",
      " 4.72728123e-04 4.71333851e-04 4.66654873e-04 4.62322457e-04\n",
      " 4.60794496e-04 4.53667525e-04 4.47987718e-04 4.46014835e-04\n",
      " 4.45595643e-04 4.39109901e-04 4.35613722e-04 4.30444701e-04\n",
      " 4.30182560e-04 4.20627425e-04 4.19086254e-04 4.15973052e-04\n",
      " 4.13851077e-04 4.09014594e-04 4.01637522e-04 3.98569924e-04\n",
      " 3.96372338e-04 3.93473482e-04 3.88920374e-04 3.84525332e-04\n",
      " 3.83094319e-04 3.79112770e-04 3.75933548e-04 3.71423436e-04\n",
      " 3.67388236e-04 3.64947576e-04 3.60667475e-04 3.58881386e-04\n",
      " 3.57143484e-04 3.54678925e-04 3.52840189e-04 3.50678196e-04\n",
      " 3.45737015e-04 3.42976363e-04 3.40594491e-04 3.34789935e-04\n",
      " 3.31510962e-04 3.29608367e-04 3.25898645e-04 3.23909262e-04\n",
      " 3.21648809e-04 3.18641949e-04 3.15748085e-04 3.13868565e-04\n",
      " 3.12520532e-04 3.09975086e-04 3.07609058e-04 3.04071113e-04\n",
      " 2.99649292e-04 2.98961082e-04 2.95848523e-04 2.91514056e-04\n",
      " 2.89553954e-04 2.88080054e-04 2.86978019e-04 2.85790889e-04\n",
      " 2.81522793e-04 2.78452084e-04 2.76677801e-04 2.74736627e-04\n",
      " 2.72291694e-04 2.69016637e-04 2.66375322e-04 2.61664237e-04\n",
      " 2.60022595e-04 2.59334939e-04 2.56349234e-04 2.55048180e-04\n",
      " 2.53753880e-04 2.52140646e-04 2.48606128e-04 2.48212766e-04\n",
      " 2.47165434e-04 2.43765948e-04 2.42008640e-04 2.39822610e-04\n",
      " 2.38660954e-04 2.37075933e-04 2.36069869e-04 2.33401973e-04\n",
      " 2.32448706e-04 2.30621891e-04 2.28526671e-04 2.27324662e-04\n",
      " 2.25867833e-04 2.21125506e-04 2.19034387e-04 2.17363586e-04\n",
      " 2.16665526e-04 2.14226354e-04 2.12317022e-04 2.11291800e-04\n",
      " 2.09242482e-04 2.05985678e-04 2.05502683e-04 2.03685221e-04\n",
      " 2.01540953e-04 1.98977326e-04 1.97528912e-04 1.95837786e-04\n",
      " 1.93676173e-04 1.92914316e-04 1.91101665e-04 1.90053800e-04\n",
      " 1.89083325e-04 1.87531056e-04 1.85586290e-04 1.84323592e-04\n",
      " 1.83101739e-04 1.81501393e-04 1.80049814e-04 1.78555419e-04\n",
      " 1.76193306e-04 1.74783780e-04 1.72962976e-04 1.71416931e-04\n",
      " 1.70843119e-04 1.69859987e-04 1.68036141e-04 1.66888484e-04\n",
      " 1.65510319e-04 1.64789790e-04 1.63810692e-04 1.62057490e-04\n",
      " 1.59725762e-04 1.59271556e-04 1.57199092e-04 1.57092324e-04\n",
      " 1.56423412e-04 1.54964866e-04 1.54653497e-04 1.51569707e-04\n",
      " 1.50612888e-04 1.49233637e-04 1.47224852e-04 1.45938754e-04\n",
      " 1.44476503e-04 1.42043097e-04 1.41778527e-04 1.40479041e-04\n",
      " 1.40076157e-04 1.38331291e-04 1.37310106e-04 1.36596605e-04\n",
      " 1.34435198e-04 1.33882054e-04 1.33266947e-04 1.32711446e-04\n",
      " 1.30067819e-04 1.29793247e-04 1.27911114e-04 1.27098903e-04\n",
      " 1.26034302e-04 1.24405094e-04 1.23727080e-04 1.22662004e-04\n",
      " 1.21400335e-04 1.20391442e-04 1.19596535e-04 1.17460936e-04\n",
      " 1.17011337e-04 1.15996951e-04 1.13873257e-04 1.12385022e-04\n",
      " 1.11649157e-04 1.10978517e-04 1.08692964e-04 1.08419628e-04\n",
      " 1.06770765e-04 1.05409422e-04 1.04993656e-04 1.04410776e-04\n",
      " 1.03344411e-04 1.01700495e-04 1.01232664e-04 9.93222924e-05\n",
      " 9.90268289e-05 9.68806751e-05 9.63340541e-05 9.41458889e-05\n",
      " 9.37702539e-05 9.28431307e-05 9.17365493e-05 9.03632636e-05\n",
      " 8.99159270e-05 8.91915104e-05 8.77297236e-05 8.73203334e-05\n",
      " 8.63909762e-05 8.57917241e-05 8.41827467e-05 8.36264947e-05\n",
      " 8.28049103e-05 8.13278290e-05 8.08000358e-05 7.98797408e-05\n",
      " 7.72193913e-05 7.65770246e-05 7.49783404e-05 7.43201482e-05\n",
      " 7.37504194e-05 7.25998629e-05 7.19328607e-05 6.97400670e-05\n",
      " 6.82447319e-05 6.63968082e-05 6.55760304e-05 6.41982107e-05\n",
      " 6.23893124e-05 6.19869856e-05 6.01781738e-05 5.75896415e-05]\n",
      "[7.86936421 6.99509194 5.84040638 5.17043313 4.70736434 4.12010561\n",
      " 3.92046902 3.58184222 3.38562617 3.20990875 3.05484477 2.89376746\n",
      " 2.72776413 2.63500115 2.40784189 2.38272088 2.28383072 2.24177349\n",
      " 2.19015129 2.09274226 2.05949339 1.97386783 1.88776707 1.81223564\n",
      " 1.79623714 1.73471071 1.70495788 1.65799492 1.62179901 1.61196069\n",
      " 1.56337042 1.51038434 1.47645823 1.45911288 1.44299923 1.4101735\n",
      " 1.40247494 1.3941517  1.3363501  1.3268127  1.30875759 1.25451476\n",
      " 1.24299221 1.23777658 1.2228971  1.20033454 1.19098311 1.18044858\n",
      " 1.14677795 1.11524865 1.11206362 1.09186501 1.08502982 1.06047469\n",
      " 1.05503877 1.03688758 1.0199738  0.99162484 0.97848513 0.96557603\n",
      " 0.95603965 0.94595281 0.92605853 0.89954275 0.89467055 0.88533693\n",
      " 0.86926124 0.85044695 0.8384215  0.83260533 0.83015079 0.82525538\n",
      " 0.8121612  0.81043929 0.80388153 0.79156851 0.781845   0.77515534\n",
      " 0.75873187 0.74820503 0.74284342 0.7398949  0.72894207 0.71221434\n",
      " 0.70811303 0.70043094 0.69841334 0.68203896 0.67505619 0.66529972\n",
      " 0.66079622 0.6543994  0.65382069 0.64482333 0.64239372 0.62294168\n",
      " 0.62143177 0.61524782 0.60791724 0.59985219 0.59777014 0.59369014\n",
      " 0.58935415 0.58192326 0.57158934 0.57033929 0.56316289 0.55316262\n",
      " 0.55002933 0.54544315 0.54396114 0.53660619 0.53400204 0.52998337\n",
      " 0.52914712 0.51922191 0.51446993 0.50914148 0.50170565 0.49809444\n",
      " 0.49388176 0.49338074 0.48513779 0.47582924 0.47436964 0.46889378\n",
      " 0.46648012 0.45572627 0.45307806 0.44967002 0.44376974 0.43963032\n",
      " 0.43741782 0.43420505 0.42576583 0.42086585 0.41765534 0.41235106\n",
      " 0.40908146 0.40527371 0.40368891 0.40009032 0.39984867 0.39526017\n",
      " 0.3934517  0.38591058 0.38162572 0.38026137 0.37814756 0.3719967\n",
      " 0.36830152 0.36420689 0.36283861 0.35872491 0.35332918 0.35093394\n",
      " 0.34884034 0.34589062 0.34504736 0.33781752 0.33733486 0.33526882\n",
      " 0.33125616 0.32942826 0.32257214 0.32003256 0.31857456 0.3171769\n",
      " 0.31435773 0.31260061 0.31123556 0.30639448 0.30605846 0.30230197\n",
      " 0.30132022 0.29699406 0.29334236 0.29037263 0.28586663 0.28464924\n",
      " 0.28337973 0.28186708 0.27986398 0.27624175 0.27435786 0.27191794\n",
      " 0.27047846 0.2673829  0.2668182  0.26437559 0.26204582 0.2604241\n",
      " 0.25980369 0.25526652 0.25423275 0.25170952 0.25000371 0.24857539\n",
      " 0.24564007 0.24480239 0.24284292 0.24157402 0.23982395 0.23865474\n",
      " 0.23680826 0.23513203 0.2329549  0.23160838 0.22972858 0.22849037\n",
      " 0.22705731 0.22565271 0.22381087 0.22228455 0.22134625 0.21984028\n",
      " 0.21890656 0.21599512 0.21310117 0.21210494 0.21032387 0.20933832\n",
      " 0.20790875 0.20752489 0.20711981 0.20501639 0.2017786  0.20135053\n",
      " 0.19884416 0.19811466 0.19731876 0.19531363 0.19502732 0.19417693\n",
      " 0.19200528 0.19087722 0.18956674 0.18808175 0.1864594  0.18561943\n",
      " 0.18462109 0.18369282 0.18245863 0.1809465  0.17986225 0.17873716\n",
      " 0.17826051 0.17601818 0.17519468 0.17389944 0.17268285 0.17204923\n",
      " 0.1705185  0.17035322 0.16799062 0.16767157 0.1651941  0.16458829\n",
      " 0.16406402 0.16255105 0.16171768 0.16099906 0.15973136 0.15914342\n",
      " 0.15788296 0.15682207 0.15640994 0.15531049 0.15429095 0.15392287\n",
      " 0.15382182 0.15216228 0.15079078 0.1496607  0.14833806 0.14703731\n",
      " 0.14673634 0.1464411  0.14510084 0.1445611  0.14401077 0.14318565\n",
      " 0.14259741 0.1412466  0.14077574 0.13929695 0.1391513  0.13886626\n",
      " 0.13773451 0.13718608 0.13670687 0.13531139 0.13459501 0.13358581\n",
      " 0.1329259  0.13247889 0.13148726 0.13037359 0.12939733 0.12906932\n",
      " 0.12803641 0.12781244 0.12734688 0.12637571 0.12539604 0.12444974\n",
      " 0.12356937 0.12336966 0.12215202 0.12191686 0.12185812 0.12100389\n",
      " 0.11992361 0.1198819  0.11814279 0.11769892 0.11754323 0.11670203\n",
      " 0.11557667 0.11537986 0.11481125 0.11435321 0.11379872 0.11329079\n",
      " 0.11292276 0.11183703 0.11136497 0.11051335 0.11020479 0.10968312\n",
      " 0.1094679  0.10918513 0.10879526 0.1074139  0.10679716 0.10608793\n",
      " 0.10552931 0.10493388 0.10432488 0.10396218 0.10362325 0.10291903\n",
      " 0.10211566 0.10159297 0.10096724 0.10033114 0.09999877 0.09947111\n",
      " 0.09854612 0.09816831 0.09781586 0.09758936 0.09678219 0.09653849\n",
      " 0.09618626 0.0956411  0.09503322 0.09471298 0.09399628 0.09376595\n",
      " 0.09320795 0.09265726 0.0918554  0.09170401 0.09153411 0.09095483\n",
      " 0.09074746 0.09017583 0.08956068 0.08914578 0.08825732 0.08798846\n",
      " 0.08773    0.08753031 0.08742589 0.08631073 0.08602497 0.0856922\n",
      " 0.08445405 0.08421137 0.08368853 0.08316061 0.08311589 0.08294522\n",
      " 0.08224486 0.08183348 0.08149224 0.08131093 0.08050441 0.08000095\n",
      " 0.07987703 0.07956373 0.07928599 0.07856671 0.07848907 0.07834418\n",
      " 0.07787776 0.07721713 0.07713372 0.0763171  0.07608346 0.07577196\n",
      " 0.07565857 0.07507008 0.07477652 0.07452862 0.07367068 0.07349339\n",
      " 0.07323414 0.07305283 0.07257179 0.07240986 0.07196754 0.07144852\n",
      " 0.07141092 0.07077713 0.07002546 0.06981726 0.06937958 0.06915675\n",
      " 0.06878817 0.06805772 0.06803807 0.06788527 0.06741788 0.06682936\n",
      " 0.06669614 0.06593501 0.06576899 0.0655396  0.0652566  0.06477217\n",
      " 0.06432869 0.06423541 0.06398709 0.06380557 0.0635485  0.06296067\n",
      " 0.06287626 0.06259684 0.06195802 0.06177724 0.06140479 0.06092277\n",
      " 0.06064729 0.06050255 0.06002106 0.05991814 0.05932563 0.05889463\n",
      " 0.05862232 0.05821189 0.05817599 0.05739493 0.05714036 0.05685437\n",
      " 0.0563359  0.05624329 0.05590714 0.05554639 0.05541598 0.05504224\n",
      " 0.0547623  0.05466114 0.0542561  0.05413551 0.05325724 0.05306581\n",
      " 0.05265455 0.05227791 0.05212794 0.05194227 0.05164458 0.05098195\n",
      " 0.05029954 0.04998414 0.04987977 0.04966841 0.0494703  0.04903516\n",
      " 0.04885162 0.04865536 0.04843307 0.04813076 0.04772657 0.04742306\n",
      " 0.04701575 0.04638935 0.04583361 0.04564234 0.04531726 0.04490986\n",
      " 0.04478699 0.04377218 0.04374415 0.04353576 0.04332519 0.04311155\n",
      " 0.04291038 0.04240191 0.04185647 0.04158621 0.04151022 0.04083501\n",
      " 0.0404456  0.04011675 0.03986833 0.0389632  0.03862998 0.03828167\n",
      " 0.03782874 0.03693441]\n"
     ]
    }
   ],
   "source": [
    "transform = lda.ComputeLdaTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_list_new:\n",
    "    class_list_new[i] = class_list_new[i].dot(transform.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normlize to sqrt(dim)\n",
    "for i in class_list_new:\n",
    "    scale = np.sqrt(PLDA_DIM) / np.linalg.norm(class_list_new[i], axis=1, keepdims=True)\n",
    "    class_list_new[i] = scale * class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda_stats = PldaStats(PLDA_DIM)\n",
    "for i in class_list_new:\n",
    "    plda_stats.add_samples(class_list_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plda_stats.sort()\n",
    "plda_stats.is_sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "nllr_x: 410.506519965879\n",
      "nllr_y: -371.40425287899023\n",
      "normalized_nllr: 39.10226708688882\n",
      "nllr_m: 411.27954757668545\n",
      "nllr_m_2: 411.2795475766853\n",
      "part1_residual -456.1316055328956\n",
      "part2_mean -411.27954757668545\n",
      "normlized_obj -455.87437731835104\n",
      "2 5\n",
      "nllr_x: 237.2322822742737\n",
      "nllr_y: -457.6529325236297\n",
      "normalized_nllr: -220.42065024935602\n",
      "nllr_m: 243.78477532119953\n",
      "nllr_m_2: 243.78477532119962\n",
      "part1_residual -438.72547415081766\n",
      "part2_mean -243.7847753211998\n",
      "normlized_obj -437.6074820187518\n",
      "3 5\n",
      "nllr_x: 234.43450562072812\n",
      "nllr_y: -457.54771370630186\n",
      "normalized_nllr: -223.11320808557372\n",
      "nllr_m: 242.64087608072506\n",
      "nllr_m_2: 242.6408760807249\n",
      "part1_residual -438.7278325670568\n",
      "part2_mean -242.64087608072512\n",
      "normlized_obj -437.6032666048508\n",
      "4 5\n",
      "nllr_x: 234.15237832932453\n",
      "nllr_y: -457.42389747904724\n",
      "normalized_nllr: -223.2715191497227\n",
      "nllr_m: 242.6170850776704\n",
      "nllr_m_2: 242.6170850776702\n",
      "part1_residual -438.7278292280607\n",
      "part2_mean -242.6170850776704\n",
      "normlized_obj -437.6031268427197\n",
      "5 5\n",
      "nllr_x: 234.11014104122722\n",
      "nllr_y: -457.40295022304605\n",
      "normalized_nllr: -223.29280918181882\n",
      "nllr_m: 242.61640027305614\n",
      "nllr_m_2: 242.6164002730559\n",
      "part1_residual -438.7278253755328\n",
      "part2_mean -242.61640027305623\n",
      "normlized_obj -437.6031190849064\n"
     ]
    }
   ],
   "source": [
    "# test_fin_prior\n",
    "plda_estimator = PldaEstimation(plda_stats)\n",
    "plda_paras = plda_estimator.estimate(iteration=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+ PLDA_PARA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(plda_paras, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+ PLDA_PARA_NAME, 'rb') as handle:\n",
    "    plda_paras = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda = PLDA(plda_paras[0], plda_paras[1], plda_paras[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "[plda_within, plda_between] = plda_estimator.get_stat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLDA_FIN_sdsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# sys.path.append('./train')\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "\n",
    "# # import vox_model_bank\n",
    "# from train import train_model_new\n",
    "# from train.read_data import *\n",
    "# from train.my_dataloader import *\n",
    "# # from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaldi_plda import *\n",
    "from kaldi_plda_new import *\n",
    "from kaldi_lda import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+PLDA_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    class_list_in_new = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of mean: 12.12652709826286\n"
     ]
    }
   ],
   "source": [
    "# Substract global mean\n",
    "global_mean = np.zeros(512)\n",
    "num_utt = 0\n",
    "for count, i in enumerate(class_list_in_new):\n",
    "    num_utt += class_list_in_new[i].shape[0]\n",
    "    global_mean += class_list_in_new[i].shape[0] * np.mean(class_list_in_new[i], axis=0)\n",
    "    \n",
    "global_mean = (1.0 / num_utt) * global_mean\n",
    "print('Norm of mean:', np.linalg.norm(global_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_list_in_new:\n",
    "    class_list_in_new[i] = class_list_in_new[i] - global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda norm of global mean: 3.223937326775059e-07\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(lda_dim=PLDA_DIM, ivector_dim=512)\n",
    "for i in class_list_in_new:\n",
    "    lda.AccStats(class_list_in_new[i])\n",
    "print('lda norm of global mean:', lda.GetGlobalMean()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input data has norm of mean 3.223937326775059e-07\n",
      "[1.03394963e+01 9.68498237e+00 7.98811097e+00 7.62710895e+00\n",
      " 7.40659819e+00 7.25867527e+00 7.04871504e+00 6.86044980e+00\n",
      " 6.58582809e+00 6.31359514e+00 6.22846498e+00 6.15102178e+00\n",
      " 5.99006090e+00 5.89584327e+00 5.58050782e+00 5.53644411e+00\n",
      " 5.51568698e+00 5.34349933e+00 5.26714878e+00 5.24573497e+00\n",
      " 5.08238761e+00 4.98427856e+00 4.91191448e+00 4.84310624e+00\n",
      " 4.79134207e+00 4.70347197e+00 4.57574800e+00 4.52931257e+00\n",
      " 4.35766039e+00 4.31324793e+00 4.26469621e+00 4.21468772e+00\n",
      " 4.08835279e+00 4.03312136e+00 4.00315868e+00 3.87906206e+00\n",
      " 3.83046421e+00 3.79815291e+00 3.71420521e+00 3.64213019e+00\n",
      " 3.57440350e+00 3.50197068e+00 3.44906056e+00 3.39868806e+00\n",
      " 3.30904321e+00 3.26592765e+00 3.22042961e+00 3.18824874e+00\n",
      " 3.14832469e+00 3.07275323e+00 3.02925617e+00 2.98261260e+00\n",
      " 2.95791561e+00 2.87306629e+00 2.84010293e+00 2.81542598e+00\n",
      " 2.80527126e+00 2.73730027e+00 2.70533397e+00 2.70310971e+00\n",
      " 2.61116668e+00 2.59296095e+00 2.53706920e+00 2.51777857e+00\n",
      " 2.47601003e+00 2.46920934e+00 2.43228487e+00 2.40637763e+00\n",
      " 2.35084972e+00 2.32738595e+00 2.29453278e+00 2.28065974e+00\n",
      " 2.23478282e+00 2.22048460e+00 2.15652595e+00 2.15253626e+00\n",
      " 2.11418988e+00 2.10114373e+00 2.06627729e+00 2.04572613e+00\n",
      " 2.02777729e+00 2.00160445e+00 1.91761821e+00 1.90395302e+00\n",
      " 1.85154281e+00 1.83644532e+00 1.80587973e+00 1.76254361e+00\n",
      " 1.75455571e+00 1.73781052e+00 1.72543641e+00 1.70771681e+00\n",
      " 1.68698676e+00 1.65491250e+00 1.63073928e+00 1.60611748e+00\n",
      " 1.59219393e+00 1.55232814e+00 1.52975154e+00 1.51195391e+00\n",
      " 1.48365572e+00 1.46146545e+00 1.44058068e+00 1.42905491e+00\n",
      " 1.39471611e+00 1.38306628e+00 1.37493242e+00 1.34316742e+00\n",
      " 1.31236919e+00 1.28306398e+00 1.25451274e+00 1.22883911e+00\n",
      " 1.21219590e+00 1.20191828e+00 1.18597901e+00 1.16289234e+00\n",
      " 1.13968986e+00 1.12947552e+00 1.08193035e+00 1.07169304e+00\n",
      " 1.05447059e+00 1.03635643e+00 1.01482054e+00 9.98531362e-01\n",
      " 9.59271659e-01 9.40224438e-01 9.22268291e-01 9.15865803e-01\n",
      " 8.86614096e-01 8.76907881e-01 8.50351580e-01 8.39880896e-01\n",
      " 8.26851565e-01 8.06204544e-01 7.74448709e-01 7.73957601e-01\n",
      " 7.52382587e-01 7.34126470e-01 7.11470461e-01 6.92253917e-01\n",
      " 6.76093843e-01 6.72136071e-01 6.42310995e-01 6.21435400e-01\n",
      " 6.12021597e-01 5.88273889e-01 5.75072414e-01 5.53058457e-01\n",
      " 5.42950663e-01 5.18873477e-01 5.11459994e-01 4.77210824e-01\n",
      " 4.64024759e-01 4.40717607e-01 4.31178012e-01 4.07113865e-01\n",
      " 3.83553793e-01 3.65939574e-01 3.31162797e-01 3.15728630e-01\n",
      " 2.79525913e-01 2.55858544e-01 2.31872316e-01 1.51166127e-01\n",
      " 1.42521690e-01 1.31166283e-01 1.00188949e-01 7.65151789e-02\n",
      " 7.39966335e-02 5.17036201e-02 4.01682341e-02 3.73947083e-02\n",
      " 2.98850141e-02 1.91741327e-02 1.74743495e-02 1.63110878e-02\n",
      " 1.53485031e-02 1.32038510e-02 1.20195607e-02 1.11556087e-02\n",
      " 9.15711927e-03 7.91339597e-03 7.50627705e-03 6.94393265e-03\n",
      " 6.35310484e-03 5.81468424e-03 5.72213309e-03 4.71781484e-03\n",
      " 4.30248885e-03 3.89282619e-03 3.79489747e-03 3.36717101e-03\n",
      " 3.28096518e-03 3.21523538e-03 3.02318968e-03 2.91891697e-03\n",
      " 2.81176461e-03 2.71927166e-03 2.57738696e-03 2.47658550e-03\n",
      " 2.26804457e-03 2.21086700e-03 2.20214397e-03 2.08629360e-03\n",
      " 1.96862184e-03 1.89114587e-03 1.84692421e-03 1.80004948e-03\n",
      " 1.70057283e-03 1.67274801e-03 1.54962500e-03 1.50907378e-03\n",
      " 1.49500572e-03 1.47381111e-03 1.39211589e-03 1.37212193e-03\n",
      " 1.30821183e-03 1.26753919e-03 1.25320331e-03 1.22436547e-03\n",
      " 1.21128926e-03 1.17780629e-03 1.15133744e-03 1.13141472e-03\n",
      " 1.12339262e-03 1.08134758e-03 1.05576832e-03 1.04365427e-03\n",
      " 1.02830031e-03 9.95914113e-04 9.84908292e-04 9.52082192e-04\n",
      " 9.45146662e-04 9.34859227e-04 9.19420643e-04 8.91757749e-04\n",
      " 8.66890967e-04 8.48523771e-04 8.42311587e-04 8.32479289e-04\n",
      " 8.27138511e-04 8.10059179e-04 7.96090041e-04 7.91139663e-04\n",
      " 7.69959657e-04 7.48481256e-04 7.36599538e-04 7.31366969e-04\n",
      " 7.19638926e-04 7.05541093e-04 6.98280576e-04 6.91014362e-04\n",
      " 6.78760971e-04 6.65426226e-04 6.50741180e-04 6.43926672e-04\n",
      " 6.39214036e-04 6.34129391e-04 6.26469603e-04 6.18958870e-04\n",
      " 6.08366699e-04 6.01883185e-04 5.94509892e-04 5.89880909e-04\n",
      " 5.83385519e-04 5.69270771e-04 5.65560053e-04 5.51759508e-04\n",
      " 5.50079772e-04 5.48315585e-04 5.35421787e-04 5.27721063e-04\n",
      " 5.23246725e-04 5.18639076e-04 5.12960671e-04 5.02392083e-04\n",
      " 4.99377717e-04 4.93186832e-04 4.91447078e-04 4.87183382e-04\n",
      " 4.83478291e-04 4.78109627e-04 4.71548005e-04 4.64895670e-04\n",
      " 4.63958304e-04 4.57079471e-04 4.45150329e-04 4.43312337e-04\n",
      " 4.41558885e-04 4.39752833e-04 4.34667983e-04 4.31868717e-04\n",
      " 4.25961301e-04 4.18804821e-04 4.16825053e-04 4.13306932e-04\n",
      " 4.07421128e-04 4.01222628e-04 3.97788466e-04 3.95381660e-04\n",
      " 3.89673141e-04 3.89177923e-04 3.83147734e-04 3.77412785e-04\n",
      " 3.73640297e-04 3.72101155e-04 3.68636117e-04 3.63396280e-04\n",
      " 3.60818127e-04 3.59929624e-04 3.57867640e-04 3.50231104e-04\n",
      " 3.48141341e-04 3.45536569e-04 3.42089689e-04 3.40065650e-04\n",
      " 3.32703175e-04 3.28245658e-04 3.26682885e-04 3.22903305e-04\n",
      " 3.20284629e-04 3.17758666e-04 3.16512666e-04 3.14880716e-04\n",
      " 3.12780825e-04 3.09428065e-04 3.04540613e-04 3.03095472e-04\n",
      " 2.97735195e-04 2.96905386e-04 2.92674785e-04 2.90871429e-04\n",
      " 2.89830985e-04 2.84728205e-04 2.80871346e-04 2.80094623e-04\n",
      " 2.78386136e-04 2.76612615e-04 2.73157855e-04 2.71602477e-04\n",
      " 2.66880328e-04 2.66256568e-04 2.63899332e-04 2.61283275e-04\n",
      " 2.59853500e-04 2.58579356e-04 2.56847684e-04 2.52445633e-04\n",
      " 2.49940519e-04 2.48466728e-04 2.47614501e-04 2.45066530e-04\n",
      " 2.42674909e-04 2.42326779e-04 2.40479358e-04 2.38644647e-04\n",
      " 2.37199364e-04 2.33424060e-04 2.32071790e-04 2.29460853e-04\n",
      " 2.28044571e-04 2.25805334e-04 2.22464386e-04 2.22195246e-04\n",
      " 2.17208973e-04 2.17019461e-04 2.16043591e-04 2.13920685e-04\n",
      " 2.11830442e-04 2.10540488e-04 2.10223304e-04 2.06909864e-04\n",
      " 2.04642812e-04 2.02686841e-04 2.01637472e-04 1.99522259e-04\n",
      " 1.98727452e-04 1.96277119e-04 1.94093228e-04 1.93243430e-04\n",
      " 1.89503485e-04 1.89266052e-04 1.88456281e-04 1.87994713e-04\n",
      " 1.84591500e-04 1.82691811e-04 1.81502752e-04 1.79907101e-04\n",
      " 1.79334616e-04 1.77304776e-04 1.76580612e-04 1.75696729e-04\n",
      " 1.74919877e-04 1.72978856e-04 1.71167312e-04 1.69896409e-04\n",
      " 1.68463501e-04 1.67498718e-04 1.66009658e-04 1.64527479e-04\n",
      " 1.63532175e-04 1.62075947e-04 1.60127005e-04 1.59385637e-04\n",
      " 1.58665549e-04 1.55405629e-04 1.54682687e-04 1.53094589e-04\n",
      " 1.52425201e-04 1.51714871e-04 1.49129635e-04 1.48498351e-04\n",
      " 1.45782641e-04 1.44690223e-04 1.44470380e-04 1.43293728e-04\n",
      " 1.42065535e-04 1.41525835e-04 1.40046284e-04 1.38235464e-04\n",
      " 1.37912126e-04 1.37675972e-04 1.35676035e-04 1.34838713e-04\n",
      " 1.33715928e-04 1.32588961e-04 1.31550702e-04 1.31241976e-04\n",
      " 1.29740170e-04 1.28947288e-04 1.27860071e-04 1.26489560e-04\n",
      " 1.24173111e-04 1.23805538e-04 1.22906724e-04 1.21630383e-04\n",
      " 1.20214796e-04 1.18910697e-04 1.17807164e-04 1.16498486e-04\n",
      " 1.15787075e-04 1.13866457e-04 1.13104833e-04 1.12993665e-04\n",
      " 1.11759355e-04 1.10088450e-04 1.09085595e-04 1.08939539e-04\n",
      " 1.07256339e-04 1.05666194e-04 1.05046801e-04 1.03447093e-04\n",
      " 1.03089929e-04 1.02886510e-04 1.01582225e-04 1.00663122e-04\n",
      " 9.98706584e-05 9.91928568e-05 9.88608589e-05 9.76524990e-05\n",
      " 9.65420594e-05 9.49326228e-05 9.42149034e-05 9.38203450e-05\n",
      " 9.20721403e-05 9.16475783e-05 9.10766711e-05 8.94544445e-05\n",
      " 8.90097013e-05 8.84521372e-05 8.70660472e-05 8.56948106e-05\n",
      " 8.52956142e-05 8.41497328e-05 8.38812044e-05 8.19805335e-05\n",
      " 8.15631389e-05 8.04980474e-05 7.98664198e-05 7.89193787e-05\n",
      " 7.78561998e-05 7.71226160e-05 7.67736985e-05 7.56360599e-05\n",
      " 7.47794214e-05 7.46062564e-05 7.37537532e-05 7.27342867e-05\n",
      " 7.22445507e-05 7.13155942e-05 7.00217173e-05 6.97376071e-05\n",
      " 6.82355548e-05 6.68221349e-05 6.60553798e-05 6.52766489e-05\n",
      " 6.41530931e-05 6.26564946e-05 6.21042650e-05 6.17128406e-05\n",
      " 6.04826156e-05 5.96655317e-05 5.88779851e-05 5.75064624e-05\n",
      " 5.53854423e-05 5.50919316e-05 5.40690318e-05 5.31464414e-05\n",
      " 5.25765067e-05 5.06759745e-05 4.95521255e-05 4.77665966e-05]\n",
      "[ 2.81905759e+01  6.76240527e+00  5.91569321e+00  5.33114173e+00\n",
      "  4.82805078e+00  4.33463433e+00  4.16305868e+00  4.06747161e+00\n",
      "  3.77969017e+00  3.36614906e+00  3.26423504e+00  3.22159759e+00\n",
      "  2.97486891e+00  2.94135086e+00  2.90467338e+00  2.83520627e+00\n",
      "  2.68381047e+00  2.67030938e+00  2.53431318e+00  2.47937213e+00\n",
      "  2.40807226e+00  2.27357179e+00  2.24091238e+00  2.20219914e+00\n",
      "  2.14132441e+00  2.12805983e+00  2.07112941e+00  2.02919523e+00\n",
      "  1.98736125e+00  1.91666365e+00  1.88799666e+00  1.84013822e+00\n",
      "  1.83543196e+00  1.81614149e+00  1.75652733e+00  1.72543768e+00\n",
      "  1.68421132e+00  1.66857619e+00  1.61568053e+00  1.58073208e+00\n",
      "  1.54814999e+00  1.49942741e+00  1.49666554e+00  1.43108708e+00\n",
      "  1.42853660e+00  1.41127899e+00  1.39049492e+00  1.37022818e+00\n",
      "  1.34476362e+00  1.33065762e+00  1.30085452e+00  1.28261994e+00\n",
      "  1.26505577e+00  1.23036018e+00  1.21667060e+00  1.20084211e+00\n",
      "  1.16735529e+00  1.15982715e+00  1.14628506e+00  1.13433135e+00\n",
      "  1.13151372e+00  1.11064338e+00  1.09268508e+00  1.08221303e+00\n",
      "  1.06445574e+00  1.06020422e+00  1.04859614e+00  1.01513562e+00\n",
      "  1.00244738e+00  9.87512066e-01  9.81132658e-01  9.52384088e-01\n",
      "  9.39649447e-01  9.35456676e-01  9.19946024e-01  9.15215887e-01\n",
      "  8.99637852e-01  8.89962605e-01  8.70852423e-01  8.57823749e-01\n",
      "  8.50799415e-01  8.49803488e-01  8.28171517e-01  8.16431271e-01\n",
      "  7.99136861e-01  7.81386463e-01  7.80290711e-01  7.67356432e-01\n",
      "  7.51518536e-01  7.48173083e-01  7.40932419e-01  7.33377914e-01\n",
      "  7.22513808e-01  7.13177981e-01  7.01357422e-01  6.97847818e-01\n",
      "  6.93686056e-01  6.87618653e-01  6.73304305e-01  6.68711603e-01\n",
      "  6.57679097e-01  6.44945460e-01  6.41798843e-01  6.30155182e-01\n",
      "  6.22964752e-01  6.11124475e-01  6.06016975e-01  5.98293388e-01\n",
      "  5.94059691e-01  5.83349843e-01  5.80928996e-01  5.73657515e-01\n",
      "  5.69830296e-01  5.67461731e-01  5.62192404e-01  5.49240231e-01\n",
      "  5.46130999e-01  5.44639274e-01  5.27735741e-01  5.23337503e-01\n",
      "  5.18162338e-01  5.09712328e-01  5.05962082e-01  4.97089579e-01\n",
      "  4.96160611e-01  4.86345587e-01  4.84846051e-01  4.80749814e-01\n",
      "  4.74054719e-01  4.67221174e-01  4.62724206e-01  4.56477081e-01\n",
      "  4.54279617e-01  4.45084408e-01  4.43707633e-01  4.30065479e-01\n",
      "  4.25215023e-01  4.15752547e-01  4.13109909e-01  4.06541726e-01\n",
      "  4.03220552e-01  3.98425880e-01  3.95636865e-01  3.93169676e-01\n",
      "  3.82661598e-01  3.80791148e-01  3.77531147e-01  3.75555503e-01\n",
      "  3.68103615e-01  3.60835281e-01  3.58790122e-01  3.56042535e-01\n",
      "  3.51623142e-01  3.48603542e-01  3.44678029e-01  3.43288789e-01\n",
      "  3.37308963e-01  3.35630598e-01  3.31921933e-01  3.27500625e-01\n",
      "  3.23893498e-01  3.21009758e-01  3.16013032e-01  3.13348267e-01\n",
      "  3.09204136e-01  3.05502624e-01  3.04331017e-01  3.00770213e-01\n",
      "  2.97325976e-01  2.94660619e-01  2.88851864e-01  2.84204334e-01\n",
      "  2.82323199e-01  2.80082248e-01  2.77098767e-01  2.73063377e-01\n",
      "  2.72151885e-01  2.69127470e-01  2.65288433e-01  2.65149223e-01\n",
      "  2.62298724e-01  2.59822338e-01  2.54744738e-01  2.51463957e-01\n",
      "  2.49057620e-01  2.46833692e-01  2.45332851e-01  2.40353775e-01\n",
      "  2.38094447e-01  2.37422838e-01  2.34677255e-01  2.30512474e-01\n",
      "  2.26582076e-01  2.23938989e-01  2.21301554e-01  2.18869442e-01\n",
      "  2.15994605e-01  2.13510093e-01  2.12307803e-01  2.10924618e-01\n",
      "  2.08408458e-01  2.07138779e-01  2.03287841e-01  2.01592624e-01\n",
      "  2.00822561e-01  1.97845915e-01  1.96092078e-01  1.94765479e-01\n",
      "  1.91694666e-01  1.89284051e-01  1.87258280e-01  1.84846998e-01\n",
      "  1.81657315e-01  1.79134742e-01  1.77109758e-01  1.75641905e-01\n",
      "  1.75252949e-01  1.71450892e-01  1.71016923e-01  1.68782222e-01\n",
      "  1.67193340e-01  1.65896833e-01  1.64335191e-01  1.62254472e-01\n",
      "  1.60773194e-01  1.56968162e-01  1.54343655e-01  1.53324649e-01\n",
      "  1.52710880e-01  1.51358974e-01  1.50416525e-01  1.49004624e-01\n",
      "  1.47952235e-01  1.46398502e-01  1.42330911e-01  1.41386529e-01\n",
      "  1.38503392e-01  1.37303095e-01  1.35298854e-01  1.33743902e-01\n",
      "  1.32105914e-01  1.31330820e-01  1.29487021e-01  1.27629329e-01\n",
      "  1.26887425e-01  1.26730873e-01  1.23315664e-01  1.22441590e-01\n",
      "  1.21453114e-01  1.20638561e-01  1.19897228e-01  1.17941213e-01\n",
      "  1.17492222e-01  1.15470859e-01  1.14446796e-01  1.13224840e-01\n",
      "  1.11216521e-01  1.09563764e-01  1.08232668e-01  1.07398338e-01\n",
      "  1.07047065e-01  1.05344874e-01  1.04317499e-01  1.03487311e-01\n",
      "  1.02114607e-01  1.00988602e-01  1.00423632e-01  9.70073885e-02\n",
      "  9.68202729e-02  9.64328197e-02  9.52707170e-02  9.26326528e-02\n",
      "  9.21671237e-02  9.16677912e-02  9.09295211e-02  8.97923640e-02\n",
      "  8.90981528e-02  8.76364810e-02  8.61260922e-02  8.56604235e-02\n",
      "  8.50173754e-02  8.30492213e-02  8.23317617e-02  8.15873176e-02\n",
      "  8.14205125e-02  7.89543718e-02  7.75191892e-02  7.71516715e-02\n",
      "  7.65437804e-02  7.51011169e-02  7.44057797e-02  7.33130389e-02\n",
      "  7.24328020e-02  7.21668891e-02  7.07089452e-02  7.01394887e-02\n",
      "  6.95775369e-02  6.86799585e-02  6.75696723e-02  6.71615357e-02\n",
      "  6.67126897e-02  6.47073405e-02  6.43680982e-02  6.42290633e-02\n",
      "  6.37198200e-02  6.29789606e-02  6.09234699e-02  6.04274411e-02\n",
      "  5.98767639e-02  5.83813112e-02  5.81376661e-02  5.66749714e-02\n",
      "  5.64025301e-02  5.53461757e-02  5.47829647e-02  5.45020005e-02\n",
      "  5.35792703e-02  5.27838367e-02  5.22042605e-02  5.14668275e-02\n",
      "  5.07665470e-02  5.01488776e-02  4.98139545e-02  4.84440363e-02\n",
      "  4.79165674e-02  4.74241134e-02  4.66976015e-02  4.61193919e-02\n",
      "  4.55468585e-02  4.44825094e-02  4.39970984e-02  4.36166988e-02\n",
      "  4.34959914e-02  4.27231464e-02  4.22514187e-02  4.15471018e-02\n",
      "  4.04798068e-02  3.99688634e-02  3.96730546e-02  3.91980146e-02\n",
      "  3.86510295e-02  3.83941750e-02  3.79619228e-02  3.75110697e-02\n",
      "  3.66855732e-02  3.62082231e-02  3.55448192e-02  3.51693405e-02\n",
      "  3.42700494e-02  3.36562769e-02  3.31293077e-02  3.23868363e-02\n",
      "  3.19004816e-02  3.16520472e-02  3.12050294e-02  3.07505679e-02\n",
      "  3.03190626e-02  2.95304130e-02  2.93876220e-02  2.88315088e-02\n",
      "  2.83343690e-02  2.77350738e-02  2.74718105e-02  2.70260895e-02\n",
      "  2.66670280e-02  2.63231531e-02  2.62289146e-02  2.49796995e-02\n",
      "  2.46459858e-02  2.39687815e-02  2.36562652e-02  2.31598000e-02\n",
      "  2.28416009e-02  2.25077582e-02  2.18838618e-02  2.18420500e-02\n",
      "  2.15984662e-02  2.12111453e-02  2.08397279e-02  2.05797910e-02\n",
      "  1.97992258e-02  1.96155973e-02  1.89417191e-02  1.87546706e-02\n",
      "  1.84841647e-02  1.83104999e-02  1.79429575e-02  1.76519837e-02\n",
      "  1.72507297e-02  1.68605302e-02  1.66176616e-02  1.61901969e-02\n",
      "  1.59761865e-02  1.54845547e-02  1.50174585e-02  1.47065886e-02\n",
      "  1.45852127e-02  1.43780057e-02  1.43085545e-02  1.38806688e-02\n",
      "  1.34996482e-02  1.32156943e-02  1.28897629e-02  1.26298711e-02\n",
      "  1.24885202e-02  1.19260438e-02  1.18846317e-02  1.14678275e-02\n",
      "  1.10712963e-02  1.04707472e-02  1.03323995e-02  1.02314165e-02\n",
      "  1.01003383e-02  9.70566174e-03  9.55712184e-03  9.28320085e-03\n",
      "  9.17807704e-03  9.00609770e-03  8.78875560e-03  8.31950661e-03\n",
      "  8.24309070e-03  8.21679489e-03  7.98350073e-03  7.78642578e-03\n",
      "  7.45386838e-03  7.28316109e-03  6.93971934e-03  6.82876123e-03\n",
      "  6.58215677e-03  6.51757381e-03  6.29525135e-03  6.10812168e-03\n",
      "  5.90250958e-03  5.70966039e-03  5.41861470e-03  5.17207401e-03\n",
      "  5.00030397e-03  4.73774214e-03  4.57381875e-03  4.50078584e-03\n",
      "  4.45611601e-03  4.39350476e-03  4.19725760e-03  3.96481900e-03\n",
      "  3.87907658e-03  3.67291469e-03  3.52364985e-03  3.26083890e-03\n",
      "  3.16112736e-03  3.02204346e-03  2.88535492e-03  2.76678687e-03\n",
      "  2.68100940e-03  2.49635228e-03  2.35824420e-03  2.25286501e-03\n",
      "  2.17507714e-03  2.03618700e-03  1.97879973e-03  1.91590869e-03\n",
      "  1.76087903e-03  1.71535572e-03  1.62283522e-03  1.47032915e-03\n",
      "  1.46635099e-03  1.32825638e-03  1.24891655e-03  1.17277612e-03\n",
      "  1.06408977e-03  1.04140782e-03  1.00573621e-03  9.08282510e-04\n",
      "  7.19268059e-04  6.45223173e-04  6.11914885e-04  5.52968130e-04\n",
      "  5.12587304e-04  4.90804117e-04  4.29659860e-04  4.02241046e-04\n",
      "  3.42197446e-04  2.92667257e-04  2.48534773e-04  2.07516670e-04\n",
      "  1.72289529e-04  1.50158955e-04  9.22779939e-05  2.04627367e-11\n",
      "  4.81358555e-12  4.32293751e-12  4.12115731e-12  3.20815961e-12\n",
      "  2.39745990e-12  2.38358847e-12  1.79325691e-12  1.43023332e-12\n",
      "  1.07860915e-12  6.46363088e-13  3.74351338e-13 -2.87399509e-13\n",
      " -3.06324689e-13 -7.20042939e-13 -9.68364475e-13 -1.46795106e-12\n",
      " -1.56655138e-12 -2.04417461e-12 -2.61154603e-12 -2.86103476e-12\n",
      " -3.31643783e-12 -4.23629162e-12 -4.61894798e-12 -6.07582040e-12]\n"
     ]
    }
   ],
   "source": [
    "transform = lda.ComputeLdaTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_list_in_new:\n",
    "    class_list_in_new[i] = class_list_in_new[i].dot(transform.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normlize to sqrt(dim)\n",
    "for i in class_list_in_new:\n",
    "    scale = np.sqrt(PLDA_DIM) / np.linalg.norm(class_list_in_new[i], axis=1, keepdims=True)\n",
    "    class_list_in_new[i] = scale * class_list_in_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda_stats = PldaStats(PLDA_DIM)\n",
    "for i in class_list_in_new:\n",
    "    plda_stats.add_samples(class_list_in_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plda_stats.sort()\n",
    "plda_stats.is_sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 2.28758791e-02, -1.92583029e-01, -5.69815745e-02,  2.48207566e-02,\n",
       "         1.07089586e-01,  5.29588552e-02, -4.25924041e-02,  2.53382421e-03,\n",
       "         1.88705904e-01, -2.09936139e-02,  5.14498793e-02,  3.27823750e-02,\n",
       "         1.11316690e-01,  1.74073196e-01, -5.65588000e-02, -3.54532872e-02,\n",
       "        -1.02041635e-02,  4.13315979e-02,  6.25163116e-02, -2.41479636e-02,\n",
       "         1.05556897e-01, -1.38488886e-02, -4.00597981e-03,  3.80593547e-02,\n",
       "        -1.94985378e-02, -5.84754417e-02,  2.19517969e-03, -2.70368056e-02,\n",
       "        -4.78412733e-02,  1.03770087e-02, -5.15434467e-02,  1.57501991e-02,\n",
       "        -1.40434899e-02, -9.01640841e-03, -3.38228523e-03,  8.63060847e-04,\n",
       "         3.12018023e-02,  3.84601114e-02, -1.18589905e-02, -8.41416671e-04,\n",
       "         1.26668652e-02, -1.37007597e-03, -8.48916272e-03,  6.67037226e-03,\n",
       "         1.90380179e-02,  2.44943392e-02,  3.41735023e-02,  7.72534289e-03,\n",
       "         1.63210721e-02, -1.10280821e-02, -1.10383094e-03, -1.35828475e-02,\n",
       "         1.20820413e-02, -2.80712536e-02, -2.65184147e-02,  2.45018433e-02,\n",
       "        -6.45125167e-03, -1.73643723e-02,  1.98172570e-02,  1.91281843e-02,\n",
       "        -3.25875137e-03, -3.19893462e-03, -9.09076500e-03, -9.27680619e-03,\n",
       "        -4.87437494e-03,  1.21272506e-02, -1.96547568e-02,  1.18548401e-02,\n",
       "         2.52038914e-02, -2.59950286e-03, -2.74031520e-02,  8.41414104e-03,\n",
       "         7.00108873e-03, -5.39028312e-03, -3.09574908e-03, -8.91889615e-03,\n",
       "        -1.14408717e-02, -1.08856217e-03,  1.55170433e-02, -3.57969003e-03,\n",
       "        -1.44469127e-02,  6.24968744e-03, -4.09830279e-03,  1.28618945e-02,\n",
       "         4.78384145e-03, -2.06146161e-02, -6.49220548e-03,  1.65303304e-02,\n",
       "        -1.97711571e-03,  1.64198535e-03,  7.63836893e-03, -2.33228402e-02,\n",
       "        -1.47282008e-02,  7.30812802e-03, -8.65892077e-03,  5.08259525e-03,\n",
       "        -1.63816379e-02, -1.15670645e-02, -4.39644061e-03, -4.43565177e-03,\n",
       "        -1.76116799e-02, -1.50086453e-02,  1.75510063e-02,  4.61686403e-03,\n",
       "        -3.36423097e-02, -9.06517110e-03, -1.07620917e-02, -2.17458924e-02,\n",
       "        -1.24265909e-02,  9.33131453e-04,  4.13231014e-03,  1.60910622e-03,\n",
       "        -1.65513523e-02,  1.15979604e-02, -1.43040064e-02, -2.00911165e-02,\n",
       "        -9.82467937e-03, -7.26549805e-03,  2.32029083e-02, -3.71266156e-03,\n",
       "        -8.40714259e-04, -1.72276576e-02,  7.62831587e-03,  1.16414578e-02,\n",
       "        -2.30473180e-03, -4.88309957e-03,  3.80397559e-03,  1.98027418e-02,\n",
       "        -7.67236836e-03, -9.38273556e-03, -1.57983867e-02,  7.57524886e-03,\n",
       "        -1.24045080e-02,  8.59007729e-03,  1.14563477e-02, -1.20593169e-02,\n",
       "        -2.43589920e-02,  1.86935358e-03, -1.06364810e-02, -6.00382686e-03,\n",
       "         6.59629413e-03,  3.57361755e-03, -8.32228557e-04,  1.63997476e-02,\n",
       "         1.83376684e-02,  1.52391015e-03, -4.72816057e-03,  1.34895788e-02,\n",
       "         1.00364165e-02,  1.98874740e-02,  9.99904049e-04,  1.06395516e-03,\n",
       "         1.13430826e-02,  7.34787900e-03,  2.42773851e-02, -1.21829063e-02,\n",
       "         5.90434799e-03,  7.53221610e-03, -2.22890071e-03, -6.67873963e-03,\n",
       "        -5.45926566e-04,  1.77649856e-02, -3.31512094e-03, -2.68212703e-03,\n",
       "        -3.74009291e-03, -1.08763249e-02,  4.38118675e-03, -5.69026157e-03,\n",
       "         7.23725076e-03, -2.54757889e-02,  1.36320639e-03, -1.95896740e-03,\n",
       "        -1.57237022e-02, -4.19728519e-02,  6.01220998e-03,  1.92058734e-02,\n",
       "         2.12385496e-03,  1.66080592e-02,  1.24167932e-03,  2.65749022e-03,\n",
       "         3.06652742e-04, -8.78519204e-03, -2.35999468e-02, -4.74558325e-03,\n",
       "         3.10012052e-03, -1.59287660e-03, -3.60501701e-04, -7.06525204e-03,\n",
       "        -1.90324892e-02, -8.31566072e-03, -2.96731061e-04,  6.91095584e-03,\n",
       "         5.59131343e-03, -3.42005080e-03, -8.99150428e-03,  5.85919348e-03,\n",
       "         1.16883129e-02, -1.29706930e-04, -6.17279175e-03,  1.82570024e-03,\n",
       "         1.44514716e-02, -1.88916183e-02,  8.60928469e-03, -1.31435429e-02,\n",
       "        -1.23989005e-02,  8.17644550e-03, -1.77382903e-02,  5.92002190e-03,\n",
       "        -2.63856034e-02,  7.26038997e-03,  1.59403235e-02, -3.98332173e-03,\n",
       "        -1.74904638e-03, -1.63243860e-03, -9.03618077e-03, -9.76733730e-03,\n",
       "         1.37523681e-02,  5.21446809e-03, -2.06041321e-03, -7.43536244e-03,\n",
       "        -6.85352282e-03, -1.89574229e-02, -2.38790867e-03, -6.43730187e-03,\n",
       "         2.31122744e-02,  6.83182490e-03,  6.72766019e-04, -3.83185880e-03,\n",
       "         5.12148856e-03, -8.22985064e-03,  9.39227901e-03,  9.51617070e-04,\n",
       "         3.20498786e-03,  9.52131275e-03, -7.89112673e-04, -4.85597782e-04,\n",
       "        -1.01867704e-02, -4.76393630e-03,  1.36285692e-02,  7.82268983e-03,\n",
       "         2.09083153e-03, -2.20915852e-03,  1.21247594e-02,  8.35245973e-03,\n",
       "        -6.97974493e-04,  8.90798948e-03,  1.02759466e-03, -1.49767655e-02,\n",
       "        -2.93614536e-03,  6.72718139e-03,  1.16551635e-02, -3.75434077e-04,\n",
       "        -3.68413843e-04, -6.56257181e-03, -4.17368352e-03, -3.06442007e-03,\n",
       "         1.17202386e-02, -9.23669772e-03,  2.52909605e-03,  4.27844270e-03,\n",
       "         3.24211760e-04, -7.32611637e-03, -2.47292356e-03,  3.73917574e-03,\n",
       "        -9.91677017e-03,  2.93576682e-03,  6.38584176e-03,  9.74730139e-03,\n",
       "        -8.56094464e-03,  2.49476796e-03, -3.14247289e-03, -5.50111833e-03,\n",
       "         4.57336652e-03, -4.71931078e-03, -8.30441515e-03,  2.07934374e-03,\n",
       "        -2.39204038e-03,  1.80797078e-03,  9.64556054e-03, -1.58428254e-02,\n",
       "        -4.76596548e-03,  1.26926908e-03,  5.16204233e-03, -4.37348451e-03,\n",
       "         5.32218530e-03, -1.28436455e-04, -1.83636048e-03,  3.69305535e-03,\n",
       "        -6.04657297e-03,  9.89673342e-04,  5.46760432e-04, -7.54294433e-03,\n",
       "        -6.95096654e-03,  3.18535397e-03, -3.61678450e-03,  9.99629684e-03,\n",
       "        -2.20893307e-03, -2.65573261e-03, -9.60968068e-03, -9.93647185e-04,\n",
       "         3.59203884e-03, -6.92439642e-03,  6.79982102e-03,  1.07836745e-02,\n",
       "         6.80097927e-03, -6.85530831e-03,  6.70384255e-03,  8.86038538e-04,\n",
       "        -3.07339703e-03, -1.56095784e-02,  1.98126421e-02, -1.76277329e-03,\n",
       "         3.09116408e-03, -1.91800337e-02,  2.20550708e-03,  5.27104173e-03,\n",
       "         5.38512481e-03, -3.45554857e-03,  5.84576473e-03, -4.46668886e-03,\n",
       "        -6.49212351e-03,  2.62867767e-03, -1.49039307e-04,  5.27619951e-03,\n",
       "         8.47699649e-03,  8.73211347e-03, -7.29167969e-03, -4.91074797e-03,\n",
       "        -8.98625092e-03, -1.66918225e-03,  4.67574277e-03, -2.35429255e-03,\n",
       "        -1.04026264e-03,  5.37616824e-04,  2.78987147e-03,  9.99495338e-03,\n",
       "         6.14139029e-03,  8.36722160e-04,  4.24843201e-03,  8.01546272e-03,\n",
       "        -5.48330180e-03, -1.63894461e-03, -4.72736996e-03,  9.72572837e-03,\n",
       "         2.86820327e-03,  7.84531103e-03, -1.67147270e-03, -2.75760774e-03,\n",
       "        -3.25843458e-03, -8.30100549e-03, -1.00192663e-02, -1.18179640e-02,\n",
       "        -6.76073879e-03, -1.44548530e-03,  1.15361158e-02,  1.94283922e-03,\n",
       "        -1.21201257e-03, -1.26083306e-03,  2.63589590e-03,  1.14662662e-02,\n",
       "         2.78878417e-04, -6.41326292e-03,  2.64753137e-03, -7.36981797e-03,\n",
       "        -1.08110734e-02, -3.03372996e-03, -3.07486010e-03, -3.21714858e-03,\n",
       "         2.07353962e-03,  1.47527964e-03]),\n",
       " array([[ 1.16272115e+00,  2.42706978e-01,  2.22254902e-01, ...,\n",
       "         -4.07402496e-03,  1.70404380e-03,  1.56079343e-03],\n",
       "        [-2.60488251e-01,  1.16722889e+00,  4.23415114e-02, ...,\n",
       "          3.09374463e-03,  5.19290449e-03, -4.33029981e-03],\n",
       "        [ 1.83891548e-01,  7.84345084e-02, -1.18804938e+00, ...,\n",
       "          3.66693098e-03,  5.73405543e-04,  5.68719120e-03],\n",
       "        ...,\n",
       "        [-8.38279126e-04, -1.20233082e-03,  1.13418769e-03, ...,\n",
       "          6.41412550e-02, -5.65142468e-01, -4.13121419e-02],\n",
       "        [ 1.43258524e-04,  1.25494193e-03, -1.72662530e-03, ...,\n",
       "          1.12990893e-01,  5.22167653e-01, -3.97592201e-01],\n",
       "        [ 1.76840318e-03,  1.94678296e-03, -3.40039194e-05, ...,\n",
       "         -1.09159498e-01, -3.72233237e-01, -1.01086345e+00]]),\n",
       " array([7.4157508 , 6.61698972, 5.76191534, 4.80422211, 4.29909981,\n",
       "        4.04979378, 3.79145844, 3.5370277 , 3.22256268, 3.14227222,\n",
       "        2.95288812, 2.77520573, 2.60507235, 2.58391587, 2.36036405,\n",
       "        2.34825076, 2.24683591, 2.19142085, 2.12571019, 2.06420673,\n",
       "        1.99427013, 1.93971631, 1.86800777, 1.858014  , 1.79100685,\n",
       "        1.77960551, 1.69063792, 1.6692715 , 1.64322069, 1.60764957,\n",
       "        1.56687085, 1.52891179, 1.51134846, 1.4740946 , 1.45980336,\n",
       "        1.41806614, 1.39426486, 1.38801324, 1.35944342, 1.32808435,\n",
       "        1.29532285, 1.25037448, 1.23983028, 1.21767519, 1.20608556,\n",
       "        1.18619008, 1.17480519, 1.1530641 , 1.13394348, 1.1207294 ,\n",
       "        1.10918889, 1.09629554, 1.0683623 , 1.05938488, 1.04196073,\n",
       "        1.03649083, 1.00552233, 0.98755389, 0.97914631, 0.96588119,\n",
       "        0.96424951, 0.93418102, 0.92772733, 0.90589827, 0.89161928,\n",
       "        0.87141858, 0.86875234, 0.8687285 , 0.8417102 , 0.83289726,\n",
       "        0.82390673, 0.80550451, 0.80347754, 0.80046786, 0.79793249,\n",
       "        0.77805727, 0.77212975, 0.76233775, 0.75567528, 0.74871149,\n",
       "        0.73762191, 0.73203949, 0.72015667, 0.71281799, 0.70847824,\n",
       "        0.70309776, 0.69516012, 0.68819234, 0.67806696, 0.66651612,\n",
       "        0.66162944, 0.65819471, 0.65489616, 0.64714134, 0.63606906,\n",
       "        0.62948095, 0.62292346, 0.61995482, 0.61308455, 0.60587121,\n",
       "        0.59850087, 0.58860221, 0.58435648, 0.57681163, 0.57274999,\n",
       "        0.57019159, 0.56424544, 0.55802231, 0.54969936, 0.54480262,\n",
       "        0.54202957, 0.53745293, 0.53267709, 0.52647337, 0.51738839,\n",
       "        0.51197249, 0.51049441, 0.50329388, 0.50147148, 0.49743113,\n",
       "        0.48864   , 0.48611321, 0.48112652, 0.47777263, 0.47579446,\n",
       "        0.47229652, 0.46773012, 0.46145025, 0.45887614, 0.44732944,\n",
       "        0.44648923, 0.43840775, 0.43624791, 0.43021592, 0.42620129,\n",
       "        0.42310369, 0.41804805, 0.41532757, 0.41378016, 0.40770473,\n",
       "        0.405146  , 0.40279378, 0.40010268, 0.39668126, 0.39309502,\n",
       "        0.38851798, 0.38508925, 0.37900607, 0.37840187, 0.37480937,\n",
       "        0.37063556, 0.36509389, 0.36150971, 0.35570126, 0.35253553,\n",
       "        0.35091195, 0.34674806, 0.34435596, 0.34146424, 0.33834491,\n",
       "        0.33718531, 0.33508233, 0.33092387, 0.32821499, 0.32429247,\n",
       "        0.32248725, 0.32146467, 0.31706844, 0.31473056, 0.31402087,\n",
       "        0.31225949, 0.30678649, 0.30494476, 0.30174501, 0.30115449,\n",
       "        0.29870061, 0.29502341, 0.29182076, 0.29038219, 0.28678042,\n",
       "        0.28430833, 0.28114882, 0.28032499, 0.27711958, 0.27639268,\n",
       "        0.27387469, 0.26880353, 0.26807296, 0.26642841, 0.26554737,\n",
       "        0.26433886, 0.26007937, 0.25783947, 0.25613789, 0.25444284,\n",
       "        0.25257984, 0.24952684, 0.2478937 , 0.24722341, 0.24575671,\n",
       "        0.24219205, 0.24093636, 0.23934446, 0.23857921, 0.23752903,\n",
       "        0.23576219, 0.2338896 , 0.23274991, 0.23221453, 0.23130132,\n",
       "        0.22812463, 0.22654785, 0.22463494, 0.22354899, 0.22238761,\n",
       "        0.22061278, 0.2173869 , 0.2149505 , 0.21439125, 0.2115752 ,\n",
       "        0.21078296, 0.20986249, 0.20830449, 0.2064293 , 0.20467125,\n",
       "        0.20380438, 0.20269614, 0.20066844, 0.19979288, 0.19865204,\n",
       "        0.19679763, 0.19611108, 0.19456825, 0.19277428, 0.19163449,\n",
       "        0.19116492, 0.19011961, 0.18937639, 0.18756994, 0.18641611,\n",
       "        0.18496349, 0.18344448, 0.18197356, 0.18037163, 0.17967113,\n",
       "        0.17879655, 0.17856107, 0.17543816, 0.17483193, 0.17398403,\n",
       "        0.1721917 , 0.17090901, 0.17009012, 0.16986477, 0.16866173,\n",
       "        0.16755602, 0.16596527, 0.16424035, 0.16249522, 0.16137927,\n",
       "        0.16087655, 0.1604576 , 0.15997091, 0.1586854 , 0.15841632,\n",
       "        0.15735935, 0.15624557, 0.15609392, 0.1552471 , 0.15375768,\n",
       "        0.15315295, 0.15238854, 0.15108664, 0.15046585, 0.14916833,\n",
       "        0.14788521, 0.14702234, 0.14567645, 0.14471969, 0.14400705,\n",
       "        0.1438017 , 0.14297557, 0.14134988, 0.14073641, 0.14039174,\n",
       "        0.13948632, 0.13827479, 0.13765722, 0.13724452, 0.13608309,\n",
       "        0.13508831, 0.13408296, 0.13349612, 0.13321235, 0.1326964 ,\n",
       "        0.13197891, 0.13143275, 0.12978794, 0.12904658, 0.1286196 ,\n",
       "        0.12733024, 0.12697502, 0.12573978, 0.12550212, 0.12426458,\n",
       "        0.12310964, 0.12255815, 0.12178075, 0.12111904, 0.12103114,\n",
       "        0.11964242, 0.11896834, 0.11843915, 0.11799256, 0.11679411,\n",
       "        0.11647427, 0.11583901, 0.11549454, 0.11468234, 0.11412334,\n",
       "        0.11319144, 0.11272473, 0.11239427, 0.11218331, 0.11170684,\n",
       "        0.11011618, 0.10989218, 0.1094385 , 0.10818942, 0.10780602,\n",
       "        0.10725891, 0.10698049, 0.10628365, 0.10579579, 0.1052602 ,\n",
       "        0.10465656, 0.10403927, 0.10290432, 0.10268827, 0.10177047,\n",
       "        0.10168534, 0.10053268, 0.09980983, 0.09922326, 0.09793719,\n",
       "        0.09752777, 0.09736923, 0.09675896, 0.09628616, 0.09586885,\n",
       "        0.09502654, 0.0949349 , 0.09477151, 0.0943387 , 0.09394076,\n",
       "        0.0928158 , 0.09258727, 0.09168301, 0.09102922, 0.09079188,\n",
       "        0.08943754, 0.08917968, 0.08841078, 0.08809696, 0.08730784,\n",
       "        0.08701383, 0.08614834, 0.08507882, 0.0835703 , 0.08272191])]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plda_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "nllr_x: 416.19672807630195\n",
      "nllr_y: -374.71070634900775\n",
      "normalized_nllr: 41.48602172729419\n",
      "nllr_m: 416.86285387182215\n",
      "nllr_m_2: 416.8628538718229\n",
      "part1_residual -451.5078325732875\n",
      "part2_mean -416.86285387182215\n",
      "normlized_obj -451.2706247610935\n",
      "2 5\n",
      "nllr_x: 193.932297015006\n",
      "nllr_y: -470.0382183919924\n",
      "normalized_nllr: -276.10592137698643\n",
      "nllr_m: 200.855603848878\n",
      "nllr_m_2: 200.85560384887793\n",
      "part1_residual -430.2420683777721\n",
      "part2_mean -200.85560384887802\n",
      "normlized_obj -428.6715013450519\n",
      "3 5\n",
      "nllr_x: 187.98922293711206\n",
      "nllr_y: -469.7062600344786\n",
      "normalized_nllr: -281.71703709736653\n",
      "nllr_m: 198.14177817354323\n",
      "nllr_m_2: 198.14177817354363\n",
      "part1_residual -430.24139205778454\n",
      "part2_mean -198.14177817354334\n",
      "normlized_obj -428.6522485892615\n",
      "4 5\n",
      "nllr_x: 186.70345257885276\n",
      "nllr_y: -469.22658878562424\n",
      "normalized_nllr: -282.5231362067715\n",
      "nllr_m: 197.92327260665508\n",
      "nllr_m_2: 197.9232726066552\n",
      "part1_residual -430.24138804357256\n",
      "part2_mean -197.92327260665505\n",
      "normlized_obj -428.650748535011\n",
      "5 5\n",
      "nllr_x: 186.27395278744015\n",
      "nllr_y: -469.0341740705965\n",
      "normalized_nllr: -282.76022128315634\n",
      "nllr_m: 197.89092350149303\n",
      "nllr_m_2: 197.89092350149303\n",
      "part1_residual -430.241382723438\n",
      "part2_mean -197.89092350149298\n",
      "normlized_obj -428.6505217629151\n"
     ]
    }
   ],
   "source": [
    "# test_fin_prior\n",
    "plda_estimator = PldaEstimation(plda_stats)\n",
    "plda_paras = plda_estimator.estimate(iteration=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+ PLDA_PARA_sdsv_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(plda_paras, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+ PLDA_PARA_sdsv_NAME, 'rb') as handle:\n",
    "    plda_paras = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda_in = PLDA(plda_paras[0], plda_paras[1], plda_paras[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "[plda_in_within, plda_in_between] = plda_estimator.get_stat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORAL adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CORAL_plda_adapt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral=CORAL(plda.mean, plda_within, plda_between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_list_in_new:\n",
    "    for j in class_list_in_new[i]:\n",
    "        coral.add_stats(1, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral.update_plda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coral_plda_paras = plda_estimator.get_output_from_var(coral.within_var, coral.between_var, np.squeeze(coral.mean), 370)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda_new = PLDA(new_coral_plda_paras[0], new_coral_plda_paras[1], new_coral_plda_paras[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORAL plus adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CORAL_plus_plda_adapt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "coralplus=CORALPlus(plda.mean, plda_within, plda_between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_list_in_new:\n",
    "    for j in class_list_in_new[i]:\n",
    "        coralplus.add_stats(1, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "coralplus.update_plda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coral_plus_plda_paras = plda_estimator.get_output_from_var(coralplus.within_var, coralplus.between_var, np.squeeze(coralplus.mean), 370)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda_new = PLDA(new_coral_plus_plda_paras[0], new_coral_plus_plda_paras[1], new_coral_plus_plda_paras[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LIP_plda_adapt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plda_in = plda\n",
    "# plda_in_within = plda_within\n",
    "# plda_in_between = plda_between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "lip = LIP()\n",
    "lip.interpolation(plda_in.mean, plda_in_within, plda_in_between, plda_within, plda_between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lip_plda_paras = plda_estimator.get_output_from_var(lip.within_var, lip.between_var, np.squeeze(lip.mean), 370)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda_new = PLDA(new_lip_plda_paras[0], new_lip_plda_paras[1], new_lip_plda_paras[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CIP_plda_adapt import *\n",
    "from CORAL_plda_adapt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral=CORAL(plda.mean, plda_within, plda_between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_list_in_new:\n",
    "    for j in class_list_in_new[i]:\n",
    "        coral.add_stats(1, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral.update_plda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plda_in = plda\n",
    "# plda_in_within = plda_within\n",
    "# plda_in_between = plda_between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip=CIP()\n",
    "cip.interpolation(plda_in.mean, plda_in_within, plda_in_between, coral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cip_plda_paras = plda_estimator.get_output_from_var(cip.within_var, cip.between_var, np.squeeze(cip.mean), 370)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda_new = PLDA(new_cip_plda_paras[0], new_cip_plda_paras[1], new_cip_plda_paras[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIP-REG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LIP_REG_plda_adapt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plda_in = plda\n",
    "# plda_in_within = plda_within\n",
    "# plda_in_between = plda_between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipreg = LIPReg()\n",
    "lipreg.interpolation(plda_in.mean, plda_in_within, plda_in_between, plda_within, plda_between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lipreg_plda_paras = plda_estimator.get_output_from_var(lipreg.within_var, lipreg.between_var, np.squeeze(lipreg.mean), 370)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda_new = PLDA(new_lipreg_plda_paras[0], new_lipreg_plda_paras[1], new_lipreg_plda_paras[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIP-REG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CIP_REG_plda_adapt import *\n",
    "from CORAL_plda_adapt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral=CORAL(plda.mean, plda_within, plda_between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_list_in_new:\n",
    "    for j in class_list_in_new[i]:\n",
    "        coral.add_stats(1, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral.update_plda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plda_in = plda\n",
    "# plda_in_within = plda_within\n",
    "# plda_in_between = plda_between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "cipreg=CIPReg()\n",
    "cipreg.interpolation(plda_in.mean, plda_in_within, plda_in_between, coral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cipreg_plda_paras = plda_estimator.get_output_from_var(cipreg.within_var, cipreg.between_var, np.squeeze(cipreg.mean), 370)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda_new = PLDA(new_cipreg_plda_paras[0], new_cipreg_plda_paras[1], new_cipreg_plda_paras[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaldi_plda_new import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptor = PldaUnsupervisedAdaptor(dim=PLDA_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_list_in_new:\n",
    "    for j in class_list_in_new[i]:\n",
    "        adaptor.add_stats(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+ PLDA_PARA_NAME, 'rb') as handle:\n",
    "    plda_paras = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kaldi_uda_plda_paras = adaptor.update_plda(plda_paras[0], plda_paras[1], plda_paras[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda_new = PLDA(new_kaldi_uda_plda_paras[0], new_kaldi_uda_plda_paras[1], new_kaldi_uda_plda_paras[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model bank\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n"
     ]
    }
   ],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/vox1_kaldi_test/vox1_kaldi_test.csv'\n",
    "train_list = '/workspace/DATASET/std/vox1test_trial_data.csv'\n",
    "test_list = {}\n",
    "model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# train_data = CSVDataSet(train_list)\n",
    "# train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=True)\n",
    "train_data = PickleDataSet(train_list)\n",
    "train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "pin_memory=False, drop_last=False, timeout=0,\\\n",
    "worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "model = model_bank.get_model(model_id, model_metric, model_settings, None)\n",
    "checkpoint = torch.load(model_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "    batch_x = batch_x.to(device)\n",
    "    label = batch_y[0]\n",
    "\n",
    "    batch_y = torch.tensor([0]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "    emb = emb.squeeze().data.cpu().numpy()\n",
    "    \n",
    "    if label not in test_list.keys():\n",
    "        test_list[label] = emb[None, :]\n",
    "    else:\n",
    "        print('repeat eer:', label)\n",
    "        break\n",
    "#         test_list[label] = np.append(test_list[label], emb[None, :], axis=0)\n",
    "    \n",
    "    if (count+1) % 500 == 0:\n",
    "        print(count+1)\n",
    "\n",
    "del model, batch_x, batch_y\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4874"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4874"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+TEST_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(test_list, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation sdsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model bank\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n"
     ]
    }
   ],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/vox1_kaldi_test/vox1_kaldi_test.csv'\n",
    "train_list = '/workspace/DATASET/std/sdsvsmall_trial_data.csv'\n",
    "test_list = {}\n",
    "model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# train_data = CSVDataSet(train_list)\n",
    "# train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=True)\n",
    "train_data = PickleDataSet(train_list)\n",
    "train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "pin_memory=False, drop_last=False, timeout=0,\\\n",
    "worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "model = model_bank.get_model(model_id, model_metric, model_settings, None)\n",
    "checkpoint = torch.load(model_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "    batch_x = batch_x.to(device)\n",
    "    label = batch_y[0]\n",
    "\n",
    "    batch_y = torch.tensor([0]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "    emb = emb.squeeze().data.cpu().numpy()\n",
    "    \n",
    "    if label not in test_list.keys():\n",
    "        test_list[label] = emb[None, :]\n",
    "    else:\n",
    "        print('repeat eer:', label)\n",
    "        break\n",
    "#         test_list[label] = np.append(test_list[label], emb[None, :], axis=0)\n",
    "    \n",
    "    if (count+1) % 500 == 0:\n",
    "        print(count+1)\n",
    "\n",
    "del model, batch_x, batch_y\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14490"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14490"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+TEST_DATA_sdsv_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(test_list, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SDSV Scoring PLDA kaldi-uda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0332815734989648, 0.2934955141476865, 0.5019927536231884)\n",
      "Starting point for CLLR is 0.401168\n",
      "Converged linear model with loss 0.13812855503534988\n",
      "(0.0332815734989648, 0.2934955141476865, 0.3532608695652174)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n",
      "Starting point for CLLR is 0.869133\n",
      "Converged linear model with loss 0.18979610822148688\n",
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SDSV Scoring PLDA CIP-REG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.030296756383712906, 0.28263457556935445, 0.3606625258799172)\n",
      "Starting point for CLLR is 0.594836\n",
      "Converged linear model with loss 0.12833518508854863\n",
      "(0.030296756383712906, 0.28263457556935445, 0.35998102139406485)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n",
      "Starting point for CLLR is 0.869133\n",
      "Converged linear model with loss 0.18979610822148688\n",
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SDSV Scoring PLDA LIP-REG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.028433402346445823, 0.2858523119392705, 0.3444703243616287)\n",
      "Starting point for CLLR is 0.641845\n",
      "Converged linear model with loss 0.12459125133976001\n",
      "(0.028433402346445823, 0.2858523119392705, 0.380891994478951)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n",
      "Starting point for CLLR is 0.869133\n",
      "Converged linear model with loss 0.18979610822148688\n",
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SDSV Scoring PLDA CIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02969289164941339, 0.2835144927536276, 0.3795462387853692)\n",
      "Starting point for CLLR is 0.528276\n",
      "Converged linear model with loss 0.12595929005448164\n",
      "(0.02969289164941339, 0.2835144927536276, 0.3566856452726018)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n",
      "Starting point for CLLR is 0.869133\n",
      "Converged linear model with loss 0.18979610822148688\n",
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SDSV Scoring PLDA LIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02789855072463768, 0.2832125603864702, 0.3481280193236715)\n",
      "Starting point for CLLR is 0.602749\n",
      "Converged linear model with loss 0.12344965045191823\n",
      "(0.02789855072463768, 0.2832125603864702, 0.3775534851621808)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n",
      "Starting point for CLLR is 0.869133\n",
      "Converged linear model with loss 0.18979610822148688\n",
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SDSV Scoring PLDA CORAL+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02789855072463768, 0.28452380952380985, 0.3773895790200138)\n",
      "Starting point for CLLR is 0.486375\n",
      "Converged linear model with loss 0.12022658409028258\n",
      "(0.02789855072463768, 0.28452380952380985, 0.34453071083505865)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n",
      "Starting point for CLLR is 0.869133\n",
      "Converged linear model with loss 0.18979610822148688\n",
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SDSV Scoring PLDA CORAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0296583850931677, 0.2910282953761233, 0.40492581090407176)\n",
      "Starting point for CLLR is 0.493019\n",
      "Converged linear model with loss 0.12652412044941985\n",
      "(0.0296583850931677, 0.2910282953761233, 0.3575224292615597)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n",
      "Starting point for CLLR is 0.869133\n",
      "Converged linear model with loss 0.18979610822148688\n",
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SDSV Scoring PLDA OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02629399585921325, 0.2928312629399539, 0.385248447204969)\n",
      "Starting point for CLLR is 0.552906\n",
      "Converged linear model with loss 0.11912664726358842\n",
      "(0.02629399585921325, 0.2928312629399539, 0.37501725327812285)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.04773982056590753, 0.48993271221532486, 9.678761214630779)\n",
      "Starting point for CLLR is 0.890078\n",
      "Converged linear model with loss 0.19103426899687426\n",
      "(0.04773982056590753, 0.48993271221532486, 0.5256297446514838)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n",
      "Starting point for CLLR is 0.869133\n",
      "Converged linear model with loss 0.18979610822148688\n",
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SDSV Scoring PLDA IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_in.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_in.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_sdsv_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_172338.wav trn_172362.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.03012422360248447, 0.2496204278813, 0.12603174603174602)\n",
      "Starting point for CLLR is 0.625024\n",
      "Converged linear model with loss 0.13291985466567877\n",
      "(0.03012422360248447, 0.2496204278813, 0.13453071083505866)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n",
      "Starting point for CLLR is 0.869133\n",
      "Converged linear model with loss 0.18979610822148688\n",
      "(0.049189095928226366, 0.4170721187025469, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/sdsvsmall_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scoring PLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02104984093319194, 0.26163838812301365, 0.4125662778366914)\n",
      "Starting point for CLLR is 0.326006\n",
      "Converged linear model with loss 0.08623393210098965\n",
      "(0.02104984093319194, 0.26163838812301365, 0.2688229056203606)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n",
      "Starting point for CLLR is 0.842628\n",
      "Converged linear model with loss 0.09200133308491727\n",
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# scoring PLDA CORAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02142099681866383, 0.2611611876988343, 0.3741781548250265)\n",
      "Starting point for CLLR is 0.347226\n",
      "Converged linear model with loss 0.08987157382109044\n",
      "(0.02142099681866383, 0.2611611876988343, 0.291118769883351)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n",
      "Starting point for CLLR is 0.842628\n",
      "Converged linear model with loss 0.09200133308491727\n",
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scoring PLDA CORAL+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.020784729586426298, 0.2615588547189809, 0.4023594909862142)\n",
      "Starting point for CLLR is 0.308798\n",
      "Converged linear model with loss 0.08617091907281849\n",
      "(0.020784729586426298, 0.2615588547189809, 0.2796129374337222)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n",
      "Starting point for CLLR is 0.842628\n",
      "Converged linear model with loss 0.09200133308491727\n",
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scoring PLDA LIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02104984093319194, 0.26163838812301365, 0.4125662778366914)\n",
      "Starting point for CLLR is 0.326006\n",
      "Converged linear model with loss 0.08623393210098967\n",
      "(0.02104984093319194, 0.26163838812301365, 0.2688229056203606)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n",
      "Starting point for CLLR is 0.842628\n",
      "Converged linear model with loss 0.09200133308491727\n",
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scoring PLDA CIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02131495227995761, 0.26216861081654635, 0.4028101802757158)\n",
      "Starting point for CLLR is 0.331509\n",
      "Converged linear model with loss 0.08786970159803127\n",
      "(0.02131495227995761, 0.26216861081654635, 0.28467656415694587)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n",
      "Starting point for CLLR is 0.842628\n",
      "Converged linear model with loss 0.09200133308491727\n",
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scoring PLDA LIP-REG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02104984093319194, 0.26163838812301365, 0.4125662778366914)\n",
      "Starting point for CLLR is 0.326006\n",
      "Converged linear model with loss 0.08623393210098963\n",
      "(0.02104984093319194, 0.26163838812301365, 0.2688229056203606)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n",
      "Starting point for CLLR is 0.842628\n",
      "Converged linear model with loss 0.09200133308491727\n",
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scoring PLDA CIP-REG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = (np.sqrt(512) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "    test_list[i] = plda_new.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = plda_new.log_likelihood_ratio(enroll_emb, 1, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_path = '/workspace/DATASET/std/vox1test_trials'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = (1.0 / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "            \n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/GREAT_ASV_system/score/')\n",
    "\n",
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.020890774125132554, 0.2638123011664924, 0.41362672322375393)\n",
      "Starting point for CLLR is 0.314537\n",
      "Converged linear model with loss 0.08645988000511412\n",
      "(0.020890774125132554, 0.2638123011664924, 0.2739395546129374)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(calib_score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n",
      "Starting point for CLLR is 0.842628\n",
      "Converged linear model with loss 0.09200133308491727\n",
      "(0.02348886532343586, 0.24504241781548108, 1.0)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/workspace/DATASET/std/vox1test_trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from JB import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+PLDA_DATA_NAME, 'rb') as handle:\n",
    "    class_list_new = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "train_list = np.zeros((1276888, 512))\n",
    "label = []\n",
    "last_pos = 0\n",
    "for count, i in enumerate(class_list_new):\n",
    "    this_len = class_list_new[i].shape[0]\n",
    "    train_list[last_pos:last_pos+this_len] = class_list_new[i]\n",
    "    last_pos = last_pos+this_len\n",
    "    label = label + this_len * [i]\n",
    "    if (count+1) % 1000 == 0:\n",
    "        print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1276888, 512)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_mean = np.mean(train_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9046652415934415"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list_centered = train_list - global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276888, 512)\n",
      "prepare done, maxNumberInOneClass= 1002\n",
      "Iterations-0: 0.0010711645996589437\n",
      "Iterations-1: 1.3523100215732059e-05\n",
      "Iterations-2: 2.4056012775033254e-06\n",
      "Iterations-3: 7.342351828003286e-07\n",
      "Iterations-4: 2.8068888850328114e-07\n",
      "Iterations-5: 1.184689619041678e-07\n",
      "Iterations-6: 5.267479095722711e-08\n",
      "Iterations-7: 2.4178416589029948e-08\n",
      "Iterations-8: 1.1338391238278522e-08\n",
      "Iterations-9: 5.399002417915827e-09\n",
      "Iterations-10: 2.6014852098979146e-09\n",
      "Iterations-11: 1.2648995479417483e-09\n",
      "Iterations-12: 6.188518191301809e-10\n",
      "Iterations-13: 3.0677699544240897e-10\n",
      "Iterations-14: 1.5350548541958987e-10\n",
      "Iterations-15: 8.009531443608684e-11\n",
      "Iterations-16: 4.7031017931828334e-11\n",
      "Iterations-17: 3.413629428325939e-11\n",
      "Iterations-18: 3.0268280274376596e-11\n",
      "Iterations-19: 2.927871093020977e-11\n"
     ]
    }
   ],
   "source": [
    "A, G = JointBayesian_Train(train_list_centered, label, fold = component_dir, complete_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "score_out_path = component_dir+'/'+'JB_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "#     test_list[i] = transform.dot(test_list[i])\n",
    "#     test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]\n",
    "#     test_list[i] = plda.transform_ivector(test_list[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = Verify(A, G, enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.028791092258748652, 0.2808589607635198, 0.592099681866384)\n",
      "Starting point for CLLR is 10.192940\n",
      "(0.028791092258748652, 0.2808589607635198, 0.592099681866384)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+'JB_score'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA-JB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from JB_tmp import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+PLDA_DATA_NAME, 'rb') as handle:\n",
    "    class_list_new = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of mean: 1.9046652386925422\n"
     ]
    }
   ],
   "source": [
    "# Substract global mean\n",
    "global_mean = np.zeros(512)\n",
    "num_utt = 0\n",
    "for count, i in enumerate(class_list_new):\n",
    "    num_utt += class_list_new[i].shape[0]\n",
    "    global_mean += class_list_new[i].shape[0] * np.mean(class_list_new[i], axis=0)\n",
    "    \n",
    "global_mean = (1.0 / num_utt) * global_mean\n",
    "print('Norm of mean:', np.linalg.norm(global_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in class_list_new:\n",
    "    class_list_new[i] = class_list_new[i] - global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PLDA_DIM = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda norm of global mean: 1.0363030848906236e-07\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(lda_dim=PLDA_DIM, ivector_dim=512)\n",
    "for i in class_list_new:\n",
    "    lda.AccStats(class_list_new[i])\n",
    "print('lda norm of global mean:', lda.GetGlobalMean()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input data has norm of mean 1.0363030848906236e-07\n",
      "[7.05680318e+00 6.83084110e+00 6.49589130e+00 6.25103781e+00\n",
      " 6.02699328e+00 5.93644421e+00 5.74553620e+00 5.71113328e+00\n",
      " 5.52863863e+00 5.48530371e+00 5.33798738e+00 5.29171180e+00\n",
      " 5.19417991e+00 5.13465376e+00 5.07992271e+00 5.03656835e+00\n",
      " 4.94590764e+00 4.87222457e+00 4.86027973e+00 4.83695617e+00\n",
      " 4.67446231e+00 4.62048504e+00 4.56140204e+00 4.53129694e+00\n",
      " 4.49590328e+00 4.46416332e+00 4.37204092e+00 4.31959085e+00\n",
      " 4.31300552e+00 4.24568159e+00 4.22761656e+00 4.13339006e+00\n",
      " 4.09174010e+00 4.06669643e+00 4.00950966e+00 3.98957290e+00\n",
      " 3.92033707e+00 3.90857520e+00 3.83256738e+00 3.74048687e+00\n",
      " 3.67952474e+00 3.63867904e+00 3.60639986e+00 3.55344168e+00\n",
      " 3.53629863e+00 3.48462131e+00 3.43491949e+00 3.41205987e+00\n",
      " 3.38153426e+00 3.36127220e+00 3.34227493e+00 3.30985634e+00\n",
      " 3.22345557e+00 3.20170408e+00 3.17643705e+00 3.10434679e+00\n",
      " 3.08763803e+00 3.05436367e+00 3.01382095e+00 2.98352146e+00\n",
      " 2.93198022e+00 2.90411634e+00 2.89903466e+00 2.83804975e+00\n",
      " 2.83351883e+00 2.78605764e+00 2.76421916e+00 2.74960267e+00\n",
      " 2.72184671e+00 2.69137132e+00 2.66338311e+00 2.63234074e+00\n",
      " 2.60219784e+00 2.57916201e+00 2.54094251e+00 2.50943206e+00\n",
      " 2.49625883e+00 2.47388711e+00 2.43530830e+00 2.42782802e+00\n",
      " 2.40034032e+00 2.38407741e+00 2.35199631e+00 2.31963590e+00\n",
      " 2.29363615e+00 2.28313650e+00 2.23608657e+00 2.21853409e+00\n",
      " 2.19684043e+00 2.14596213e+00 2.13420261e+00 2.12014413e+00\n",
      " 2.10439291e+00 2.06883039e+00 2.05822375e+00 2.01022595e+00\n",
      " 1.99369039e+00 1.97317591e+00 1.94283417e+00 1.90353871e+00\n",
      " 1.87266091e+00 1.82212012e+00 1.79120874e+00 1.77931542e+00\n",
      " 1.76385932e+00 1.73636444e+00 1.72209424e+00 1.68983678e+00\n",
      " 1.68067125e+00 1.63594565e+00 1.62080880e+00 1.60219155e+00\n",
      " 1.57460791e+00 1.55914501e+00 1.54711486e+00 1.52296514e+00\n",
      " 1.49303048e+00 1.48645691e+00 1.46302605e+00 1.44177406e+00\n",
      " 1.41063840e+00 1.39109357e+00 1.34906669e+00 1.33973311e+00\n",
      " 1.30432705e+00 1.25813219e+00 1.24786896e+00 1.22109354e+00\n",
      " 1.17852543e+00 1.16385927e+00 1.15515713e+00 1.12614338e+00\n",
      " 1.09951167e+00 1.08985197e+00 1.07348132e+00 1.05523889e+00\n",
      " 1.02161995e+00 1.00762190e+00 9.93792060e-01 9.45702369e-01\n",
      " 9.44586199e-01 9.26228945e-01 8.83398926e-01 8.28087345e-01\n",
      " 8.18886626e-01 7.83129310e-01 7.68436026e-01 7.61940351e-01\n",
      " 7.41613533e-01 7.18352937e-01 6.87489149e-01 6.78282083e-01\n",
      " 6.63211061e-01 5.89789159e-01 5.64599335e-01 5.62415737e-01\n",
      " 5.15598158e-01 4.95816375e-01 4.66256690e-01 3.96909883e-01\n",
      " 3.69744427e-01 3.40163152e-01 3.16658055e-01 2.20342006e-01\n",
      " 1.77412807e-01 1.62348963e-01 1.13433408e-01 1.04143794e-01\n",
      " 9.23012515e-02 6.58251454e-02 5.03778839e-02 4.32825786e-02\n",
      " 3.96143481e-02 2.39915614e-02 2.07418059e-02 1.94120242e-02\n",
      " 1.83273528e-02 1.66401563e-02 1.37179018e-02 1.31433994e-02\n",
      " 1.09389968e-02 1.00937527e-02 9.10398464e-03 8.41884768e-03\n",
      " 8.21084741e-03 7.02544367e-03 6.67112735e-03 5.74895556e-03\n",
      " 5.05565115e-03 4.69090728e-03 4.35393488e-03 4.18306941e-03\n",
      " 3.75041347e-03 3.69952198e-03 3.66422388e-03 3.35833611e-03\n",
      " 3.19666180e-03 3.05606799e-03 2.99444263e-03 2.78763446e-03\n",
      " 2.66529292e-03 2.49253493e-03 2.40373173e-03 2.28956599e-03\n",
      " 2.26859062e-03 2.24107159e-03 2.18416341e-03 2.15291719e-03\n",
      " 2.04664334e-03 1.94030304e-03 1.82721200e-03 1.77794011e-03\n",
      " 1.66097870e-03 1.65769693e-03 1.62021493e-03 1.60019356e-03\n",
      " 1.53859557e-03 1.53278112e-03 1.46885077e-03 1.41467815e-03\n",
      " 1.38346137e-03 1.37021374e-03 1.33519086e-03 1.28631320e-03\n",
      " 1.27506176e-03 1.26278431e-03 1.23741163e-03 1.21681072e-03\n",
      " 1.18913923e-03 1.15499244e-03 1.12259513e-03 1.10034376e-03\n",
      " 1.05677072e-03 1.04647519e-03 1.03127828e-03 1.02111508e-03\n",
      " 1.00223998e-03 9.85524920e-04 9.80106346e-04 9.68459414e-04\n",
      " 9.33999160e-04 9.23698519e-04 9.20974378e-04 9.17141524e-04\n",
      " 8.84159561e-04 8.74858006e-04 8.55983514e-04 8.48933289e-04\n",
      " 8.28119220e-04 8.18546170e-04 8.15102568e-04 8.08212287e-04\n",
      " 7.99599182e-04 7.68249256e-04 7.61137218e-04 7.55893982e-04\n",
      " 7.48146979e-04 7.40816173e-04 7.27943518e-04 7.15833339e-04\n",
      " 7.10598456e-04 7.03241478e-04 7.02368637e-04 6.90800849e-04\n",
      " 6.80590705e-04 6.72903526e-04 6.57635388e-04 6.49746893e-04\n",
      " 6.45237338e-04 6.42866221e-04 6.34058605e-04 6.28318514e-04\n",
      " 6.22107773e-04 6.11596017e-04 5.99638318e-04 5.93325326e-04\n",
      " 5.88482681e-04 5.82386306e-04 5.75183602e-04 5.67868522e-04\n",
      " 5.61815773e-04 5.56771509e-04 5.50629977e-04 5.46127168e-04\n",
      " 5.39479533e-04 5.37195523e-04 5.29377517e-04 5.25238151e-04\n",
      " 5.20466755e-04 5.15755587e-04 5.13007013e-04 5.04392696e-04\n",
      " 4.98673374e-04 4.92546028e-04 4.83500338e-04 4.79392882e-04\n",
      " 4.72728123e-04 4.71333851e-04 4.66654873e-04 4.62322457e-04\n",
      " 4.60794496e-04 4.53667525e-04 4.47987718e-04 4.46014835e-04\n",
      " 4.45595643e-04 4.39109901e-04 4.35613722e-04 4.30444701e-04\n",
      " 4.30182560e-04 4.20627425e-04 4.19086254e-04 4.15973052e-04\n",
      " 4.13851077e-04 4.09014594e-04 4.01637522e-04 3.98569924e-04\n",
      " 3.96372338e-04 3.93473482e-04 3.88920374e-04 3.84525332e-04\n",
      " 3.83094319e-04 3.79112770e-04 3.75933548e-04 3.71423436e-04\n",
      " 3.67388236e-04 3.64947576e-04 3.60667475e-04 3.58881386e-04\n",
      " 3.57143484e-04 3.54678925e-04 3.52840189e-04 3.50678196e-04\n",
      " 3.45737015e-04 3.42976363e-04 3.40594491e-04 3.34789935e-04\n",
      " 3.31510962e-04 3.29608367e-04 3.25898645e-04 3.23909262e-04\n",
      " 3.21648809e-04 3.18641949e-04 3.15748085e-04 3.13868565e-04\n",
      " 3.12520532e-04 3.09975086e-04 3.07609058e-04 3.04071113e-04\n",
      " 2.99649292e-04 2.98961082e-04 2.95848523e-04 2.91514056e-04\n",
      " 2.89553954e-04 2.88080054e-04 2.86978019e-04 2.85790889e-04\n",
      " 2.81522793e-04 2.78452084e-04 2.76677801e-04 2.74736627e-04\n",
      " 2.72291694e-04 2.69016637e-04 2.66375322e-04 2.61664237e-04\n",
      " 2.60022595e-04 2.59334939e-04 2.56349234e-04 2.55048180e-04\n",
      " 2.53753880e-04 2.52140646e-04 2.48606128e-04 2.48212766e-04\n",
      " 2.47165434e-04 2.43765948e-04 2.42008640e-04 2.39822610e-04\n",
      " 2.38660954e-04 2.37075933e-04 2.36069869e-04 2.33401973e-04\n",
      " 2.32448706e-04 2.30621891e-04 2.28526671e-04 2.27324662e-04\n",
      " 2.25867833e-04 2.21125506e-04 2.19034387e-04 2.17363586e-04\n",
      " 2.16665526e-04 2.14226354e-04 2.12317022e-04 2.11291800e-04\n",
      " 2.09242482e-04 2.05985678e-04 2.05502683e-04 2.03685221e-04\n",
      " 2.01540953e-04 1.98977326e-04 1.97528912e-04 1.95837786e-04\n",
      " 1.93676173e-04 1.92914316e-04 1.91101665e-04 1.90053800e-04\n",
      " 1.89083325e-04 1.87531056e-04 1.85586290e-04 1.84323592e-04\n",
      " 1.83101739e-04 1.81501393e-04 1.80049814e-04 1.78555419e-04\n",
      " 1.76193306e-04 1.74783780e-04 1.72962976e-04 1.71416931e-04\n",
      " 1.70843119e-04 1.69859987e-04 1.68036141e-04 1.66888484e-04\n",
      " 1.65510319e-04 1.64789790e-04 1.63810692e-04 1.62057490e-04\n",
      " 1.59725762e-04 1.59271556e-04 1.57199092e-04 1.57092324e-04\n",
      " 1.56423412e-04 1.54964866e-04 1.54653497e-04 1.51569707e-04\n",
      " 1.50612888e-04 1.49233637e-04 1.47224852e-04 1.45938754e-04\n",
      " 1.44476503e-04 1.42043097e-04 1.41778527e-04 1.40479041e-04\n",
      " 1.40076157e-04 1.38331291e-04 1.37310106e-04 1.36596605e-04\n",
      " 1.34435198e-04 1.33882054e-04 1.33266947e-04 1.32711446e-04\n",
      " 1.30067819e-04 1.29793247e-04 1.27911114e-04 1.27098903e-04\n",
      " 1.26034302e-04 1.24405094e-04 1.23727080e-04 1.22662004e-04\n",
      " 1.21400335e-04 1.20391442e-04 1.19596535e-04 1.17460936e-04\n",
      " 1.17011337e-04 1.15996951e-04 1.13873257e-04 1.12385022e-04\n",
      " 1.11649157e-04 1.10978517e-04 1.08692964e-04 1.08419628e-04\n",
      " 1.06770765e-04 1.05409422e-04 1.04993656e-04 1.04410776e-04\n",
      " 1.03344411e-04 1.01700495e-04 1.01232664e-04 9.93222924e-05\n",
      " 9.90268289e-05 9.68806751e-05 9.63340541e-05 9.41458889e-05\n",
      " 9.37702539e-05 9.28431307e-05 9.17365493e-05 9.03632636e-05\n",
      " 8.99159270e-05 8.91915104e-05 8.77297236e-05 8.73203334e-05\n",
      " 8.63909762e-05 8.57917241e-05 8.41827467e-05 8.36264947e-05\n",
      " 8.28049103e-05 8.13278290e-05 8.08000358e-05 7.98797408e-05\n",
      " 7.72193913e-05 7.65770246e-05 7.49783404e-05 7.43201482e-05\n",
      " 7.37504194e-05 7.25998629e-05 7.19328607e-05 6.97400670e-05\n",
      " 6.82447319e-05 6.63968082e-05 6.55760304e-05 6.41982107e-05\n",
      " 6.23893124e-05 6.19869856e-05 6.01781738e-05 5.75896415e-05]\n",
      "[7.86936421 6.99509194 5.84040638 5.17043313 4.70736434 4.12010561\n",
      " 3.92046902 3.58184222 3.38562617 3.20990875 3.05484477 2.89376746\n",
      " 2.72776413 2.63500115 2.40784189 2.38272088 2.28383072 2.24177349\n",
      " 2.19015129 2.09274226 2.05949339 1.97386783 1.88776707 1.81223564\n",
      " 1.79623714 1.73471071 1.70495788 1.65799492 1.62179901 1.61196069\n",
      " 1.56337042 1.51038434 1.47645823 1.45911288 1.44299923 1.4101735\n",
      " 1.40247494 1.3941517  1.3363501  1.3268127  1.30875759 1.25451476\n",
      " 1.24299221 1.23777658 1.2228971  1.20033454 1.19098311 1.18044858\n",
      " 1.14677795 1.11524865 1.11206362 1.09186501 1.08502982 1.06047469\n",
      " 1.05503877 1.03688758 1.0199738  0.99162484 0.97848513 0.96557603\n",
      " 0.95603965 0.94595281 0.92605853 0.89954275 0.89467055 0.88533693\n",
      " 0.86926124 0.85044695 0.8384215  0.83260533 0.83015079 0.82525538\n",
      " 0.8121612  0.81043929 0.80388153 0.79156851 0.781845   0.77515534\n",
      " 0.75873187 0.74820503 0.74284342 0.7398949  0.72894207 0.71221434\n",
      " 0.70811303 0.70043094 0.69841334 0.68203896 0.67505619 0.66529972\n",
      " 0.66079622 0.6543994  0.65382069 0.64482333 0.64239372 0.62294168\n",
      " 0.62143177 0.61524782 0.60791724 0.59985219 0.59777014 0.59369014\n",
      " 0.58935415 0.58192326 0.57158934 0.57033929 0.56316289 0.55316262\n",
      " 0.55002933 0.54544315 0.54396114 0.53660619 0.53400204 0.52998337\n",
      " 0.52914712 0.51922191 0.51446993 0.50914148 0.50170565 0.49809444\n",
      " 0.49388176 0.49338074 0.48513779 0.47582924 0.47436964 0.46889378\n",
      " 0.46648012 0.45572627 0.45307806 0.44967002 0.44376974 0.43963032\n",
      " 0.43741782 0.43420505 0.42576583 0.42086585 0.41765534 0.41235106\n",
      " 0.40908146 0.40527371 0.40368891 0.40009032 0.39984867 0.39526017\n",
      " 0.3934517  0.38591058 0.38162572 0.38026137 0.37814756 0.3719967\n",
      " 0.36830152 0.36420689 0.36283861 0.35872491 0.35332918 0.35093394\n",
      " 0.34884034 0.34589062 0.34504736 0.33781752 0.33733486 0.33526882\n",
      " 0.33125616 0.32942826 0.32257214 0.32003256 0.31857456 0.3171769\n",
      " 0.31435773 0.31260061 0.31123556 0.30639448 0.30605846 0.30230197\n",
      " 0.30132022 0.29699406 0.29334236 0.29037263 0.28586663 0.28464924\n",
      " 0.28337973 0.28186708 0.27986398 0.27624175 0.27435786 0.27191794\n",
      " 0.27047846 0.2673829  0.2668182  0.26437559 0.26204582 0.2604241\n",
      " 0.25980369 0.25526652 0.25423275 0.25170952 0.25000371 0.24857539\n",
      " 0.24564007 0.24480239 0.24284292 0.24157402 0.23982395 0.23865474\n",
      " 0.23680826 0.23513203 0.2329549  0.23160838 0.22972858 0.22849037\n",
      " 0.22705731 0.22565271 0.22381087 0.22228455 0.22134625 0.21984028\n",
      " 0.21890656 0.21599512 0.21310117 0.21210494 0.21032387 0.20933832\n",
      " 0.20790875 0.20752489 0.20711981 0.20501639 0.2017786  0.20135053\n",
      " 0.19884416 0.19811466 0.19731876 0.19531363 0.19502732 0.19417693\n",
      " 0.19200528 0.19087722 0.18956674 0.18808175 0.1864594  0.18561943\n",
      " 0.18462109 0.18369282 0.18245863 0.1809465  0.17986225 0.17873716\n",
      " 0.17826051 0.17601818 0.17519468 0.17389944 0.17268285 0.17204923\n",
      " 0.1705185  0.17035322 0.16799062 0.16767157 0.1651941  0.16458829\n",
      " 0.16406402 0.16255105 0.16171768 0.16099906 0.15973136 0.15914342\n",
      " 0.15788296 0.15682207 0.15640994 0.15531049 0.15429095 0.15392287\n",
      " 0.15382182 0.15216228 0.15079078 0.1496607  0.14833806 0.14703731\n",
      " 0.14673634 0.1464411  0.14510084 0.1445611  0.14401077 0.14318565\n",
      " 0.14259741 0.1412466  0.14077574 0.13929695 0.1391513  0.13886626\n",
      " 0.13773451 0.13718608 0.13670687 0.13531139 0.13459501 0.13358581\n",
      " 0.1329259  0.13247889 0.13148726 0.13037359 0.12939733 0.12906932\n",
      " 0.12803641 0.12781244 0.12734688 0.12637571 0.12539604 0.12444974\n",
      " 0.12356937 0.12336966 0.12215202 0.12191686 0.12185812 0.12100389\n",
      " 0.11992361 0.1198819  0.11814279 0.11769892 0.11754323 0.11670203\n",
      " 0.11557667 0.11537986 0.11481125 0.11435321 0.11379872 0.11329079\n",
      " 0.11292276 0.11183703 0.11136497 0.11051335 0.11020479 0.10968312\n",
      " 0.1094679  0.10918513 0.10879526 0.1074139  0.10679716 0.10608793\n",
      " 0.10552931 0.10493388 0.10432488 0.10396218 0.10362325 0.10291903\n",
      " 0.10211566 0.10159297 0.10096724 0.10033114 0.09999877 0.09947111\n",
      " 0.09854612 0.09816831 0.09781586 0.09758936 0.09678219 0.09653849\n",
      " 0.09618626 0.0956411  0.09503322 0.09471298 0.09399628 0.09376595\n",
      " 0.09320795 0.09265726 0.0918554  0.09170401 0.09153411 0.09095483\n",
      " 0.09074746 0.09017583 0.08956068 0.08914578 0.08825732 0.08798846\n",
      " 0.08773    0.08753031 0.08742589 0.08631073 0.08602497 0.0856922\n",
      " 0.08445405 0.08421137 0.08368853 0.08316061 0.08311589 0.08294522\n",
      " 0.08224486 0.08183348 0.08149224 0.08131093 0.08050441 0.08000095\n",
      " 0.07987703 0.07956373 0.07928599 0.07856671 0.07848907 0.07834418\n",
      " 0.07787776 0.07721713 0.07713372 0.0763171  0.07608346 0.07577196\n",
      " 0.07565857 0.07507008 0.07477652 0.07452862 0.07367068 0.07349339\n",
      " 0.07323414 0.07305283 0.07257179 0.07240986 0.07196754 0.07144852\n",
      " 0.07141092 0.07077713 0.07002546 0.06981726 0.06937958 0.06915675\n",
      " 0.06878817 0.06805772 0.06803807 0.06788527 0.06741788 0.06682936\n",
      " 0.06669614 0.06593501 0.06576899 0.0655396  0.0652566  0.06477217\n",
      " 0.06432869 0.06423541 0.06398709 0.06380557 0.0635485  0.06296067\n",
      " 0.06287626 0.06259684 0.06195802 0.06177724 0.06140479 0.06092277\n",
      " 0.06064729 0.06050255 0.06002106 0.05991814 0.05932563 0.05889463\n",
      " 0.05862232 0.05821189 0.05817599 0.05739493 0.05714036 0.05685437\n",
      " 0.0563359  0.05624329 0.05590714 0.05554639 0.05541598 0.05504224\n",
      " 0.0547623  0.05466114 0.0542561  0.05413551 0.05325724 0.05306581\n",
      " 0.05265455 0.05227791 0.05212794 0.05194227 0.05164458 0.05098195\n",
      " 0.05029954 0.04998414 0.04987977 0.04966841 0.0494703  0.04903516\n",
      " 0.04885162 0.04865536 0.04843307 0.04813076 0.04772657 0.04742306\n",
      " 0.04701575 0.04638935 0.04583361 0.04564234 0.04531726 0.04490986\n",
      " 0.04478699 0.04377218 0.04374415 0.04353576 0.04332519 0.04311155\n",
      " 0.04291038 0.04240191 0.04185647 0.04158621 0.04151022 0.04083501\n",
      " 0.0404456  0.04011675 0.03986833 0.0389632  0.03862998 0.03828167\n",
      " 0.03782874 0.03693441]\n"
     ]
    }
   ],
   "source": [
    "transform = lda.ComputeLdaTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in class_list_new:\n",
    "    class_list_new[i] = class_list_new[i].dot(transform.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normlize to sqrt(dim)\n",
    "for i in class_list_new:\n",
    "    scale = np.sqrt(PLDA_DIM) / np.linalg.norm(class_list_new[i], axis=1, keepdims=True)\n",
    "    class_list_new[i] = scale * class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "train_list = np.zeros((1276888, PLDA_DIM))\n",
    "label = []\n",
    "last_pos = 0\n",
    "for count, i in enumerate(class_list_new):\n",
    "    this_len = class_list_new[i].shape[0]\n",
    "    train_list[last_pos:last_pos+this_len] = class_list_new[i]\n",
    "    last_pos = last_pos+this_len\n",
    "    label = label + this_len * [i]\n",
    "    if (count+1) % 1000 == 0:\n",
    "        print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1276888, 512)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276888, 512)\n",
      "prepare done, maxNumberInOneClass= 1002\n",
      "Iterations-0: 0.0013375771781835597\n",
      "Iterations-1: 0.00020715537950710702\n",
      "Iterations-2: 8.002533716710512e-05\n",
      "Convergence:  2 8.002533716710512e-05\n"
     ]
    }
   ],
   "source": [
    "A, G = JointBayesian_Train(train_list, label, fold = component_dir, complete_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "score_out_path = component_dir+'/'+'JB_lda_512_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TEST_DATA_NAME, 'rb') as handle:\n",
    "    test_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in test_list:\n",
    "    test_list[i] = test_list[i].squeeze()\n",
    "    test_list[i] = test_list[i] - global_mean\n",
    "    test_list[i] = transform.dot(test_list[i])\n",
    "    test_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(test_list[i])) * test_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id10270-x6uYqmx31kE-00001.wav id10270-8jEAjG6SegY-00008.wav target\n",
      "\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "#                 continue\n",
    "            enroll_emb = test_list[line.split(' ')[0][:-4]].squeeze()\n",
    "            test_emb = test_list[line.split(' ')[1][:-4]].squeeze()\n",
    "\n",
    "            cosine = Verify(A, G, enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(line.split(' ')[0]+' '+line.split(' ')[1]+' '+str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 5000 == 0:\n",
    "                print(count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.020837751855779407, 0.26558854718982505, 0.5770943796394485)\n",
      "Starting point for CLLR is 10.179847\n",
      "(0.020837751855779407, 0.26558854718982505, 0.5770943796394485)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+'JB_lda_score'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.01993637327677622, 0.26134676564156306, 0.5799575821845175)\n",
      "Starting point for CLLR is 10.246580\n",
      "(0.01993637327677622, 0.26134676564156306, 0.5799575821845175)\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+'JB_lda_512_score'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "config = {'p_target': [0.01, 0.005], 'c_miss': 1, 'c_fa': 1}\n",
    "\n",
    "print(scoring(score_file, key_file, config))\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "print(scoring(score_file, key_file, config))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
