{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import traceback\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fft = librosa.get_fftlib()\n",
    "class VoxIterableDataset(object):\n",
    "    def __init__(self, data_dir_dict, data_len_dict, config):        \n",
    "        with open(data_dir_dict['spk2utt_train_dict'], 'rb') as handle:\n",
    "            self.spk2utt_train_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['music_dict'], 'rb') as handle:\n",
    "            self.music_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['noise_dict'], 'rb') as handle:\n",
    "            self.noise_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['babble_dict'], 'rb') as handle:\n",
    "            self.babble_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['rir_dict'], 'rb') as handle:\n",
    "            self.rir_dict = pickle.load(handle)\n",
    "            \n",
    "        with open(data_len_dict['spk2utt_train_len'], 'rb') as handle:\n",
    "            self.spk2utt_train_len = pickle.load(handle)\n",
    "        with open(data_len_dict['music_len'], 'rb') as handle:\n",
    "            self.music_len = pickle.load(handle)\n",
    "        with open(data_len_dict['noise_len'], 'rb') as handle:\n",
    "            self.noise_len = pickle.load(handle)\n",
    "        with open(data_len_dict['babble_len'], 'rb') as handle:\n",
    "            self.babble_len = pickle.load(handle)\n",
    "        \n",
    "        \n",
    "        self.random_spkrs_batchlist = None\n",
    "        self.ramdom_batch_len = None\n",
    "        self.random_noise_type = None\n",
    "        \n",
    "        \n",
    "        self.possible_babble_num = [3, 4, 5, 6, 7]\n",
    "        self.possible_babble_snr = [13, 15, 17, 20]\n",
    "        self.possible_noise_snr = [0, 5, 10, 15]\n",
    "        self.possible_music_snr = [5, 8, 10, 15]\n",
    "        \n",
    "        self.sr = config['sr']\n",
    "        self.repeats = config['repeats']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.extended_prefectch = config['extended_prefectch']\n",
    "        \n",
    "        self.mfcc_dim = 30\n",
    "        \n",
    "        # Auxiliary paras\n",
    "        self.multi_read_count = 0\n",
    "        self.preload_mem = False\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        assert len(self.ramdom_batch_len) == len(self.random_spkrs_batchlist)\n",
    "        try:\n",
    "            batch_frame_len = self.ramdom_batch_len.pop(0)\n",
    "            batch_spkrs = self.random_spkrs_batchlist.pop(0)\n",
    "            batch_noise_type = self.random_noise_type.pop(0)\n",
    "            batched_feats = np.zeros([self.batch_size, batch_frame_len, self.mfcc_dim])\n",
    "            batched_labels = np.zeros(self.batch_size)\n",
    "            \n",
    "            for batch_index, (spkr, noise_type) in enumerate(zip(batch_spkrs, batch_noise_type)):\n",
    "                \n",
    "                concat_wav, VAD_result = self._colleting_and_slicing(spkr, batch_frame_len,\\\n",
    "                hop_len=160, extended_prefectch=self.extended_prefectch)\n",
    "            \n",
    "                \n",
    "                if noise_type == 0:\n",
    "                    aug_wav = concat_wav\n",
    "                \n",
    "                elif noise_type == 1:\n",
    "                    aug_wav = self._add_rebverb(concat_wav)\n",
    "                   \n",
    "                elif noise_type == 2:\n",
    "                    aug_wav = self._add_noise(concat_wav)\n",
    "                    \n",
    "                elif noise_type == 3:\n",
    "                    aug_wav = self._add_music(concat_wav)\n",
    "                  \n",
    "                elif noise_type == 4:\n",
    "                    aug_wav = self._add_babble(concat_wav)\n",
    "             \n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                    \n",
    "            \n",
    "                single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "                dct_type=2, n_fft=512, hop_length=160, \\\n",
    "                win_length=None, window='hann', power=2.0, \\\n",
    "                center=True, pad_mode='reflect', n_mels=30, \\\n",
    "                fmin=20, fmax=7600)\n",
    "                # Note single_feats needs transpose\n",
    "                out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "                # Apply VAD\n",
    "                assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "                out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "                batched_feats[batch_index] = out_feats[:batch_frame_len]\n",
    "                batched_labels[batch_index] = spkr\n",
    "                \n",
    "            return batched_feats, batched_labels\n",
    "        \n",
    "        except IndexError:\n",
    "            raise StopIteration\n",
    "\n",
    "    def process_one_utt(self, utt_dir):\n",
    "        try:\n",
    "            concat_wav, _ = librosa.load(utt_dir, sr=self.sr)\n",
    "            \n",
    "            VAD_result = self._VAD_detection(concat_wav)\n",
    "            \n",
    "            aug_wav = concat_wav\n",
    "\n",
    "            single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "            dct_type=2, n_fft=512, hop_length=160, \\\n",
    "            win_length=None, window='hann', power=2.0, \\\n",
    "            center=True, pad_mode='reflect', n_mels=30, \\\n",
    "            fmin=20, fmax=7600)\n",
    "            # Note single_feats needs transpose\n",
    "            out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "            # Apply VAD\n",
    "            assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "            out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "            \n",
    "            batched_feats = out_feats[None, :, :]\n",
    "                \n",
    "            return batched_feats\n",
    "        \n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def process_one_utt_noVAD(self, utt_dir):\n",
    "        try:\n",
    "            concat_wav, _ = librosa.load(utt_dir, sr=self.sr)\n",
    "            \n",
    "            aug_wav = concat_wav\n",
    "\n",
    "            single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "            dct_type=2, n_fft=512, hop_length=160, \\\n",
    "            win_length=None, window='hann', power=2.0, \\\n",
    "            center=True, pad_mode='reflect', n_mels=30, \\\n",
    "            fmin=20, fmax=7600)\n",
    "            # Note single_feats needs transpose\n",
    "            out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "            \n",
    "            batched_feats = out_feats[None, :, :]\n",
    "                \n",
    "            return batched_feats\n",
    "        \n",
    "        except Exception:\n",
    "            traceback.print_exc()            \n",
    "    \n",
    "    def noise_data_preload(self):\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            _, _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            _, _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            _, _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "    \n",
    "    def noise_data_preload2mem(self):\n",
    "        print('preloading to memory')\n",
    "        \n",
    "        self.music_preload_dict = {}\n",
    "        self.noise_preload_dict = {}\n",
    "        self.babble_preload_dict = {}\n",
    "        self.preload_mem = True\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            self.music_preload_dict[i], _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            self.noise_preload_dict[i], _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            self.babble_preload_dict[i], _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)       \n",
    "        \n",
    "        \n",
    "    def get_random_list(self):\n",
    "        spkrs_list = self.repeats * list(self.spk2utt_train_dict.keys())\n",
    "        random.shuffle(spkrs_list)\n",
    "        len_spkrs_list = len(spkrs_list)\n",
    "        self.random_spkrs_batchlist = [spkrs_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        self.ramdom_batch_len = [random.randint(200, 400) for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        noise_type_list = [i%5 for i in range(len_spkrs_list)]\n",
    "\n",
    "        random.shuffle(noise_type_list)\n",
    "        self.random_noise_type = [noise_type_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        assert len(self.random_spkrs_batchlist) == len(self.ramdom_batch_len)\\\n",
    "        == len(self.random_noise_type)\n",
    "        \n",
    "    def _colleting_and_slicing(self, spkr, batch_frame_len, hop_len=160, extended_prefectch=2.0):\n",
    "        \n",
    "        least_wav_len = (batch_frame_len - 1) * hop_len\n",
    "        concat_utt = np.zeros(0)\n",
    "        valid_frames_len = 0\n",
    "        \n",
    "        # Use to count multi_read_count\n",
    "        get_count = 0\n",
    "\n",
    "        while valid_frames_len < batch_frame_len:\n",
    "            concat_utt = np.zeros(0)\n",
    "\n",
    "            utt_dir = self._get_random_spk_utt(spkr, self.spk2utt_train_dict)\n",
    "            utt_len = self.spk2utt_train_len[utt_dir]\n",
    "#             off = self._get_random_offset(least_wav_len, utt_len) / self.sr\n",
    "            off = self._get_random_offset(least_wav_len+extended_prefectch*self.sr, utt_len) / self.sr\n",
    "            dur = least_wav_len / self.sr + extended_prefectch\n",
    "            \n",
    "            utt_part, _ = librosa.load(utt_dir, sr=self.sr, offset=off, duration=dur)\n",
    "            \n",
    "            concat_utt = np.append(concat_utt, utt_part)\n",
    "            detected_frames = self._VAD_detection(concat_utt)\n",
    "            valid_frames_len = np.sum(detected_frames)\n",
    "\n",
    "            get_count += 1\n",
    "\n",
    "        if get_count > 1:\n",
    "            self.multi_read_count += 1\n",
    "\n",
    "        VAD_result = detected_frames\n",
    "        return concat_utt, VAD_result\n",
    "    \n",
    "    def _add_rebverb(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = in_wav\n",
    "        filter_dir = self._get_random_noise(self.rir_dict)\n",
    "        filter, _ = librosa.load(filter_dir, sr=self.sr)\n",
    "        \n",
    "        signal_length = len(signal)\n",
    "        filter_length = len(filter)\n",
    "        output_length = signal_length + filter_length - 1\n",
    "        output = np.zeros(output_length)\n",
    "\n",
    "        fft_length = 2**np.ceil(np.log2(4 * filter_length)).astype(np.int)\n",
    "        block_length = fft_length - filter_length + 1\n",
    "\n",
    "\n",
    "        filter_padded = np.zeros(fft_length)\n",
    "        filter_padded[0:filter_length] = filter\n",
    "        filter_padded = fft.rfft(filter_padded)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(signal_length//block_length + 1):\n",
    "            process_length = min(block_length, signal_length - i * block_length);\n",
    "            signal_block_padded = np.zeros(fft_length)\n",
    "            signal_block_padded[0:process_length] = signal[i * block_length : i * block_length + process_length]\n",
    "            signal_block_padded = fft.rfft(signal_block_padded)\n",
    "\n",
    "            signal_block_padded = filter_padded * signal_block_padded\n",
    "\n",
    "            signal_block_padded = fft.irfft(signal_block_padded, n=fft_length)\n",
    "\n",
    "            if (i*block_length + fft_length) <= output_length:\n",
    "                output[i*block_length : i*block_length + fft_length] += signal_block_padded\n",
    "            else:\n",
    "                output[i*block_length : output_length] += signal_block_padded[:output_length-i*block_length]\n",
    "        \n",
    "        # shift with max index of filter\n",
    "        shift_index = np.argmax(filter)\n",
    "        \n",
    "        final_out = output[shift_index:shift_index+signal_length]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_noise(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.noise_dict, return_index=True)\n",
    "            noise_len = self.noise_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "                \n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_noise_snr[random.randint(0, len(self.possible_noise_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_music(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.music_dict, return_index=True)\n",
    "            noise_len = self.music_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_music_snr[random.randint(0, len(self.possible_music_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_babble(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        signal_off = 0\n",
    "        bg_spks_num = self.possible_babble_num[random.randint(0, len(self.possible_babble_num)-1)]    \n",
    "        for _ in range(bg_spks_num):            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.babble_dict, return_index=True)\n",
    "            noise_len = self.babble_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_babble_snr[random.randint(0, len(self.possible_babble_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_db(self, in_wav, noise, signal_off, snr_db, power_before_reverb):\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "\n",
    "        noise_power = noise.dot(noise) / len(noise)\n",
    "        scale_factor = np.sqrt(10**(-snr_db / 10) * power_before_reverb / noise_power)\n",
    "        noise = scale_factor * noise\n",
    "\n",
    "        add_length = min(len(noise), len(signal)-signal_off)\n",
    "        signal[signal_off:signal_off+add_length] += noise[:add_length]\n",
    "        out_wav = signal      \n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _CMVN(self, in_feat, cmn_window = 300, normalize_variance = False):             \n",
    "        num_frames = in_feat.shape[0]\n",
    "        dim = in_feat.shape[1]\n",
    "        last_window_start = -1\n",
    "        last_window_end = -1\n",
    "        cur_sum = np.zeros(dim)\n",
    "        cur_sumsq = np.zeros(dim)\n",
    "\n",
    "        out_feat = np.zeros([num_frames, dim])\n",
    "\n",
    "        for t in range(num_frames):\n",
    "            window_start = 0\n",
    "            window_end = 0\n",
    "\n",
    "            window_start = t - int(cmn_window / 2)\n",
    "            window_end = window_start + cmn_window\n",
    "\n",
    "            if (window_start < 0):\n",
    "                window_end -= window_start\n",
    "                window_start = 0\n",
    "\n",
    "            if (window_end > num_frames):\n",
    "                window_start -= (window_end - num_frames)\n",
    "                window_end = num_frames\n",
    "                if (window_start < 0):\n",
    "                    window_start = 0\n",
    "\n",
    "            if (last_window_start == -1):\n",
    "                input_part = in_feat[window_start:window_end]\n",
    "                cur_sum = np.sum(input_part, axis=0, keepdims=False)\n",
    "                if normalize_variance:\n",
    "                    cur_sumsq = np.sum(input_part**2, axis=0, keepdims=False)\n",
    "            else:\n",
    "                if (window_start > last_window_start):\n",
    "                    frame_to_remove = in_feat[last_window_start]\n",
    "                    cur_sum -= frame_to_remove\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq -= frame_to_remove**2\n",
    "\n",
    "                if (window_end > last_window_end):\n",
    "                    frame_to_add = in_feat[last_window_end]\n",
    "                    cur_sum += frame_to_add\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq += frame_to_add**2\n",
    "\n",
    "            window_frames = window_end - window_start\n",
    "            last_window_start = window_start\n",
    "            last_window_end = window_end\n",
    "\n",
    "            out_feat[t] = in_feat[t] - (1.0 / window_frames) * cur_sum\n",
    "\n",
    "\n",
    "            if normalize_variance:\n",
    "                if (window_frames == 1):\n",
    "                    out_feat[t] = 0.0\n",
    "                else:\n",
    "                    variance = (1.0 / window_frames) * cur_sumsq - (1.0 / window_frames**2) * cur_sum**2\n",
    "                    variance = np.maximum(1.0e-10, variance)\n",
    "                    out_feat[t] /= variance**(0.5)\n",
    "                    \n",
    "        return out_feat\n",
    "\n",
    "    def _get_random_noise(self, noise_dict, return_index=False):\n",
    "        dict_len = len(noise_dict)\n",
    "        i = random.randint(0, dict_len-1)\n",
    "        noise_dir = noise_dict[i]\n",
    "        \n",
    "        if return_index:\n",
    "            return noise_dir, i\n",
    "        else:\n",
    "            return noise_dir\n",
    "    \n",
    "    def _get_random_spk_utt(self, spkr, spk2utt):\n",
    "        this_utts = spk2utt[spkr]\n",
    "        this_num_utts = len(this_utts)\n",
    "        i = random.randint(0, this_num_utts-1)\n",
    "        utt_dir = this_utts[i]\n",
    "        return utt_dir\n",
    "\n",
    "    def _get_random_offset(self, expected_length, utt_len):\n",
    "        if expected_length > utt_len:\n",
    "            return 0\n",
    "        \n",
    "        free_length = utt_len - expected_length\n",
    "        offset = random.randint(0, free_length)\n",
    "        return offset\n",
    "        \n",
    "    @property\n",
    "    def _VAD_config(self):\n",
    "        vad_energy_threshold = -3.0\n",
    "        vad_energy_mean_scale = 1.0\n",
    "        vad_frames_context = 0\n",
    "        vad_proportion_threshold = 0.12\n",
    "        \n",
    "        return vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold\n",
    "        \n",
    "        \n",
    "    def _VAD_detection(self, wav):\n",
    "        vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold = self._VAD_config\n",
    "        \n",
    "        y_tmp = np.pad(wav, int(512 // 2), mode='reflect')\n",
    "        y_tmp = librosa.util.frame(y_tmp, frame_length=512, hop_length=160)\n",
    "        y_log_energy = np.log(np.maximum(np.sum(y_tmp**2, axis=0), 1e-15))\n",
    "\n",
    "        T = len(y_log_energy)\n",
    "        output_voiced = np.zeros(T)\n",
    "        if (T == 0):\n",
    "            raise Exception(\"zero wave length\")\n",
    "\n",
    "        energy_threshold = vad_energy_threshold\n",
    "        if (vad_energy_mean_scale != 0.0):\n",
    "            assert(vad_energy_mean_scale > 0.0)\n",
    "            energy_threshold += vad_energy_mean_scale * np.sum(y_log_energy) / T\n",
    "\n",
    "\n",
    "        assert(vad_frames_context >= 0)\n",
    "        assert(vad_proportion_threshold > 0.0 and vad_proportion_threshold < 1.0);\n",
    "\n",
    "        for t in range(T):\n",
    "            num_count = 0\n",
    "            den_count = 0\n",
    "            context = vad_frames_context\n",
    "            for t2 in range(t - context, t + context+1):\n",
    "                if (t2 >= 0 and t2 < T):\n",
    "                    den_count+=1\n",
    "                    if (y_log_energy[t2] > energy_threshold):\n",
    "                        num_count+=1\n",
    "\n",
    "            if (num_count >= den_count * vad_proportion_threshold):\n",
    "                output_voiced[t] = 1.0\n",
    "            else:\n",
    "                output_voiced[t] = 0.0\n",
    "        \n",
    "        return output_voiced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "data_dir_dict = {}\n",
    "\n",
    "# val\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(OPT_INDEX, 'spk2utt_val_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(OPT_INDEX, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(OPT_INDEX, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(OPT_INDEX, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(OPT_INDEX, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(OPT_INDEX, 'spk2utt_val_len')\n",
    "data_len_dict['music_len'] = os.path.join(OPT_INDEX, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(OPT_INDEX, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(OPT_INDEX, 'babble_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/task2_train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = {}\n",
    "with open('/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/docs/train_labels.txt', 'r') as f:\n",
    "    for count, line in enumerate(f):\n",
    "        if count == 0:\n",
    "            continuee(line)\n",
    "            continue\n",
    "        line = line[:-1]\n",
    "        utt, label = line.split\n",
    "        train_labels[utt] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "1779.1428241729736\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = None\n",
    "config['batch_size'] = None\n",
    "config['extended_prefectch'] = None\n",
    "\n",
    "# trial_dict_dir = '/Lun0/zhiyong/dataset/trial_dict'\n",
    "\n",
    "def trial_data_preload(dataset, i, train_list, train_labels):\n",
    "        \n",
    "    for i, line in enumerate(train_list):\n",
    "        data = dataset.process_one_utt(line)\n",
    "        utt_label = line.split('/')[-1][:-4]\n",
    "        label = train_labels[utt_label]\n",
    "        with open('/Lun0/zhiyong/SdSV_2020_deepmine/train_mfcc/'+utt_label, 'wb') as handle:\n",
    "            pickle.dump((data.astype(np.float16), [label]), handle)\n",
    "        if ((i+1) % 1000) == 0:    \n",
    "            print(i+1)\n",
    "\n",
    "dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, train_list, train_labels)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process_enr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "data_dir_dict = {}\n",
    "\n",
    "# val\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(OPT_INDEX, 'spk2utt_val_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(OPT_INDEX, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(OPT_INDEX, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(OPT_INDEX, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(OPT_INDEX, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(OPT_INDEX, 'spk2utt_val_len')\n",
    "data_len_dict['music_len'] = os.path.join(OPT_INDEX, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(OPT_INDEX, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(OPT_INDEX, 'babble_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enr_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/wav/enrollment/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "1779.1428241729736\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = None\n",
    "config['batch_size'] = None\n",
    "config['extended_prefectch'] = None\n",
    "\n",
    "# trial_dict_dir = '/Lun0/zhiyong/dataset/trial_dict'\n",
    "\n",
    "def trial_data_preload(dataset, i, enr_list):\n",
    "        \n",
    "    for i, line in enumerate(enr_list):\n",
    "        data = dataset.process_one_utt(line)\n",
    "        label = line.split('/')[-1][:-4]\n",
    "        with open('/Lun0/zhiyong/SdSV_2020_deepmine/enr_mfcc/'+label, 'wb') as handle:\n",
    "            pickle.dump((data.astype(np.float16), [label]), handle)\n",
    "        if ((i+1) % 1000) == 0:    \n",
    "            print(i+1)\n",
    "\n",
    "dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, enr_list)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process_evl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "data_dir_dict = {}\n",
    "\n",
    "# val\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(OPT_INDEX, 'spk2utt_val_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(OPT_INDEX, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(OPT_INDEX, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(OPT_INDEX, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(OPT_INDEX, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(OPT_INDEX, 'spk2utt_val_len')\n",
    "data_len_dict['music_len'] = os.path.join(OPT_INDEX, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(OPT_INDEX, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(OPT_INDEX, 'babble_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evl_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/evaluation/wav/evaluation/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "502.18626618385315\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = None\n",
    "config['batch_size'] = None\n",
    "config['extended_prefectch'] = None\n",
    "\n",
    "# trial_dict_dir = '/Lun0/zhiyong/dataset/trial_dict'\n",
    "\n",
    "def trial_data_preload(dataset, i, evl_list):\n",
    "        \n",
    "    for i, line in enumerate(evl_list):\n",
    "        data = dataset.process_one_utt(line)\n",
    "        label = line.split('/')[-1][:-4]\n",
    "        with open('/Lun0/zhiyong/SdSV_2020_deepmine/evl_mfcc/'+label, 'wb') as handle:\n",
    "            pickle.dump((data.astype(np.float16), [label]), handle)\n",
    "        if ((i+1) % 1000) == 0:    \n",
    "            print(i+1)\n",
    "\n",
    "dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, evl_list)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = '/Lun0/zhiyong/SdSV_2020_deepmine/train_mfcc'\n",
    "expected_len = 85764\n",
    "workers = 1\n",
    "single_worker_len = int(expected_len / workers)\n",
    "output = '/Lun0/zhiyong/SdSV_2020_deepmine/train_mfcc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mfcc_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/train_mfcc/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert expected_len == len(train_mfcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(output, 'w') as f:\n",
    "    for i in train_mfcc_list:\n",
    "        path = i\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85764"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make enr index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = '/Lun0/zhiyong/SdSV_2020_deepmine/enr_mfcc'\n",
    "expected_len = 110673\n",
    "workers = 1\n",
    "single_worker_len = int(expected_len / workers)\n",
    "output = '/Lun0/zhiyong/SdSV_2020_deepmine/enr_mfcc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enr_mfcc_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/enr_mfcc/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert expected_len == len(enr_mfcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(output, 'w') as f:\n",
    "    for i in enr_mfcc_list:\n",
    "        path = i\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make evl index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = '/Lun0/zhiyong/SdSV_2020_deepmine/evl_mfcc'\n",
    "expected_len = 69542\n",
    "workers = 1\n",
    "single_worker_len = int(expected_len / workers)\n",
    "output = '/Lun0/zhiyong/SdSV_2020_deepmine/evl_mfcc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evl_mfcc_list = glob.glob('/Lun0/zhiyong/SdSV_2020_deepmine/evl_mfcc/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert expected_len == len(evl_mfcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(output, 'w') as f:\n",
    "    for i in evl_mfcc_list:\n",
    "        path = i\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./train')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# import vox_model_bank\n",
    "from train import train_model_new\n",
    "from train.read_data import *\n",
    "from train.my_dataloader import *\n",
    "# from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = '/Lun2/rzz/kaldi-master/egs/zhiyong/sre19/exp/Xvector_SAP_nodilate_1L_long_cosanel_newloader_newdata_2(test)/ckpt/min_eer.model'\n",
    "model_id = 'Xvector_SAP_nodilate_1L'\n",
    "model_metric = 'AM_normfree_softmax_anneal_ce_head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "component_dir = './sdsvc_inplda'\n",
    "PLDA_DIM = 370\n",
    "PLDA_DATA_NAME = 'plda_data'\n",
    "TEST_DATA_NAME = 'test_data_370'\n",
    "PLDA_PARA_NAME = 'plda_para_370'\n",
    "SCORING_PLDA_NAME = 'score_plda_370'\n",
    "SCORING_COSINE_NAME = 'score_cosine_370'\n",
    "ENR_DATA_NAME = 'enr_data'\n",
    "EVL_DATA_NAME = 'evl_data'\n",
    "TRAIN_DATA_NAME = 'train_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(component_dir):\n",
    "    os.makedirs(component_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU multiprocess for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_p = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/plda_full_data.csv'\n",
    "train_list = '/Lun0/zhiyong/SdSV_2020_deepmine/train_mfcc.csv'\n",
    "# train_data = CSVDataSet(train_list)\n",
    "train_data = PickleDataSet(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_len = len(train_data)\n",
    "num_per_process = (85764 // num_p) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "class_list_new_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8577\n",
      "8571\n"
     ]
    }
   ],
   "source": [
    "data_m = []\n",
    "# class_list_new_m = []\n",
    "for i in range(num_p):\n",
    "    data = torch.utils.data.Subset(train_data, np.arange(i*num_per_process, min((i+1)*num_per_process, train_data_len)))\n",
    "    data_m.append(data)\n",
    "    class_list_new_m.append({})\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_m(i, train_data, class_list_new_m):\n",
    "#     train_list = '/Lun0/zhiyong/dataset/vox12_kaldi_train_data/vox12_kaldi_train_data.csv'\n",
    "    model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if i < 26:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(i%2)\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     torch.cuda.set_device(i%2)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     train_data = CSVDataSet(train_list)\n",
    "#     train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=False)\n",
    "\n",
    "    train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "    batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "    pin_memory=False, drop_last=False, timeout=0,\\\n",
    "    worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "    model = train_model_new.get_model(model_id, model_metric, None, model_settings, None)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    class_list_new = {}\n",
    "\n",
    "    for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = batch_x.to(device)\n",
    "        label = batch_y[0].split('-')[0]\n",
    "        batch_y = torch.tensor([0]).to(device)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "        except:\n",
    "            print('Proc', str(i), 'EER:', label)\n",
    "            continue\n",
    "    #     _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "        emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "        if label not in class_list_new.keys():\n",
    "            class_list_new[label] = emb[None, :]\n",
    "        else:\n",
    "            class_list_new[label] = np.append(class_list_new[label], emb[None, :], axis=0)\n",
    "\n",
    "        if (count+1) % 10000 == 0:\n",
    "            print('Proc '+ str(i) + ':' + str((count+1) // 10000))\n",
    "    \n",
    "    class_list_new_m[i] = class_list_new\n",
    "    del model, batch_x, batch_y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n"
     ]
    }
   ],
   "source": [
    "processes = [Process(target = extract_feature_m, args = (i, data_m[i], class_list_new_m)) for i in range(num_p)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85764"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new_m:\n",
    "    for j in i:\n",
    "        count += len(i[j])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_list_new = class_list_new_m[0]\n",
    "\n",
    "for count, this_list in enumerate(class_list_new_m):\n",
    "    if count == 0:\n",
    "        continue\n",
    "    for this_label in this_list:\n",
    "        if this_label not in class_list_new.keys():\n",
    "            class_list_new[this_label] = this_list[this_label]\n",
    "        else:\n",
    "            class_list_new[this_label] = np.append(class_list_new[this_label], this_list[this_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85764"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nanlist = []\n",
    "for i in class_list_new:\n",
    "    if np.isnan(class_list_new[i]).any():\n",
    "        print(i)\n",
    "        nanlist.append(i)\n",
    "for i in nanlist:\n",
    "    class_list_new.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85764"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+TRAIN_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(class_list_new, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU multiprocess for enr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_p = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/plda_full_data.csv'\n",
    "train_list = '/Lun0/zhiyong/SdSV_2020_deepmine/enr_mfcc.csv'\n",
    "# train_data = CSVDataSet(train_list)\n",
    "train_data = PickleDataSet(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_len = len(train_data)\n",
    "num_per_process = (110673 // num_p) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "class_list_new_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11068\n",
      "11068\n",
      "11068\n",
      "11068\n",
      "11068\n",
      "11068\n",
      "11068\n",
      "11068\n",
      "11068\n",
      "11061\n"
     ]
    }
   ],
   "source": [
    "data_m = []\n",
    "# class_list_new_m = []\n",
    "for i in range(num_p):\n",
    "    data = torch.utils.data.Subset(train_data, np.arange(i*num_per_process, min((i+1)*num_per_process, train_data_len)))\n",
    "    data_m.append(data)\n",
    "    class_list_new_m.append({})\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_m(i, train_data, class_list_new_m):\n",
    "#     train_list = '/Lun0/zhiyong/dataset/vox12_kaldi_train_data/vox12_kaldi_train_data.csv'\n",
    "    model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if i < 26:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(i%2)\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     torch.cuda.set_device(i%2)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     train_data = CSVDataSet(train_list)\n",
    "#     train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=False)\n",
    "\n",
    "    train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "    batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "    pin_memory=False, drop_last=False, timeout=0,\\\n",
    "    worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "    model = train_model_new.get_model(model_id, model_metric, None, model_settings, None)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    class_list_new = {}\n",
    "\n",
    "    for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = batch_x.to(device)\n",
    "        label = batch_y[0].split('-')[0]\n",
    "        batch_y = torch.tensor([0]).to(device)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "        except:\n",
    "            print('Proc', str(i), 'EER:', label)\n",
    "            continue\n",
    "    #     _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "        emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "        if label not in class_list_new.keys():\n",
    "            class_list_new[label] = emb[None, :]\n",
    "        else:\n",
    "            class_list_new[label] = np.append(class_list_new[label], emb[None, :], axis=0)\n",
    "\n",
    "        if (count+1) % 10000 == 0:\n",
    "            print('Proc '+ str(i) + ':' + str((count+1) // 10000))\n",
    "    \n",
    "    class_list_new_m[i] = class_list_new\n",
    "    del model, batch_x, batch_y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Proc 8:1\n",
      "Proc 2:1\n",
      "Proc 6:1\n",
      "Proc 0:1\n",
      "Proc 4:1\n",
      "Proc 7:1\n",
      "Proc 1:1\n",
      "Proc 9:1\n",
      "Proc 3:1\n",
      "Proc 5:1\n"
     ]
    }
   ],
   "source": [
    "processes = [Process(target = extract_feature_m, args = (i, data_m[i], class_list_new_m)) for i in range(num_p)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new_m:\n",
    "    for j in i:\n",
    "        count += len(i[j])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_list_new = class_list_new_m[0]\n",
    "\n",
    "for count, this_list in enumerate(class_list_new_m):\n",
    "    if count == 0:\n",
    "        continue\n",
    "    for this_label in this_list:\n",
    "        if this_label not in class_list_new.keys():\n",
    "            class_list_new[this_label] = this_list[this_label]\n",
    "        else:\n",
    "            class_list_new[this_label] = np.append(class_list_new[this_label], this_list[this_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nanlist = []\n",
    "for i in class_list_new:\n",
    "    if np.isnan(class_list_new[i]).any():\n",
    "        print(i)\n",
    "        nanlist.append(i)\n",
    "for i in nanlist:\n",
    "    class_list_new.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110673"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+ENR_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(class_list_new, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU multiprocess for evl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_p = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_list = '/Lun0/zhiyong/dataset/plda_full_data.csv'\n",
    "train_list = '/Lun0/zhiyong/SdSV_2020_deepmine/evl_mfcc.csv'\n",
    "# train_data = CSVDataSet(train_list)\n",
    "train_data = PickleDataSet(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_len = len(train_data)\n",
    "num_per_process = (69542 // num_p) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "class_list_new_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6955\n",
      "6947\n"
     ]
    }
   ],
   "source": [
    "data_m = []\n",
    "# class_list_new_m = []\n",
    "for i in range(num_p):\n",
    "    data = torch.utils.data.Subset(train_data, np.arange(i*num_per_process, min((i+1)*num_per_process, train_data_len)))\n",
    "    data_m.append(data)\n",
    "    class_list_new_m.append({})\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_m(i, train_data, class_list_new_m):\n",
    "#     train_list = '/Lun0/zhiyong/dataset/vox12_kaldi_train_data/vox12_kaldi_train_data.csv'\n",
    "    model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if i < 26:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(i%2)\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     torch.cuda.set_device(i%2)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     train_data = CSVDataSet(train_list)\n",
    "#     train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=False)\n",
    "\n",
    "    train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "    batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "    pin_memory=False, drop_last=False, timeout=0,\\\n",
    "    worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "    model = train_model_new.get_model(model_id, model_metric, None, model_settings, None)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    class_list_new = {}\n",
    "\n",
    "    for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = batch_x.to(device)\n",
    "        label = batch_y[0].split('-')[0]\n",
    "        batch_y = torch.tensor([0]).to(device)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "        except:\n",
    "            print('Proc', str(i), 'EER:', label)\n",
    "            continue\n",
    "    #     _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "        emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "        if label not in class_list_new.keys():\n",
    "            class_list_new[label] = emb[None, :]\n",
    "        else:\n",
    "            class_list_new[label] = np.append(class_list_new[label], emb[None, :], axis=0)\n",
    "\n",
    "        if (count+1) % 10000 == 0:\n",
    "            print('Proc '+ str(i) + ':' + str((count+1) // 10000))\n",
    "    \n",
    "    class_list_new_m[i] = class_list_new\n",
    "    del model, batch_x, batch_y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n"
     ]
    }
   ],
   "source": [
    "processes = [Process(target = extract_feature_m, args = (i, data_m[i], class_list_new_m)) for i in range(num_p)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new_m:\n",
    "    for j in i:\n",
    "        count += len(i[j])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_list_new = class_list_new_m[0]\n",
    "\n",
    "for count, this_list in enumerate(class_list_new_m):\n",
    "    if count == 0:\n",
    "        continue\n",
    "    for this_label in this_list:\n",
    "        if this_label not in class_list_new.keys():\n",
    "            class_list_new[this_label] = this_list[this_label]\n",
    "        else:\n",
    "            class_list_new[this_label] = np.append(class_list_new[this_label], this_list[this_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nanlist = []\n",
    "for i in class_list_new:\n",
    "    if np.isnan(class_list_new[i]).any():\n",
    "        print(i)\n",
    "        nanlist.append(i)\n",
    "for i in nanlist:\n",
    "    class_list_new.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69542"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+EVL_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(class_list_new, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU multiprocess for plda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_p = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list = '/Lun0/zhiyong/dataset/plda_full_data.csv'\n",
    "# train_list = '/Lun0/zhiyong/dataset/plda_full_data_noVAD.csv'\n",
    "# train_data = CSVDataSet(train_list)\n",
    "train_data = PickleDataSet(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_len = len(train_data)\n",
    "num_per_process = (1276888 // num_p) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "class_list_new_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45604\n",
      "45580\n"
     ]
    }
   ],
   "source": [
    "data_m = []\n",
    "# class_list_new_m = []\n",
    "for i in range(num_p):\n",
    "    data = torch.utils.data.Subset(train_data, np.arange(i*num_per_process, min((i+1)*num_per_process, train_data_len)))\n",
    "    data_m.append(data)\n",
    "    class_list_new_m.append({})\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_m(i, train_data, class_list_new_m):\n",
    "#     train_list = '/Lun0/zhiyong/dataset/vox12_kaldi_train_data/vox12_kaldi_train_data.csv'\n",
    "    model_settings = {'in_feat': 30, 'emb_size': 512, 'class_num': 7323, 's': 50, 'm': 0.2, 'anneal_steps': 0, 'HistK_len': 0}\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if i < 26:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(i%2)\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#     torch.cuda.set_device(i%2)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     train_data = CSVDataSet(train_list)\n",
    "#     train_dataloader = DataLoader(dataset=train_data, batch_size = 1, shuffle = False, num_workers = 32, pin_memory=False)\n",
    "\n",
    "    train_dataloader = My_DataLoader(train_data, batch_size=None, shuffle=False, sampler=None,\\\n",
    "    batch_sampler=None, num_workers=8, collate_fn=None,\\\n",
    "    pin_memory=False, drop_last=False, timeout=0,\\\n",
    "    worker_init_fn=None, multiprocessing_context=None)\n",
    "\n",
    "    model = train_model_new.get_model(model_id, model_metric, None, model_settings, None)\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    class_list_new = {}\n",
    "\n",
    "    for count, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = batch_x.to(device)\n",
    "        label = batch_y[0].split('-')[0]\n",
    "        batch_y = torch.tensor([0]).to(device)\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "        except:\n",
    "            print('Proc', str(i), 'EER:', label)\n",
    "            continue\n",
    "    #     _, _, emb, _, _ = model(batch_x, batch_y, mod='eval')\n",
    "\n",
    "        emb = emb.squeeze().data.cpu().numpy()\n",
    "\n",
    "        if label not in class_list_new.keys():\n",
    "            class_list_new[label] = emb[None, :]\n",
    "        else:\n",
    "            class_list_new[label] = np.append(class_list_new[label], emb[None, :], axis=0)\n",
    "\n",
    "        if (count+1) % 10000 == 0:\n",
    "            print('Proc '+ str(i) + ':' + str((count+1) // 10000))\n",
    "    \n",
    "    class_list_new_m[i] = class_list_new\n",
    "    del model, batch_x, batch_y\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Using new training model bank\n",
      "Proc 27:1\n",
      "Proc 24:1\n",
      "Proc 26:1\n",
      "Proc 22:1\n",
      "Proc 20:1\n",
      "Proc 16:1\n",
      "Proc 10:1\n",
      "Proc 6:1\n",
      "Proc 8:1\n",
      "Proc 18:1\n",
      "Proc 4:1\n",
      "Proc 25:1\n",
      "Proc 2:1\n",
      "Proc 12:1\n",
      "Proc 14:1\n",
      "Proc 21:1\n",
      "Proc 19:1\n",
      "Proc 0:1\n",
      "Proc 11:1\n",
      "Proc 23:1\n",
      "Proc 9:1\n",
      "Proc 15:1\n",
      "Proc 5:1\n",
      "Proc 7:1\n",
      "Proc 13:1\n",
      "Proc 3:1\n",
      "Proc 17:1\n",
      "Proc 1:1\n",
      "Proc 24:2\n",
      "Proc 27:2\n",
      "Proc 26:2\n",
      "Proc 20:2\n",
      "Proc 22:2\n",
      "Proc 18:2\n",
      "Proc 16:2\n",
      "Proc 8:2\n",
      "Proc 14:2\n",
      "Proc 12:2\n",
      "Proc 25:2\n",
      "Proc 10:2\n",
      "Proc 4:2\n",
      "Proc 6:2\n",
      "Proc 2:2\n",
      "Proc 21:2\n",
      "Proc 0:2\n",
      "Proc 19:2\n",
      "Proc 9:2\n",
      "Proc 11:2\n",
      "Proc 23:2\n",
      "Proc 17:2\n",
      "Proc 15:2\n",
      "Proc 7:2\n",
      "Proc 13:2\n",
      "Proc 5:2\n",
      "Proc 3:2\n",
      "Proc 1:2\n",
      "Proc 24:3\n",
      "Proc 26:3\n",
      "Proc 27:3\n",
      "Proc 22:3\n",
      "Proc 18:3\n",
      "Proc 20:3\n",
      "Proc 16:3\n",
      "Proc 14:3\n",
      "Proc 8:3\n",
      "Proc 12:3\n",
      "Proc 10:3\n",
      "Proc 4:3\n",
      "Proc 25:3\n",
      "Proc 6:3\n",
      "Proc 2:3\n",
      "Proc 0:3\n",
      "Proc 19:3\n",
      "Proc 21:3\n",
      "Proc 9:3\n",
      "Proc 23:3\n",
      "Proc 11:3\n",
      "Proc 15:3\n",
      "Proc 17:3\n",
      "Proc 7:3\n",
      "Proc 13:3\n",
      "Proc 5:3\n",
      "Proc 3:3\n",
      "Proc 1:3\n",
      "Proc 26:4\n",
      "Proc 24:4\n",
      "Proc 27:4\n",
      "Proc 22:4\n",
      "Proc 20:4\n",
      "Proc 18:4\n",
      "Proc 16:4\n",
      "Proc 14:4\n",
      "Proc 12:4\n",
      "Proc 8:4\n",
      "Proc 10:4\n",
      "Proc 25:4\n",
      "Proc 6:4\n",
      "Proc 4:4\n",
      "Proc 2:4\n",
      "Proc 0:4\n",
      "Proc 19:4\n",
      "Proc 21:4\n",
      "Proc 23:4\n",
      "Proc 15:4\n",
      "Proc 9:4\n",
      "Proc 11:4\n",
      "Proc 7:4\n",
      "Proc 13:4\n",
      "Proc 5:4\n",
      "Proc 17:4\n",
      "Proc 3:4\n",
      "Proc 1:4\n"
     ]
    }
   ],
   "source": [
    "processes = [Process(target = extract_feature_m, args = (i, data_m[i], class_list_new_m)) for i in range(num_p)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new_m:\n",
    "    for j in i:\n",
    "        count += len(i[j])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_list_new = class_list_new_m[0]\n",
    "\n",
    "for count, this_list in enumerate(class_list_new_m):\n",
    "    if count == 0:\n",
    "        continue\n",
    "    for this_label in this_list:\n",
    "        if this_label not in class_list_new.keys():\n",
    "            class_list_new[this_label] = this_list[this_label]\n",
    "        else:\n",
    "            class_list_new[this_label] = np.append(class_list_new[this_label], this_list[this_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in class_list_new:\n",
    "    count += len(class_list_new[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nanlist = []\n",
    "for i in class_list_new:\n",
    "    if np.isnan(class_list_new[i]).any():\n",
    "        print(i)\n",
    "        nanlist.append(i)\n",
    "for i in nanlist:\n",
    "    class_list_new.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7323"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+PLDA_DATA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(class_list_new, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_list_new = {}\n",
    "# for i in class_list:\n",
    "#     class_list_new[i[:-1]] = class_list[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLDA_FIN_use_in_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./train')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# import vox_model_bank\n",
    "from train import train_model_new\n",
    "from train.read_data import *\n",
    "from train.my_dataloader import *\n",
    "# from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kaldi_plda import *\n",
    "from kaldi_lda import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Lun2/rzz/kaldi-master/egs/zhiyong/sre19/sdsvc'+'/'+TRAIN_DATA_NAME, 'rb') as handle:\n",
    "    class_list_new = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of mean: 12.031487330768723\n"
     ]
    }
   ],
   "source": [
    "# Substract global mean\n",
    "global_mean = np.zeros(512)\n",
    "num_utt = 0\n",
    "for count, i in enumerate(class_list_new):\n",
    "    num_utt += class_list_new[i].shape[0]\n",
    "    global_mean += class_list_new[i].shape[0] * np.mean(class_list_new[i], axis=0)\n",
    "    \n",
    "global_mean = (1.0 / num_utt) * global_mean\n",
    "print('Norm of mean:', np.linalg.norm(global_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in class_list_new:\n",
    "    class_list_new[i] = class_list_new[i] - global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # normlize to sqrt(dim)\n",
    "# for i in class_list_new:\n",
    "#     scale = np.sqrt(512) / np.linalg.norm(class_list_new[i], axis=1, keepdims=True)\n",
    "#     class_list_new[i] = scale * class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda norm of global mean: 2.8653313769658535e-07\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(lda_dim=PLDA_DIM, ivector_dim=512)\n",
    "for i in class_list_new:\n",
    "    lda.AccStats(class_list_new[i])\n",
    "print('lda norm of global mean:', lda.GetGlobalMean()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input data has norm of mean 2.8653313769658535e-07\n",
      "[1.00531658e+01 9.60899132e+00 8.14134214e+00 7.70498357e+00\n",
      " 7.33186561e+00 7.16010181e+00 7.05509187e+00 6.77176034e+00\n",
      " 6.56656810e+00 6.52020664e+00 6.42611119e+00 6.22055816e+00\n",
      " 6.13212612e+00 5.94108608e+00 5.72257750e+00 5.65134576e+00\n",
      " 5.52867619e+00 5.48125395e+00 5.29912012e+00 5.28386514e+00\n",
      " 5.23628651e+00 5.05314686e+00 4.94017966e+00 4.87810063e+00\n",
      " 4.78808739e+00 4.74433992e+00 4.64066359e+00 4.52685802e+00\n",
      " 4.41001558e+00 4.32139604e+00 4.24199060e+00 4.20187384e+00\n",
      " 4.10986064e+00 4.01978615e+00 3.96018313e+00 3.89928840e+00\n",
      " 3.85070341e+00 3.77504480e+00 3.69112948e+00 3.64613560e+00\n",
      " 3.61838559e+00 3.52519984e+00 3.44211620e+00 3.39075713e+00\n",
      " 3.30173681e+00 3.29761050e+00 3.22039029e+00 3.19961525e+00\n",
      " 3.13482911e+00 3.10368038e+00 3.08897828e+00 2.98942457e+00\n",
      " 2.97878852e+00 2.93035772e+00 2.84299462e+00 2.82927370e+00\n",
      " 2.76700888e+00 2.71857006e+00 2.69994862e+00 2.66784333e+00\n",
      " 2.63748252e+00 2.61215821e+00 2.58562721e+00 2.54359035e+00\n",
      " 2.50087889e+00 2.45256910e+00 2.42799299e+00 2.40588013e+00\n",
      " 2.38157901e+00 2.34310884e+00 2.29496374e+00 2.26512874e+00\n",
      " 2.22278754e+00 2.20486536e+00 2.13650045e+00 2.11355252e+00\n",
      " 2.09446408e+00 2.08693096e+00 2.05729428e+00 2.04268512e+00\n",
      " 2.02135565e+00 1.99279860e+00 1.94315037e+00 1.94022526e+00\n",
      " 1.85807934e+00 1.83629677e+00 1.81740333e+00 1.80140227e+00\n",
      " 1.77518373e+00 1.75526423e+00 1.73271155e+00 1.70496954e+00\n",
      " 1.68410606e+00 1.64163422e+00 1.61579334e+00 1.60620362e+00\n",
      " 1.59374757e+00 1.55501741e+00 1.52748467e+00 1.49284808e+00\n",
      " 1.47646953e+00 1.45027919e+00 1.44416315e+00 1.40327819e+00\n",
      " 1.38146288e+00 1.35013290e+00 1.32347716e+00 1.31450109e+00\n",
      " 1.30945847e+00 1.30131765e+00 1.25707952e+00 1.23606130e+00\n",
      " 1.20147593e+00 1.17869131e+00 1.15988612e+00 1.15064190e+00\n",
      " 1.13103640e+00 1.10963532e+00 1.08093997e+00 1.05532943e+00\n",
      " 1.04174888e+00 1.03139964e+00 1.01947699e+00 9.92295426e-01\n",
      " 9.70138034e-01 9.50482327e-01 9.43540678e-01 9.20857933e-01\n",
      " 9.13116089e-01 8.79608020e-01 8.58077772e-01 8.53989325e-01\n",
      " 8.11677253e-01 7.95057045e-01 7.70371955e-01 7.67419214e-01\n",
      " 7.40963224e-01 7.22294814e-01 7.14866840e-01 6.93600309e-01\n",
      " 6.77211039e-01 6.49384402e-01 6.14224989e-01 6.09581093e-01\n",
      " 6.02552240e-01 5.84878660e-01 5.72073401e-01 5.58656142e-01\n",
      " 5.42589129e-01 4.86804184e-01 4.82200023e-01 4.69715106e-01\n",
      " 4.37613056e-01 4.21162196e-01 4.14684302e-01 3.84847017e-01\n",
      " 3.67333239e-01 3.48776939e-01 3.32326436e-01 2.81674835e-01\n",
      " 2.61404002e-01 2.27331137e-01 2.19754573e-01 1.82106918e-01\n",
      " 1.39425964e-01 1.33708536e-01 1.16821676e-01 1.10036559e-01\n",
      " 7.60774777e-02 6.67581040e-02 4.66806030e-02 4.51270619e-02\n",
      " 3.57855662e-02 3.36903025e-02 2.73401372e-02 2.34116445e-02\n",
      " 2.02576951e-02 1.89845212e-02 1.70346583e-02 1.34502806e-02\n",
      " 1.11852036e-02 1.02410981e-02 9.38093726e-03 8.60817841e-03\n",
      " 6.98375115e-03 6.48083247e-03 6.12905615e-03 5.92273902e-03\n",
      " 5.65906858e-03 5.11871153e-03 4.92669431e-03 4.60499400e-03\n",
      " 4.39842950e-03 4.27587740e-03 3.96379413e-03 3.72724127e-03\n",
      " 3.50866230e-03 3.31656632e-03 3.18054777e-03 3.02980193e-03\n",
      " 2.81854112e-03 2.76712678e-03 2.65574774e-03 2.46676624e-03\n",
      " 2.45993106e-03 2.32481396e-03 2.28376463e-03 2.07682071e-03\n",
      " 1.98201351e-03 1.94503753e-03 1.87251852e-03 1.81383643e-03\n",
      " 1.72028161e-03 1.70160954e-03 1.63658634e-03 1.58720921e-03\n",
      " 1.54411666e-03 1.50568137e-03 1.47261445e-03 1.44231233e-03\n",
      " 1.39132749e-03 1.37005884e-03 1.33872992e-03 1.30124125e-03\n",
      " 1.24677812e-03 1.21559409e-03 1.19912596e-03 1.15729361e-03\n",
      " 1.12762958e-03 1.10140280e-03 1.09487470e-03 1.07623944e-03\n",
      " 1.06080369e-03 1.04037167e-03 1.02538028e-03 9.97786765e-04\n",
      " 9.73101931e-04 9.66076109e-04 9.56663994e-04 9.41533070e-04\n",
      " 9.26325367e-04 9.02671355e-04 8.89978490e-04 8.71885739e-04\n",
      " 8.42635561e-04 8.30664294e-04 8.27422462e-04 8.07723273e-04\n",
      " 8.00643152e-04 7.87617085e-04 7.79970910e-04 7.55639759e-04\n",
      " 7.43486723e-04 7.40663883e-04 7.27938518e-04 7.23537065e-04\n",
      " 7.17426617e-04 7.00946002e-04 6.86460532e-04 6.76918730e-04\n",
      " 6.71867544e-04 6.57846681e-04 6.50819489e-04 6.43592933e-04\n",
      " 6.41860990e-04 6.24977488e-04 6.04421280e-04 6.00269206e-04\n",
      " 5.92558039e-04 5.88942909e-04 5.85558688e-04 5.80466124e-04\n",
      " 5.70902982e-04 5.67111068e-04 5.60142586e-04 5.52339931e-04\n",
      " 5.41277343e-04 5.37844655e-04 5.34981297e-04 5.29092153e-04\n",
      " 5.21909219e-04 5.12396687e-04 5.10152487e-04 5.04050133e-04\n",
      " 4.98540862e-04 4.94895320e-04 4.85744194e-04 4.82903174e-04\n",
      " 4.80097055e-04 4.77397653e-04 4.68301826e-04 4.65397027e-04\n",
      " 4.62078610e-04 4.52557444e-04 4.49113190e-04 4.46078664e-04\n",
      " 4.37540062e-04 4.30547103e-04 4.26996190e-04 4.23993610e-04\n",
      " 4.18591693e-04 4.14140190e-04 4.08856727e-04 4.07490331e-04\n",
      " 4.04379405e-04 3.97233017e-04 3.95686837e-04 3.91585769e-04\n",
      " 3.87410672e-04 3.82845747e-04 3.80822302e-04 3.78414769e-04\n",
      " 3.76157906e-04 3.74043434e-04 3.68746067e-04 3.68452471e-04\n",
      " 3.64285251e-04 3.58228162e-04 3.56215070e-04 3.52866847e-04\n",
      " 3.51016794e-04 3.47691537e-04 3.41740941e-04 3.37375872e-04\n",
      " 3.36411669e-04 3.32195010e-04 3.29043242e-04 3.24819473e-04\n",
      " 3.23570468e-04 3.19276942e-04 3.17156297e-04 3.14706710e-04\n",
      " 3.13140247e-04 3.10874245e-04 3.08443892e-04 3.04778162e-04\n",
      " 3.04306862e-04 3.01114477e-04 2.98213556e-04 2.95176067e-04\n",
      " 2.94803267e-04 2.92423243e-04 2.90551860e-04 2.86723747e-04\n",
      " 2.84682709e-04 2.81050008e-04 2.78246839e-04 2.76762896e-04\n",
      " 2.72948236e-04 2.70501670e-04 2.69673047e-04 2.68303825e-04\n",
      " 2.67785057e-04 2.62927272e-04 2.59961875e-04 2.57568222e-04\n",
      " 2.56037239e-04 2.53827426e-04 2.52137725e-04 2.46756357e-04\n",
      " 2.45797758e-04 2.42336768e-04 2.40997374e-04 2.39955896e-04\n",
      " 2.37150089e-04 2.34203734e-04 2.32497725e-04 2.31228444e-04\n",
      " 2.29974652e-04 2.27957627e-04 2.23570784e-04 2.22972926e-04\n",
      " 2.18927259e-04 2.18468612e-04 2.15329801e-04 2.13241747e-04\n",
      " 2.12848892e-04 2.09499041e-04 2.09065452e-04 2.06788023e-04\n",
      " 2.06262748e-04 2.05466401e-04 2.04569486e-04 2.02316042e-04\n",
      " 2.01639038e-04 1.98460985e-04 1.98002210e-04 1.95616361e-04\n",
      " 1.93361867e-04 1.91362473e-04 1.90604066e-04 1.89884015e-04\n",
      " 1.88549667e-04 1.87032184e-04 1.86017000e-04 1.84680754e-04\n",
      " 1.82621091e-04 1.81160830e-04 1.79736635e-04 1.78979551e-04\n",
      " 1.76556051e-04 1.75414408e-04 1.74590435e-04 1.71523594e-04\n",
      " 1.69814791e-04 1.68748939e-04 1.67714572e-04 1.66302034e-04\n",
      " 1.63466959e-04 1.63095209e-04 1.61810147e-04 1.60686716e-04\n",
      " 1.58815660e-04 1.58338288e-04 1.57770448e-04 1.56464062e-04\n",
      " 1.54454081e-04 1.53235581e-04 1.53115096e-04 1.50458902e-04\n",
      " 1.49080939e-04 1.47511179e-04 1.46694772e-04 1.45101776e-04\n",
      " 1.44680460e-04 1.43403475e-04 1.41753530e-04 1.40061353e-04\n",
      " 1.38977251e-04 1.38336652e-04 1.36375624e-04 1.35656839e-04\n",
      " 1.34988728e-04 1.34284043e-04 1.32407893e-04 1.31937494e-04\n",
      " 1.30606841e-04 1.30146520e-04 1.28349576e-04 1.27353168e-04\n",
      " 1.25990121e-04 1.24396843e-04 1.23203868e-04 1.21227278e-04\n",
      " 1.20224202e-04 1.19860219e-04 1.18377845e-04 1.17516984e-04\n",
      " 1.16623538e-04 1.15489810e-04 1.14455167e-04 1.14188196e-04\n",
      " 1.12455231e-04 1.12078248e-04 1.10682457e-04 1.09665756e-04\n",
      " 1.09128158e-04 1.08325901e-04 1.06902549e-04 1.05532073e-04\n",
      " 1.05112070e-04 1.03778163e-04 1.02178751e-04 1.00886740e-04\n",
      " 1.00669278e-04 9.98157201e-05 9.84137101e-05 9.83261573e-05\n",
      " 9.67136270e-05 9.55611764e-05 9.50304051e-05 9.40123626e-05\n",
      " 9.38882690e-05 9.27254996e-05 9.24429988e-05 9.22135180e-05\n",
      " 8.99900421e-05 8.87560435e-05 8.80997505e-05 8.75649703e-05\n",
      " 8.61460352e-05 8.54024931e-05 8.42046937e-05 8.40413323e-05\n",
      " 8.33940722e-05 8.21751339e-05 8.12262106e-05 7.94811976e-05\n",
      " 7.85424305e-05 7.80594852e-05 7.70059186e-05 7.67084224e-05\n",
      " 7.45982008e-05 7.37591904e-05 7.33608010e-05 7.22418407e-05\n",
      " 7.13217005e-05 7.06564977e-05 6.97934178e-05 6.86269929e-05\n",
      " 6.76478968e-05 6.72083600e-05 6.64928213e-05 6.52767643e-05\n",
      " 6.45602363e-05 6.35915059e-05 6.13954372e-05 6.09048353e-05\n",
      " 5.83279456e-05 5.74172602e-05 5.66288953e-05 5.45501554e-05]\n",
      "[2.67654483e+01 6.96352866e+00 5.71810639e+00 5.36734559e+00\n",
      " 4.82384912e+00 4.12078074e+00 3.99933571e+00 3.89711328e+00\n",
      " 3.61144117e+00 3.40296918e+00 3.26200768e+00 3.10363726e+00\n",
      " 2.86698552e+00 2.77842887e+00 2.70770877e+00 2.66430719e+00\n",
      " 2.51951532e+00 2.47142325e+00 2.41624337e+00 2.33622820e+00\n",
      " 2.29948151e+00 2.22348132e+00 2.21122416e+00 2.17024795e+00\n",
      " 2.07256856e+00 2.01562723e+00 1.98115789e+00 1.97827264e+00\n",
      " 1.91879205e+00 1.86222573e+00 1.86162167e+00 1.83134565e+00\n",
      " 1.81732161e+00 1.77942815e+00 1.72087634e+00 1.67809040e+00\n",
      " 1.64826761e+00 1.59854459e+00 1.59125482e+00 1.56569441e+00\n",
      " 1.53509498e+00 1.49698024e+00 1.48357525e+00 1.45698695e+00\n",
      " 1.44373955e+00 1.42908448e+00 1.37042419e+00 1.32753360e+00\n",
      " 1.32568105e+00 1.31374359e+00 1.30788947e+00 1.28255215e+00\n",
      " 1.26724657e+00 1.22059291e+00 1.21420167e+00 1.20130039e+00\n",
      " 1.19713077e+00 1.17397279e+00 1.15924213e+00 1.15289829e+00\n",
      " 1.12262109e+00 1.10463117e+00 1.08240372e+00 1.07803489e+00\n",
      " 1.06180644e+00 1.05087497e+00 1.02153519e+00 1.01005940e+00\n",
      " 9.86378297e-01 9.76595040e-01 9.67033110e-01 9.60726295e-01\n",
      " 9.43922023e-01 9.31908587e-01 9.20153408e-01 9.12836276e-01\n",
      " 8.89465416e-01 8.73832368e-01 8.65106617e-01 8.61594436e-01\n",
      " 8.48964365e-01 8.32732128e-01 8.27018892e-01 8.13177425e-01\n",
      " 8.04535116e-01 7.92471129e-01 7.89263632e-01 7.75571567e-01\n",
      " 7.69987279e-01 7.65714537e-01 7.50911509e-01 7.48369236e-01\n",
      " 7.41116624e-01 7.31554899e-01 7.27523513e-01 7.12697896e-01\n",
      " 7.01010569e-01 6.86193552e-01 6.80095298e-01 6.75201192e-01\n",
      " 6.61995889e-01 6.59108774e-01 6.45155273e-01 6.39800453e-01\n",
      " 6.30643162e-01 6.24536437e-01 6.11110269e-01 6.05362414e-01\n",
      " 5.98405422e-01 5.88937885e-01 5.83559540e-01 5.77404950e-01\n",
      " 5.73063615e-01 5.69687358e-01 5.66363460e-01 5.58859680e-01\n",
      " 5.47567451e-01 5.41079174e-01 5.30154180e-01 5.23266001e-01\n",
      " 5.19150047e-01 5.14975426e-01 5.09146120e-01 5.06510548e-01\n",
      " 4.97093749e-01 4.93672694e-01 4.83391240e-01 4.79821266e-01\n",
      " 4.75415132e-01 4.66101511e-01 4.64923046e-01 4.57607122e-01\n",
      " 4.54592406e-01 4.49193858e-01 4.46582160e-01 4.41999468e-01\n",
      " 4.34225669e-01 4.28822992e-01 4.26451679e-01 4.21433309e-01\n",
      " 4.15577423e-01 4.15200235e-01 4.13318913e-01 4.09546471e-01\n",
      " 4.07796030e-01 4.04678015e-01 3.95883860e-01 3.87392866e-01\n",
      " 3.80298701e-01 3.75767001e-01 3.74797875e-01 3.73680465e-01\n",
      " 3.69701047e-01 3.66518824e-01 3.59296778e-01 3.54427076e-01\n",
      " 3.52896655e-01 3.47477764e-01 3.44449314e-01 3.39831415e-01\n",
      " 3.37410596e-01 3.35505470e-01 3.31531514e-01 3.27898517e-01\n",
      " 3.23567226e-01 3.20166174e-01 3.14433001e-01 3.12313314e-01\n",
      " 3.10753990e-01 3.08381495e-01 3.03412214e-01 3.02344404e-01\n",
      " 3.00054371e-01 2.96195294e-01 2.92319993e-01 2.91123337e-01\n",
      " 2.86920817e-01 2.81136957e-01 2.79898973e-01 2.76417765e-01\n",
      " 2.73903004e-01 2.72276548e-01 2.69890259e-01 2.67946530e-01\n",
      " 2.66375263e-01 2.62096849e-01 2.59711054e-01 2.57554419e-01\n",
      " 2.55029768e-01 2.51695726e-01 2.51162278e-01 2.49626993e-01\n",
      " 2.48204239e-01 2.39460675e-01 2.38139448e-01 2.36084628e-01\n",
      " 2.32778251e-01 2.31388426e-01 2.28877187e-01 2.25919998e-01\n",
      " 2.24356914e-01 2.21985983e-01 2.19863869e-01 2.18010522e-01\n",
      " 2.15947781e-01 2.13864687e-01 2.10561089e-01 2.10247072e-01\n",
      " 2.08159857e-01 2.06925139e-01 2.04224476e-01 2.01953723e-01\n",
      " 2.00590223e-01 1.96837829e-01 1.95934438e-01 1.95812016e-01\n",
      " 1.92861321e-01 1.90431760e-01 1.89133416e-01 1.86053557e-01\n",
      " 1.85475308e-01 1.81894378e-01 1.80950961e-01 1.79705524e-01\n",
      " 1.76626449e-01 1.74443971e-01 1.71545757e-01 1.71050496e-01\n",
      " 1.70238834e-01 1.67270750e-01 1.65060687e-01 1.64832168e-01\n",
      " 1.63996422e-01 1.63040813e-01 1.58230353e-01 1.55603928e-01\n",
      " 1.55495735e-01 1.55073222e-01 1.53308494e-01 1.53031655e-01\n",
      " 1.50119768e-01 1.49458823e-01 1.47275590e-01 1.45271370e-01\n",
      " 1.43509467e-01 1.42205797e-01 1.40349349e-01 1.38225833e-01\n",
      " 1.37442476e-01 1.36741341e-01 1.35113860e-01 1.33388657e-01\n",
      " 1.32572987e-01 1.31846962e-01 1.30299127e-01 1.28236949e-01\n",
      " 1.26726128e-01 1.25808759e-01 1.24490047e-01 1.23435612e-01\n",
      " 1.21588348e-01 1.19930872e-01 1.19414768e-01 1.17765255e-01\n",
      " 1.17369096e-01 1.15936025e-01 1.15410357e-01 1.14679265e-01\n",
      " 1.14229068e-01 1.10998887e-01 1.10154568e-01 1.09853795e-01\n",
      " 1.06651006e-01 1.05914591e-01 1.03737118e-01 1.03359395e-01\n",
      " 1.02147240e-01 1.00671898e-01 9.98247026e-02 9.87712023e-02\n",
      " 9.80344410e-02 9.60881286e-02 9.58487945e-02 9.47738550e-02\n",
      " 9.41394221e-02 9.31678631e-02 9.24741899e-02 9.17521271e-02\n",
      " 9.02437073e-02 8.96030346e-02 8.83393234e-02 8.79446228e-02\n",
      " 8.69168815e-02 8.55419350e-02 8.40302598e-02 8.39364222e-02\n",
      " 8.33452228e-02 8.29460603e-02 8.03602470e-02 7.98622352e-02\n",
      " 7.93243195e-02 7.91407218e-02 7.85118270e-02 7.77173571e-02\n",
      " 7.66099273e-02 7.63007139e-02 7.55332235e-02 7.48916643e-02\n",
      " 7.35715805e-02 7.29973580e-02 7.22307043e-02 7.21101367e-02\n",
      " 7.11971608e-02 7.08217246e-02 7.04026754e-02 6.92831842e-02\n",
      " 6.75429361e-02 6.70027503e-02 6.67322934e-02 6.52943807e-02\n",
      " 6.40673571e-02 6.36733112e-02 6.32645370e-02 6.22947499e-02\n",
      " 6.16982546e-02 6.13149810e-02 6.05114900e-02 6.01147017e-02\n",
      " 5.99408458e-02 5.90083701e-02 5.81730171e-02 5.72033215e-02\n",
      " 5.66328771e-02 5.54302436e-02 5.52943419e-02 5.44742163e-02\n",
      " 5.36356823e-02 5.32634427e-02 5.29239265e-02 5.18554782e-02\n",
      " 5.12387786e-02 5.08753665e-02 4.96531602e-02 4.90349939e-02\n",
      " 4.87852039e-02 4.80441677e-02 4.76959924e-02 4.70680222e-02\n",
      " 4.61675468e-02 4.57929044e-02 4.49016259e-02 4.40521677e-02\n",
      " 4.39311567e-02 4.35842645e-02 4.33506183e-02 4.26812813e-02\n",
      " 4.17459178e-02 4.15959796e-02 4.09784407e-02 4.04339244e-02\n",
      " 3.98290725e-02 3.93735118e-02 3.91315965e-02 3.88347075e-02\n",
      " 3.82282205e-02 3.76778832e-02 3.74678153e-02 3.68449363e-02\n",
      " 3.60423783e-02 3.57863695e-02 3.48654399e-02 3.44042736e-02\n",
      " 3.41965057e-02 3.40363127e-02 3.34563557e-02 3.30306936e-02\n",
      " 3.28095334e-02 3.16174586e-02 3.14972418e-02 3.12237158e-02\n",
      " 3.08540633e-02 3.04051966e-02 2.99412188e-02 2.93166639e-02\n",
      " 2.90377892e-02 2.89399611e-02 2.82710448e-02 2.78149967e-02\n",
      " 2.73520860e-02 2.67470729e-02 2.65327582e-02 2.63055326e-02\n",
      " 2.57679286e-02 2.53050476e-02 2.52078985e-02 2.50293666e-02\n",
      " 2.44384629e-02 2.42427173e-02 2.38166769e-02 2.34000180e-02\n",
      " 2.30474221e-02 2.28952385e-02 2.26726992e-02 2.22292808e-02\n",
      " 2.13926710e-02 2.09990424e-02 2.07580006e-02 2.03451210e-02\n",
      " 1.99590287e-02 1.98729518e-02 1.93264643e-02 1.92298088e-02\n",
      " 1.89979871e-02 1.86469894e-02 1.84417367e-02 1.79787554e-02\n",
      " 1.78677141e-02 1.75514948e-02 1.72623051e-02 1.68293081e-02\n",
      " 1.65585072e-02 1.59703125e-02 1.58820665e-02 1.57565308e-02\n",
      " 1.55870772e-02 1.52938720e-02 1.49973531e-02 1.46509478e-02\n",
      " 1.44753796e-02 1.40267244e-02 1.39203239e-02 1.38224406e-02\n",
      " 1.32919175e-02 1.31160731e-02 1.27174805e-02 1.25289581e-02\n",
      " 1.23403231e-02 1.21082048e-02 1.19878308e-02 1.17003405e-02\n",
      " 1.15497516e-02 1.08705761e-02 1.05743130e-02 1.05630992e-02\n",
      " 1.03981737e-02 1.00727983e-02 9.97714722e-03 9.77630835e-03\n",
      " 9.60870943e-03 9.33517989e-03 9.22513292e-03 9.07563182e-03\n",
      " 8.78784139e-03 8.48653111e-03 8.34533367e-03 8.18151579e-03\n",
      " 7.97585872e-03 7.86818774e-03 7.83519642e-03 7.71767711e-03\n",
      " 7.45495113e-03 7.20993133e-03 7.03188520e-03 6.73097899e-03\n",
      " 6.50545368e-03 6.42083940e-03 6.29934976e-03 6.10930036e-03\n",
      " 6.01427271e-03 5.93790604e-03 5.75552469e-03 5.37049242e-03\n",
      " 5.25957771e-03 5.15697405e-03 4.96878169e-03 4.77967515e-03\n",
      " 4.70344524e-03 4.62100322e-03 4.50443866e-03 4.34596624e-03\n",
      " 4.18373628e-03 4.02659408e-03 3.89250618e-03 3.80526485e-03\n",
      " 3.61639278e-03 3.57152538e-03 3.44737527e-03 3.35877074e-03\n",
      " 3.23492068e-03 2.95489711e-03 2.85734555e-03 2.70940238e-03\n",
      " 2.59334962e-03 2.57515605e-03 2.42214881e-03 2.30001067e-03\n",
      " 2.25005672e-03 2.10666503e-03 2.05728325e-03 1.84226759e-03\n",
      " 1.78283905e-03 1.64828872e-03 1.58118506e-03 1.42599988e-03\n",
      " 1.26384293e-03 1.21783224e-03 1.19400850e-03 1.07748852e-03\n",
      " 1.03616576e-03 9.78688939e-04 8.07198497e-04 6.75788844e-04]\n"
     ]
    }
   ],
   "source": [
    "transform = lda.ComputeLdaTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # normlize to sqrt(dim)\n",
    "# for i in class_list_new:\n",
    "#     scale = np.sqrt(512) / np.linalg.norm(class_list_new[i], axis=1, keepdims=True)\n",
    "#     class_list_new[i] = scale * class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in class_list_new:\n",
    "    class_list_new[i] = class_list_new[i].dot(transform.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normlize to sqrt(dim)\n",
    "for i in class_list_new:\n",
    "    scale = np.sqrt(PLDA_DIM) / np.linalg.norm(class_list_new[i], axis=1, keepdims=True)\n",
    "    class_list_new[i] = scale * class_list_new[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plda_stats = PldaStats(PLDA_DIM)\n",
    "for i in class_list_new:\n",
    "    plda_stats.add_samples(class_list_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plda_stats.sort()\n",
    "plda_stats.is_sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "nllr_x: 415.9723976703759\n",
      "nllr_y: -375.0606103559314\n",
      "normalized_nllr: 40.91178731444452\n",
      "nllr_m: 416.633875646446\n",
      "nllr_m_2: 416.6338756464473\n",
      "part1_residual -451.60054050755394\n",
      "part2_mean -416.633875646446\n",
      "normlized_obj -451.3608082313269\n",
      "2 5\n",
      "nllr_x: 207.30559619722723\n",
      "nllr_y: -469.9342870046941\n",
      "normalized_nllr: -262.62869080746685\n",
      "nllr_m: 213.68699151699732\n",
      "nllr_m_2: 213.6869915169976\n",
      "part1_residual -430.3645418857068\n",
      "part2_mean -213.6869915169973\n",
      "normlized_obj -428.878995507077\n",
      "3 5\n",
      "nllr_x: 202.99232929235615\n",
      "nllr_y: -469.82649885969016\n",
      "normalized_nllr: -266.8341695673341\n",
      "nllr_m: 211.78839948672058\n",
      "nllr_m_2: 211.78839948672032\n",
      "part1_residual -430.36461346146484\n",
      "part2_mean -211.7883994867204\n",
      "normlized_obj -428.86604980052147\n",
      "4 5\n",
      "nllr_x: 202.27490758474815\n",
      "nllr_y: -469.5368121834577\n",
      "normalized_nllr: -267.26190459870946\n",
      "nllr_m: 211.69105715276243\n",
      "nllr_m_2: 211.69105715276254\n",
      "part1_residual -430.3646114579601\n",
      "part2_mean -211.6910571527623\n",
      "normlized_obj -428.86538042942306\n",
      "5 5\n",
      "nllr_x: 202.0911427059306\n",
      "nllr_y: -469.4489707032933\n",
      "normalized_nllr: -267.3578279973627\n",
      "nllr_m: 211.68244423388606\n",
      "nllr_m_2: 211.68244423388612\n",
      "part1_residual -430.3646064795268\n",
      "part2_mean -211.68244423388606\n",
      "normlized_obj -428.8653164347477\n"
     ]
    }
   ],
   "source": [
    "# test_fin_prior\n",
    "plda_estimator = PldaEstimation(plda_stats)\n",
    "plda_paras = plda_estimator.estimate(iteration=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/'+ PLDA_PARA_NAME\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(plda_paras, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PLDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+ PLDA_PARA_NAME, 'rb') as handle:\n",
    "    plda_paras = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plda = PLDA(plda_paras[0], plda_paras[1], plda_paras[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(component_dir+'/'+TRAIN_DATA_NAME, 'rb') as handle:\n",
    "    train_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_list = np.zeros([0, 512])\n",
    "for i in train_data:\n",
    "    unlabeled_list = np.append(unlabeled_list, train_data[i], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "major_mean = np.mean(unlabeled_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# out = component_dir+'/major_mean'\n",
    "# with open(out, 'wb') as handle:\n",
    "#     pickle.dump(major_mean, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_list = unlabeled_list - major_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_list = unlabeled_list.dot(transform.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normlize to sqrt(dim)\n",
    "scale = np.sqrt(PLDA_DIM) / np.linalg.norm(unlabeled_list, axis=1, keepdims=True)\n",
    "unlabeled_list = scale * unlabeled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adaptor = PldaUnsupervisedAdaptor(dim=PLDA_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(unlabeled_list.shape[0]):\n",
    "    adaptor.add_stats(unlabeled_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_plda_paras = adaptor.update_plda(plda_paras[0], plda_paras[1], plda_paras[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "out = component_dir+'/new_plda_paras'\n",
    "with open(out, 'wb') as handle:\n",
    "    pickle.dump(new_plda_paras, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plda = PLDA(new_plda_paras[0], new_plda_paras[1], new_plda_paras[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enroll models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./sdsvc'+'/'+ENR_DATA_NAME, 'rb') as handle:\n",
    "    enr_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enr_list = {}\n",
    "num_utt = {}\n",
    "with open('/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/docs/model_enrollment.txt', 'r') as f:\n",
    "    for count, line in enumerate(f):\n",
    "        if count == 0:\n",
    "            continue\n",
    "        info = line[:-1].split(' ')\n",
    "        model_label = info[0]\n",
    "        num_utt[model_label] = len(info)-1\n",
    "        for i in range(1, len(info)):\n",
    "            if model_label not in enr_list.keys():\n",
    "                enr_list[model_label] = enr_data[info[i]]\n",
    "            else:\n",
    "                enr_list[model_label] = np.append(enr_list[model_label], enr_data[info[i]], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./sdsvc'+'/'+EVL_DATA_NAME, 'rb') as handle:\n",
    "    evl_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/docs/trials.txt'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in enr_list:\n",
    "    enr_list[i] = np.mean(enr_list[i], axis=0).squeeze()\n",
    "    enr_list[i] = enr_list[i] - global_mean\n",
    "    enr_list[i] = transform.dot(enr_list[i])\n",
    "    enr_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(enr_list[i])) * enr_list[i]\n",
    "    num = num_utt[i]\n",
    "    enr_list[i] = plda.transform_ivector(enr_list[i], num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in evl_data:\n",
    "    evl_data[i] = evl_data[i].squeeze()\n",
    "    evl_data[i] = evl_data[i] - global_mean\n",
    "    evl_data[i] = transform.dot(evl_data[i])\n",
    "    evl_data[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(evl_data[i])) * evl_data[i]\n",
    "    evl_data[i] = plda.transform_ivector(evl_data[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-id evaluation-file-id\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            line = line[:-1]\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "                continue\n",
    "            enroll_emb = enr_list[line.split(' ')[0]].squeeze()\n",
    "            num = num_utt[line.split(' ')[0]]\n",
    "            test_emb = evl_data[line.split(' ')[1]].squeeze()\n",
    "\n",
    "            cosine = plda.log_likelihood_ratio(enroll_emb, num, test_emb)\n",
    "            \n",
    "            of.write(\"{:.2f}\\n\".format(cosine))\n",
    "            \n",
    "            if (count+1) % 100000 == 0:\n",
    "                print((count+1) // 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13198024"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scoring adapt plda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/docs/trials.txt'\n",
    "score_out_path = component_dir+'/'+SCORING_PLDA_NAME+'adapt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in enr_list:\n",
    "    enr_list[i] = np.mean(enr_list[i], axis=0).squeeze()\n",
    "    enr_list[i] = enr_list[i] - major_mean\n",
    "    enr_list[i] = transform.dot(enr_list[i])\n",
    "    enr_list[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(enr_list[i])) * enr_list[i]\n",
    "    num = num_utt[i]\n",
    "    enr_list[i] = plda.transform_ivector(enr_list[i], num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in evl_data:\n",
    "    evl_data[i] = evl_data[i].squeeze()\n",
    "    evl_data[i] = evl_data[i] - major_mean\n",
    "    evl_data[i] = transform.dot(evl_data[i])\n",
    "    evl_data[i] = (np.sqrt(PLDA_DIM) / np.linalg.norm(evl_data[i])) * evl_data[i]\n",
    "    evl_data[i] = plda.transform_ivector(evl_data[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-id evaluation-file-id\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n",
      "20.0\n",
      "21.0\n",
      "22.0\n",
      "23.0\n",
      "24.0\n",
      "25.0\n",
      "26.0\n",
      "27.0\n",
      "28.0\n",
      "29.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "33.0\n",
      "34.0\n",
      "35.0\n",
      "36.0\n",
      "37.0\n",
      "38.0\n",
      "39.0\n",
      "40.0\n",
      "41.0\n",
      "42.0\n",
      "43.0\n",
      "44.0\n",
      "45.0\n",
      "46.0\n",
      "47.0\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "51.0\n",
      "52.0\n",
      "53.0\n",
      "54.0\n",
      "55.0\n",
      "56.0\n",
      "57.0\n",
      "58.0\n",
      "59.0\n",
      "60.0\n",
      "61.0\n",
      "62.0\n",
      "63.0\n",
      "64.0\n",
      "65.0\n",
      "66.0\n",
      "67.0\n",
      "68.0\n",
      "69.0\n",
      "70.0\n",
      "71.0\n",
      "72.0\n",
      "73.0\n",
      "74.0\n",
      "75.0\n",
      "76.0\n",
      "77.0\n",
      "78.0\n",
      "79.0\n",
      "80.0\n",
      "81.0\n",
      "82.0\n",
      "83.0\n",
      "84.0\n",
      "85.0\n",
      "86.0\n",
      "87.0\n",
      "88.0\n",
      "89.0\n",
      "90.0\n",
      "91.0\n",
      "92.0\n",
      "93.0\n",
      "94.0\n",
      "95.0\n",
      "96.0\n",
      "97.0\n",
      "98.0\n",
      "99.0\n",
      "100.0\n",
      "101.0\n",
      "102.0\n",
      "103.0\n",
      "104.0\n",
      "105.0\n",
      "106.0\n",
      "107.0\n",
      "108.0\n",
      "109.0\n",
      "110.0\n",
      "111.0\n",
      "112.0\n",
      "113.0\n",
      "114.0\n",
      "115.0\n",
      "116.0\n",
      "117.0\n",
      "118.0\n",
      "119.0\n",
      "120.0\n",
      "121.0\n",
      "122.0\n",
      "123.0\n",
      "124.0\n",
      "125.0\n",
      "126.0\n",
      "127.0\n",
      "128.0\n",
      "129.0\n",
      "130.0\n",
      "131.0\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            line = line[:-1]\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "                continue\n",
    "            enroll_emb = enr_list[line.split(' ')[0]].squeeze()\n",
    "            num = num_utt[line.split(' ')[0]]\n",
    "            test_emb = evl_data[line.split(' ')[1]].squeeze()\n",
    "\n",
    "            cosine = plda.log_likelihood_ratio(enroll_emb, num, test_emb)\n",
    "            \n",
    "            of.write(str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 100000 == 0:\n",
    "                print((count+1) // 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13198024"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cosine Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_path = '/Lun0/zhiyong/SdSV_2020_deepmine/task2_enrollment/docs/trials.txt'\n",
    "score_out_path = component_dir+'/'+SCORING_COSINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in enr_list:\n",
    "    enr_list[i] = np.mean(enr_list[i], axis=0).squeeze()\n",
    "    enr_list[i] = (1.0 / np.linalg.norm(enr_list[i])) * enr_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in evl_data:\n",
    "    evl_data[i] = evl_data[i].squeeze()\n",
    "    evl_data[i] = (1.0 / np.linalg.norm(evl_data[i])) * evl_data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-id evaluation-file-id\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "with open(score_out_path, 'w') as of:\n",
    "    with open(trail_path, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            line = line[:-1]\n",
    "            if count == 0:\n",
    "                print(line)\n",
    "                continue\n",
    "            enroll_emb = enr_list[line.split(' ')[0]].squeeze()\n",
    "            test_emb = evl_data[line.split(' ')[1]].squeeze()\n",
    "\n",
    "            cosine = np.dot(enroll_emb, test_emb)\n",
    "            \n",
    "            of.write(str(cosine)+'\\n')\n",
    "            \n",
    "            if (count+1) % 100000 == 0:\n",
    "                print((count+1) // 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_scorer import scoring\n",
    "from calibrate_scores import calibrating\n",
    "from apply_calibration import applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.98\t0.216\t0.303\n",
      "Starting point for CLLR is 0.320928\n",
      "Converged linear model with loss 0.08190182800917162\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.98\t0.216\t0.258\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t02.18\t0.231\t1.000\n",
      "Starting point for CLLR is 0.842448\n",
      "Converged linear model with loss 0.08916190600896338\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t02.18\t0.231\t0.260\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from score_norm_1 import score_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "ori_score = component_dir+'/'+SCORING_PLDA_NAME\n",
    "norm_score = component_dir+'/'+SCORING_PLDA_NAME+'_norm'\n",
    "score_norm(ori_score, norm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.88\t0.312\t1.000\n",
      "Starting point for CLLR is 0.538934\n",
      "Converged linear model with loss 0.07954009941343457\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.88\t0.312\t0.334\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_PLDA_NAME+'_norm'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/dell/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "ori_score = component_dir+'/'+SCORING_COSINE_NAME\n",
    "norm_score = component_dir+'/'+SCORING_COSINE_NAME+'_norm'\n",
    "score_norm(ori_score, norm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.81\t0.311\t1.000\n",
      "Starting point for CLLR is 0.536303\n",
      "Converged linear model with loss 0.07717334626909308\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.81\t0.311\t0.331\n"
     ]
    }
   ],
   "source": [
    "score_file = component_dir+'/'+SCORING_COSINE_NAME+'_norm'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = score_file+'_calib'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "_ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file])\n",
    "applying(linear_model_pth, [score_file], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting point for CLLR is 0.581688\n",
      "Converged linear model with loss 0.074283602014203\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.74\t0.204\t0.221\n"
     ]
    }
   ],
   "source": [
    "score_file_1 = component_dir+'/'+SCORING_PLDA_NAME\n",
    "score_file_2 = component_dir+'/'+SCORING_COSINE_NAME\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = component_dir+'/'+'fuse'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "# _ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file_1, score_file_2])\n",
    "applying(linear_model_pth, [score_file_1, score_file_2], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting point for CLLR is 0.537618\n",
      "Converged linear model with loss 0.0694378887070766\n",
      "\n",
      "Set\tEER[%]\tmin_C\tact_C\n",
      "OUT\t01.61\t0.266\t0.291\n"
     ]
    }
   ],
   "source": [
    "score_file_1 = component_dir+'/'+SCORING_PLDA_NAME+'_norm'\n",
    "score_file_2 = component_dir+'/'+SCORING_COSINE_NAME+'_norm'\n",
    "key_file = '/Lun0/zhiyong/dataset/vox1_kaldi_test/trials'\n",
    "calib_score_file = component_dir+'/'+'fuse_norm'\n",
    "linear_model_pth = component_dir+'/'+'calib.pth'\n",
    "\n",
    "# _ = scoring(score_file, key_file)\n",
    "calibrating(linear_model_pth, 50, key_file, [score_file_1, score_file_2])\n",
    "applying(linear_model_pth, [score_file_1, score_file_2], calib_score_file)\n",
    "_ = scoring(calib_score_file, key_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
