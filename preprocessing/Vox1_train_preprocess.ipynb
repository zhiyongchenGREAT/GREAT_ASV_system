{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import traceback\n",
    "import shutil\n",
    "\n",
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = '/workspace/GREAT_ASV_system/'\n",
    "sys.path.append(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPT_INDEX = '/workspace/DATASET/server9_ssd/STD_VOX1_EGS'\n",
    "if not os.path.exists(OPT_INDEX):\n",
    "    os.mkdir(OPT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOX_TRAIN_DIR = '/workspace/DATASET/server9/voxceleb'\n",
    "AUG_INFO_DIR = '/workspace/DATASET/server9/STD_musan&rir_info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO_DIR = os.path.join(OPT_INDEX, 'VOX1_INFO')\n",
    "if not os.path.exists(INFO_DIR):\n",
    "    os.mkdir(INFO_DIR)\n",
    "\n",
    "spk2id = os.path.join(INFO_DIR, 'spk2id')\n",
    "spk2utt_dict = os.path.join(INFO_DIR, 'spk2utt_dict')\n",
    "spk2utt_train_dict = os.path.join(INFO_DIR, 'spk2utt_train_dict')\n",
    "spk2utt_val_dict = os.path.join(INFO_DIR, 'spk2utt_val_dict')\n",
    "spk2utt_train_len = os.path.join(INFO_DIR, 'spk2utt_train_len')\n",
    "spk2utt_val_len = os.path.join(INFO_DIR, 'spk2utt_val_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_utt_num = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make spk2utt dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk2utt = {}\n",
    "spk2utt_train = {}\n",
    "spk2utt_val = {}\n",
    "\n",
    "with open(spk2id, 'w') as f:\n",
    "    pass\n",
    "\n",
    "label_dir = glob.glob(VOX_TRAIN_DIR+'/vox1/dev/wav/*')\n",
    "label = [i.split('/')[-1] for i in label_dir]\n",
    "\n",
    "for count, i in enumerate(label):\n",
    "    with open(spk2id, 'a') as f:\n",
    "        f.write(str(count)+','+i+'\\n')\n",
    "    spk2utt[count] = glob.glob(os.path.join(VOX_TRAIN_DIR+'/vox1/dev/wav/', i)+'/*/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1211"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spk2utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148642\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "count_list = []\n",
    "for i in spk2utt:\n",
    "    count += len(spk2utt[i])\n",
    "    count_list.append(len(spk2utt[i]))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(spk2utt_dict, 'wb') as handle:\n",
    "    pickle.dump(spk2utt, handle)\n",
    "\n",
    "with open(spk2utt_dict, 'rb') as handle:\n",
    "    spk2utt = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_length = []\n",
    "for i in spk2utt:\n",
    "    utt_length.append(len(spk2utt[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_length = np.argsort(utt_length)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk2utt_train = copy.deepcopy(spk2utt)\n",
    "for i in range(val_utt_num):   \n",
    "    spk2utt_val[utt_length[i]] = [spk2utt[utt_length[i]][0]]\n",
    "    spk2utt_train[utt_length[i]] = spk2utt[utt_length[i]][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148442\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "count_list = []\n",
    "for i in spk2utt_train:\n",
    "    count += len(spk2utt_train[i])\n",
    "    count_list.append(len(spk2utt[i]))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(spk2utt_train_dict, 'wb') as handle:\n",
    "    pickle.dump(spk2utt_train, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "count_list = []\n",
    "for i in spk2utt_val:\n",
    "    count += len(spk2utt_val[i])\n",
    "    count_list.append(len(spk2utt[i]))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(spk2utt_val_dict, 'wb') as handle:\n",
    "    pickle.dump(spk2utt_val, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use multi-process to check read wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "spk2utt_train_len_dict_m = manager.list()\n",
    "eer_m = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err = []\n",
    "with open(spk2utt_train_dict, 'rb') as handle:\n",
    "    spk2utt_train = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk2utt_train_splitlist = []\n",
    "num_per_process = len(spk2utt_train) // 10\n",
    "for i in range(9):\n",
    "    spk2utt_train_splitlist.append([j for j in range(i*num_per_process, (i+1)*num_per_process)])\n",
    "    spk2utt_train_len_dict_m.append({})\n",
    "spk2utt_train_splitlist.append([j for j in range(9*num_per_process, len(spk2utt_train))])\n",
    "spk2utt_train_len_dict_m.append({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav_m(p, spk2utt_train, spk2utt_train_split, spk2utt_train_len_dict_m, eer_m):\n",
    "    spk2utt_train_len_dict = {}\n",
    "    for count, i in enumerate(spk2utt_train_split):\n",
    "        for utt in spk2utt_train[i]:\n",
    "            try:\n",
    "                spk2utt_train_len_dict[utt] = librosa.core.load(utt, sr=16000)[0].shape[0]\n",
    "            except Exception:\n",
    "                eer_m.append([p, utt])\n",
    "                continue\n",
    "        print(count)\n",
    "    spk2utt_train_len_dict_m[p] = spk2utt_train_len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "7\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "9\n",
      "4\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "10\n",
      "5\n",
      "6\n",
      "8\n",
      "7\n",
      "5\n",
      "7\n",
      "11\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "8\n",
      "4\n",
      "9\n",
      "8\n",
      "5\n",
      "7\n",
      "9\n",
      "7\n",
      "12\n",
      "7\n",
      "9\n",
      "10\n",
      "5\n",
      "8\n",
      "8\n",
      "10\n",
      "13\n",
      "11\n",
      "8\n",
      "9\n",
      "14\n",
      "6\n",
      "10\n",
      "9\n",
      "6\n",
      "8\n",
      "7\n",
      "15\n",
      "11\n",
      "9\n",
      "12\n",
      "10\n",
      "7\n",
      "11\n",
      "16\n",
      "9\n",
      "17\n",
      "12\n",
      "13\n",
      "10\n",
      "10\n",
      "10\n",
      "18\n",
      "12\n",
      "11\n",
      "11\n",
      "11\n",
      "8\n",
      "12\n",
      "19\n",
      "13\n",
      "11\n",
      "8\n",
      "12\n",
      "13\n",
      "12\n",
      "14\n",
      "9\n",
      "20\n",
      "14\n",
      "10\n",
      "12\n",
      "9\n",
      "13\n",
      "13\n",
      "15\n",
      "15\n",
      "16\n",
      "13\n",
      "14\n",
      "14\n",
      "13\n",
      "16\n",
      "15\n",
      "14\n",
      "15\n",
      "10\n",
      "16\n",
      "11\n",
      "15\n",
      "14\n",
      "17\n",
      "14\n",
      "17\n",
      "11\n",
      "12\n",
      "16\n",
      "21\n",
      "17\n",
      "15\n",
      "12\n",
      "15\n",
      "22\n",
      "17\n",
      "16\n",
      "18\n",
      "13\n",
      "13\n",
      "17\n",
      "18\n",
      "16\n",
      "23\n",
      "18\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "14\n",
      "18\n",
      "14\n",
      "20\n",
      "18\n",
      "19\n",
      "19\n",
      "24\n",
      "15\n",
      "19\n",
      "20\n",
      "17\n",
      "19\n",
      "21\n",
      "15\n",
      "20\n",
      "25\n",
      "20\n",
      "20\n",
      "16\n",
      "21\n",
      "16\n",
      "21\n",
      "17\n",
      "22\n",
      "22\n",
      "18\n",
      "21\n",
      "18\n",
      "22\n",
      "19\n",
      "21\n",
      "22\n",
      "19\n",
      "19\n",
      "23\n",
      "23\n",
      "17\n",
      "22\n",
      "26\n",
      "23\n",
      "20\n",
      "23\n",
      "20\n",
      "27\n",
      "21\n",
      "18\n",
      "23\n",
      "24\n",
      "21\n",
      "28\n",
      "25\n",
      "24\n",
      "22\n",
      "24\n",
      "20\n",
      "24\n",
      "22\n",
      "25\n",
      "21\n",
      "24\n",
      "29\n",
      "23\n",
      "25\n",
      "19\n",
      "25\n",
      "24\n",
      "26\n",
      "26\n",
      "20\n",
      "25\n",
      "30\n",
      "26\n",
      "25\n",
      "26\n",
      "22\n",
      "26\n",
      "21\n",
      "27\n",
      "31\n",
      "27\n",
      "28\n",
      "27\n",
      "27\n",
      "26\n",
      "22\n",
      "28\n",
      "23\n",
      "27\n",
      "32\n",
      "28\n",
      "23\n",
      "29\n",
      "28\n",
      "27\n",
      "33\n",
      "24\n",
      "28\n",
      "28\n",
      "23\n",
      "29\n",
      "30\n",
      "29\n",
      "34\n",
      "24\n",
      "29\n",
      "30\n",
      "29\n",
      "24\n",
      "25\n",
      "31\n",
      "29\n",
      "30\n",
      "25\n",
      "30\n",
      "26\n",
      "31\n",
      "35\n",
      "32\n",
      "31\n",
      "32\n",
      "26\n",
      "25\n",
      "30\n",
      "31\n",
      "27\n",
      "36\n",
      "26\n",
      "27\n",
      "28\n",
      "33\n",
      "31\n",
      "30\n",
      "29\n",
      "30\n",
      "37\n",
      "34\n",
      "28\n",
      "38\n",
      "31\n",
      "32\n",
      "32\n",
      "33\n",
      "27\n",
      "3931\n",
      "\n",
      "29\n",
      "32\n",
      "35\n",
      "30\n",
      "32\n",
      "33\n",
      "32\n",
      "33\n",
      "33\n",
      "28\n",
      "31\n",
      "33\n",
      "34\n",
      "34\n",
      "33\n",
      "34\n",
      "36\n",
      "32\n",
      "34\n",
      "37\n",
      "40\n",
      "35\n",
      "29\n",
      "34\n",
      "36\n",
      "34\n",
      "38\n",
      "41\n",
      "39\n",
      "33\n",
      "35\n",
      "35\n",
      "35\n",
      "42\n",
      "36\n",
      "40\n",
      "30\n",
      "35\n",
      "34\n",
      "36\n",
      "36\n",
      "37\n",
      "35\n",
      "43\n",
      "37\n",
      "38\n",
      "31\n",
      "37\n",
      "38\n",
      "37\n",
      "36\n",
      "36\n",
      "44\n",
      "32\n",
      "35\n",
      "38\n",
      "38\n",
      "39\n",
      "45\n",
      "37\n",
      "39\n",
      "41\n",
      "37\n",
      "46\n",
      "38\n",
      "33\n",
      "39\n",
      "38\n",
      "36\n",
      "40\n",
      "40\n",
      "40\n",
      "34\n",
      "47\n",
      "41\n",
      "39\n",
      "39\n",
      "42\n",
      "37\n",
      "39\n",
      "43\n",
      "41\n",
      "48\n",
      "42\n",
      "41\n",
      "38\n",
      "40\n",
      "43\n",
      "44\n",
      "39\n",
      "41\n",
      "49\n",
      "44\n",
      "40\n",
      "42\n",
      "42\n",
      "45\n",
      "50\n",
      "42\n",
      "45\n",
      "51\n",
      "40\n",
      "43\n",
      "52\n",
      "40\n",
      "43\n",
      "35\n",
      "53\n",
      "44\n",
      "36\n",
      "41\n",
      "43\n",
      "37\n",
      "42\n",
      "41\n",
      "45\n",
      "44\n",
      "44\n",
      "46\n",
      "38\n",
      "46\n",
      "43\n",
      "54\n",
      "45\n",
      "45\n",
      "46\n",
      "39\n",
      "46\n",
      "47\n",
      "46\n",
      "47\n",
      "47\n",
      "42\n",
      "48\n",
      "47\n",
      "41\n",
      "55\n",
      "48\n",
      "48\n",
      "40\n",
      "49\n",
      "56\n",
      "43\n",
      "47\n",
      "49\n",
      "48\n",
      "49\n",
      "57\n",
      "50\n",
      "50\n",
      "49\n",
      "44\n",
      "44\n",
      "58\n",
      "48\n",
      "45\n",
      "51\n",
      "49\n",
      "51\n",
      "41\n",
      "50\n",
      "52\n",
      "45\n",
      "50\n",
      "51\n",
      "51\n",
      "42\n",
      "46\n",
      "50\n",
      "52\n",
      "46\n",
      "51\n",
      "47\n",
      "42\n",
      "52\n",
      "59\n",
      "53\n",
      "52\n",
      "43\n",
      "47\n",
      "48\n",
      "53\n",
      "53\n",
      "53\n",
      "52\n",
      "54\n",
      "49\n",
      "60\n",
      "43\n",
      "54\n",
      "55\n",
      "54\n",
      "61\n",
      "48\n",
      "55\n",
      "50\n",
      "44\n",
      "54\n",
      "62\n",
      "44\n",
      "53\n",
      "56\n",
      "49\n",
      "63\n",
      "55\n",
      "51\n",
      "45\n",
      "54\n",
      "56\n",
      "45\n",
      "64\n",
      "57\n",
      "50\n",
      "55\n",
      "55\n",
      "57\n",
      "51\n",
      "65\n",
      "46\n",
      "58\n",
      "46\n",
      "66\n",
      "52\n",
      "58\n",
      "47\n",
      "56\n",
      "56\n",
      "59\n",
      "56\n",
      "57\n",
      "57\n",
      "52\n",
      "47\n",
      "67\n",
      "59\n",
      "58\n",
      "60\n",
      "53\n",
      "68\n",
      "58\n",
      "57\n",
      "54\n",
      "48\n",
      "59\n",
      "69\n",
      "59\n",
      "48\n",
      "70\n",
      "61\n",
      "53\n",
      "58\n",
      "49\n",
      "49\n",
      "62\n",
      "60\n",
      "59\n",
      "60\n",
      "50\n",
      "54\n",
      "61\n",
      "60\n",
      "50\n",
      "71\n",
      "60\n",
      "51\n",
      "55\n",
      "72\n",
      "55\n",
      "62\n",
      "61\n",
      "56\n",
      "73\n",
      "52\n",
      "61\n",
      "63\n",
      "74\n",
      "62\n",
      "57\n",
      "63\n",
      "56\n",
      "62\n",
      "51\n",
      "53\n",
      "64\n",
      "63\n",
      "63\n",
      "57\n",
      "54\n",
      "61\n",
      "65\n",
      "64\n",
      "58\n",
      "75\n",
      "55\n",
      "64\n",
      "66\n",
      "64\n",
      "65\n",
      "52\n",
      "76\n",
      "59\n",
      "65\n",
      "58\n",
      "53\n",
      "67\n",
      "56\n",
      "60\n",
      "68\n",
      "54\n",
      "66\n",
      "65\n",
      "62\n",
      "77\n",
      "67\n",
      "57\n",
      "55\n",
      "63\n",
      "78\n",
      "66\n",
      "68\n",
      "58\n",
      "59\n",
      "67\n",
      "66\n",
      "69\n",
      "69\n",
      "64\n",
      "56\n",
      "60\n",
      "67\n",
      "59\n",
      "70\n",
      "61\n",
      "79\n",
      "62\n",
      "80\n",
      "65\n",
      "60\n",
      "81\n",
      "68\n",
      "63\n",
      "71\n",
      "68\n",
      "61\n",
      "57\n",
      "82\n",
      "69\n",
      "64\n",
      "69\n",
      "72\n",
      "70\n",
      "73\n",
      "66\n",
      "70\n",
      "71\n",
      "67\n",
      "70\n",
      "83\n",
      "71\n",
      "58\n",
      "68\n",
      "71\n",
      "62\n",
      "72\n",
      "69\n",
      "65\n",
      "59\n",
      "84\n",
      "73\n",
      "72\n",
      "85\n",
      "74\n",
      "70\n",
      "63\n",
      "74\n",
      "86\n",
      "60\n",
      "75\n",
      "72\n",
      "73\n",
      "61\n",
      "71\n",
      "64\n",
      "61\n",
      "66\n",
      "76\n",
      "62\n",
      "72\n",
      "75\n",
      "62\n",
      "65\n",
      "63\n",
      "63\n",
      "67\n",
      "64\n",
      "64\n",
      "73\n",
      "74\n",
      "77\n",
      "76\n",
      "73\n",
      "66\n",
      "65\n",
      "75\n",
      "65\n",
      "74\n",
      "78\n",
      "87\n",
      "77\n",
      "68\n",
      "88\n",
      "75\n",
      "79\n",
      "76\n",
      "89\n",
      "74\n",
      "66\n",
      "66\n",
      "77\n",
      "69\n",
      "76\n",
      "75\n",
      "90\n",
      "67\n",
      "78\n",
      "67\n",
      "78\n",
      "70\n",
      "80\n",
      "76\n",
      "68\n",
      "77\n",
      "67\n",
      "79\n",
      "81\n",
      "78\n",
      "79\n",
      "68\n",
      "71\n",
      "79\n",
      "68\n",
      "80\n",
      "82\n",
      "91\n",
      "69\n",
      "77\n",
      "80\n",
      "69\n",
      "70\n",
      "83\n",
      "81\n",
      "80\n",
      "81\n",
      "78\n",
      "92\n",
      "72\n",
      "84\n",
      "70\n",
      "73\n",
      "93\n",
      "82\n",
      "71\n",
      "81\n",
      "69\n",
      "71\n",
      "74\n",
      "79\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "72\n",
      "72\n",
      "83\n",
      "76\n",
      "82\n",
      "94\n",
      "73\n",
      "86\n",
      "77\n",
      "87\n",
      "71\n",
      "82\n",
      "73\n",
      "74\n",
      "83\n",
      "81\n",
      "88\n",
      "78\n",
      "72\n",
      "95\n",
      "75\n",
      "83\n",
      "89\n",
      "82\n",
      "74\n",
      "84\n",
      "76\n",
      "84\n",
      "85\n",
      "84\n",
      "75\n",
      "85\n",
      "73\n",
      "90\n",
      "96\n",
      "77\n",
      "83\n",
      "86\n",
      "91\n",
      "74\n",
      "78\n",
      "79\n",
      "85\n",
      "86\n",
      "75\n",
      "97\n",
      "92\n",
      "87\n",
      "76\n",
      "80\n",
      "84\n",
      "76\n",
      "81\n",
      "79\n",
      "77\n",
      "93\n",
      "86\n",
      "85\n",
      "77\n",
      "98\n",
      "87\n",
      "87\n",
      "82\n",
      "88\n",
      "99\n",
      "78\n",
      "94\n",
      "86\n",
      "78\n",
      "89\n",
      "87\n",
      "83\n",
      "95\n",
      "80\n",
      "88\n",
      "88\n",
      "79\n",
      "100\n",
      "79\n",
      "90\n",
      "96\n",
      "89\n",
      "101\n",
      "81\n",
      "80\n",
      "80\n",
      "89\n",
      "97\n",
      "84\n",
      "82\n",
      "88\n",
      "85\n",
      "90\n",
      "81\n",
      "102\n",
      "98\n",
      "90\n",
      "81\n",
      "91\n",
      "91\n",
      "86\n",
      "82\n",
      "89\n",
      "103\n",
      "92\n",
      "92\n",
      "99\n",
      "83\n",
      "91\n",
      "104\n",
      "93\n",
      "90\n",
      "100\n",
      "93\n",
      "84\n",
      "105\n",
      "92\n",
      "101\n",
      "91\n",
      "87\n",
      "85\n",
      "106\n",
      "94\n",
      "82\n",
      "88\n",
      "83\n",
      "92\n",
      "102\n",
      "86\n",
      "107\n",
      "93\n",
      "89\n",
      "95\n",
      "83\n",
      "94\n",
      "84\n",
      "108\n",
      "103\n",
      "94\n",
      "84\n",
      "96\n",
      "93\n",
      "90\n",
      "109\n",
      "104\n",
      "87\n",
      "94\n",
      "97\n",
      "110\n",
      "91\n",
      "85\n",
      "88\n",
      "111\n",
      "95\n",
      "95\n",
      "85\n",
      "89\n",
      "105\n",
      "86\n",
      "98\n",
      "106\n",
      "90\n",
      "92\n",
      "112\n",
      "96\n",
      "113\n",
      "95\n",
      "99\n",
      "86\n",
      "91\n",
      "100\n",
      "93\n",
      "92\n",
      "87\n",
      "96\n",
      "107\n",
      "96\n",
      "114\n",
      "101\n",
      "87\n",
      "97\n",
      "93\n",
      "94\n",
      "108\n",
      "88\n",
      "98\n",
      "115\n",
      "94\n",
      "88\n",
      "95\n",
      "95\n",
      "89\n",
      "102\n",
      "90\n",
      "116\n",
      "89\n",
      "96\n",
      "96\n",
      "97\n",
      "103\n",
      "117\n",
      "97\n",
      "104\n",
      "97\n",
      "91\n",
      "97\n",
      "98\n",
      "99\n",
      "98\n",
      "92\n",
      "105\n",
      "98\n",
      "100\n",
      "118\n",
      "99\n",
      "99\n",
      "90\n",
      "101\n",
      "100\n",
      "106\n",
      "102\n",
      "119\n",
      "98\n",
      "91\n",
      "99\n",
      "101\n",
      "93\n",
      "100\n",
      "103\n",
      "92\n",
      "120\n",
      "99\n",
      "101\n",
      "102\n",
      "94\n",
      "109\n",
      "100\n",
      "100\n",
      "102\n",
      "93\n",
      "107\n",
      "103\n",
      "110\n",
      "95\n",
      "104\n",
      "94\n",
      "101\n",
      "111\n",
      "101\n",
      "103\n",
      "95\n",
      "96\n",
      "102\n",
      "108\n",
      "102\n",
      "112\n",
      "105\n",
      "97\n",
      "96\n",
      "104\n",
      "113\n",
      "103\n",
      "109\n",
      "106\n",
      "104\n",
      "104\n",
      "114\n",
      "97\n",
      "103\n",
      "98\n",
      "105\n",
      "110\n",
      "105\n",
      "99\n",
      "115\n",
      "98\n",
      "107\n",
      "106\n",
      "106\n",
      "111\n",
      "104\n",
      "99\n",
      "108\n",
      "112\n",
      "100\n",
      "107\n",
      "105\n",
      "109\n",
      "101\n",
      "107\n",
      "113\n",
      "108\n",
      "105\n",
      "110\n",
      "106\n",
      "114\n",
      "109\n",
      "111\n",
      "107\n",
      "106\n",
      "108\n",
      "112\n",
      "108\n",
      "115\n",
      "107\n",
      "116\n",
      "113\n",
      "109\n",
      "109\n",
      "116\n",
      "100\n",
      "108\n",
      "102\n",
      "117\n",
      "109\n",
      "110\n",
      "110\n",
      "103\n",
      "110\n",
      "117\n",
      "111\n",
      "110\n",
      "101\n",
      "111\n",
      "104\n",
      "118\n",
      "118\n",
      "114\n",
      "112\n",
      "105\n",
      "111\n",
      "113\n",
      "111\n",
      "119\n",
      "115\n",
      "112\n",
      "106\n",
      "114\n",
      "107\n",
      "115\n",
      "120\n",
      "112\n",
      "102\n",
      "113\n",
      "116\n",
      "116\n",
      "113\n",
      "103\n",
      "119\n",
      "112\n",
      "114\n",
      "117\n",
      "104\n",
      "113\n",
      "117\n",
      "115\n",
      "108\n",
      "105\n",
      "120\n",
      "114\n",
      "109\n",
      "115\n",
      "118\n",
      "114\n",
      "106\n",
      "116\n",
      "118\n",
      "110\n",
      "107\n",
      "116\n",
      "108\n",
      "119\n",
      "111\n",
      "119\n",
      "117\n",
      "115\n",
      "120\n",
      "112\n",
      "109\n",
      "113\n",
      "120\n",
      "117\n",
      "116\n",
      "114\n",
      "110\n",
      "118\n",
      "118\n",
      "115\n",
      "117\n",
      "116\n",
      "111\n",
      "119\n",
      "112\n",
      "119\n",
      "113\n",
      "117\n",
      "118\n",
      "120\n",
      "120\n",
      "118\n",
      "119\n",
      "114\n",
      "119\n",
      "120\n",
      "115\n",
      "120\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "with open(spk2utt_train_dict, 'rb') as handle:\n",
    "    spk2utt_train = pickle.load(handle)\n",
    "\n",
    "processes = [Process(target = read_wav_m, args = (i, spk2utt_train, spk2utt_train_splitlist[i], spk2utt_train_len_dict_m, eer_m)) for i in range(10)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OPT_INDEX+'/spk2utt_train_len_TMP', 'wb') as handle:\n",
    "    pickle.dump(spk2utt_train_len_dict_m, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_len_num 148442\n"
     ]
    }
   ],
   "source": [
    "spk2utt_train_len_dict = {}\n",
    "for this_dict in spk2utt_train_len_dict_m:\n",
    "    for count, i in enumerate(this_dict):\n",
    "        spk2utt_train_len_dict[i] = this_dict[i]\n",
    "#         print(count)\n",
    "print('train_len_num', len(spk2utt_train_len_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_list = list(eer_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(spk2utt_train_len, 'wb') as handle:\n",
    "    pickle.dump(spk2utt_train_len_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spk2utt_train_len_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err = []\n",
    "# with open(spk2utt_train_dict, 'rb') as handle:\n",
    "#     spk2utt_train = pickle.load(handle)\n",
    "\n",
    "# for i in spk2utt_train:\n",
    "#     for utt in spk2utt_train[i]:\n",
    "#         try:\n",
    "#             spk2utt_train_len_dict[utt] = librosa.core.load(utt, sr=16000)[0].shape[0]\n",
    "#         except Exception:\n",
    "#             err.append(utt)\n",
    "#             continue\n",
    "#     print(i)\n",
    "            \n",
    "# with open(spk2utt_train_len, 'wb') as handle:\n",
    "#     pickle.dump(spk2utt_train_len_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk2utt_val_len_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150\n",
      "956\n",
      "398\n",
      "163\n",
      "35\n",
      "162\n",
      "963\n",
      "796\n",
      "877\n",
      "728\n",
      "571\n",
      "1189\n",
      "288\n",
      "1108\n",
      "1158\n",
      "1133\n",
      "1172\n",
      "395\n",
      "1014\n",
      "543\n",
      "1102\n",
      "1112\n",
      "250\n",
      "505\n",
      "154\n",
      "823\n",
      "758\n",
      "1040\n",
      "966\n",
      "62\n",
      "1082\n",
      "303\n",
      "329\n",
      "1034\n",
      "510\n",
      "1191\n",
      "871\n",
      "1179\n",
      "808\n",
      "44\n",
      "102\n",
      "468\n",
      "838\n",
      "326\n",
      "970\n",
      "82\n",
      "619\n",
      "10\n",
      "204\n",
      "769\n",
      "67\n",
      "246\n",
      "172\n",
      "1141\n",
      "418\n",
      "253\n",
      "637\n",
      "789\n",
      "41\n",
      "16\n",
      "160\n",
      "292\n",
      "308\n",
      "986\n",
      "1063\n",
      "169\n",
      "20\n",
      "734\n",
      "866\n",
      "884\n",
      "1056\n",
      "23\n",
      "732\n",
      "1024\n",
      "1009\n",
      "108\n",
      "428\n",
      "1065\n",
      "538\n",
      "429\n",
      "1042\n",
      "27\n",
      "696\n",
      "390\n",
      "822\n",
      "332\n",
      "907\n",
      "450\n",
      "18\n",
      "341\n",
      "405\n",
      "679\n",
      "821\n",
      "479\n",
      "660\n",
      "1078\n",
      "830\n",
      "1130\n",
      "1174\n",
      "567\n",
      "371\n",
      "563\n",
      "820\n",
      "1010\n",
      "795\n",
      "120\n",
      "673\n",
      "147\n",
      "304\n",
      "860\n",
      "131\n",
      "124\n",
      "156\n",
      "921\n",
      "1041\n",
      "161\n",
      "731\n",
      "431\n",
      "843\n",
      "804\n",
      "1142\n",
      "356\n",
      "924\n",
      "294\n",
      "219\n",
      "579\n",
      "634\n",
      "365\n",
      "586\n",
      "14\n",
      "259\n",
      "989\n",
      "1100\n",
      "179\n",
      "1080\n",
      "847\n",
      "524\n",
      "422\n",
      "1067\n",
      "239\n",
      "1028\n",
      "129\n",
      "200\n",
      "178\n",
      "1204\n",
      "712\n",
      "954\n",
      "652\n",
      "93\n",
      "666\n",
      "900\n",
      "1036\n",
      "740\n",
      "1160\n",
      "1114\n",
      "145\n",
      "1086\n",
      "339\n",
      "1155\n",
      "1022\n",
      "578\n",
      "208\n",
      "6\n",
      "812\n",
      "612\n",
      "481\n",
      "555\n",
      "649\n",
      "137\n",
      "419\n",
      "87\n",
      "30\n",
      "978\n",
      "521\n",
      "1122\n",
      "78\n",
      "617\n",
      "776\n",
      "11\n",
      "467\n",
      "224\n",
      "258\n",
      "76\n",
      "281\n",
      "442\n",
      "982\n",
      "381\n",
      "736\n",
      "507\n",
      "201\n",
      "243\n",
      "539\n",
      "642\n",
      "66\n",
      "46\n",
      "864\n",
      "623\n",
      "1101\n",
      "475\n",
      "337\n"
     ]
    }
   ],
   "source": [
    "err = []\n",
    "with open(spk2utt_val_dict, 'rb') as handle:\n",
    "    spk2utt_val = pickle.load(handle)\n",
    "\n",
    "for i in spk2utt_val:\n",
    "    for utt in spk2utt_val[i]:\n",
    "        try:\n",
    "            spk2utt_val_len_dict[utt] = librosa.core.load(utt, sr=16000)[0].shape[0]\n",
    "        except Exception:\n",
    "            err.append(utt)\n",
    "            continue\n",
    "    print(i)\n",
    "\n",
    "with open(spk2utt_val_len, 'wb') as handle:\n",
    "    pickle.dump(spk2utt_val_len_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.Utils.preprocessing_3type import ThreeTypes_IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_dict = {}\n",
    "\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(INFO_DIR, 'spk2utt_train_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(AUG_INFO_DIR, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(AUG_INFO_DIR, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(AUG_INFO_DIR, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(AUG_INFO_DIR, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(INFO_DIR, 'spk2utt_train_len')\n",
    "data_len_dict['music_len'] = os.path.join(AUG_INFO_DIR, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(AUG_INFO_DIR, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(AUG_INFO_DIR, 'babble_len')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi episode process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESS = 1500\n",
    "RUNNING_P = 10\n",
    "\n",
    "MFCC_O = os.path.join(OPT_INDEX, 'TRAIN_VOX2_MFCC')\n",
    "LOGMELFB_O = os.path.join(OPT_INDEX, 'TRAIN_VOX2_FB')\n",
    "RAWWAV_O = os.path.join(OPT_INDEX, 'TRAIN_VOX2_RAW')\n",
    "EER_LOG = os.path.join(OPT_INDEX, 'EER_LOG')\n",
    "G_LOG = os.path.join(OPT_INDEX, 'G_LOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MFCC_O):\n",
    "    os.mkdir(MFCC_O)\n",
    "else:\n",
    "    shutil.rmtree(MFCC_O)\n",
    "    \n",
    "if not os.path.exists(LOGMELFB_O):\n",
    "    os.mkdir(LOGMELFB_O)\n",
    "else:\n",
    "    shutil.rmtree(LOGMELFB_O)\n",
    "    \n",
    "if not os.path.exists(RAWWAV_O):\n",
    "    os.mkdir(RAWWAV_O)\n",
    "else:\n",
    "    shutil.rmtree(RAWWAV_O)\n",
    "\n",
    "with open(EER_LOG, 'w') as f:\n",
    "    pass\n",
    "\n",
    "with open(G_LOG, 'w') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = 1\n",
    "config['batch_size'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preloading music_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "preloading noise_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "preloading babble_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "episode 150\n",
      "last episode [1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n"
     ]
    }
   ],
   "source": [
    "def iter_data_preload(dataset, i):\n",
    "    dataset.get_random_list()\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        for count, (rw, fb, mfcc, label) in enumerate(dataset):\n",
    "            file_name = str(i)+str('_')+str(count)\n",
    "            with open(os.path.join(RAWWAV_O, file_name), 'wb') as handle:\n",
    "                pickle.dump((rw.astype(np.float16), label.astype(np.int16)), handle)\n",
    "                \n",
    "            with open(os.path.join(LOGMELFB_O, file_name), 'wb') as handle:\n",
    "                pickle.dump((fb.astype(np.float16), label.astype(np.int16)), handle)\n",
    "                \n",
    "            with open(os.path.join(MFCC_O, file_name), 'wb') as handle:\n",
    "                pickle.dump((mfcc.astype(np.float16), label.astype(np.int16)), handle)\n",
    "            \n",
    "            with open(G_LOG, 'a') as f:\n",
    "                f.write(str(time.time()-start_time)+'\\n')\n",
    "            start_time = time.time()\n",
    "            \n",
    "    except Exception:\n",
    "        with open(EER_LOG, 'a') as f:\n",
    "            traceback.print_exc(file=f)\n",
    "        raise Exception\n",
    "\n",
    "dataset = ThreeTypes_IterableDataset(config, data_dir_dict, data_len_dict)\n",
    "dataset.noise_data_preload()\n",
    "\n",
    "p_list = []\n",
    "for i in range(PROCESS // RUNNING_P):\n",
    "    p_list.append([j for j in range(i*RUNNING_P, i*RUNNING_P+RUNNING_P)])\n",
    "if (PROCESS % RUNNING_P) != 0:\n",
    "    p_list.append([j for j in range((i+1)*RUNNING_P, PROCESS)])\n",
    "\n",
    "print('episode', len(p_list))\n",
    "print('last episode', p_list[-1])\n",
    "\n",
    "start_time = time.time()\n",
    "for ps in p_list:\n",
    "    print(ps[0])\n",
    "    processes = [Process(target = iter_data_preload, args = (dataset, i)) for i in ps]\n",
    "    [p.start() for p in processes]\n",
    "    joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal\n",
    "# config = {}\n",
    "\n",
    "# config['sr'] = 16000\n",
    "# config['repeats'] = 150\n",
    "# config['batch_size'] = 1\n",
    "# config['extended_prefectch'] = 1.0\n",
    "# config['running_p'] = 10\n",
    "# config['out_dir'] = '/Lun0/zhiyong/dataset/test_1/'\n",
    "# config['err_log'] = '/Lun0/zhiyong/dataset/tmp_data_errlog'\n",
    "\n",
    "# def iter_data_preload(dataset, i):\n",
    "#     dataset.get_random_list()\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "#         for count, (data, label) in enumerate(dataset):\n",
    "#             with open(config['out_dir']+str(i)+str('_')+str(count), 'wb') as handle:\n",
    "#                 pickle.dump((data.astype(np.float16), label.astype(np.int16)), handle)\n",
    "# #             print(time.time()-start_time)\n",
    "#             with open(config['err_log'], 'a') as f:\n",
    "#                 f.write(str(time.time()-start_time)+'\\n')\n",
    "#             start_time = time.time()\n",
    "            \n",
    "#             if ((count+1)%10000) == 0:\n",
    "#                 print((count+1)//10000)\n",
    "#     except Exception:\n",
    "#         with open(config['err_log'], 'a') as f:\n",
    "#             traceback.print_exc(file=f)\n",
    "#         raise Exception\n",
    "\n",
    "# dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "# # dataset.noise_data_preload2mem()\n",
    "# dataset.noise_data_preload()\n",
    "\n",
    "# processes = [Process(target = iter_data_preload, args = (dataset, i)) for i in range(config['running_p'])]\n",
    "# start_time = time.time()\n",
    "# [p.start() for p in processes]\n",
    "# joined = [p.join() for p in processes]\n",
    "# print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mfcc_dir = os.path.join(INFO_DIR, 'train_mfcc.csv')\n",
    "train_fb_dir = os.path.join(INFO_DIR, 'train_fb.csv')\n",
    "train_rw_dir = os.path.join(INFO_DIR, 'train_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_len = glob.glob(MFCC_O+'/*')\n",
    "fb_len = glob.glob(LOGMELFB_O+'/*')\n",
    "raw_len = glob.glob(RAWWAV_O+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 1816500\n",
      "fb 1816500\n",
      "raw 1816500\n"
     ]
    }
   ],
   "source": [
    "print('mfcc', len(mfcc_len))\n",
    "print('fb', len(fb_len))\n",
    "print('raw', len(raw_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 1816500\n",
      "fb 1816500\n",
      "raw 1816500\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with open(train_mfcc_dir, 'w') as f:\n",
    "    for path in mfcc_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('mfcc', count)\n",
    "\n",
    "count = 0\n",
    "with open(train_fb_dir, 'w') as f:\n",
    "    for path in fb_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('fb', count)\n",
    "\n",
    "count = 0\n",
    "with open(train_rw_dir, 'w') as f:\n",
    "    for path in raw_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('raw', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1816500"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1211 * 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_MFCC_O = os.path.join(OPT_INDEX, 'VAL_MFCC')\n",
    "VAL_LOGMELFB_O = os.path.join(OPT_INDEX, 'VAL_FB')\n",
    "VAL_RAWWAV_O = os.path.join(OPT_INDEX, 'VAL_RAW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_dict = {}\n",
    "\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(INFO_DIR, 'spk2utt_val_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(AUG_INFO_DIR, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(AUG_INFO_DIR, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(AUG_INFO_DIR, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(AUG_INFO_DIR, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(INFO_DIR, 'spk2utt_val_len')\n",
    "data_len_dict['music_len'] = os.path.join(AUG_INFO_DIR, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(AUG_INFO_DIR, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(AUG_INFO_DIR, 'babble_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(VAL_MFCC_O):\n",
    "    os.mkdir(VAL_MFCC_O)\n",
    "else:\n",
    "    shutil.rmtree(VAL_MFCC_O)\n",
    "    os.mkdir(VAL_MFCC_O)\n",
    "    \n",
    "if not os.path.exists(VAL_LOGMELFB_O):\n",
    "    os.mkdir(VAL_LOGMELFB_O)\n",
    "else:\n",
    "    shutil.rmtree(VAL_LOGMELFB_O)\n",
    "    os.mkdir(VAL_LOGMELFB_O)\n",
    "    \n",
    "if not os.path.exists(VAL_RAWWAV_O):\n",
    "    os.mkdir(VAL_RAWWAV_O)\n",
    "else:\n",
    "    shutil.rmtree(VAL_RAWWAV_O)\n",
    "    os.mkdir(VAL_RAWWAV_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = 5\n",
    "config['batch_size'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preloading music_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "preloading noise_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "preloading babble_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "def iter_data_preload(dataset, i):\n",
    "    dataset.get_random_list()\n",
    "    for count, (rw, fb, mfcc, label) in enumerate(dataset):\n",
    "        file_name = str(i)+str('_')+str(count)\n",
    "        with open(os.path.join(VAL_RAWWAV_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((rw.astype(np.float16), label.astype(np.int16)), handle)\n",
    "\n",
    "        with open(os.path.join(VAL_LOGMELFB_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((fb.astype(np.float16), label.astype(np.int16)), handle)\n",
    "\n",
    "        with open(os.path.join(VAL_MFCC_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((mfcc.astype(np.float16), label.astype(np.int16)), handle)\n",
    "        start_time = time.time()\n",
    "\n",
    "dataset = ThreeTypes_IterableDataset(config, data_dir_dict, data_len_dict)\n",
    "dataset.noise_data_preload()\n",
    "\n",
    "processes = [Process(target = iter_data_preload, args = (dataset, i)) for i in range(1)]\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make validation index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mfcc_dir = os.path.join(INFO_DIR, 'val_mfcc.csv')\n",
    "val_fb_dir = os.path.join(INFO_DIR, 'val_fb.csv')\n",
    "val_rw_dir = os.path.join(INFO_DIR, 'val_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_len = glob.glob(VAL_MFCC_O+'/*')\n",
    "fb_len = glob.glob(VAL_LOGMELFB_O+'/*')\n",
    "raw_len = glob.glob(VAL_RAWWAV_O+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 1000\n",
      "fb 1000\n",
      "raw 1000\n"
     ]
    }
   ],
   "source": [
    "print('mfcc', len(mfcc_len))\n",
    "print('fb', len(fb_len))\n",
    "print('raw', len(raw_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 1000\n",
      "fb 1000\n",
      "raw 1000\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with open(val_mfcc_dir, 'w') as f:\n",
    "    for path in mfcc_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('mfcc', count)\n",
    "\n",
    "count = 0\n",
    "with open(val_fb_dir, 'w') as f:\n",
    "    for path in fb_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('fb', count)\n",
    "\n",
    "count = 0\n",
    "with open(val_rw_dir, 'w') as f:\n",
    "    for path in raw_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('raw', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
