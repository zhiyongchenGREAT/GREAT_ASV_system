{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import traceback\n",
    "import shutil\n",
    "\n",
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = '/workspace/GREAT_ASV_system/'\n",
    "sys.path.append(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPT_INDEX = '/workspace/DATASET/server9/STD_VOX_EGS'\n",
    "if not os.path.exists(OPT_INDEX):\n",
    "    os.mkdir(OPT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOX_TRAIN_DIR = '/workspace/DATASET/server9/voxceleb'\n",
    "AUG_INFO_DIR = '/workspace/DATASET/server9/STD_musan&rir_info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO_DIR = os.path.join(OPT_INDEX, 'VOX_TRIAL_INFO')\n",
    "if not os.path.exists(INFO_DIR):\n",
    "    os.mkdir(INFO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Trials dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial dict\n",
    "trial_dir = os.path.join(VOX_TRAIN_DIR, 'vox1')\n",
    "trial_dict_out = os.path.join(INFO_DIR, 'vox_trial_dict')\n",
    "trial_dict = {}\n",
    "\n",
    "tmp_dir_list = glob.glob(trial_dir+'/*/*/*/*/*.wav')\n",
    "for count, this_dir in enumerate(tmp_dir_list):\n",
    "    trial_dict[count] = this_dir\n",
    "with open(trial_dict_out, 'wb') as handle:\n",
    "    pickle.dump(trial_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153516"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial dict o\n",
    "trial_dir = os.path.join(VOX_TRAIN_DIR, 'vox1')\n",
    "trial_dict_o_out = os.path.join(INFO_DIR, 'vox_trial_dict_o')\n",
    "trial_dict = {}\n",
    "\n",
    "tmp_dir_list = glob.glob(trial_dir+'/test/*/*/*/*.wav')\n",
    "for count, this_dir in enumerate(tmp_dir_list):\n",
    "    trial_dict[count] = this_dir\n",
    "with open(trial_dict_o_out, 'wb') as handle:\n",
    "    pickle.dump(trial_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4874"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trials data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.Utils.preprocessing_3type import ThreeTypes_IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC_O = os.path.join(OPT_INDEX, 'VOX_TRIALS_MFCC')\n",
    "LOGMELFB_O = os.path.join(OPT_INDEX, 'VOX_TRIALS_FB')\n",
    "RAWWAV_O = os.path.join(OPT_INDEX, 'VOX_TRIALS_RAW')\n",
    "EER_LOG = os.path.join(OPT_INDEX, 'EER_LOG_VOX_TRIAL')\n",
    "G_LOG = os.path.join(OPT_INDEX, 'G_LOG_VOX_TRIAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MFCC_O):\n",
    "    os.mkdir(MFCC_O)\n",
    "else:\n",
    "    shutil.rmtree(MFCC_O)\n",
    "    \n",
    "if not os.path.exists(LOGMELFB_O):\n",
    "    os.mkdir(LOGMELFB_O)\n",
    "else:\n",
    "    shutil.rmtree(LOGMELFB_O)\n",
    "    \n",
    "if not os.path.exists(RAWWAV_O):\n",
    "    os.mkdir(RAWWAV_O)\n",
    "else:\n",
    "    shutil.rmtree(RAWWAV_O)\n",
    "\n",
    "with open(EER_LOG, 'w') as f:\n",
    "    pass\n",
    "\n",
    "with open(G_LOG, 'w') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = 1\n",
    "config['batch_size'] = 1\n",
    "\n",
    "trial_dict_dir = os.path.join(INFO_DIR, 'vox_trial_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_feats_rawwave, batched_feats_LogMelFB, batched_feats_MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "25268.819949150085\n"
     ]
    }
   ],
   "source": [
    "def trial_data_preload(dataset, i, trial_dict_dir):\n",
    "    with open(trial_dict_dir, 'rb') as handle:\n",
    "        trial_dict = pickle.load(handle)\n",
    "        \n",
    "    start_time = time.time()\n",
    "    for count, i in enumerate(trial_dict):\n",
    "        rw, fb, mfcc = dataset.process_one_utt(trial_dict[i])\n",
    "        lbpart = trial_dict[i].split('/')[-3:]\n",
    "        lbpart = lbpart[0]+'-'+lbpart[1]+'-'+lbpart[2]\n",
    "        label = lbpart[:-4]\n",
    "        \n",
    "        file_name = str(i)\n",
    "        with open(os.path.join(RAWWAV_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((rw.astype(np.float16), [label]), handle)\n",
    "        with open(os.path.join(LOGMELFB_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((fb.astype(np.float16), [label]), handle)\n",
    "        with open(os.path.join(MFCC_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((mfcc.astype(np.float16), [label]), handle)        \n",
    "        if (count+1) % 5000 == 0:\n",
    "            print(count+1)\n",
    "\n",
    "dataset = ThreeTypes_IterableDataset(config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, trial_dict_dir)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trials index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_mfcc_dir = os.path.join(INFO_DIR, 'trials_mfcc.csv')\n",
    "trials_fb_dir = os.path.join(INFO_DIR, 'trials_fb.csv')\n",
    "trials_rw_dir = os.path.join(INFO_DIR, 'trials_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_len = glob.glob(MFCC_O+'/*')\n",
    "fb_len = glob.glob(LOGMELFB_O+'/*')\n",
    "raw_len = glob.glob(RAWWAV_O+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 153516\n",
      "fb 153516\n",
      "raw 153516\n"
     ]
    }
   ],
   "source": [
    "print('mfcc', len(mfcc_len))\n",
    "print('fb', len(fb_len))\n",
    "print('raw', len(raw_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 153516\n",
      "fb 153516\n",
      "raw 153516\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with open(trials_mfcc_dir, 'w') as f:\n",
    "    for path in mfcc_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('mfcc', count)\n",
    "\n",
    "count = 0\n",
    "with open(trials_fb_dir, 'w') as f:\n",
    "    for path in fb_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('fb', count)\n",
    "\n",
    "count = 0\n",
    "with open(trials_rw_dir, 'w') as f:\n",
    "    for path in raw_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('raw', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trials data o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.Utils.preprocessing_3type import ThreeTypes_IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC_O = os.path.join(OPT_INDEX, 'VOX_TRIALS_MFCC_O')\n",
    "LOGMELFB_O = os.path.join(OPT_INDEX, 'VOX_TRIALS_FB_O')\n",
    "RAWWAV_O = os.path.join(OPT_INDEX, 'VOX_TRIALS_RAW_O')\n",
    "EER_LOG = os.path.join(OPT_INDEX, 'EER_LOG_VOX_TRIAL_O')\n",
    "G_LOG = os.path.join(OPT_INDEX, 'G_LOG_VOX_TRIAL_O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MFCC_O):\n",
    "    os.mkdir(MFCC_O)\n",
    "else:\n",
    "    shutil.rmtree(MFCC_O)\n",
    "    \n",
    "if not os.path.exists(LOGMELFB_O):\n",
    "    os.mkdir(LOGMELFB_O)\n",
    "else:\n",
    "    shutil.rmtree(LOGMELFB_O)\n",
    "    \n",
    "if not os.path.exists(RAWWAV_O):\n",
    "    os.mkdir(RAWWAV_O)\n",
    "else:\n",
    "    shutil.rmtree(RAWWAV_O)\n",
    "\n",
    "with open(EER_LOG, 'w') as f:\n",
    "    pass\n",
    "\n",
    "with open(G_LOG, 'w') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = 1\n",
    "config['batch_size'] = 1\n",
    "\n",
    "trial_dict_dir = os.path.join(INFO_DIR, 'vox_trial_dict_o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "def trial_data_preload(dataset, i, trial_dict_dir):\n",
    "    with open(trial_dict_dir, 'rb') as handle:\n",
    "        trial_dict = pickle.load(handle)\n",
    "        \n",
    "    start_time = time.time()\n",
    "    for count, i in enumerate(trial_dict):\n",
    "        rw, fb, mfcc = dataset.process_one_utt(trial_dict[i])\n",
    "        lbpart = trial_dict[i].split('/')[-3:]\n",
    "        lbpart = lbpart[0]+'-'+lbpart[1]+'-'+lbpart[2]\n",
    "        label = lbpart[:-4]\n",
    "        \n",
    "        file_name = str(i)\n",
    "        with open(os.path.join(RAWWAV_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((rw.astype(np.float16), [label]), handle)\n",
    "        with open(os.path.join(LOGMELFB_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((fb.astype(np.float16), [label]), handle)\n",
    "        with open(os.path.join(MFCC_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((mfcc.astype(np.float16), [label]), handle)        \n",
    "        if (count+1) % 1000 == 0:\n",
    "            print(count+1)\n",
    "\n",
    "dataset = ThreeTypes_IterableDataset(config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, trial_dict_dir)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trials index o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_mfcc_dir = os.path.join(INFO_DIR, 'trials_mfcc_o.csv')\n",
    "trials_fb_dir = os.path.join(INFO_DIR, 'trials_fb_o.csv')\n",
    "trials_rw_dir = os.path.join(INFO_DIR, 'trials_raw_o.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_len = glob.glob(MFCC_O+'/*')\n",
    "fb_len = glob.glob(LOGMELFB_O+'/*')\n",
    "raw_len = glob.glob(RAWWAV_O+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 4874\n",
      "fb 4874\n",
      "raw 4874\n"
     ]
    }
   ],
   "source": [
    "print('mfcc', len(mfcc_len))\n",
    "print('fb', len(fb_len))\n",
    "print('raw', len(raw_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 4874\n",
      "fb 4874\n",
      "raw 4874\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with open(trials_mfcc_dir, 'w') as f:\n",
    "    for path in mfcc_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('mfcc', count)\n",
    "\n",
    "count = 0\n",
    "with open(trials_fb_dir, 'w') as f:\n",
    "    for path in fb_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('fb', count)\n",
    "\n",
    "count = 0\n",
    "with open(trials_rw_dir, 'w') as f:\n",
    "    for path in raw_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('raw', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trial keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vox_trials_o_dir = os.path.join(INFO_DIR, 'vox_trials_o')\n",
    "vox_trials_e_dir = os.path.join(INFO_DIR, 'vox_trials_e')\n",
    "vox_trials_h_dir = os.path.join(INFO_DIR, 'vox_trials_h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_vox_trials_o_dir = os.path.join(INFO_DIR, 'ORI_veri_test2.txt')\n",
    "ori_vox_trials_e_dir = os.path.join(INFO_DIR, 'ORI_list_test_all2.txt')\n",
    "ori_vox_trials_h_dir = os.path.join(INFO_DIR, 'ORI_list_test_hard2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vox_o 37611\n"
     ]
    }
   ],
   "source": [
    "with open(ori_vox_trials_o_dir, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(vox_trials_o_dir, 'w') as f:\n",
    "    for count, line in enumerate(lines):\n",
    "        cmp = line[:-1].split(' ')\n",
    "        if cmp[0] == '0':\n",
    "            cmp_a = cmp[1].split('/')\n",
    "            out_1 = cmp_a[0]+'-'+cmp_a[1]+'-'+cmp_a[2]\n",
    "            cmp_b = cmp[2].split('/')\n",
    "            out_2 = cmp_b[0]+'-'+cmp_b[1]+'-'+cmp_b[2]\n",
    "            out_3 = 'nontarget'\n",
    "            out = out_1+' '+out_2+' '+out_3+'\\n'\n",
    "        else:\n",
    "            cmp_a = cmp[1].split('/')\n",
    "            out_1 = cmp_a[0]+'-'+cmp_a[1]+'-'+cmp_a[2]\n",
    "            cmp_b = cmp[2].split('/')\n",
    "            out_2 = cmp_b[0]+'-'+cmp_b[1]+'-'+cmp_b[2]\n",
    "            out_3 = 'target'\n",
    "            out = out_1+' '+out_2+' '+out_3+'\\n'\n",
    "        f.write(out)\n",
    "print('vox_o', count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vox_e 579818\n"
     ]
    }
   ],
   "source": [
    "with open(ori_vox_trials_e_dir, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(vox_trials_e_dir, 'w') as f:\n",
    "    for count, line in enumerate(lines):\n",
    "        cmp = line[:-1].split(' ')\n",
    "        if cmp[0] == '0':\n",
    "            cmp_a = cmp[1].split('/')\n",
    "            out_1 = cmp_a[0]+'-'+cmp_a[1]+'-'+cmp_a[2]\n",
    "            cmp_b = cmp[2].split('/')\n",
    "            out_2 = cmp_b[0]+'-'+cmp_b[1]+'-'+cmp_b[2]\n",
    "            out_3 = 'nontarget'\n",
    "            out = out_1+' '+out_2+' '+out_3+'\\n'\n",
    "        else:\n",
    "            cmp_a = cmp[1].split('/')\n",
    "            out_1 = cmp_a[0]+'-'+cmp_a[1]+'-'+cmp_a[2]\n",
    "            cmp_b = cmp[2].split('/')\n",
    "            out_2 = cmp_b[0]+'-'+cmp_b[1]+'-'+cmp_b[2]\n",
    "            out_3 = 'target'\n",
    "            out = out_1+' '+out_2+' '+out_3+'\\n'\n",
    "        f.write(out)\n",
    "print('vox_e', count+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vox_h 550894\n"
     ]
    }
   ],
   "source": [
    "with open(ori_vox_trials_h_dir, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(vox_trials_h_dir, 'w') as f:\n",
    "    for count, line in enumerate(lines):\n",
    "        cmp = line[:-1].split(' ')\n",
    "        if cmp[0] == '0':\n",
    "            cmp_a = cmp[1].split('/')\n",
    "            out_1 = cmp_a[0]+'-'+cmp_a[1]+'-'+cmp_a[2]\n",
    "            cmp_b = cmp[2].split('/')\n",
    "            out_2 = cmp_b[0]+'-'+cmp_b[1]+'-'+cmp_b[2]\n",
    "            out_3 = 'nontarget'\n",
    "            out = out_1+' '+out_2+' '+out_3+'\\n'\n",
    "        else:\n",
    "            cmp_a = cmp[1].split('/')\n",
    "            out_1 = cmp_a[0]+'-'+cmp_a[1]+'-'+cmp_a[2]\n",
    "            cmp_b = cmp[2].split('/')\n",
    "            out_2 = cmp_b[0]+'-'+cmp_b[1]+'-'+cmp_b[2]\n",
    "            out_3 = 'target'\n",
    "            out = out_1+' '+out_2+' '+out_3+'\\n'\n",
    "        f.write(out)\n",
    "print('vox_h', count+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
