{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import traceback\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make file index dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPT_INDEX = '/Lun0/zhiyong/libri'\n",
    "# data_dir = '/Lun0/zhiyong/dataset/vox2/dev/aac'\n",
    "# data_dir_1 = '/Lun0/zhiyong/dataset/vox1/dev/wav'\n",
    "# data_dir_2test = '/Lun0/zhiyong/dataset/vox2/test/aac'\n",
    "data_dir_100 = '/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-100'\n",
    "data_dir_360 = '/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360'\n",
    "data_dir_o500 = '/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-other-500'\n",
    "new_start_id = 7911 #vox with 0-7322 in with 7323-7910\n",
    "\n",
    "\n",
    "spk2id = os.path.join(OPT_INDEX, 'spk2id')\n",
    "spk2utt_dict = os.path.join(OPT_INDEX, 'spk2utt_dict')\n",
    "spk2utt_train_dict = os.path.join(OPT_INDEX, 'spk2utt_train_dict')\n",
    "# spk2utt_val_dict = os.path.join(OPT_INDEX, 'spk2utt_val_dict')\n",
    "# val_utt_num = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spk2utt = {}\n",
    "# spk2utt_train = {}\n",
    "# spk2utt_val = {}\n",
    "\n",
    "with open(spk2id, 'w') as f:\n",
    "    pass\n",
    "\n",
    "label_dir = glob.glob(data_dir_100+'/*')\n",
    "label = [i.split('/')[-1] for i in label_dir]\n",
    "\n",
    "label_dir = glob.glob(data_dir_360+'/*')\n",
    "label_1 = [i.split('/')[-1] for i in label_dir]\n",
    "\n",
    "label_dir = glob.glob(data_dir_o500+'/*')\n",
    "label_2 = [i.split('/')[-1] for i in label_dir]\n",
    "\n",
    "for count, i in enumerate(label):\n",
    "    with open(spk2id, 'a') as f:\n",
    "        f.write(str(count+new_start_id)+','+i+'\\n')\n",
    "    spk2utt[count+new_start_id] = glob.glob(os.path.join(data_dir_100, i)+'/*/*.flac')\n",
    "\n",
    "for count_1, i in enumerate(label_1):\n",
    "    with open(spk2id, 'a') as f:\n",
    "        f.write(str(new_start_id+count+1+count_1)+','+i+'\\n')\n",
    "    spk2utt[new_start_id+count+1+count_1] = glob.glob(os.path.join(data_dir_360, i)+'/*/*.flac')\n",
    "\n",
    "for count_2, i in enumerate(label_2):\n",
    "    with open(spk2id, 'a') as f:\n",
    "        f.write(str(new_start_id+count+1+count_1+1+count_2)+','+i+'\\n')\n",
    "    spk2utt[new_start_id+count+1+count_1+1+count_2] = glob.glob(os.path.join(data_dir_o500, i)+'/*/*.flac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2338"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be class:\n",
    "251+921+1166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10248"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7910 + 2338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2338"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spk2utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([7911, 7912, 7913, 7914, 7915, 7916, 7917, 7918, 7919, 7920, 7921, 7922, 7923, 7924, 7925, 7926, 7927, 7928, 7929, 7930, 7931, 7932, 7933, 7934, 7935, 7936, 7937, 7938, 7939, 7940, 7941, 7942, 7943, 7944, 7945, 7946, 7947, 7948, 7949, 7950, 7951, 7952, 7953, 7954, 7955, 7956, 7957, 7958, 7959, 7960, 7961, 7962, 7963, 7964, 7965, 7966, 7967, 7968, 7969, 7970, 7971, 7972, 7973, 7974, 7975, 7976, 7977, 7978, 7979, 7980, 7981, 7982, 7983, 7984, 7985, 7986, 7987, 7988, 7989, 7990, 7991, 7992, 7993, 7994, 7995, 7996, 7997, 7998, 7999, 8000, 8001, 8002, 8003, 8004, 8005, 8006, 8007, 8008, 8009, 8010, 8011, 8012, 8013, 8014, 8015, 8016, 8017, 8018, 8019, 8020, 8021, 8022, 8023, 8024, 8025, 8026, 8027, 8028, 8029, 8030, 8031, 8032, 8033, 8034, 8035, 8036, 8037, 8038, 8039, 8040, 8041, 8042, 8043, 8044, 8045, 8046, 8047, 8048, 8049, 8050, 8051, 8052, 8053, 8054, 8055, 8056, 8057, 8058, 8059, 8060, 8061, 8062, 8063, 8064, 8065, 8066, 8067, 8068, 8069, 8070, 8071, 8072, 8073, 8074, 8075, 8076, 8077, 8078, 8079, 8080, 8081, 8082, 8083, 8084, 8085, 8086, 8087, 8088, 8089, 8090, 8091, 8092, 8093, 8094, 8095, 8096, 8097, 8098, 8099, 8100, 8101, 8102, 8103, 8104, 8105, 8106, 8107, 8108, 8109, 8110, 8111, 8112, 8113, 8114, 8115, 8116, 8117, 8118, 8119, 8120, 8121, 8122, 8123, 8124, 8125, 8126, 8127, 8128, 8129, 8130, 8131, 8132, 8133, 8134, 8135, 8136, 8137, 8138, 8139, 8140, 8141, 8142, 8143, 8144, 8145, 8146, 8147, 8148, 8149, 8150, 8151, 8152, 8153, 8154, 8155, 8156, 8157, 8158, 8159, 8160, 8161, 8162, 8163, 8164, 8165, 8166, 8167, 8168, 8169, 8170, 8171, 8172, 8173, 8174, 8175, 8176, 8177, 8178, 8179, 8180, 8181, 8182, 8183, 8184, 8185, 8186, 8187, 8188, 8189, 8190, 8191, 8192, 8193, 8194, 8195, 8196, 8197, 8198, 8199, 8200, 8201, 8202, 8203, 8204, 8205, 8206, 8207, 8208, 8209, 8210, 8211, 8212, 8213, 8214, 8215, 8216, 8217, 8218, 8219, 8220, 8221, 8222, 8223, 8224, 8225, 8226, 8227, 8228, 8229, 8230, 8231, 8232, 8233, 8234, 8235, 8236, 8237, 8238, 8239, 8240, 8241, 8242, 8243, 8244, 8245, 8246, 8247, 8248, 8249, 8250, 8251, 8252, 8253, 8254, 8255, 8256, 8257, 8258, 8259, 8260, 8261, 8262, 8263, 8264, 8265, 8266, 8267, 8268, 8269, 8270, 8271, 8272, 8273, 8274, 8275, 8276, 8277, 8278, 8279, 8280, 8281, 8282, 8283, 8284, 8285, 8286, 8287, 8288, 8289, 8290, 8291, 8292, 8293, 8294, 8295, 8296, 8297, 8298, 8299, 8300, 8301, 8302, 8303, 8304, 8305, 8306, 8307, 8308, 8309, 8310, 8311, 8312, 8313, 8314, 8315, 8316, 8317, 8318, 8319, 8320, 8321, 8322, 8323, 8324, 8325, 8326, 8327, 8328, 8329, 8330, 8331, 8332, 8333, 8334, 8335, 8336, 8337, 8338, 8339, 8340, 8341, 8342, 8343, 8344, 8345, 8346, 8347, 8348, 8349, 8350, 8351, 8352, 8353, 8354, 8355, 8356, 8357, 8358, 8359, 8360, 8361, 8362, 8363, 8364, 8365, 8366, 8367, 8368, 8369, 8370, 8371, 8372, 8373, 8374, 8375, 8376, 8377, 8378, 8379, 8380, 8381, 8382, 8383, 8384, 8385, 8386, 8387, 8388, 8389, 8390, 8391, 8392, 8393, 8394, 8395, 8396, 8397, 8398, 8399, 8400, 8401, 8402, 8403, 8404, 8405, 8406, 8407, 8408, 8409, 8410, 8411, 8412, 8413, 8414, 8415, 8416, 8417, 8418, 8419, 8420, 8421, 8422, 8423, 8424, 8425, 8426, 8427, 8428, 8429, 8430, 8431, 8432, 8433, 8434, 8435, 8436, 8437, 8438, 8439, 8440, 8441, 8442, 8443, 8444, 8445, 8446, 8447, 8448, 8449, 8450, 8451, 8452, 8453, 8454, 8455, 8456, 8457, 8458, 8459, 8460, 8461, 8462, 8463, 8464, 8465, 8466, 8467, 8468, 8469, 8470, 8471, 8472, 8473, 8474, 8475, 8476, 8477, 8478, 8479, 8480, 8481, 8482, 8483, 8484, 8485, 8486, 8487, 8488, 8489, 8490, 8491, 8492, 8493, 8494, 8495, 8496, 8497, 8498, 8499, 8500, 8501, 8502, 8503, 8504, 8505, 8506, 8507, 8508, 8509, 8510, 8511, 8512, 8513, 8514, 8515, 8516, 8517, 8518, 8519, 8520, 8521, 8522, 8523, 8524, 8525, 8526, 8527, 8528, 8529, 8530, 8531, 8532, 8533, 8534, 8535, 8536, 8537, 8538, 8539, 8540, 8541, 8542, 8543, 8544, 8545, 8546, 8547, 8548, 8549, 8550, 8551, 8552, 8553, 8554, 8555, 8556, 8557, 8558, 8559, 8560, 8561, 8562, 8563, 8564, 8565, 8566, 8567, 8568, 8569, 8570, 8571, 8572, 8573, 8574, 8575, 8576, 8577, 8578, 8579, 8580, 8581, 8582, 8583, 8584, 8585, 8586, 8587, 8588, 8589, 8590, 8591, 8592, 8593, 8594, 8595, 8596, 8597, 8598, 8599, 8600, 8601, 8602, 8603, 8604, 8605, 8606, 8607, 8608, 8609, 8610, 8611, 8612, 8613, 8614, 8615, 8616, 8617, 8618, 8619, 8620, 8621, 8622, 8623, 8624, 8625, 8626, 8627, 8628, 8629, 8630, 8631, 8632, 8633, 8634, 8635, 8636, 8637, 8638, 8639, 8640, 8641, 8642, 8643, 8644, 8645, 8646, 8647, 8648, 8649, 8650, 8651, 8652, 8653, 8654, 8655, 8656, 8657, 8658, 8659, 8660, 8661, 8662, 8663, 8664, 8665, 8666, 8667, 8668, 8669, 8670, 8671, 8672, 8673, 8674, 8675, 8676, 8677, 8678, 8679, 8680, 8681, 8682, 8683, 8684, 8685, 8686, 8687, 8688, 8689, 8690, 8691, 8692, 8693, 8694, 8695, 8696, 8697, 8698, 8699, 8700, 8701, 8702, 8703, 8704, 8705, 8706, 8707, 8708, 8709, 8710, 8711, 8712, 8713, 8714, 8715, 8716, 8717, 8718, 8719, 8720, 8721, 8722, 8723, 8724, 8725, 8726, 8727, 8728, 8729, 8730, 8731, 8732, 8733, 8734, 8735, 8736, 8737, 8738, 8739, 8740, 8741, 8742, 8743, 8744, 8745, 8746, 8747, 8748, 8749, 8750, 8751, 8752, 8753, 8754, 8755, 8756, 8757, 8758, 8759, 8760, 8761, 8762, 8763, 8764, 8765, 8766, 8767, 8768, 8769, 8770, 8771, 8772, 8773, 8774, 8775, 8776, 8777, 8778, 8779, 8780, 8781, 8782, 8783, 8784, 8785, 8786, 8787, 8788, 8789, 8790, 8791, 8792, 8793, 8794, 8795, 8796, 8797, 8798, 8799, 8800, 8801, 8802, 8803, 8804, 8805, 8806, 8807, 8808, 8809, 8810, 8811, 8812, 8813, 8814, 8815, 8816, 8817, 8818, 8819, 8820, 8821, 8822, 8823, 8824, 8825, 8826, 8827, 8828, 8829, 8830, 8831, 8832, 8833, 8834, 8835, 8836, 8837, 8838, 8839, 8840, 8841, 8842, 8843, 8844, 8845, 8846, 8847, 8848, 8849, 8850, 8851, 8852, 8853, 8854, 8855, 8856, 8857, 8858, 8859, 8860, 8861, 8862, 8863, 8864, 8865, 8866, 8867, 8868, 8869, 8870, 8871, 8872, 8873, 8874, 8875, 8876, 8877, 8878, 8879, 8880, 8881, 8882, 8883, 8884, 8885, 8886, 8887, 8888, 8889, 8890, 8891, 8892, 8893, 8894, 8895, 8896, 8897, 8898, 8899, 8900, 8901, 8902, 8903, 8904, 8905, 8906, 8907, 8908, 8909, 8910, 8911, 8912, 8913, 8914, 8915, 8916, 8917, 8918, 8919, 8920, 8921, 8922, 8923, 8924, 8925, 8926, 8927, 8928, 8929, 8930, 8931, 8932, 8933, 8934, 8935, 8936, 8937, 8938, 8939, 8940, 8941, 8942, 8943, 8944, 8945, 8946, 8947, 8948, 8949, 8950, 8951, 8952, 8953, 8954, 8955, 8956, 8957, 8958, 8959, 8960, 8961, 8962, 8963, 8964, 8965, 8966, 8967, 8968, 8969, 8970, 8971, 8972, 8973, 8974, 8975, 8976, 8977, 8978, 8979, 8980, 8981, 8982, 8983, 8984, 8985, 8986, 8987, 8988, 8989, 8990, 8991, 8992, 8993, 8994, 8995, 8996, 8997, 8998, 8999, 9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016, 9017, 9018, 9019, 9020, 9021, 9022, 9023, 9024, 9025, 9026, 9027, 9028, 9029, 9030, 9031, 9032, 9033, 9034, 9035, 9036, 9037, 9038, 9039, 9040, 9041, 9042, 9043, 9044, 9045, 9046, 9047, 9048, 9049, 9050, 9051, 9052, 9053, 9054, 9055, 9056, 9057, 9058, 9059, 9060, 9061, 9062, 9063, 9064, 9065, 9066, 9067, 9068, 9069, 9070, 9071, 9072, 9073, 9074, 9075, 9076, 9077, 9078, 9079, 9080, 9081, 9082, 9083, 9084, 9085, 9086, 9087, 9088, 9089, 9090, 9091, 9092, 9093, 9094, 9095, 9096, 9097, 9098, 9099, 9100, 9101, 9102, 9103, 9104, 9105, 9106, 9107, 9108, 9109, 9110, 9111, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9120, 9121, 9122, 9123, 9124, 9125, 9126, 9127, 9128, 9129, 9130, 9131, 9132, 9133, 9134, 9135, 9136, 9137, 9138, 9139, 9140, 9141, 9142, 9143, 9144, 9145, 9146, 9147, 9148, 9149, 9150, 9151, 9152, 9153, 9154, 9155, 9156, 9157, 9158, 9159, 9160, 9161, 9162, 9163, 9164, 9165, 9166, 9167, 9168, 9169, 9170, 9171, 9172, 9173, 9174, 9175, 9176, 9177, 9178, 9179, 9180, 9181, 9182, 9183, 9184, 9185, 9186, 9187, 9188, 9189, 9190, 9191, 9192, 9193, 9194, 9195, 9196, 9197, 9198, 9199, 9200, 9201, 9202, 9203, 9204, 9205, 9206, 9207, 9208, 9209, 9210, 9211, 9212, 9213, 9214, 9215, 9216, 9217, 9218, 9219, 9220, 9221, 9222, 9223, 9224, 9225, 9226, 9227, 9228, 9229, 9230, 9231, 9232, 9233, 9234, 9235, 9236, 9237, 9238, 9239, 9240, 9241, 9242, 9243, 9244, 9245, 9246, 9247, 9248, 9249, 9250, 9251, 9252, 9253, 9254, 9255, 9256, 9257, 9258, 9259, 9260, 9261, 9262, 9263, 9264, 9265, 9266, 9267, 9268, 9269, 9270, 9271, 9272, 9273, 9274, 9275, 9276, 9277, 9278, 9279, 9280, 9281, 9282, 9283, 9284, 9285, 9286, 9287, 9288, 9289, 9290, 9291, 9292, 9293, 9294, 9295, 9296, 9297, 9298, 9299, 9300, 9301, 9302, 9303, 9304, 9305, 9306, 9307, 9308, 9309, 9310, 9311, 9312, 9313, 9314, 9315, 9316, 9317, 9318, 9319, 9320, 9321, 9322, 9323, 9324, 9325, 9326, 9327, 9328, 9329, 9330, 9331, 9332, 9333, 9334, 9335, 9336, 9337, 9338, 9339, 9340, 9341, 9342, 9343, 9344, 9345, 9346, 9347, 9348, 9349, 9350, 9351, 9352, 9353, 9354, 9355, 9356, 9357, 9358, 9359, 9360, 9361, 9362, 9363, 9364, 9365, 9366, 9367, 9368, 9369, 9370, 9371, 9372, 9373, 9374, 9375, 9376, 9377, 9378, 9379, 9380, 9381, 9382, 9383, 9384, 9385, 9386, 9387, 9388, 9389, 9390, 9391, 9392, 9393, 9394, 9395, 9396, 9397, 9398, 9399, 9400, 9401, 9402, 9403, 9404, 9405, 9406, 9407, 9408, 9409, 9410, 9411, 9412, 9413, 9414, 9415, 9416, 9417, 9418, 9419, 9420, 9421, 9422, 9423, 9424, 9425, 9426, 9427, 9428, 9429, 9430, 9431, 9432, 9433, 9434, 9435, 9436, 9437, 9438, 9439, 9440, 9441, 9442, 9443, 9444, 9445, 9446, 9447, 9448, 9449, 9450, 9451, 9452, 9453, 9454, 9455, 9456, 9457, 9458, 9459, 9460, 9461, 9462, 9463, 9464, 9465, 9466, 9467, 9468, 9469, 9470, 9471, 9472, 9473, 9474, 9475, 9476, 9477, 9478, 9479, 9480, 9481, 9482, 9483, 9484, 9485, 9486, 9487, 9488, 9489, 9490, 9491, 9492, 9493, 9494, 9495, 9496, 9497, 9498, 9499, 9500, 9501, 9502, 9503, 9504, 9505, 9506, 9507, 9508, 9509, 9510, 9511, 9512, 9513, 9514, 9515, 9516, 9517, 9518, 9519, 9520, 9521, 9522, 9523, 9524, 9525, 9526, 9527, 9528, 9529, 9530, 9531, 9532, 9533, 9534, 9535, 9536, 9537, 9538, 9539, 9540, 9541, 9542, 9543, 9544, 9545, 9546, 9547, 9548, 9549, 9550, 9551, 9552, 9553, 9554, 9555, 9556, 9557, 9558, 9559, 9560, 9561, 9562, 9563, 9564, 9565, 9566, 9567, 9568, 9569, 9570, 9571, 9572, 9573, 9574, 9575, 9576, 9577, 9578, 9579, 9580, 9581, 9582, 9583, 9584, 9585, 9586, 9587, 9588, 9589, 9590, 9591, 9592, 9593, 9594, 9595, 9596, 9597, 9598, 9599, 9600, 9601, 9602, 9603, 9604, 9605, 9606, 9607, 9608, 9609, 9610, 9611, 9612, 9613, 9614, 9615, 9616, 9617, 9618, 9619, 9620, 9621, 9622, 9623, 9624, 9625, 9626, 9627, 9628, 9629, 9630, 9631, 9632, 9633, 9634, 9635, 9636, 9637, 9638, 9639, 9640, 9641, 9642, 9643, 9644, 9645, 9646, 9647, 9648, 9649, 9650, 9651, 9652, 9653, 9654, 9655, 9656, 9657, 9658, 9659, 9660, 9661, 9662, 9663, 9664, 9665, 9666, 9667, 9668, 9669, 9670, 9671, 9672, 9673, 9674, 9675, 9676, 9677, 9678, 9679, 9680, 9681, 9682, 9683, 9684, 9685, 9686, 9687, 9688, 9689, 9690, 9691, 9692, 9693, 9694, 9695, 9696, 9697, 9698, 9699, 9700, 9701, 9702, 9703, 9704, 9705, 9706, 9707, 9708, 9709, 9710, 9711, 9712, 9713, 9714, 9715, 9716, 9717, 9718, 9719, 9720, 9721, 9722, 9723, 9724, 9725, 9726, 9727, 9728, 9729, 9730, 9731, 9732, 9733, 9734, 9735, 9736, 9737, 9738, 9739, 9740, 9741, 9742, 9743, 9744, 9745, 9746, 9747, 9748, 9749, 9750, 9751, 9752, 9753, 9754, 9755, 9756, 9757, 9758, 9759, 9760, 9761, 9762, 9763, 9764, 9765, 9766, 9767, 9768, 9769, 9770, 9771, 9772, 9773, 9774, 9775, 9776, 9777, 9778, 9779, 9780, 9781, 9782, 9783, 9784, 9785, 9786, 9787, 9788, 9789, 9790, 9791, 9792, 9793, 9794, 9795, 9796, 9797, 9798, 9799, 9800, 9801, 9802, 9803, 9804, 9805, 9806, 9807, 9808, 9809, 9810, 9811, 9812, 9813, 9814, 9815, 9816, 9817, 9818, 9819, 9820, 9821, 9822, 9823, 9824, 9825, 9826, 9827, 9828, 9829, 9830, 9831, 9832, 9833, 9834, 9835, 9836, 9837, 9838, 9839, 9840, 9841, 9842, 9843, 9844, 9845, 9846, 9847, 9848, 9849, 9850, 9851, 9852, 9853, 9854, 9855, 9856, 9857, 9858, 9859, 9860, 9861, 9862, 9863, 9864, 9865, 9866, 9867, 9868, 9869, 9870, 9871, 9872, 9873, 9874, 9875, 9876, 9877, 9878, 9879, 9880, 9881, 9882, 9883, 9884, 9885, 9886, 9887, 9888, 9889, 9890, 9891, 9892, 9893, 9894, 9895, 9896, 9897, 9898, 9899, 9900, 9901, 9902, 9903, 9904, 9905, 9906, 9907, 9908, 9909, 9910, 9911, 9912, 9913, 9914, 9915, 9916, 9917, 9918, 9919, 9920, 9921, 9922, 9923, 9924, 9925, 9926, 9927, 9928, 9929, 9930, 9931, 9932, 9933, 9934, 9935, 9936, 9937, 9938, 9939, 9940, 9941, 9942, 9943, 9944, 9945, 9946, 9947, 9948, 9949, 9950, 9951, 9952, 9953, 9954, 9955, 9956, 9957, 9958, 9959, 9960, 9961, 9962, 9963, 9964, 9965, 9966, 9967, 9968, 9969, 9970, 9971, 9972, 9973, 9974, 9975, 9976, 9977, 9978, 9979, 9980, 9981, 9982, 9983, 9984, 9985, 9986, 9987, 9988, 9989, 9990, 9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000, 10001, 10002, 10003, 10004, 10005, 10006, 10007, 10008, 10009, 10010, 10011, 10012, 10013, 10014, 10015, 10016, 10017, 10018, 10019, 10020, 10021, 10022, 10023, 10024, 10025, 10026, 10027, 10028, 10029, 10030, 10031, 10032, 10033, 10034, 10035, 10036, 10037, 10038, 10039, 10040, 10041, 10042, 10043, 10044, 10045, 10046, 10047, 10048, 10049, 10050, 10051, 10052, 10053, 10054, 10055, 10056, 10057, 10058, 10059, 10060, 10061, 10062, 10063, 10064, 10065, 10066, 10067, 10068, 10069, 10070, 10071, 10072, 10073, 10074, 10075, 10076, 10077, 10078, 10079, 10080, 10081, 10082, 10083, 10084, 10085, 10086, 10087, 10088, 10089, 10090, 10091, 10092, 10093, 10094, 10095, 10096, 10097, 10098, 10099, 10100, 10101, 10102, 10103, 10104, 10105, 10106, 10107, 10108, 10109, 10110, 10111, 10112, 10113, 10114, 10115, 10116, 10117, 10118, 10119, 10120, 10121, 10122, 10123, 10124, 10125, 10126, 10127, 10128, 10129, 10130, 10131, 10132, 10133, 10134, 10135, 10136, 10137, 10138, 10139, 10140, 10141, 10142, 10143, 10144, 10145, 10146, 10147, 10148, 10149, 10150, 10151, 10152, 10153, 10154, 10155, 10156, 10157, 10158, 10159, 10160, 10161, 10162, 10163, 10164, 10165, 10166, 10167, 10168, 10169, 10170, 10171, 10172, 10173, 10174, 10175, 10176, 10177, 10178, 10179, 10180, 10181, 10182, 10183, 10184, 10185, 10186, 10187, 10188, 10189, 10190, 10191, 10192, 10193, 10194, 10195, 10196, 10197, 10198, 10199, 10200, 10201, 10202, 10203, 10204, 10205, 10206, 10207, 10208, 10209, 10210, 10211, 10212, 10213, 10214, 10215, 10216, 10217, 10218, 10219, 10220, 10221, 10222, 10223, 10224, 10225, 10226, 10227, 10228, 10229, 10230, 10231, 10232, 10233, 10234, 10235, 10236, 10237, 10238, 10239, 10240, 10241, 10242, 10243, 10244, 10245, 10246, 10247, 10248])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spk2utt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281241\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "count_list = []\n",
    "for i in spk2utt:\n",
    "    count += len(spk2utt[i])\n",
    "    count_list.append(len(spk2utt[i]))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(spk2utt_dict, 'wb') as handle:\n",
    "    pickle.dump(spk2utt, handle)\n",
    "\n",
    "with open(spk2utt_dict, 'rb') as handle:\n",
    "    spk2utt = pickle.load(handle)\n",
    "spk2utt_train = spk2utt\n",
    "\n",
    "spk2utt_train = copy.deepcopy(spk2utt)\n",
    "# for i in range(val_utt_num):\n",
    "#     spk2utt_val[i] = [spk2utt[i][0]]\n",
    "#     spk2utt_train[i] = spk2utt[i][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281241\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "count_list = []\n",
    "for i in spk2utt_train:\n",
    "    count += len(spk2utt_train[i])\n",
    "    count_list.append(len(spk2utt[i]))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(spk2utt_train_dict, 'wb') as handle:\n",
    "    pickle.dump(spk2utt_train, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# count = 0\n",
    "# count_list = []\n",
    "# for i in spk2utt_val:\n",
    "#     count += len(spk2utt_val[i])\n",
    "#     count_list.append(len(spk2utt[i]))\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(spk2utt_val_dict, 'wb') as handle:\n",
    "#     pickle.dump(spk2utt_val, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music_dir = '/Lun0/zhiyong/dataset/musan/music'\n",
    "noise_dir = '/Lun0/zhiyong/dataset/musan/noise'\n",
    "speech_dir = '/Lun0/zhiyong/dataset/musan/speech'\n",
    "rir_dir = '/Lun0/zhiyong/dataset/RIRS_NOISES'\n",
    "\n",
    "music_dict_out = os.path.join(OPT_INDEX, 'music_dict')\n",
    "noise_dict_out = os.path.join(OPT_INDEX, 'noise_dict')\n",
    "babble_dict_out = os.path.join(OPT_INDEX, 'babble_dict')\n",
    "rir_dict_out = os.path.join(OPT_INDEX, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music_dict = {}\n",
    "noise_dict = {}\n",
    "babble_dict = {}\n",
    "rir_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_dir_list = glob.glob(music_dir+'/*/*.wav')\n",
    "for count, this_dir in enumerate(tmp_dir_list):\n",
    "    music_dict[count] = this_dir\n",
    "with open(music_dict_out, 'wb') as handle:\n",
    "    pickle.dump(music_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_dir_list = glob.glob(noise_dir+'/*/*.wav')\n",
    "for count, this_dir in enumerate(tmp_dir_list):\n",
    "    noise_dict[count] = this_dir\n",
    "with open(noise_dict_out, 'wb') as handle:\n",
    "    pickle.dump(noise_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_dir_list = glob.glob(speech_dir+'/*/*.wav')\n",
    "for count, this_dir in enumerate(tmp_dir_list):\n",
    "    babble_dict[count] = this_dir\n",
    "with open(babble_dict_out, 'wb') as handle:\n",
    "    pickle.dump(babble_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_dir_list = glob.glob(rir_dir+'/simulated_rirs/smallroom/*/*.wav')\n",
    "for count, this_dir in enumerate(tmp_dir_list):\n",
    "    rir_dict[count] = this_dir\n",
    "tmp_dir_list = glob.glob(rir_dir+'/simulated_rirs/mediumroom/*/*.wav')\n",
    "for count_2, this_dir in enumerate(tmp_dir_list):\n",
    "    rir_dict[count +1 + count_2] = this_dir\n",
    "\n",
    "with open(rir_dict_out, 'wb') as handle:\n",
    "    pickle.dump(rir_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music_len = os.path.join(OPT_INDEX, 'music_len')\n",
    "noise_len = os.path.join(OPT_INDEX, 'noise_len')\n",
    "babble_len = os.path.join(OPT_INDEX, 'babble_len')\n",
    "spk2utt_train_len = os.path.join(OPT_INDEX, 'spk2utt_train_len')\n",
    "# spk2utt_val_len = os.path.join(OPT_INDEX, 'spk2utt_val_len')\n",
    "\n",
    "music_len_dict = {}\n",
    "noise_len_dict = {}\n",
    "babble_len_dict = {}\n",
    "spk2utt_train_len_dict = {}\n",
    "# spk2utt_val_len_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(music_dict_out, 'rb') as handle:\n",
    "    music_dict = pickle.load(handle)\n",
    "\n",
    "for i in music_dict:\n",
    "    music_len_dict[i] = librosa.core.load(music_dict[i], sr=16000)[0].shape[0]\n",
    "\n",
    "with open(music_len, 'wb') as handle:\n",
    "    pickle.dump(music_len_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(noise_dict_out, 'rb') as handle:\n",
    "    noise_dict = pickle.load(handle)\n",
    "\n",
    "for i in noise_dict:\n",
    "    noise_len_dict[i] = librosa.core.load(noise_dict[i], sr=16000)[0].shape[0]\n",
    "\n",
    "with open(noise_len, 'wb') as handle:\n",
    "    pickle.dump(noise_len_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(babble_dict_out, 'rb') as handle:\n",
    "    babble_dict = pickle.load(handle)\n",
    "\n",
    "for i in babble_dict:\n",
    "    babble_len_dict[i] = librosa.core.load(babble_dict[i], sr=16000)[0].shape[0]\n",
    "\n",
    "with open(babble_len, 'wb') as handle:\n",
    "    pickle.dump(babble_len_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(spk2utt_train_dict, 'rb') as handle:\n",
    "    spk2utt_train = pickle.load(handle)\n",
    "\n",
    "for i in spk2utt_train:\n",
    "    for utt in spk2utt_train[i]:\n",
    "        spk2utt_train_len_dict[utt] = librosa.core.load(utt, sr=16000)[0].shape[0]\n",
    "\n",
    "with open(spk2utt_train_len, 'wb') as handle:\n",
    "    pickle.dump(spk2utt_train_len_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(spk2utt_val_dict, 'rb') as handle:\n",
    "    spk2utt_val = pickle.load(handle)\n",
    "\n",
    "for i in spk2utt_val:\n",
    "    for utt in spk2utt_val[i]:\n",
    "        spk2utt_val_len_dict[utt] = librosa.core.load(utt, sr=16000)[0].shape[0]\n",
    "\n",
    "with open(spk2utt_val_len, 'wb') as handle:\n",
    "    pickle.dump(spk2utt_val_len_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trial dict\n",
    "trial_dir = '/Lun0/zhiyong/dataset/vox1/test/wav'\n",
    "trial_dict_out = os.path.join(OPT_INDEX, 'trial_dict')\n",
    "trial_dict = {}\n",
    "\n",
    "tmp_dir_list = glob.glob(trial_dir+'/*/*/*.wav')\n",
    "for count, this_dir in enumerate(tmp_dir_list):\n",
    "    trial_dict[count] = this_dir\n",
    "with open(trial_dict_out, 'wb') as handle:\n",
    "    pickle.dump(trial_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4874"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterable Dataset & Make train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fft = librosa.get_fftlib()\n",
    "class VoxIterableDataset(object):\n",
    "    def __init__(self, data_dir_dict, data_len_dict, config):        \n",
    "        with open(data_dir_dict['spk2utt_train_dict'], 'rb') as handle:\n",
    "            self.spk2utt_train_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['music_dict'], 'rb') as handle:\n",
    "            self.music_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['noise_dict'], 'rb') as handle:\n",
    "            self.noise_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['babble_dict'], 'rb') as handle:\n",
    "            self.babble_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['rir_dict'], 'rb') as handle:\n",
    "            self.rir_dict = pickle.load(handle)\n",
    "            \n",
    "        with open(data_len_dict['spk2utt_train_len'], 'rb') as handle:\n",
    "            self.spk2utt_train_len = pickle.load(handle)\n",
    "        with open(data_len_dict['music_len'], 'rb') as handle:\n",
    "            self.music_len = pickle.load(handle)\n",
    "        with open(data_len_dict['noise_len'], 'rb') as handle:\n",
    "            self.noise_len = pickle.load(handle)\n",
    "        with open(data_len_dict['babble_len'], 'rb') as handle:\n",
    "            self.babble_len = pickle.load(handle)\n",
    "        \n",
    "        \n",
    "        self.random_spkrs_batchlist = None\n",
    "        self.ramdom_batch_len = None\n",
    "        self.random_noise_type = None\n",
    "        \n",
    "        \n",
    "        self.possible_babble_num = [3, 4, 5, 6, 7]\n",
    "        self.possible_babble_snr = [13, 15, 17, 20]\n",
    "        self.possible_noise_snr = [0, 5, 10, 15]\n",
    "        self.possible_music_snr = [5, 8, 10, 15]\n",
    "        \n",
    "        self.sr = config['sr']\n",
    "        self.repeats = config['repeats']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.extended_prefectch = config['extended_prefectch']\n",
    "        \n",
    "        self.mfcc_dim = 30\n",
    "        \n",
    "        # Auxiliary paras\n",
    "        self.multi_read_count = 0\n",
    "        self.preload_mem = False\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        assert len(self.ramdom_batch_len) == len(self.random_spkrs_batchlist)\n",
    "        try:\n",
    "            batch_frame_len = self.ramdom_batch_len.pop(0)\n",
    "            batch_spkrs = self.random_spkrs_batchlist.pop(0)\n",
    "            batch_noise_type = self.random_noise_type.pop(0)\n",
    "            batched_feats = np.zeros([self.batch_size, batch_frame_len, self.mfcc_dim])\n",
    "            batched_labels = np.zeros(self.batch_size)\n",
    "            \n",
    "            for batch_index, (spkr, noise_type) in enumerate(zip(batch_spkrs, batch_noise_type)):\n",
    "                \n",
    "                concat_wav, VAD_result = self._colleting_and_slicing(spkr, batch_frame_len,\\\n",
    "                hop_len=160, extended_prefectch=self.extended_prefectch)\n",
    "            \n",
    "                \n",
    "                if noise_type == 0:\n",
    "                    aug_wav = concat_wav\n",
    "                \n",
    "                elif noise_type == 1:\n",
    "                    aug_wav = self._add_rebverb(concat_wav)\n",
    "                   \n",
    "                elif noise_type == 2:\n",
    "                    aug_wav = self._add_noise(concat_wav)\n",
    "                    \n",
    "                elif noise_type == 3:\n",
    "                    aug_wav = self._add_music(concat_wav)\n",
    "                  \n",
    "                elif noise_type == 4:\n",
    "                    aug_wav = self._add_babble(concat_wav)\n",
    "             \n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                    \n",
    "            \n",
    "                single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "                dct_type=2, n_fft=512, hop_length=160, \\\n",
    "                win_length=None, window='hann', power=2.0, \\\n",
    "                center=True, pad_mode='reflect', n_mels=30, \\\n",
    "                fmin=20, fmax=7600)\n",
    "                # Note single_feats needs transpose\n",
    "                out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "                # Apply VAD\n",
    "                assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "                out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "                batched_feats[batch_index] = out_feats[:batch_frame_len]\n",
    "                batched_labels[batch_index] = spkr\n",
    "                \n",
    "            return batched_feats, batched_labels\n",
    "        \n",
    "        except IndexError:\n",
    "            raise StopIteration\n",
    "\n",
    "    def process_one_utt(self, utt_dir):\n",
    "        try:\n",
    "            concat_wav, _ = librosa.load(utt_dir, sr=self.sr)\n",
    "            \n",
    "            VAD_result = self._VAD_detection(concat_wav)\n",
    "            \n",
    "            aug_wav = concat_wav\n",
    "\n",
    "            single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "            dct_type=2, n_fft=512, hop_length=160, \\\n",
    "            win_length=None, window='hann', power=2.0, \\\n",
    "            center=True, pad_mode='reflect', n_mels=30, \\\n",
    "            fmin=20, fmax=7600)\n",
    "            # Note single_feats needs transpose\n",
    "            out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "            # Apply VAD\n",
    "            assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "            out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "            \n",
    "            batched_feats = out_feats[None, :, :]\n",
    "                \n",
    "            return batched_feats\n",
    "        \n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def process_one_utt_noVAD(self, utt_dir):\n",
    "        try:\n",
    "            concat_wav, _ = librosa.load(utt_dir, sr=self.sr)\n",
    "            \n",
    "            aug_wav = concat_wav\n",
    "\n",
    "            single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "            dct_type=2, n_fft=512, hop_length=160, \\\n",
    "            win_length=None, window='hann', power=2.0, \\\n",
    "            center=True, pad_mode='reflect', n_mels=30, \\\n",
    "            fmin=20, fmax=7600)\n",
    "            # Note single_feats needs transpose\n",
    "            out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "            \n",
    "            batched_feats = out_feats[None, :, :]\n",
    "                \n",
    "            return batched_feats\n",
    "        \n",
    "        except Exception:\n",
    "            traceback.print_exc()            \n",
    "    \n",
    "    def noise_data_preload(self):\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            _, _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            _, _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            _, _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "    \n",
    "    def noise_data_preload2mem(self):\n",
    "        print('preloading to memory')\n",
    "        \n",
    "        self.music_preload_dict = {}\n",
    "        self.noise_preload_dict = {}\n",
    "        self.babble_preload_dict = {}\n",
    "        self.preload_mem = True\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            self.music_preload_dict[i], _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            self.noise_preload_dict[i], _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            self.babble_preload_dict[i], _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)       \n",
    "        \n",
    "        \n",
    "    def get_random_list(self):\n",
    "        spkrs_list = self.repeats * list(self.spk2utt_train_dict.keys())\n",
    "        random.shuffle(spkrs_list)\n",
    "        len_spkrs_list = len(spkrs_list)\n",
    "        self.random_spkrs_batchlist = [spkrs_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        self.ramdom_batch_len = [random.randint(400, 400) for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        noise_type_list = [i%5 for i in range(len_spkrs_list)]\n",
    "\n",
    "        random.shuffle(noise_type_list)\n",
    "        self.random_noise_type = [noise_type_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        assert len(self.random_spkrs_batchlist) == len(self.ramdom_batch_len)\\\n",
    "        == len(self.random_noise_type)\n",
    "        \n",
    "    def _colleting_and_slicing(self, spkr, batch_frame_len, hop_len=160, extended_prefectch=2.0):\n",
    "        \n",
    "        least_wav_len = (batch_frame_len - 1) * hop_len\n",
    "        concat_utt = np.zeros(0)\n",
    "        valid_frames_len = 0\n",
    "        \n",
    "        # Use to count multi_read_count\n",
    "        get_count = 0\n",
    "\n",
    "        while valid_frames_len < batch_frame_len:\n",
    "#             concat_utt = np.zeros(0)\n",
    "            if get_count == 0:\n",
    "                utt_dir = self._get_random_spk_utt(spkr, self.spk2utt_train_dict)\n",
    "                utt_len = self.spk2utt_train_len[utt_dir]\n",
    "#             off = self._get_random_offset(least_wav_len, utt_len) / self.sr\n",
    "            off = self._get_random_offset(least_wav_len+extended_prefectch*self.sr, utt_len) / self.sr\n",
    "            dur = least_wav_len / self.sr + extended_prefectch\n",
    "            \n",
    "            try:\n",
    "                utt_part, _ = librosa.load(utt_dir, sr=self.sr, offset=off, duration=dur)\n",
    "            except Exception:\n",
    "                get_count += 1\n",
    "                print(utt_dir, off, dur)\n",
    "                continue\n",
    "#                 raise Exception(utt_dir+' '+str(off)+' '+str(dur))       \n",
    "            \n",
    "            concat_utt = np.append(concat_utt, utt_part)\n",
    "            detected_frames = self._VAD_detection(concat_utt)\n",
    "            valid_frames_len = np.sum(detected_frames)\n",
    "\n",
    "            get_count += 1\n",
    "\n",
    "        if get_count > 1:\n",
    "            self.multi_read_count += 1\n",
    "\n",
    "        VAD_result = detected_frames\n",
    "        return concat_utt, VAD_result\n",
    "    \n",
    "    def _add_rebverb(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = in_wav\n",
    "        filter_dir = self._get_random_noise(self.rir_dict)\n",
    "        filter, _ = librosa.load(filter_dir, sr=self.sr)\n",
    "        \n",
    "        signal_length = len(signal)\n",
    "        filter_length = len(filter)\n",
    "        output_length = signal_length + filter_length - 1\n",
    "        output = np.zeros(output_length)\n",
    "\n",
    "        fft_length = 2**np.ceil(np.log2(4 * filter_length)).astype(np.int)\n",
    "        block_length = fft_length - filter_length + 1\n",
    "\n",
    "\n",
    "        filter_padded = np.zeros(fft_length)\n",
    "        filter_padded[0:filter_length] = filter\n",
    "        filter_padded = fft.rfft(filter_padded)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(signal_length//block_length + 1):\n",
    "            process_length = min(block_length, signal_length - i * block_length);\n",
    "            signal_block_padded = np.zeros(fft_length)\n",
    "            signal_block_padded[0:process_length] = signal[i * block_length : i * block_length + process_length]\n",
    "            signal_block_padded = fft.rfft(signal_block_padded)\n",
    "\n",
    "            signal_block_padded = filter_padded * signal_block_padded\n",
    "\n",
    "            signal_block_padded = fft.irfft(signal_block_padded, n=fft_length)\n",
    "\n",
    "            if (i*block_length + fft_length) <= output_length:\n",
    "                output[i*block_length : i*block_length + fft_length] += signal_block_padded\n",
    "            else:\n",
    "                output[i*block_length : output_length] += signal_block_padded[:output_length-i*block_length]\n",
    "        \n",
    "        # shift with max index of filter\n",
    "        shift_index = np.argmax(filter)\n",
    "        \n",
    "        final_out = output[shift_index:shift_index+signal_length]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_noise(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.noise_dict, return_index=True)\n",
    "            noise_len = self.noise_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "                \n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_noise_snr[random.randint(0, len(self.possible_noise_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_music(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.music_dict, return_index=True)\n",
    "            noise_len = self.music_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_music_snr[random.randint(0, len(self.possible_music_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_babble(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        signal_off = 0\n",
    "        bg_spks_num = self.possible_babble_num[random.randint(0, len(self.possible_babble_num)-1)]    \n",
    "        for _ in range(bg_spks_num):            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.babble_dict, return_index=True)\n",
    "            noise_len = self.babble_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_babble_snr[random.randint(0, len(self.possible_babble_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_db(self, in_wav, noise, signal_off, snr_db, power_before_reverb):\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "\n",
    "        noise_power = noise.dot(noise) / len(noise)\n",
    "        scale_factor = np.sqrt(10**(-snr_db / 10) * power_before_reverb / noise_power)\n",
    "        noise = scale_factor * noise\n",
    "\n",
    "        add_length = min(len(noise), len(signal)-signal_off)\n",
    "        signal[signal_off:signal_off+add_length] += noise[:add_length]\n",
    "        out_wav = signal      \n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _CMVN(self, in_feat, cmn_window = 300, normalize_variance = False):             \n",
    "        num_frames = in_feat.shape[0]\n",
    "        dim = in_feat.shape[1]\n",
    "        last_window_start = -1\n",
    "        last_window_end = -1\n",
    "        cur_sum = np.zeros(dim)\n",
    "        cur_sumsq = np.zeros(dim)\n",
    "\n",
    "        out_feat = np.zeros([num_frames, dim])\n",
    "\n",
    "        for t in range(num_frames):\n",
    "            window_start = 0\n",
    "            window_end = 0\n",
    "\n",
    "            window_start = t - int(cmn_window / 2)\n",
    "            window_end = window_start + cmn_window\n",
    "\n",
    "            if (window_start < 0):\n",
    "                window_end -= window_start\n",
    "                window_start = 0\n",
    "\n",
    "            if (window_end > num_frames):\n",
    "                window_start -= (window_end - num_frames)\n",
    "                window_end = num_frames\n",
    "                if (window_start < 0):\n",
    "                    window_start = 0\n",
    "\n",
    "            if (last_window_start == -1):\n",
    "                input_part = in_feat[window_start:window_end]\n",
    "                cur_sum = np.sum(input_part, axis=0, keepdims=False)\n",
    "                if normalize_variance:\n",
    "                    cur_sumsq = np.sum(input_part**2, axis=0, keepdims=False)\n",
    "            else:\n",
    "                if (window_start > last_window_start):\n",
    "                    frame_to_remove = in_feat[last_window_start]\n",
    "                    cur_sum -= frame_to_remove\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq -= frame_to_remove**2\n",
    "\n",
    "                if (window_end > last_window_end):\n",
    "                    frame_to_add = in_feat[last_window_end]\n",
    "                    cur_sum += frame_to_add\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq += frame_to_add**2\n",
    "\n",
    "            window_frames = window_end - window_start\n",
    "            last_window_start = window_start\n",
    "            last_window_end = window_end\n",
    "\n",
    "            out_feat[t] = in_feat[t] - (1.0 / window_frames) * cur_sum\n",
    "\n",
    "\n",
    "            if normalize_variance:\n",
    "                if (window_frames == 1):\n",
    "                    out_feat[t] = 0.0\n",
    "                else:\n",
    "                    variance = (1.0 / window_frames) * cur_sumsq - (1.0 / window_frames**2) * cur_sum**2\n",
    "                    variance = np.maximum(1.0e-10, variance)\n",
    "                    out_feat[t] /= variance**(0.5)\n",
    "                    \n",
    "        return out_feat\n",
    "\n",
    "    def _get_random_noise(self, noise_dict, return_index=False):\n",
    "        dict_len = len(noise_dict)\n",
    "        i = random.randint(0, dict_len-1)\n",
    "        noise_dir = noise_dict[i]\n",
    "        \n",
    "        if return_index:\n",
    "            return noise_dir, i\n",
    "        else:\n",
    "            return noise_dir\n",
    "    \n",
    "    def _get_random_spk_utt(self, spkr, spk2utt):\n",
    "        this_utts = spk2utt[spkr]\n",
    "        this_num_utts = len(this_utts)\n",
    "        i = random.randint(0, this_num_utts-1)\n",
    "        utt_dir = this_utts[i]\n",
    "        return utt_dir\n",
    "\n",
    "    def _get_random_offset(self, expected_length, utt_len):\n",
    "        if expected_length > utt_len:\n",
    "            return 0\n",
    "        \n",
    "        free_length = utt_len - expected_length\n",
    "        offset = random.randint(0, free_length)\n",
    "        return offset\n",
    "        \n",
    "    @property\n",
    "    def _VAD_config(self):\n",
    "        vad_energy_threshold = -3.0\n",
    "        vad_energy_mean_scale = 1.0\n",
    "        vad_frames_context = 0\n",
    "        vad_proportion_threshold = 0.12\n",
    "        \n",
    "        return vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold\n",
    "        \n",
    "        \n",
    "    def _VAD_detection(self, wav):\n",
    "        vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold = self._VAD_config\n",
    "        \n",
    "        y_tmp = np.pad(wav, int(512 // 2), mode='reflect')\n",
    "        y_tmp = librosa.util.frame(y_tmp, frame_length=512, hop_length=160)\n",
    "        y_log_energy = np.log(np.maximum(np.sum(y_tmp**2, axis=0), 1e-15))\n",
    "\n",
    "        T = len(y_log_energy)\n",
    "        output_voiced = np.zeros(T)\n",
    "        if (T == 0):\n",
    "            raise Exception(\"zero wave length\")\n",
    "\n",
    "        energy_threshold = vad_energy_threshold\n",
    "        if (vad_energy_mean_scale != 0.0):\n",
    "            assert(vad_energy_mean_scale > 0.0)\n",
    "            energy_threshold += vad_energy_mean_scale * np.sum(y_log_energy) / T\n",
    "\n",
    "\n",
    "        assert(vad_frames_context >= 0)\n",
    "        assert(vad_proportion_threshold > 0.0 and vad_proportion_threshold < 1.0);\n",
    "\n",
    "        for t in range(T):\n",
    "            num_count = 0\n",
    "            den_count = 0\n",
    "            context = vad_frames_context\n",
    "            for t2 in range(t - context, t + context+1):\n",
    "                if (t2 >= 0 and t2 < T):\n",
    "                    den_count+=1\n",
    "                    if (y_log_energy[t2] > energy_threshold):\n",
    "                        num_count+=1\n",
    "\n",
    "            if (num_count >= den_count * vad_proportion_threshold):\n",
    "                output_voiced[t] = 1.0\n",
    "            else:\n",
    "                output_voiced[t] = 0.0\n",
    "        \n",
    "        return output_voiced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPT_INDEX_1 = '/Lun0/zhiyong/dataset'\n",
    "data_dir_dict = {}\n",
    "\n",
    "# train\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(OPT_INDEX, 'spk2utt_train_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(OPT_INDEX_1, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(OPT_INDEX_1, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(OPT_INDEX_1, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(OPT_INDEX_1, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['music_len'] = os.path.join(OPT_INDEX_1, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(OPT_INDEX_1, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(OPT_INDEX_1, 'babble_len')\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(OPT_INDEX, 'spk2utt_train_len')\n",
    "# data_len_dict['spk2utt_val_len'] = os.path.join(OPT_INDEX, 'spk2utt_val_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preloading music_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "preloading noise_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "preloading babble_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-100/4788/94904/4788-94904-0018.flac 1.40625 4.5\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360/1212/75242/1212-75242-0002.flac 4.2633125 3.57\n",
      "10299.95515537262\n"
     ]
    }
   ],
   "source": [
    "# config = {}\n",
    "\n",
    "# config['sr'] = 16000\n",
    "# config['repeats'] = 150\n",
    "# config['batch_size'] = 128\n",
    "# config['extended_prefectch'] = 1.0\n",
    "\n",
    "# def iter_data_preload(dataset, i, start):\n",
    "#     dataset.get_random_list()\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "#         for count, (data, label) in enumerate(dataset):\n",
    "#             with open('/Lun0/zhiyong/libri/train_data/'+str(i)+str('_')+str(start+1+count), 'wb') as handle:\n",
    "#                 pickle.dump((data.astype(np.float16), label.astype(np.int16)), handle)\n",
    "# #             print(time.time()-start_time)\n",
    "#             with open('/Lun0/zhiyong/libri/tmp_data_errlog_1', 'a') as f:\n",
    "#                 f.write(str(time.time()-start_time)+'\\n')\n",
    "#             start_time = time.time()\n",
    "#             if start+1+count == 2738:\n",
    "#                 break\n",
    "#     except Exception:\n",
    "#         with open('/Lun0/zhiyong/libri/tmp_data_errlog_1', 'a') as f:\n",
    "#             traceback.print_exc(file=f)\n",
    "#         raise Exception\n",
    "\n",
    "# dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "# # dataset.noise_data_preload2mem()\n",
    "# dataset.noise_data_preload()\n",
    "\n",
    "# # processes = [Process(target = iter_data_preload, args = (dataset, i)) for i in range(10)]\n",
    "# start_list = {1:2001, 3:1087, 7:923, 9:1288}\n",
    "# processes = [Process(target = iter_data_preload, args = (dataset, i, start_list[i])) for i in [1, 3, 7, 9]]\n",
    "# start_time = time.time()\n",
    "# [p.start() for p in processes]\n",
    "# joined = [p.join() for p in processes]\n",
    "# print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preloading music_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "preloading noise_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "preloading babble_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-other-500/2288/139962/2288-139962-0008.flac 7.89075 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-other-500/7001/12337/7001-12337-0095.flac 5.3880625 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360/1987/144135/1987-144135-0100.flac 0.7945 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360/1212/75242/1212-75242-0002.flac 4.3838125 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360/1212/75242/1212-75242-0002.flac 4.8921875 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-100/4788/94904/4788-94904-0018.flac 1.4620625 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360/4595/45218/4595-45218-0016.flac 2.82675 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360/8772/295710/8772-295710-0051.flac 4.366375 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-other-500/2288/139962/2288-139962-0008.flac 6.7504375 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-other-500/3319/171003/3319-171003-0026.flac 3.359875 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-other-500/3319/171003/3319-171003-0026.flac 3.69375 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360/1212/75242/1212-75242-0002.flac 4.386125 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360/882/123268/882-123268-0027.flac 8.212375 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360/1212/75242/1212-75242-0002.flac 4.189875 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-other-500/2288/139962/2288-139962-0008.flac 8.3074375 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-other-500/2288/139962/2288-139962-0008.flac 7.1463125 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360/7766/109658/7766-109658-0063.flac 3.1745625 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-other-500/5970/54428/5970-54428-0023.flac 1.3469375 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-clean-360/3330/170956/3330-170956-0050.flac 1.3803125 4.99\n",
      "/Lun0/zhiyong/SdSV_2020_deepmine/librispeech/LibriSpeech/train-other-500/7147/80028/7147-80028-0025.flac 1.7855 4.99\n",
      "72711.21259474754\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = 150\n",
    "config['batch_size'] = 1\n",
    "config['extended_prefectch'] = 1.0\n",
    "\n",
    "def iter_data_preload(dataset, i):\n",
    "    dataset.get_random_list()\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        for count, (data, label) in enumerate(dataset):\n",
    "            with open('/Lun0/zhiyong/libri/train_data_sparse/'+str(i)+str('_')+str(count), 'wb') as handle:\n",
    "                pickle.dump((data.astype(np.float16), label.astype(np.int16)), handle)\n",
    "#             print(time.time()-start_time)\n",
    "            with open('/Lun0/zhiyong/libri/tmp_data_errlog_1', 'a') as f:\n",
    "                f.write(str(time.time()-start_time)+'\\n')\n",
    "            start_time = time.time()\n",
    "    except Exception:\n",
    "        with open('/Lun0/zhiyong/libri/tmp_data_errlog_1', 'a') as f:\n",
    "            traceback.print_exc(file=f)\n",
    "        raise Exception\n",
    "\n",
    "dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "# dataset.noise_data_preload2mem()\n",
    "dataset.noise_data_preload()\n",
    "\n",
    "processes = [Process(target = iter_data_preload, args = (dataset, i)) for i in range(10)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27390"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2739*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3507000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2338*1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "train_data_dir = os.path.join(OPT_INDEX, 'train_data_sparse')\n",
    "expected_len = 3507000\n",
    "workers = 10\n",
    "single_worker_len = int(expected_len / workers)\n",
    "output = os.path.join(OPT_INDEX, 'train_data_sparse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3507000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob(train_data_dir+'/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert expected_len == len(glob.glob(train_data_dir+'/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(output, 'w') as f:\n",
    "    for i in range(workers):\n",
    "        for j in range(single_worker_len):\n",
    "            path = os.path.join(train_data_dir, str(i)+'_'+str(j))\n",
    "            assert os.path.isfile(path)\n",
    "            f.write(path+'\\n')\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3507000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "# train_data_dir = os.path.join(OPT_INDEX, 'tmp_data_2')\n",
    "# expected_len = 85810\n",
    "# workers = 10\n",
    "# single_worker_len = int(expected_len / workers)\n",
    "# output = os.path.join(OPT_INDEX, 'tmp_data_2_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assert expected_len == len(glob.glob(train_data_dir+'/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# with open(output, 'w') as f:\n",
    "#     for i in range(workers):\n",
    "#         for j in range(single_worker_len):\n",
    "#             path = os.path.join(train_data_dir, str(i)+'_'+str(j))\n",
    "#             assert os.path.isfile(path)\n",
    "#             f.write(path+'\\n')\n",
    "#             count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85810"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class PickleDataSet(Dataset):\n",
    "#     def __init__(self, spkid2utt_csv):\n",
    "#         self.spkid2utt = pd.read_csv(spkid2utt_csv, header=None)\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         path = self.spkid2utt[0][index]\n",
    "#         with open(path, 'rb') as handle:\n",
    "#             batch_data = pickle.load(handle)\n",
    "#         batch_feats = batch_data[0].astype(np.float32)\n",
    "#         batch_labels = batch_data[1].astype(np.int64)\n",
    "       \n",
    "#         return batch_feats, batch_labels\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.spkid2utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle_dataset = PickleDataSet(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# length = len(pickle_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# length_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(length):\n",
    "#     length_list.append(pickle_dataset[i][0].shape[1])\n",
    "#     if (i+1) % 1000 == 0:\n",
    "#         print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in length_list:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make validation data (Need only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fft = librosa.get_fftlib()\n",
    "class VoxIterableDataset(object):\n",
    "    def __init__(self, data_dir_dict, data_len_dict, config):        \n",
    "        with open(data_dir_dict['spk2utt_train_dict'], 'rb') as handle:\n",
    "            self.spk2utt_train_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['music_dict'], 'rb') as handle:\n",
    "            self.music_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['noise_dict'], 'rb') as handle:\n",
    "            self.noise_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['babble_dict'], 'rb') as handle:\n",
    "            self.babble_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['rir_dict'], 'rb') as handle:\n",
    "            self.rir_dict = pickle.load(handle)\n",
    "            \n",
    "        with open(data_len_dict['spk2utt_train_len'], 'rb') as handle:\n",
    "            self.spk2utt_train_len = pickle.load(handle)\n",
    "        with open(data_len_dict['music_len'], 'rb') as handle:\n",
    "            self.music_len = pickle.load(handle)\n",
    "        with open(data_len_dict['noise_len'], 'rb') as handle:\n",
    "            self.noise_len = pickle.load(handle)\n",
    "        with open(data_len_dict['babble_len'], 'rb') as handle:\n",
    "            self.babble_len = pickle.load(handle)\n",
    "        \n",
    "        \n",
    "        self.random_spkrs_batchlist = None\n",
    "        self.ramdom_batch_len = None\n",
    "        self.random_noise_type = None\n",
    "        \n",
    "        \n",
    "        self.possible_babble_num = [3, 4, 5, 6, 7]\n",
    "        self.possible_babble_snr = [13, 15, 17, 20]\n",
    "        self.possible_noise_snr = [0, 5, 10, 15]\n",
    "        self.possible_music_snr = [5, 8, 10, 15]\n",
    "        \n",
    "        self.sr = config['sr']\n",
    "        self.repeats = config['repeats']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.extended_prefectch = config['extended_prefectch']\n",
    "        \n",
    "        self.mfcc_dim = 30\n",
    "        \n",
    "        # Auxiliary paras\n",
    "        self.multi_read_count = 0\n",
    "        self.preload_mem = False\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        assert len(self.ramdom_batch_len) == len(self.random_spkrs_batchlist)\n",
    "        try:\n",
    "            batch_frame_len = self.ramdom_batch_len.pop(0)\n",
    "            batch_spkrs = self.random_spkrs_batchlist.pop(0)\n",
    "            batch_noise_type = self.random_noise_type.pop(0)\n",
    "            batched_feats = np.zeros([self.batch_size, batch_frame_len, self.mfcc_dim])\n",
    "            batched_labels = np.zeros(self.batch_size)\n",
    "            \n",
    "            for batch_index, (spkr, noise_type) in enumerate(zip(batch_spkrs, batch_noise_type)):\n",
    "                \n",
    "                concat_wav, VAD_result = self._colleting_and_slicing(spkr, batch_frame_len,\\\n",
    "                hop_len=160, extended_prefectch=self.extended_prefectch)\n",
    "            \n",
    "                \n",
    "                if noise_type == 0:\n",
    "                    aug_wav = concat_wav\n",
    "                \n",
    "                elif noise_type == 1:\n",
    "                    aug_wav = self._add_rebverb(concat_wav)\n",
    "                   \n",
    "                elif noise_type == 2:\n",
    "                    aug_wav = self._add_noise(concat_wav)\n",
    "                    \n",
    "                elif noise_type == 3:\n",
    "                    aug_wav = self._add_music(concat_wav)\n",
    "                  \n",
    "                elif noise_type == 4:\n",
    "                    aug_wav = self._add_babble(concat_wav)\n",
    "             \n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                    \n",
    "            \n",
    "                single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "                dct_type=2, n_fft=512, hop_length=160, \\\n",
    "                win_length=None, window='hann', power=2.0, \\\n",
    "                center=True, pad_mode='reflect', n_mels=30, \\\n",
    "                fmin=20, fmax=7600)\n",
    "                # Note single_feats needs transpose\n",
    "                out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "                # Apply VAD\n",
    "                assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "#                 out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "                batched_feats[batch_index] = out_feats[:batch_frame_len]\n",
    "                batched_labels[batch_index] = spkr\n",
    "                \n",
    "            return batched_feats, batched_labels\n",
    "        \n",
    "        except IndexError:\n",
    "            raise StopIteration\n",
    "\n",
    "    def process_one_utt(self, utt_dir):\n",
    "        try:\n",
    "            concat_wav, _ = librosa.load(utt_dir, sr=self.sr)\n",
    "            \n",
    "            VAD_result = self._VAD_detection(concat_wav)\n",
    "            \n",
    "            aug_wav = concat_wav\n",
    "\n",
    "            single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "            dct_type=2, n_fft=512, hop_length=160, \\\n",
    "            win_length=None, window='hann', power=2.0, \\\n",
    "            center=True, pad_mode='reflect', n_mels=30, \\\n",
    "            fmin=20, fmax=7600)\n",
    "            # Note single_feats needs transpose\n",
    "            out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "            # Apply VAD\n",
    "            assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "            out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "            \n",
    "            batched_feats = out_feats[None, :, :]\n",
    "                \n",
    "            return batched_feats\n",
    "        \n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def process_one_utt_noVAD(self, utt_dir):\n",
    "        try:\n",
    "            concat_wav, _ = librosa.load(utt_dir, sr=self.sr)\n",
    "            \n",
    "            aug_wav = concat_wav\n",
    "\n",
    "            single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "            dct_type=2, n_fft=512, hop_length=160, \\\n",
    "            win_length=None, window='hann', power=2.0, \\\n",
    "            center=True, pad_mode='reflect', n_mels=30, \\\n",
    "            fmin=20, fmax=7600)\n",
    "            # Note single_feats needs transpose\n",
    "            out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "            \n",
    "            batched_feats = out_feats[None, :, :]\n",
    "                \n",
    "            return batched_feats\n",
    "        \n",
    "        except Exception:\n",
    "            traceback.print_exc()            \n",
    "    \n",
    "    def noise_data_preload(self):\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            _, _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            _, _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            _, _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "    \n",
    "    def noise_data_preload2mem(self):\n",
    "        print('preloading to memory')\n",
    "        \n",
    "        self.music_preload_dict = {}\n",
    "        self.noise_preload_dict = {}\n",
    "        self.babble_preload_dict = {}\n",
    "        self.preload_mem = True\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            self.music_preload_dict[i], _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            self.noise_preload_dict[i], _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            self.babble_preload_dict[i], _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)       \n",
    "        \n",
    "        \n",
    "    def get_random_list(self):\n",
    "        spkrs_list = self.repeats * list(self.spk2utt_train_dict.keys())\n",
    "        random.shuffle(spkrs_list)\n",
    "        len_spkrs_list = len(spkrs_list)\n",
    "        self.random_spkrs_batchlist = [spkrs_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        self.ramdom_batch_len = [random.randint(200, 400) for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        noise_type_list = [i%5 for i in range(len_spkrs_list)]\n",
    "\n",
    "        random.shuffle(noise_type_list)\n",
    "        self.random_noise_type = [noise_type_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        assert len(self.random_spkrs_batchlist) == len(self.ramdom_batch_len)\\\n",
    "        == len(self.random_noise_type)\n",
    "        \n",
    "    def _colleting_and_slicing(self, spkr, batch_frame_len, hop_len=160, extended_prefectch=2.0):\n",
    "        \n",
    "        least_wav_len = (batch_frame_len - 1) * hop_len\n",
    "        concat_utt = np.zeros(0)\n",
    "        valid_frames_len = 0\n",
    "        \n",
    "        # Use to count multi_read_count\n",
    "        get_count = 0\n",
    "\n",
    "        while valid_frames_len < batch_frame_len:\n",
    "#             concat_utt = np.zeros(0)\n",
    "\n",
    "            utt_dir = self._get_random_spk_utt(spkr, self.spk2utt_train_dict)\n",
    "            utt_len = self.spk2utt_train_len[utt_dir]\n",
    "#             off = self._get_random_offset(least_wav_len, utt_len) / self.sr\n",
    "            off = self._get_random_offset(least_wav_len+extended_prefectch*self.sr, utt_len) / self.sr\n",
    "            dur = least_wav_len / self.sr + extended_prefectch\n",
    "            \n",
    "            utt_part, _ = librosa.load(utt_dir, sr=self.sr, offset=off, duration=dur)\n",
    "            \n",
    "            concat_utt = np.append(concat_utt, utt_part)\n",
    "            detected_frames = self._VAD_detection(concat_utt)\n",
    "            valid_frames_len = np.sum(detected_frames)\n",
    "\n",
    "            get_count += 1\n",
    "\n",
    "        if get_count > 1:\n",
    "            self.multi_read_count += 1\n",
    "\n",
    "        VAD_result = detected_frames\n",
    "        return concat_utt, VAD_result\n",
    "    \n",
    "    def _add_rebverb(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = in_wav\n",
    "        filter_dir = self._get_random_noise(self.rir_dict)\n",
    "        filter, _ = librosa.load(filter_dir, sr=self.sr)\n",
    "        \n",
    "        signal_length = len(signal)\n",
    "        filter_length = len(filter)\n",
    "        output_length = signal_length + filter_length - 1\n",
    "        output = np.zeros(output_length)\n",
    "\n",
    "        fft_length = 2**np.ceil(np.log2(4 * filter_length)).astype(np.int)\n",
    "        block_length = fft_length - filter_length + 1\n",
    "\n",
    "\n",
    "        filter_padded = np.zeros(fft_length)\n",
    "        filter_padded[0:filter_length] = filter\n",
    "        filter_padded = fft.rfft(filter_padded)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(signal_length//block_length + 1):\n",
    "            process_length = min(block_length, signal_length - i * block_length);\n",
    "            signal_block_padded = np.zeros(fft_length)\n",
    "            signal_block_padded[0:process_length] = signal[i * block_length : i * block_length + process_length]\n",
    "            signal_block_padded = fft.rfft(signal_block_padded)\n",
    "\n",
    "            signal_block_padded = filter_padded * signal_block_padded\n",
    "\n",
    "            signal_block_padded = fft.irfft(signal_block_padded, n=fft_length)\n",
    "\n",
    "            if (i*block_length + fft_length) <= output_length:\n",
    "                output[i*block_length : i*block_length + fft_length] += signal_block_padded\n",
    "            else:\n",
    "                output[i*block_length : output_length] += signal_block_padded[:output_length-i*block_length]\n",
    "        \n",
    "        # shift with max index of filter\n",
    "        shift_index = np.argmax(filter)\n",
    "        \n",
    "        final_out = output[shift_index:shift_index+signal_length]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_noise(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.noise_dict, return_index=True)\n",
    "            noise_len = self.noise_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "                \n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_noise_snr[random.randint(0, len(self.possible_noise_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_music(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.music_dict, return_index=True)\n",
    "            noise_len = self.music_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_music_snr[random.randint(0, len(self.possible_music_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_babble(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        signal_off = 0\n",
    "        bg_spks_num = self.possible_babble_num[random.randint(0, len(self.possible_babble_num)-1)]    \n",
    "        for _ in range(bg_spks_num):            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.babble_dict, return_index=True)\n",
    "            noise_len = self.babble_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_babble_snr[random.randint(0, len(self.possible_babble_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_db(self, in_wav, noise, signal_off, snr_db, power_before_reverb):\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "\n",
    "        noise_power = noise.dot(noise) / len(noise)\n",
    "        scale_factor = np.sqrt(10**(-snr_db / 10) * power_before_reverb / noise_power)\n",
    "        noise = scale_factor * noise\n",
    "\n",
    "        add_length = min(len(noise), len(signal)-signal_off)\n",
    "        signal[signal_off:signal_off+add_length] += noise[:add_length]\n",
    "        out_wav = signal      \n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _CMVN(self, in_feat, cmn_window = 300, normalize_variance = False):             \n",
    "        num_frames = in_feat.shape[0]\n",
    "        dim = in_feat.shape[1]\n",
    "        last_window_start = -1\n",
    "        last_window_end = -1\n",
    "        cur_sum = np.zeros(dim)\n",
    "        cur_sumsq = np.zeros(dim)\n",
    "\n",
    "        out_feat = np.zeros([num_frames, dim])\n",
    "\n",
    "        for t in range(num_frames):\n",
    "            window_start = 0\n",
    "            window_end = 0\n",
    "\n",
    "            window_start = t - int(cmn_window / 2)\n",
    "            window_end = window_start + cmn_window\n",
    "\n",
    "            if (window_start < 0):\n",
    "                window_end -= window_start\n",
    "                window_start = 0\n",
    "\n",
    "            if (window_end > num_frames):\n",
    "                window_start -= (window_end - num_frames)\n",
    "                window_end = num_frames\n",
    "                if (window_start < 0):\n",
    "                    window_start = 0\n",
    "\n",
    "            if (last_window_start == -1):\n",
    "                input_part = in_feat[window_start:window_end]\n",
    "                cur_sum = np.sum(input_part, axis=0, keepdims=False)\n",
    "                if normalize_variance:\n",
    "                    cur_sumsq = np.sum(input_part**2, axis=0, keepdims=False)\n",
    "            else:\n",
    "                if (window_start > last_window_start):\n",
    "                    frame_to_remove = in_feat[last_window_start]\n",
    "                    cur_sum -= frame_to_remove\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq -= frame_to_remove**2\n",
    "\n",
    "                if (window_end > last_window_end):\n",
    "                    frame_to_add = in_feat[last_window_end]\n",
    "                    cur_sum += frame_to_add\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq += frame_to_add**2\n",
    "\n",
    "            window_frames = window_end - window_start\n",
    "            last_window_start = window_start\n",
    "            last_window_end = window_end\n",
    "\n",
    "            out_feat[t] = in_feat[t] - (1.0 / window_frames) * cur_sum\n",
    "\n",
    "\n",
    "            if normalize_variance:\n",
    "                if (window_frames == 1):\n",
    "                    out_feat[t] = 0.0\n",
    "                else:\n",
    "                    variance = (1.0 / window_frames) * cur_sumsq - (1.0 / window_frames**2) * cur_sum**2\n",
    "                    variance = np.maximum(1.0e-10, variance)\n",
    "                    out_feat[t] /= variance**(0.5)\n",
    "                    \n",
    "        return out_feat\n",
    "\n",
    "    def _get_random_noise(self, noise_dict, return_index=False):\n",
    "        dict_len = len(noise_dict)\n",
    "        i = random.randint(0, dict_len-1)\n",
    "        noise_dir = noise_dict[i]\n",
    "        \n",
    "        if return_index:\n",
    "            return noise_dir, i\n",
    "        else:\n",
    "            return noise_dir\n",
    "    \n",
    "    def _get_random_spk_utt(self, spkr, spk2utt):\n",
    "        this_utts = spk2utt[spkr]\n",
    "        this_num_utts = len(this_utts)\n",
    "        i = random.randint(0, this_num_utts-1)\n",
    "        utt_dir = this_utts[i]\n",
    "        return utt_dir\n",
    "\n",
    "    def _get_random_offset(self, expected_length, utt_len):\n",
    "        if expected_length > utt_len:\n",
    "            return 0\n",
    "        \n",
    "        free_length = utt_len - expected_length\n",
    "        offset = random.randint(0, free_length)\n",
    "        return offset\n",
    "        \n",
    "    @property\n",
    "    def _VAD_config(self):\n",
    "        vad_energy_threshold = -3.0\n",
    "        vad_energy_mean_scale = 1.0\n",
    "        vad_frames_context = 0\n",
    "        vad_proportion_threshold = 0.12\n",
    "        \n",
    "        return vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold\n",
    "        \n",
    "        \n",
    "    def _VAD_detection(self, wav):\n",
    "        vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold = self._VAD_config\n",
    "        \n",
    "        y_tmp = np.pad(wav, int(512 // 2), mode='reflect')\n",
    "        y_tmp = librosa.util.frame(y_tmp, frame_length=512, hop_length=160)\n",
    "        y_log_energy = np.log(np.maximum(np.sum(y_tmp**2, axis=0), 1e-15))\n",
    "\n",
    "        T = len(y_log_energy)\n",
    "        output_voiced = np.zeros(T)\n",
    "        if (T == 0):\n",
    "            raise Exception(\"zero wave length\")\n",
    "\n",
    "        energy_threshold = vad_energy_threshold\n",
    "        if (vad_energy_mean_scale != 0.0):\n",
    "            assert(vad_energy_mean_scale > 0.0)\n",
    "            energy_threshold += vad_energy_mean_scale * np.sum(y_log_energy) / T\n",
    "\n",
    "\n",
    "        assert(vad_frames_context >= 0)\n",
    "        assert(vad_proportion_threshold > 0.0 and vad_proportion_threshold < 1.0);\n",
    "\n",
    "        for t in range(T):\n",
    "            num_count = 0\n",
    "            den_count = 0\n",
    "            context = vad_frames_context\n",
    "            for t2 in range(t - context, t + context+1):\n",
    "                if (t2 >= 0 and t2 < T):\n",
    "                    den_count+=1\n",
    "                    if (y_log_energy[t2] > energy_threshold):\n",
    "                        num_count+=1\n",
    "\n",
    "            if (num_count >= den_count * vad_proportion_threshold):\n",
    "                output_voiced[t] = 1.0\n",
    "            else:\n",
    "                output_voiced[t] = 0.0\n",
    "        \n",
    "        return output_voiced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "data_dir_dict = {}\n",
    "\n",
    "# val\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(OPT_INDEX, 'spk2utt_val_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(OPT_INDEX_1, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(OPT_INDEX_1, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(OPT_INDEX_1, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(OPT_INDEX_1, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(OPT_INDEX, 'spk2utt_val_len')\n",
    "data_len_dict['music_len'] = os.path.join(OPT_INDEX_1, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(OPT_INDEX_1, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(OPT_INDEX_1, 'babble_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preloading music_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "preloading noise_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "preloading babble_dict\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "8.780897378921509\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = 5\n",
    "config['batch_size'] = 1\n",
    "config['extended_prefectch'] = 1.0\n",
    "\n",
    "def iter_data_preload(dataset, i):\n",
    "    dataset.get_random_list()\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        for count, (data, label) in enumerate(dataset):\n",
    "            with open('/Lun0/zhiyong/vox_small_novad_sparse/val_data/'+str(count), 'wb') as handle:\n",
    "                pickle.dump((data.astype(np.float16), label.astype(np.int16)), handle)\n",
    "#             print(time.time()-start_time)\n",
    "            with open('/Lun0/zhiyong/vox_small_novad_sparse/tmp_data_errlog', 'a') as f:\n",
    "                f.write(str(time.time()-start_time)+'\\n')\n",
    "            start_time = time.time()\n",
    "    except Exception:\n",
    "        with open('/Lun0/zhiyong/vox_small_novad_sparse/tmp_data_errlog', 'a') as f:\n",
    "            traceback.print_exc(file=f)\n",
    "        raise Exception\n",
    "\n",
    "dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "# dataset.noise_data_preload2mem()\n",
    "dataset.noise_data_preload()\n",
    "\n",
    "processes = [Process(target = iter_data_preload, args = (dataset, i)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make validation index (Need only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "train_data_dir = os.path.join(OPT_INDEX, 'val_data')\n",
    "expected_len = 1000\n",
    "workers = 1\n",
    "single_worker_len = int(expected_len / workers)\n",
    "output = os.path.join(OPT_INDEX, 'val_data_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert expected_len == len(glob.glob(train_data_dir+'/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(output, 'w') as f:\n",
    "    for j in range(single_worker_len):\n",
    "        path = os.path.join(train_data_dir, str(j))\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trial data (Need only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fft = librosa.get_fftlib()\n",
    "class VoxIterableDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, data_dir_dict, data_len_dict, config):        \n",
    "        with open(data_dir_dict['spk2utt_train_dict'], 'rb') as handle:\n",
    "            self.spk2utt_train_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['music_dict'], 'rb') as handle:\n",
    "            self.music_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['noise_dict'], 'rb') as handle:\n",
    "            self.noise_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['babble_dict'], 'rb') as handle:\n",
    "            self.babble_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['rir_dict'], 'rb') as handle:\n",
    "            self.rir_dict = pickle.load(handle)\n",
    "            \n",
    "        with open(data_len_dict['spk2utt_train_len'], 'rb') as handle:\n",
    "            self.spk2utt_train_len = pickle.load(handle)\n",
    "        with open(data_len_dict['music_len'], 'rb') as handle:\n",
    "            self.music_len = pickle.load(handle)\n",
    "        with open(data_len_dict['noise_len'], 'rb') as handle:\n",
    "            self.noise_len = pickle.load(handle)\n",
    "        with open(data_len_dict['babble_len'], 'rb') as handle:\n",
    "            self.babble_len = pickle.load(handle)\n",
    "        \n",
    "        \n",
    "        self.random_spkrs_batchlist = None\n",
    "        self.ramdom_batch_len = None\n",
    "        self.random_noise_type = None\n",
    "        \n",
    "        \n",
    "        self.possible_babble_num = [3, 4, 5, 6, 7]\n",
    "        self.possible_babble_snr = [13, 15, 17, 20]\n",
    "        self.possible_noise_snr = [0, 5, 10, 15]\n",
    "        self.possible_music_snr = [5, 8, 10, 15]\n",
    "        \n",
    "        self.sr = config['sr']\n",
    "        self.repeats = config['repeats']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.extended_prefectch = config['extended_prefectch']\n",
    "        \n",
    "        self.mfcc_dim = 30\n",
    "        \n",
    "        # Auxiliary paras\n",
    "        self.multi_read_count = 0\n",
    "        self.preload_mem = False\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        assert len(self.ramdom_batch_len) == len(self.random_spkrs_batchlist)\n",
    "        try:\n",
    "            batch_frame_len = self.ramdom_batch_len.pop(0)\n",
    "            batch_spkrs = self.random_spkrs_batchlist.pop(0)\n",
    "            batch_noise_type = self.random_noise_type.pop(0)\n",
    "            batched_feats = np.zeros([self.batch_size, batch_frame_len, self.mfcc_dim])\n",
    "            batched_labels = np.zeros(self.batch_size)\n",
    "            \n",
    "            for batch_index, (spkr, noise_type) in enumerate(zip(batch_spkrs, batch_noise_type)):\n",
    "                \n",
    "                concat_wav, VAD_result = self._colleting_and_slicing(spkr, batch_frame_len,\\\n",
    "                hop_len=160, extended_prefectch=self.extended_prefectch)\n",
    "            \n",
    "                \n",
    "                if noise_type == 0:\n",
    "                    aug_wav = concat_wav\n",
    "                \n",
    "                elif noise_type == 1:\n",
    "                    aug_wav = self._add_rebverb(concat_wav)\n",
    "                   \n",
    "                elif noise_type == 2:\n",
    "                    aug_wav = self._add_noise(concat_wav)\n",
    "                    \n",
    "                elif noise_type == 3:\n",
    "                    aug_wav = self._add_music(concat_wav)\n",
    "                  \n",
    "                elif noise_type == 4:\n",
    "                    aug_wav = self._add_babble(concat_wav)\n",
    "             \n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                    \n",
    "            \n",
    "                single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "                dct_type=2, n_fft=512, hop_length=160, \\\n",
    "                win_length=None, window='hann', power=2.0, \\\n",
    "                center=True, pad_mode='reflect', n_mels=30, \\\n",
    "                fmin=20, fmax=7600)\n",
    "                # Note single_feats needs transpose\n",
    "                out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "                # Apply VAD\n",
    "                assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "                out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "                batched_feats[batch_index] = out_feats[:batch_frame_len]\n",
    "                batched_labels[batch_index] = spkr\n",
    "                \n",
    "            return batched_feats, batched_labels\n",
    "        \n",
    "        except IndexError:\n",
    "            raise StopIteration\n",
    "\n",
    "    def process_one_utt(self, utt_dir):\n",
    "        try:\n",
    "            concat_wav, _ = librosa.load(utt_dir, sr=self.sr)\n",
    "            \n",
    "            VAD_result = self._VAD_detection(concat_wav)\n",
    "            \n",
    "            aug_wav = concat_wav\n",
    "\n",
    "            single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "            dct_type=2, n_fft=512, hop_length=160, \\\n",
    "            win_length=None, window='hann', power=2.0, \\\n",
    "            center=True, pad_mode='reflect', n_mels=30, \\\n",
    "            fmin=20, fmax=7600)\n",
    "            # Note single_feats needs transpose\n",
    "            out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "            # Apply VAD\n",
    "            assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "            out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "            \n",
    "            batched_feats = out_feats[None, :, :]\n",
    "                \n",
    "            return batched_feats\n",
    "        \n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    def noise_data_preload(self):\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            _, _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            _, _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            _, _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "    \n",
    "    def noise_data_preload2mem(self):\n",
    "        print('preloading to memory')\n",
    "        \n",
    "        self.music_preload_dict = {}\n",
    "        self.noise_preload_dict = {}\n",
    "        self.babble_preload_dict = {}\n",
    "        self.preload_mem = True\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            self.music_preload_dict[i], _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            self.noise_preload_dict[i], _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            self.babble_preload_dict[i], _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)       \n",
    "        \n",
    "        \n",
    "    def get_random_list(self):\n",
    "        spkrs_list = self.repeats * list(self.spk2utt_train_dict.keys())\n",
    "        random.shuffle(spkrs_list)\n",
    "        len_spkrs_list = len(spkrs_list)\n",
    "        self.random_spkrs_batchlist = [spkrs_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        self.ramdom_batch_len = [random.randint(200, 400) for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        noise_type_list = [i%5 for i in range(len_spkrs_list)]\n",
    "\n",
    "        random.shuffle(noise_type_list)\n",
    "        self.random_noise_type = [noise_type_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        assert len(self.random_spkrs_batchlist) == len(self.ramdom_batch_len)\\\n",
    "        == len(self.random_noise_type)\n",
    "        \n",
    "    def _colleting_and_slicing(self, spkr, batch_frame_len, hop_len=160, extended_prefectch=2.0):\n",
    "        \n",
    "        least_wav_len = (batch_frame_len - 1) * hop_len\n",
    "        concat_utt = np.zeros(0)\n",
    "        valid_frames_len = 0\n",
    "        \n",
    "        # Use to count multi_read_count\n",
    "        get_count = 0\n",
    "\n",
    "        while valid_frames_len < batch_frame_len:\n",
    "            utt_dir = self._get_random_spk_utt(spkr, self.spk2utt_train_dict)\n",
    "            utt_len = self.spk2utt_train_len[utt_dir]\n",
    "#             off = self._get_random_offset(least_wav_len, utt_len) / self.sr\n",
    "            off = self._get_random_offset(least_wav_len+extended_prefectch*self.sr, utt_len) / self.sr\n",
    "            dur = least_wav_len / self.sr + extended_prefectch\n",
    "            \n",
    "            utt_part, _ = librosa.load(utt_dir, sr=self.sr, offset=off, duration=dur)\n",
    "            \n",
    "            concat_utt = np.append(concat_utt, utt_part)\n",
    "            detected_frames = self._VAD_detection(concat_utt)\n",
    "            valid_frames_len = np.sum(detected_frames)\n",
    "\n",
    "            get_count += 1\n",
    "\n",
    "        if get_count > 1:\n",
    "            self.multi_read_count += 1\n",
    "\n",
    "        VAD_result = detected_frames\n",
    "        return concat_utt, VAD_result\n",
    "    \n",
    "    def _add_rebverb(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = in_wav\n",
    "        filter_dir = self._get_random_noise(self.rir_dict)\n",
    "        filter, _ = librosa.load(filter_dir, sr=self.sr)\n",
    "        \n",
    "        signal_length = len(signal)\n",
    "        filter_length = len(filter)\n",
    "        output_length = signal_length + filter_length - 1\n",
    "        output = np.zeros(output_length)\n",
    "\n",
    "        fft_length = 2**np.ceil(np.log2(4 * filter_length)).astype(np.int)\n",
    "        block_length = fft_length - filter_length + 1\n",
    "\n",
    "\n",
    "        filter_padded = np.zeros(fft_length)\n",
    "        filter_padded[0:filter_length] = filter\n",
    "        filter_padded = fft.rfft(filter_padded)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(signal_length//block_length + 1):\n",
    "            process_length = min(block_length, signal_length - i * block_length);\n",
    "            signal_block_padded = np.zeros(fft_length)\n",
    "            signal_block_padded[0:process_length] = signal[i * block_length : i * block_length + process_length]\n",
    "            signal_block_padded = fft.rfft(signal_block_padded)\n",
    "\n",
    "            signal_block_padded = filter_padded * signal_block_padded\n",
    "\n",
    "            signal_block_padded = fft.irfft(signal_block_padded, n=fft_length)\n",
    "\n",
    "            if (i*block_length + fft_length) <= output_length:\n",
    "                output[i*block_length : i*block_length + fft_length] += signal_block_padded\n",
    "            else:\n",
    "                output[i*block_length : output_length] += signal_block_padded[:output_length-i*block_length]\n",
    "        \n",
    "        # shift with max index of filter\n",
    "        shift_index = np.argmax(filter)\n",
    "        \n",
    "        final_out = output[shift_index:shift_index+signal_length]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_noise(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = in_wav\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.noise_dict, return_index=True)\n",
    "            noise_len = self.noise_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "                \n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_noise_snr[random.randint(0, len(self.possible_noise_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_music(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = in_wav\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.music_dict, return_index=True)\n",
    "            noise_len = self.music_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_music_snr[random.randint(0, len(self.possible_music_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_babble(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = in_wav\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        signal_off = 0\n",
    "        bg_spks_num = self.possible_babble_num[random.randint(0, len(self.possible_babble_num)-1)]    \n",
    "        for _ in range(bg_spks_num):            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.babble_dict, return_index=True)\n",
    "            noise_len = self.babble_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_babble_snr[random.randint(0, len(self.possible_babble_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_db(self, in_wav, noise, signal_off, snr_db, power_before_reverb):\n",
    "        signal = in_wav\n",
    "\n",
    "        noise_power = noise.dot(noise) / len(noise)\n",
    "        scale_factor = np.sqrt(10**(-snr_db / 10) * power_before_reverb / noise_power)\n",
    "        noise = scale_factor * noise\n",
    "\n",
    "        add_length = min(len(noise), len(signal)-signal_off)\n",
    "        signal[signal_off:signal_off+add_length] += noise[:add_length]\n",
    "        out_wav = signal      \n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _CMVN(self, in_feat, cmn_window = 300, normalize_variance = False):             \n",
    "        num_frames = in_feat.shape[0]\n",
    "        dim = in_feat.shape[1]\n",
    "        last_window_start = -1\n",
    "        last_window_end = -1\n",
    "        cur_sum = np.zeros(dim)\n",
    "        cur_sumsq = np.zeros(dim)\n",
    "\n",
    "        out_feat = np.zeros([num_frames, dim])\n",
    "\n",
    "        for t in range(num_frames):\n",
    "            window_start = 0\n",
    "            window_end = 0\n",
    "\n",
    "            window_start = t - int(cmn_window / 2)\n",
    "            window_end = window_start + cmn_window\n",
    "\n",
    "            if (window_start < 0):\n",
    "                window_end -= window_start\n",
    "                window_start = 0\n",
    "\n",
    "            if (window_end > num_frames):\n",
    "                window_start -= (window_end - num_frames)\n",
    "                window_end = num_frames\n",
    "                if (window_start < 0):\n",
    "                    window_start = 0\n",
    "\n",
    "            if (last_window_start == -1):\n",
    "                input_part = in_feat[window_start:window_end]\n",
    "                cur_sum = np.sum(input_part, axis=0, keepdims=False)\n",
    "                if normalize_variance:\n",
    "                    cur_sumsq = np.sum(input_part**2, axis=0, keepdims=False)\n",
    "            else:\n",
    "                if (window_start > last_window_start):\n",
    "                    frame_to_remove = in_feat[last_window_start]\n",
    "                    cur_sum -= frame_to_remove\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq -= frame_to_remove**2\n",
    "\n",
    "                if (window_end > last_window_end):\n",
    "                    frame_to_add = in_feat[last_window_end]\n",
    "                    cur_sum += frame_to_add\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq += frame_to_add**2\n",
    "\n",
    "            window_frames = window_end - window_start\n",
    "            last_window_start = window_start\n",
    "            last_window_end = window_end\n",
    "\n",
    "            out_feat[t] = in_feat[t] - (1.0 / window_frames) * cur_sum\n",
    "\n",
    "\n",
    "            if normalize_variance:\n",
    "                if (window_frames == 1):\n",
    "                    out_feat[t] = 0.0\n",
    "                else:\n",
    "                    variance = (1.0 / window_frames) * cur_sumsq - (1.0 / window_frames**2) * cur_sum**2\n",
    "                    variance = np.maximum(1.0e-10, variance)\n",
    "                    out_feat[t] /= variance**(0.5)\n",
    "                    \n",
    "        return out_feat\n",
    "\n",
    "    def _get_random_noise(self, noise_dict, return_index=False):\n",
    "        dict_len = len(noise_dict)\n",
    "        i = random.randint(0, dict_len-1)\n",
    "        noise_dir = noise_dict[i]\n",
    "        \n",
    "        if return_index:\n",
    "            return noise_dir, i\n",
    "        else:\n",
    "            return noise_dir\n",
    "    \n",
    "    def _get_random_spk_utt(self, spkr, spk2utt):\n",
    "        this_utts = spk2utt[spkr]\n",
    "        this_num_utts = len(this_utts)\n",
    "        i = random.randint(0, this_num_utts-1)\n",
    "        utt_dir = this_utts[i]\n",
    "        return utt_dir\n",
    "\n",
    "    def _get_random_offset(self, expected_length, utt_len):\n",
    "        if expected_length > utt_len:\n",
    "            return 0\n",
    "        \n",
    "        free_length = utt_len - expected_length\n",
    "        offset = random.randint(0, free_length)\n",
    "        return offset\n",
    "        \n",
    "    @property\n",
    "    def _VAD_config(self):\n",
    "        vad_energy_threshold = -3.0\n",
    "        vad_energy_mean_scale = 1.0\n",
    "        vad_frames_context = 0\n",
    "        vad_proportion_threshold = 0.12\n",
    "        \n",
    "        return vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold\n",
    "        \n",
    "        \n",
    "    def _VAD_detection(self, wav):\n",
    "        vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold = self._VAD_config\n",
    "        \n",
    "        y_tmp = np.pad(wav, int(512 // 2), mode='reflect')\n",
    "        y_tmp = librosa.util.frame(y_tmp, frame_length=512, hop_length=160)\n",
    "        y_log_energy = np.log(np.maximum(np.sum(y_tmp**2, axis=0), 1e-15))\n",
    "\n",
    "        T = len(y_log_energy)\n",
    "        output_voiced = np.zeros(T)\n",
    "        if (T == 0):\n",
    "            raise Exception(\"zero wave length\")\n",
    "\n",
    "        energy_threshold = vad_energy_threshold\n",
    "        if (vad_energy_mean_scale != 0.0):\n",
    "            assert(vad_energy_mean_scale > 0.0)\n",
    "            energy_threshold += vad_energy_mean_scale * np.sum(y_log_energy) / T\n",
    "\n",
    "\n",
    "        assert(vad_frames_context >= 0)\n",
    "        assert(vad_proportion_threshold > 0.0 and vad_proportion_threshold < 1.0);\n",
    "\n",
    "        for t in range(T):\n",
    "            num_count = 0\n",
    "            den_count = 0\n",
    "            context = vad_frames_context\n",
    "            for t2 in range(t - context, t + context+1):\n",
    "                if (t2 >= 0 and t2 < T):\n",
    "                    den_count+=1\n",
    "                    if (y_log_energy[t2] > energy_threshold):\n",
    "                        num_count+=1\n",
    "\n",
    "            if (num_count >= den_count * vad_proportion_threshold):\n",
    "                output_voiced[t] = 1.0\n",
    "            else:\n",
    "                output_voiced[t] = 0.0\n",
    "        \n",
    "        return output_voiced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "data_dir_dict = {}\n",
    "\n",
    "# val\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(OPT_INDEX, 'spk2utt_val_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(OPT_INDEX, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(OPT_INDEX, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(OPT_INDEX, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(OPT_INDEX, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(OPT_INDEX, 'spk2utt_val_len')\n",
    "data_len_dict['music_len'] = os.path.join(OPT_INDEX, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(OPT_INDEX, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(OPT_INDEX, 'babble_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07287907600402832\n",
      "0.022907257080078125\n",
      "0.025229215621948242\n",
      "0.03087759017944336\n",
      "0.027460336685180664\n",
      "0.012605428695678711\n",
      "0.013921260833740234\n",
      "0.018674850463867188\n",
      "0.025691986083984375\n",
      "0.01715874671936035\n",
      "0.022578716278076172\n",
      "0.03155040740966797\n",
      "0.013101339340209961\n",
      "0.021047592163085938\n",
      "0.020425796508789062\n",
      "0.014108896255493164\n",
      "0.018069982528686523\n",
      "0.028415679931640625\n",
      "0.0164029598236084\n",
      "0.023502588272094727\n",
      "0.024616718292236328\n",
      "0.013360738754272461\n",
      "0.042522430419921875\n",
      "0.023035049438476562\n",
      "0.040648698806762695\n",
      "0.01689767837524414\n",
      "0.028036832809448242\n",
      "0.02653956413269043\n",
      "0.08423042297363281\n",
      "0.024197816848754883\n",
      "0.0241091251373291\n",
      "0.04253411293029785\n",
      "0.03831362724304199\n",
      "0.014290809631347656\n",
      "0.01449894905090332\n",
      "0.06771516799926758\n",
      "0.014318466186523438\n",
      "0.022284984588623047\n",
      "0.019834041595458984\n",
      "0.02354121208190918\n",
      "0.012340068817138672\n",
      "0.01557016372680664\n",
      "0.023464202880859375\n",
      "0.01560068130493164\n",
      "0.017389774322509766\n",
      "0.014495849609375\n",
      "0.02409219741821289\n",
      "0.014666557312011719\n",
      "0.014875173568725586\n",
      "0.027643442153930664\n",
      "0.017742156982421875\n",
      "0.028305530548095703\n",
      "0.018347740173339844\n",
      "0.014204263687133789\n",
      "0.0405726432800293\n",
      "0.01997995376586914\n",
      "0.015014410018920898\n",
      "0.013019561767578125\n",
      "0.013629674911499023\n",
      "0.012783527374267578\n",
      "0.017466068267822266\n",
      "0.014346837997436523\n",
      "0.016431331634521484\n",
      "0.02593207359313965\n",
      "0.033419132232666016\n",
      "0.07106733322143555\n",
      "0.018721342086791992\n",
      "0.028947114944458008\n",
      "0.03543663024902344\n",
      "0.01842522621154785\n",
      "0.024548053741455078\n",
      "0.03908371925354004\n",
      "0.014697790145874023\n",
      "0.019433975219726562\n",
      "0.014988899230957031\n",
      "0.029254913330078125\n",
      "0.02964496612548828\n",
      "0.06325268745422363\n",
      "0.02861332893371582\n",
      "0.04225754737854004\n",
      "0.01415395736694336\n",
      "0.030156373977661133\n",
      "0.029134035110473633\n",
      "0.03950762748718262\n",
      "0.022902965545654297\n",
      "0.03625607490539551\n",
      "0.0342402458190918\n",
      "0.013651132583618164\n",
      "0.014018774032592773\n",
      "0.03785300254821777\n",
      "0.018654584884643555\n",
      "0.020727157592773438\n",
      "0.07468175888061523\n",
      "0.0531620979309082\n",
      "0.01586604118347168\n",
      "0.021210908889770508\n",
      "0.012563705444335938\n",
      "0.0226438045501709\n",
      "0.011960506439208984\n",
      "0.010555028915405273\n",
      "0.018109798431396484\n",
      "0.011117935180664062\n",
      "0.016857385635375977\n",
      "0.014727592468261719\n",
      "0.010823726654052734\n",
      "0.012499094009399414\n",
      "0.012473344802856445\n",
      "0.008815526962280273\n",
      "0.018097639083862305\n",
      "0.014119625091552734\n",
      "0.014220714569091797\n",
      "0.013225555419921875\n",
      "0.007857561111450195\n",
      "0.009951591491699219\n",
      "0.013373613357543945\n",
      "0.009924888610839844\n",
      "0.008493661880493164\n",
      "0.010815858840942383\n",
      "0.009593009948730469\n",
      "0.018572330474853516\n",
      "0.07205677032470703\n",
      "0.0454716682434082\n",
      "0.033443450927734375\n",
      "0.00791311264038086\n",
      "0.015869855880737305\n",
      "0.007550716400146484\n",
      "0.013656377792358398\n",
      "0.009833335876464844\n",
      "0.018664836883544922\n",
      "0.01134634017944336\n",
      "0.009940862655639648\n",
      "0.01289820671081543\n",
      "0.016077518463134766\n",
      "0.023659467697143555\n",
      "0.015933513641357422\n",
      "0.009775876998901367\n",
      "0.019744157791137695\n",
      "0.007987499237060547\n",
      "0.01880192756652832\n",
      "0.015582799911499023\n",
      "0.014909982681274414\n",
      "0.042243242263793945\n",
      "0.009639501571655273\n",
      "0.014176607131958008\n",
      "0.01958608627319336\n",
      "0.04639387130737305\n",
      "0.020220041275024414\n",
      "0.012225866317749023\n",
      "0.019420623779296875\n",
      "0.013441085815429688\n",
      "0.008234262466430664\n",
      "0.015025615692138672\n",
      "0.009503602981567383\n",
      "0.009033679962158203\n",
      "0.00763392448425293\n",
      "0.009250402450561523\n",
      "0.018107175827026367\n",
      "0.028470277786254883\n",
      "0.013184785842895508\n",
      "0.014389753341674805\n",
      "0.010588884353637695\n",
      "0.04127645492553711\n",
      "0.02359747886657715\n",
      "0.012930631637573242\n",
      "0.055570125579833984\n",
      "0.01947498321533203\n",
      "0.0216519832611084\n",
      "0.010826587677001953\n",
      "0.02994680404663086\n",
      "0.00799560546875\n",
      "0.013400793075561523\n",
      "0.02350330352783203\n",
      "0.03570556640625\n",
      "0.01685333251953125\n",
      "0.009282827377319336\n",
      "0.007829904556274414\n",
      "0.04286623001098633\n",
      "0.01708841323852539\n",
      "0.01119089126586914\n",
      "0.008615493774414062\n",
      "0.037722110748291016\n",
      "0.007738590240478516\n",
      "0.012284040451049805\n",
      "0.031092166900634766\n",
      "0.013503789901733398\n",
      "0.021608352661132812\n",
      "0.014264106750488281\n",
      "0.03553199768066406\n",
      "0.0338902473449707\n",
      "0.024049758911132812\n",
      "0.019843339920043945\n",
      "0.034914493560791016\n",
      "0.0255892276763916\n",
      "0.031079769134521484\n",
      "0.039475202560424805\n",
      "0.015786409378051758\n",
      "0.013303756713867188\n",
      "0.013622760772705078\n",
      "0.03301668167114258\n",
      "0.022730112075805664\n",
      "0.014357566833496094\n",
      "0.015166759490966797\n",
      "0.012252569198608398\n",
      "0.027245521545410156\n",
      "0.010152339935302734\n",
      "0.015510797500610352\n",
      "0.014160633087158203\n",
      "0.01990509033203125\n",
      "0.016381263732910156\n",
      "0.012949705123901367\n",
      "0.013863086700439453\n",
      "0.016210079193115234\n",
      "0.04951810836791992\n",
      "0.07479333877563477\n",
      "0.03978157043457031\n",
      "0.009435653686523438\n",
      "0.011482954025268555\n",
      "0.008269786834716797\n",
      "0.01317596435546875\n",
      "0.030858993530273438\n",
      "0.01029825210571289\n",
      "0.019131183624267578\n",
      "0.015269041061401367\n",
      "0.008627176284790039\n",
      "0.009629487991333008\n",
      "0.018213510513305664\n",
      "0.029299497604370117\n",
      "0.017888784408569336\n",
      "0.021380901336669922\n",
      "0.008020877838134766\n",
      "0.024430036544799805\n",
      "0.012475013732910156\n",
      "0.07192349433898926\n",
      "0.015964031219482422\n",
      "0.018666744232177734\n",
      "0.017476558685302734\n",
      "0.04440140724182129\n",
      "0.02405524253845215\n",
      "0.013907432556152344\n",
      "0.03789186477661133\n",
      "0.04208660125732422\n",
      "0.017684459686279297\n",
      "0.07555818557739258\n",
      "0.02927875518798828\n",
      "0.024362564086914062\n",
      "0.012843132019042969\n",
      "0.04361128807067871\n",
      "0.04684019088745117\n",
      "0.03588604927062988\n",
      "0.013548612594604492\n",
      "0.02010631561279297\n",
      "0.018313169479370117\n",
      "0.030263185501098633\n",
      "0.02204155921936035\n",
      "0.027383089065551758\n",
      "0.026609420776367188\n",
      "0.016951560974121094\n",
      "0.01536250114440918\n",
      "0.016338825225830078\n",
      "0.01535797119140625\n",
      "0.026525259017944336\n",
      "0.02197098731994629\n",
      "0.02145552635192871\n",
      "0.012351036071777344\n",
      "0.0210263729095459\n",
      "0.012526273727416992\n",
      "0.013412952423095703\n",
      "0.029580354690551758\n",
      "0.016269683837890625\n",
      "0.01658940315246582\n",
      "0.030872106552124023\n",
      "0.02460765838623047\n",
      "0.013647794723510742\n",
      "0.014832496643066406\n",
      "0.02165365219116211\n",
      "0.019984960556030273\n",
      "0.013062238693237305\n",
      "0.037343502044677734\n",
      "0.03253030776977539\n",
      "0.032222747802734375\n",
      "0.039320945739746094\n",
      "0.013379573822021484\n",
      "0.02843785285949707\n",
      "0.02597784996032715\n",
      "0.03066563606262207\n",
      "0.022148847579956055\n",
      "0.016338109970092773\n",
      "0.027140140533447266\n",
      "0.012366771697998047\n",
      "0.026560306549072266\n",
      "0.01555013656616211\n",
      "0.017380237579345703\n",
      "0.018027782440185547\n",
      "0.010074615478515625\n",
      "0.014505147933959961\n",
      "0.01420140266418457\n",
      "0.008294105529785156\n",
      "0.013019561767578125\n",
      "0.017426729202270508\n",
      "0.022882699966430664\n",
      "0.008707761764526367\n",
      "0.011033773422241211\n",
      "0.013537168502807617\n",
      "0.02273082733154297\n",
      "0.008266210556030273\n",
      "0.011632204055786133\n",
      "0.008335113525390625\n",
      "0.028183937072753906\n",
      "0.07556843757629395\n",
      "0.011056184768676758\n",
      "0.05406546592712402\n",
      "0.012343645095825195\n",
      "0.012748241424560547\n",
      "0.020353078842163086\n",
      "0.02481222152709961\n",
      "0.010147571563720703\n",
      "0.010729551315307617\n",
      "0.011386394500732422\n",
      "0.00836181640625\n",
      "0.013280153274536133\n",
      "0.013796091079711914\n",
      "0.03591632843017578\n",
      "0.01953434944152832\n",
      "0.011486053466796875\n",
      "0.01151728630065918\n",
      "0.012424468994140625\n",
      "0.01737213134765625\n",
      "0.04741477966308594\n",
      "0.02056741714477539\n",
      "0.011715173721313477\n",
      "0.010584592819213867\n",
      "0.08536338806152344\n",
      "0.029256582260131836\n",
      "0.018570661544799805\n",
      "0.016295194625854492\n",
      "0.015516996383666992\n",
      "0.01534724235534668\n",
      "0.009524106979370117\n",
      "0.008885860443115234\n",
      "0.009281396865844727\n",
      "0.008321762084960938\n",
      "0.009182929992675781\n",
      "0.00910043716430664\n",
      "0.022124290466308594\n",
      "0.016907691955566406\n",
      "0.013989448547363281\n",
      "0.013050317764282227\n",
      "0.036101579666137695\n",
      "0.015599966049194336\n",
      "0.011338949203491211\n",
      "0.008923053741455078\n",
      "0.01264333724975586\n",
      "0.02841043472290039\n",
      "0.008663177490234375\n",
      "0.010106325149536133\n",
      "0.023172378540039062\n",
      "0.013528585433959961\n",
      "0.022045135498046875\n",
      "0.016087055206298828\n",
      "0.009582042694091797\n",
      "0.013546943664550781\n",
      "0.009127378463745117\n",
      "0.009333372116088867\n",
      "0.01521611213684082\n",
      "0.008891582489013672\n",
      "0.010133504867553711\n",
      "0.010707855224609375\n",
      "0.009350776672363281\n",
      "0.011931419372558594\n",
      "0.008350372314453125\n",
      "0.011069297790527344\n",
      "0.01147317886352539\n",
      "0.012671232223510742\n",
      "0.011487245559692383\n",
      "0.009349584579467773\n",
      "0.013607025146484375\n",
      "0.01325535774230957\n",
      "0.012322187423706055\n",
      "0.012830972671508789\n",
      "0.017745494842529297\n",
      "0.020053863525390625\n",
      "0.02032756805419922\n",
      "0.025994539260864258\n",
      "0.011792659759521484\n",
      "0.009034872055053711\n",
      "0.009105443954467773\n",
      "0.009757041931152344\n",
      "0.012621879577636719\n",
      "0.026653289794921875\n",
      "0.014754533767700195\n",
      "0.010757923126220703\n",
      "0.013144254684448242\n",
      "0.012196540832519531\n",
      "0.017642736434936523\n",
      "0.009281635284423828\n",
      "0.009348869323730469\n",
      "0.010613441467285156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015488147735595703\n",
      "0.009747028350830078\n",
      "0.013583660125732422\n",
      "0.01604628562927246\n",
      "0.010938882827758789\n",
      "0.016330718994140625\n",
      "0.018108606338500977\n",
      "0.024467945098876953\n",
      "0.015343666076660156\n",
      "0.020621299743652344\n",
      "0.012320280075073242\n",
      "0.009239673614501953\n",
      "0.010608434677124023\n",
      "0.012408018112182617\n",
      "0.009007692337036133\n",
      "0.009940624237060547\n",
      "0.023001909255981445\n",
      "0.009037256240844727\n",
      "0.013557195663452148\n",
      "0.012632608413696289\n",
      "0.011828184127807617\n",
      "0.01585078239440918\n",
      "0.00923299789428711\n",
      "0.009802579879760742\n",
      "0.018346071243286133\n",
      "0.010751485824584961\n",
      "0.014223575592041016\n",
      "0.023897171020507812\n",
      "0.01324915885925293\n",
      "0.013222217559814453\n",
      "0.017880678176879883\n",
      "0.012619972229003906\n",
      "0.01996016502380371\n",
      "0.012471199035644531\n",
      "0.01659870147705078\n",
      "0.01203155517578125\n",
      "0.026020288467407227\n",
      "0.009439945220947266\n",
      "0.018280982971191406\n",
      "0.013326883316040039\n",
      "0.014516353607177734\n",
      "0.016368865966796875\n",
      "0.009016990661621094\n",
      "0.014873981475830078\n",
      "0.013907432556152344\n",
      "0.03354215621948242\n",
      "0.009061813354492188\n",
      "0.014988183975219727\n",
      "0.014760017395019531\n",
      "0.01511383056640625\n",
      "0.022618770599365234\n",
      "0.02258896827697754\n",
      "0.010262012481689453\n",
      "0.0116119384765625\n",
      "0.009026050567626953\n",
      "0.010134458541870117\n",
      "0.010088920593261719\n",
      "0.01711869239807129\n",
      "0.015459299087524414\n",
      "0.0172421932220459\n",
      "0.021323680877685547\n",
      "0.009772539138793945\n",
      "0.01373600959777832\n",
      "0.008526802062988281\n",
      "0.009428024291992188\n",
      "0.02336287498474121\n",
      "0.013035774230957031\n",
      "0.008235454559326172\n",
      "0.01955270767211914\n",
      "0.015310287475585938\n",
      "0.014157533645629883\n",
      "0.02034139633178711\n",
      "0.016344308853149414\n",
      "0.021232128143310547\n",
      "0.044814348220825195\n",
      "0.019450664520263672\n",
      "0.021744728088378906\n",
      "0.013655900955200195\n",
      "0.020411014556884766\n",
      "0.046803951263427734\n",
      "0.02266073226928711\n",
      "0.028785228729248047\n",
      "0.02048206329345703\n",
      "0.036787986755371094\n",
      "0.01715087890625\n",
      "0.020216941833496094\n",
      "0.020782947540283203\n",
      "0.025480985641479492\n",
      "0.01255035400390625\n",
      "0.04084205627441406\n",
      "0.01636648178100586\n",
      "0.022508859634399414\n",
      "0.01903820037841797\n",
      "0.013077974319458008\n",
      "0.07625174522399902\n",
      "0.01359701156616211\n",
      "0.012744665145874023\n",
      "0.038637638092041016\n",
      "0.018014907836914062\n",
      "0.010849237442016602\n",
      "0.01786518096923828\n",
      "0.02000594139099121\n",
      "0.014704704284667969\n",
      "0.010505914688110352\n",
      "0.012149810791015625\n",
      "0.008556604385375977\n",
      "0.019500732421875\n",
      "0.01351475715637207\n",
      "0.04955744743347168\n",
      "0.04346179962158203\n",
      "0.013172149658203125\n",
      "0.017812013626098633\n",
      "0.029480695724487305\n",
      "0.009617805480957031\n",
      "0.021542787551879883\n",
      "0.009393692016601562\n",
      "0.012155294418334961\n",
      "0.010148048400878906\n",
      "0.015211105346679688\n",
      "0.01698923110961914\n",
      "0.01903986930847168\n",
      "0.010649919509887695\n",
      "0.01616191864013672\n",
      "0.012664794921875\n",
      "0.04088187217712402\n",
      "0.010406017303466797\n",
      "0.025185346603393555\n",
      "0.01909494400024414\n",
      "0.017840147018432617\n",
      "0.019247055053710938\n",
      "0.008820533752441406\n",
      "0.015866518020629883\n",
      "0.010551214218139648\n",
      "0.00858759880065918\n",
      "0.012066841125488281\n",
      "0.016051769256591797\n",
      "0.013641119003295898\n",
      "0.01544642448425293\n",
      "0.010255098342895508\n",
      "0.00873255729675293\n",
      "0.008384227752685547\n",
      "0.010709524154663086\n",
      "0.008784294128417969\n",
      "0.010272026062011719\n",
      "0.008775711059570312\n",
      "0.0201723575592041\n",
      "0.031273603439331055\n",
      "0.009978532791137695\n",
      "0.013557672500610352\n",
      "0.08221626281738281\n",
      "0.02185535430908203\n",
      "0.014150857925415039\n",
      "0.02824115753173828\n",
      "0.018289566040039062\n",
      "0.011288881301879883\n",
      "0.02614736557006836\n",
      "0.02765345573425293\n",
      "0.011837005615234375\n",
      "0.011416435241699219\n",
      "0.014230012893676758\n",
      "0.018633127212524414\n",
      "0.025141239166259766\n",
      "0.020910978317260742\n",
      "0.02178478240966797\n",
      "0.015410900115966797\n",
      "0.022099733352661133\n",
      "0.017332792282104492\n",
      "0.013358116149902344\n",
      "0.011815547943115234\n",
      "0.04340529441833496\n",
      "0.02293705940246582\n",
      "0.02026844024658203\n",
      "0.016366243362426758\n",
      "0.009749174118041992\n",
      "0.008522272109985352\n",
      "0.04513263702392578\n",
      "0.026183605194091797\n",
      "0.01818990707397461\n",
      "0.009665966033935547\n",
      "0.026546478271484375\n",
      "0.01145625114440918\n",
      "0.010201215744018555\n",
      "0.010575532913208008\n",
      "0.019666671752929688\n",
      "0.014665842056274414\n",
      "0.03348231315612793\n",
      "0.03816056251525879\n",
      "0.018945693969726562\n",
      "0.020578384399414062\n",
      "0.009807825088500977\n",
      "0.010332107543945312\n",
      "0.008312702178955078\n",
      "0.008515119552612305\n",
      "0.010017871856689453\n",
      "0.014948129653930664\n",
      "0.01669764518737793\n",
      "0.01740097999572754\n",
      "0.02781844139099121\n",
      "0.017328977584838867\n",
      "0.016809701919555664\n",
      "0.019379854202270508\n",
      "0.008348941802978516\n",
      "0.015649795532226562\n",
      "0.023486614227294922\n",
      "0.03555631637573242\n",
      "0.010569334030151367\n",
      "0.017719268798828125\n",
      "0.027944087982177734\n",
      "0.012215614318847656\n",
      "0.013952016830444336\n",
      "0.031427621841430664\n",
      "0.017159461975097656\n",
      "0.024757862091064453\n",
      "0.02992105484008789\n",
      "0.011084318161010742\n",
      "0.012470006942749023\n",
      "0.014255046844482422\n",
      "0.016620397567749023\n",
      "0.009548187255859375\n",
      "0.011678218841552734\n",
      "0.011682510375976562\n",
      "0.023897647857666016\n",
      "0.012890815734863281\n",
      "0.015641450881958008\n",
      "0.014609098434448242\n",
      "0.01767563819885254\n",
      "0.014668464660644531\n",
      "0.012244224548339844\n",
      "0.012201070785522461\n",
      "0.007588624954223633\n",
      "0.011776924133300781\n",
      "0.007371664047241211\n",
      "0.011412382125854492\n",
      "0.013191699981689453\n",
      "0.018199443817138672\n",
      "0.01174020767211914\n",
      "0.010292530059814453\n",
      "0.016121387481689453\n",
      "0.015751123428344727\n",
      "0.01066279411315918\n",
      "0.010979890823364258\n",
      "0.008575916290283203\n",
      "0.01099705696105957\n",
      "0.007816314697265625\n",
      "0.007574319839477539\n",
      "0.008088827133178711\n",
      "0.024496793746948242\n",
      "0.026178598403930664\n",
      "0.01440882682800293\n",
      "0.01674365997314453\n",
      "0.02906322479248047\n",
      "0.036446571350097656\n",
      "0.11472702026367188\n",
      "0.04017996788024902\n",
      "0.019132137298583984\n",
      "0.015356779098510742\n",
      "0.020909547805786133\n",
      "0.02300095558166504\n",
      "0.022439241409301758\n",
      "0.01744699478149414\n",
      "0.03412294387817383\n",
      "0.04381155967712402\n",
      "0.02018141746520996\n",
      "0.055730581283569336\n",
      "0.0219118595123291\n",
      "0.03628969192504883\n",
      "0.03875088691711426\n",
      "0.05404996871948242\n",
      "0.027976036071777344\n",
      "0.024157047271728516\n",
      "0.02829742431640625\n",
      "0.06836962699890137\n",
      "0.015668630599975586\n",
      "0.01735997200012207\n",
      "0.045768022537231445\n",
      "0.02883291244506836\n",
      "0.051233530044555664\n",
      "0.01690053939819336\n",
      "0.018439769744873047\n",
      "0.01607346534729004\n",
      "0.0208282470703125\n",
      "0.029341936111450195\n",
      "0.04295635223388672\n",
      "0.018304824829101562\n",
      "0.01185297966003418\n",
      "0.008749008178710938\n",
      "0.010085582733154297\n",
      "0.01658940315246582\n",
      "0.009413480758666992\n",
      "0.008344650268554688\n",
      "0.010298967361450195\n",
      "0.010178089141845703\n",
      "0.009166479110717773\n",
      "0.011290550231933594\n",
      "0.01648092269897461\n",
      "0.012800931930541992\n",
      "0.007539033889770508\n",
      "0.009973526000976562\n",
      "0.019974231719970703\n",
      "0.01309967041015625\n",
      "0.010660886764526367\n",
      "0.0207977294921875\n",
      "0.022268056869506836\n",
      "0.01409912109375\n",
      "0.014750480651855469\n",
      "0.014369726181030273\n",
      "0.012369155883789062\n",
      "0.025606393814086914\n",
      "0.012745857238769531\n",
      "0.022745609283447266\n",
      "0.01728963851928711\n",
      "0.013902902603149414\n",
      "0.017850875854492188\n",
      "0.01640033721923828\n",
      "0.014685630798339844\n",
      "0.014982223510742188\n",
      "0.017203092575073242\n",
      "0.022495508193969727\n",
      "0.013787031173706055\n",
      "0.021934986114501953\n",
      "0.014749288558959961\n",
      "0.014690637588500977\n",
      "0.022280454635620117\n",
      "0.03941154479980469\n",
      "0.014246940612792969\n",
      "0.01606297492980957\n",
      "0.009878873825073242\n",
      "0.01172780990600586\n",
      "0.011483192443847656\n",
      "0.016651391983032227\n",
      "0.01091623306274414\n",
      "0.011356830596923828\n",
      "0.00936126708984375\n",
      "0.009975671768188477\n",
      "0.009201526641845703\n",
      "0.008894205093383789\n",
      "0.009109258651733398\n",
      "0.02044224739074707\n",
      "0.011040925979614258\n",
      "0.00871419906616211\n",
      "0.014620780944824219\n",
      "0.012439727783203125\n",
      "0.01618337631225586\n",
      "0.014194965362548828\n",
      "0.009979009628295898\n",
      "0.023013591766357422\n",
      "0.015955448150634766\n",
      "0.015653610229492188\n",
      "0.00842142105102539\n",
      "0.013521432876586914\n",
      "0.014510154724121094\n",
      "0.011323928833007812\n",
      "0.009441375732421875\n",
      "0.01887679100036621\n",
      "0.019385099411010742\n",
      "0.016878604888916016\n",
      "0.013529539108276367\n",
      "0.014284610748291016\n",
      "0.012421369552612305\n",
      "0.019902944564819336\n",
      "0.020268678665161133\n",
      "0.012307167053222656\n",
      "0.017628192901611328\n",
      "0.014677286148071289\n",
      "0.013165712356567383\n",
      "0.025372028350830078\n",
      "0.01619863510131836\n",
      "0.014850616455078125\n",
      "0.013117551803588867\n",
      "0.01284337043762207\n",
      "0.020726919174194336\n",
      "0.013105392456054688\n",
      "0.019713401794433594\n",
      "0.028314590454101562\n",
      "0.013849973678588867\n",
      "0.014481067657470703\n",
      "0.013452529907226562\n",
      "0.017556190490722656\n",
      "0.01674199104309082\n",
      "0.011837482452392578\n",
      "0.022412538528442383\n",
      "0.02205348014831543\n",
      "0.021886825561523438\n",
      "0.02605462074279785\n",
      "0.012272357940673828\n",
      "0.01661205291748047\n",
      "0.016522884368896484\n",
      "0.013964653015136719\n",
      "0.014161109924316406\n",
      "0.012881040573120117\n",
      "0.026130199432373047\n",
      "0.023084640502929688\n",
      "0.016627788543701172\n",
      "0.013324975967407227\n",
      "0.012407302856445312\n",
      "0.0181734561920166\n",
      "0.020869970321655273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03825807571411133\n",
      "0.017183542251586914\n",
      "0.01438283920288086\n",
      "0.024358034133911133\n",
      "0.03087592124938965\n",
      "0.017307043075561523\n",
      "0.012839555740356445\n",
      "0.016971826553344727\n",
      "0.028851985931396484\n",
      "0.012452840805053711\n",
      "0.016255855560302734\n",
      "0.01796245574951172\n",
      "0.020953655242919922\n",
      "0.032532453536987305\n",
      "0.00838613510131836\n",
      "0.009426355361938477\n",
      "0.007505655288696289\n",
      "0.0780487060546875\n",
      "0.0366055965423584\n",
      "0.033304691314697266\n",
      "0.11432552337646484\n",
      "0.02301621437072754\n",
      "0.02089548110961914\n",
      "0.030603647232055664\n",
      "0.05159616470336914\n",
      "0.014839649200439453\n",
      "0.01777815818786621\n",
      "0.06510543823242188\n",
      "0.02220439910888672\n",
      "0.021721839904785156\n",
      "0.03770709037780762\n",
      "0.03400111198425293\n",
      "0.013321876525878906\n",
      "0.013467550277709961\n",
      "0.02005600929260254\n",
      "0.015294551849365234\n",
      "0.040691375732421875\n",
      "0.023011207580566406\n",
      "0.020557880401611328\n",
      "0.022239208221435547\n",
      "0.022853612899780273\n",
      "0.012698888778686523\n",
      "0.022971630096435547\n",
      "0.04580879211425781\n",
      "0.02337932586669922\n",
      "0.0379328727722168\n",
      "0.01364588737487793\n",
      "0.029843568801879883\n",
      "0.014996528625488281\n",
      "0.034122467041015625\n",
      "0.014875650405883789\n",
      "0.06096625328063965\n",
      "0.044670820236206055\n",
      "0.018639564514160156\n",
      "0.02751016616821289\n",
      "0.016170501708984375\n",
      "0.013000965118408203\n",
      "0.033978939056396484\n",
      "0.03435373306274414\n",
      "0.0197296142578125\n",
      "0.019243717193603516\n",
      "0.044954538345336914\n",
      "0.01585221290588379\n",
      "0.02519083023071289\n",
      "0.015064001083374023\n",
      "0.019333600997924805\n",
      "0.013279199600219727\n",
      "0.012273788452148438\n",
      "0.01752495765686035\n",
      "0.01830768585205078\n",
      "0.025487899780273438\n",
      "0.02785658836364746\n",
      "0.05178427696228027\n",
      "0.012764453887939453\n",
      "0.0528111457824707\n",
      "0.01808786392211914\n",
      "0.01813960075378418\n",
      "0.016882658004760742\n",
      "0.04259634017944336\n",
      "0.015766382217407227\n",
      "0.04563188552856445\n",
      "0.018356800079345703\n",
      "0.0183103084564209\n",
      "0.018154621124267578\n",
      "0.012871503829956055\n",
      "0.016941547393798828\n",
      "0.029677629470825195\n",
      "0.020713090896606445\n",
      "0.01983928680419922\n",
      "0.03450512886047363\n",
      "0.01849055290222168\n",
      "0.028447866439819336\n",
      "0.04880356788635254\n",
      "0.058046817779541016\n",
      "0.01777362823486328\n",
      "0.016661405563354492\n",
      "0.030192852020263672\n",
      "0.030910491943359375\n",
      "0.0283658504486084\n",
      "0.14788103103637695\n",
      "0.0580897331237793\n",
      "0.05780506134033203\n",
      "0.05041217803955078\n",
      "0.04678916931152344\n",
      "0.024936199188232422\n",
      "0.08185482025146484\n",
      "0.018586397171020508\n",
      "0.015869140625\n",
      "0.03148913383483887\n",
      "0.027358531951904297\n",
      "0.01635575294494629\n",
      "0.012559652328491211\n",
      "0.022063732147216797\n",
      "0.01896953582763672\n",
      "0.019623279571533203\n",
      "0.062341928482055664\n",
      "0.05426144599914551\n",
      "0.032195091247558594\n",
      "0.016996383666992188\n",
      "0.013256311416625977\n",
      "0.04102921485900879\n",
      "0.013056278228759766\n",
      "0.014328241348266602\n",
      "0.014667272567749023\n",
      "0.02368330955505371\n",
      "0.031739234924316406\n",
      "0.018822669982910156\n",
      "0.014796972274780273\n",
      "0.01259613037109375\n",
      "0.014862298965454102\n",
      "0.0229184627532959\n",
      "0.023565292358398438\n",
      "0.014251947402954102\n",
      "0.009519577026367188\n",
      "0.011503458023071289\n",
      "0.03517508506774902\n",
      "0.010664701461791992\n",
      "0.02802896499633789\n",
      "0.0078125\n",
      "0.023706436157226562\n",
      "0.009631156921386719\n",
      "0.014914274215698242\n",
      "0.011035680770874023\n",
      "0.013207674026489258\n",
      "0.008186578750610352\n",
      "0.026265859603881836\n",
      "0.013381004333496094\n",
      "0.009368896484375\n",
      "0.008716344833374023\n",
      "0.014243364334106445\n",
      "0.013366222381591797\n",
      "0.04874229431152344\n",
      "0.03809094429016113\n",
      "0.008516311645507812\n",
      "0.013300895690917969\n",
      "0.010962247848510742\n",
      "0.02009415626525879\n",
      "0.01280522346496582\n",
      "0.022546768188476562\n",
      "0.04279518127441406\n",
      "0.010981321334838867\n",
      "0.007370948791503906\n",
      "0.009195089340209961\n",
      "0.011440038681030273\n",
      "0.011461973190307617\n",
      "0.010359048843383789\n",
      "0.00919651985168457\n",
      "0.007470130920410156\n",
      "0.013148307800292969\n",
      "0.00785207748413086\n",
      "0.008739471435546875\n",
      "0.007902383804321289\n",
      "0.0108642578125\n",
      "0.01055908203125\n",
      "0.012221813201904297\n",
      "0.008725404739379883\n",
      "0.015575408935546875\n",
      "0.01450204849243164\n",
      "0.024219274520874023\n",
      "0.012983083724975586\n",
      "0.01946401596069336\n",
      "0.01981496810913086\n",
      "0.016898632049560547\n",
      "0.02146005630493164\n",
      "0.031877994537353516\n",
      "0.02025628089904785\n",
      "0.022413253784179688\n",
      "0.03267073631286621\n",
      "0.01615428924560547\n",
      "0.017431259155273438\n",
      "0.019616127014160156\n",
      "0.01832270622253418\n",
      "0.016959190368652344\n",
      "0.015404939651489258\n",
      "0.020572423934936523\n",
      "0.016277551651000977\n",
      "0.01858663558959961\n",
      "0.017121315002441406\n",
      "0.015263080596923828\n",
      "0.023113250732421875\n",
      "0.04195356369018555\n",
      "0.016287565231323242\n",
      "0.016241788864135742\n",
      "0.018108367919921875\n",
      "0.01536417007446289\n",
      "0.033599853515625\n",
      "0.02300882339477539\n",
      "0.015541791915893555\n",
      "0.015395879745483398\n",
      "0.028563976287841797\n",
      "0.01425790786743164\n",
      "0.0198671817779541\n",
      "0.019634008407592773\n",
      "0.015790224075317383\n",
      "0.022383928298950195\n",
      "0.022893905639648438\n",
      "0.025279998779296875\n",
      "0.017252206802368164\n",
      "0.02177882194519043\n",
      "0.013918161392211914\n",
      "0.03247809410095215\n",
      "0.016635417938232422\n",
      "0.013757944107055664\n",
      "0.01233053207397461\n",
      "0.01238703727722168\n",
      "0.018060684204101562\n",
      "0.017456769943237305\n",
      "0.018596887588500977\n",
      "0.01275014877319336\n",
      "0.014697074890136719\n",
      "0.01425027847290039\n",
      "0.01887822151184082\n",
      "0.03354334831237793\n",
      "0.02101445198059082\n",
      "0.014238357543945312\n",
      "0.015841007232666016\n",
      "0.02485489845275879\n",
      "0.015041828155517578\n",
      "0.017078161239624023\n",
      "0.051718950271606445\n",
      "0.0294187068939209\n",
      "0.012392282485961914\n",
      "0.013348102569580078\n",
      "0.048380374908447266\n",
      "0.016247034072875977\n",
      "0.04206657409667969\n",
      "0.015081167221069336\n",
      "0.017706632614135742\n",
      "0.023938894271850586\n",
      "0.017354249954223633\n",
      "0.027196407318115234\n",
      "0.024636507034301758\n",
      "0.01330876350402832\n",
      "0.013510465621948242\n",
      "0.017960309982299805\n",
      "0.01292562484741211\n",
      "0.01434469223022461\n",
      "0.015141010284423828\n",
      "0.014952898025512695\n",
      "0.01987624168395996\n",
      "0.021811962127685547\n",
      "0.030946731567382812\n",
      "0.030944108963012695\n",
      "0.029682636260986328\n",
      "0.025800704956054688\n",
      "0.012324333190917969\n",
      "0.015562772750854492\n",
      "0.023044347763061523\n",
      "0.014331817626953125\n",
      "0.020897626876831055\n",
      "0.013120651245117188\n",
      "0.016167402267456055\n",
      "0.015216350555419922\n",
      "0.014752626419067383\n",
      "0.012810707092285156\n",
      "0.013963699340820312\n",
      "0.021790266036987305\n",
      "0.015159130096435547\n",
      "0.013042926788330078\n",
      "0.03569483757019043\n",
      "0.049292802810668945\n",
      "0.018527984619140625\n",
      "0.008488655090332031\n",
      "0.011488914489746094\n",
      "0.018857240676879883\n",
      "0.012239217758178711\n",
      "0.010370731353759766\n",
      "0.008359432220458984\n",
      "0.00918722152709961\n",
      "0.013019561767578125\n",
      "0.01119685173034668\n",
      "0.008443832397460938\n",
      "0.02846360206604004\n",
      "0.014089345932006836\n",
      "0.010527849197387695\n",
      "0.009466886520385742\n",
      "0.009068489074707031\n",
      "0.010935544967651367\n",
      "0.009338140487670898\n",
      "0.03719592094421387\n",
      "0.03632211685180664\n",
      "0.02905559539794922\n",
      "0.017742633819580078\n",
      "0.0406036376953125\n",
      "0.01260828971862793\n",
      "0.03038334846496582\n",
      "0.01582503318786621\n",
      "0.2160658836364746\n",
      "0.05009961128234863\n",
      "0.024384498596191406\n",
      "0.042958974838256836\n",
      "0.017823219299316406\n",
      "0.028522491455078125\n",
      "0.032335519790649414\n",
      "0.06828570365905762\n",
      "0.024017810821533203\n",
      "0.018909692764282227\n",
      "0.013452768325805664\n",
      "0.038532257080078125\n",
      "0.047866106033325195\n",
      "0.05287575721740723\n",
      "0.008199930191040039\n",
      "0.04571270942687988\n",
      "0.03181004524230957\n",
      "0.009176015853881836\n",
      "0.0096282958984375\n",
      "0.02255535125732422\n",
      "0.019828319549560547\n",
      "0.013157129287719727\n",
      "0.02189183235168457\n",
      "0.010007858276367188\n",
      "0.017876148223876953\n",
      "0.044931650161743164\n",
      "0.024533510208129883\n",
      "0.013842344284057617\n",
      "0.019133329391479492\n",
      "0.024943113327026367\n",
      "0.02040386199951172\n",
      "0.007815122604370117\n",
      "0.012921571731567383\n",
      "0.017348766326904297\n",
      "0.014547348022460938\n",
      "0.015176534652709961\n",
      "0.019352436065673828\n",
      "0.016571521759033203\n",
      "0.013933658599853516\n",
      "0.007983207702636719\n",
      "0.010767698287963867\n",
      "0.008866071701049805\n",
      "0.02275252342224121\n",
      "0.02544093132019043\n",
      "0.048274993896484375\n",
      "0.04590463638305664\n",
      "0.07198262214660645\n",
      "0.025255680084228516\n",
      "0.013083696365356445\n",
      "0.03610563278198242\n",
      "0.01599884033203125\n",
      "0.015908241271972656\n",
      "0.012385845184326172\n",
      "0.048848867416381836\n",
      "0.035634756088256836\n",
      "0.018297195434570312\n",
      "0.017597436904907227\n",
      "0.05777287483215332\n",
      "0.09433150291442871\n",
      "0.0569610595703125\n",
      "0.025192737579345703\n",
      "0.05340743064880371\n",
      "0.048364877700805664\n",
      "0.052135467529296875\n",
      "0.05651068687438965\n",
      "0.021897077560424805\n",
      "0.0461583137512207\n",
      "0.07270383834838867\n",
      "0.0357363224029541\n",
      "0.01410984992980957\n",
      "0.013231039047241211\n",
      "0.015192031860351562\n",
      "0.02043747901916504\n",
      "0.012441873550415039\n",
      "0.01481771469116211\n",
      "0.01750969886779785\n",
      "0.015330314636230469\n",
      "0.04407811164855957\n",
      "0.02196812629699707\n",
      "0.013464689254760742\n",
      "0.020531892776489258\n",
      "0.04686141014099121\n",
      "0.013947248458862305\n",
      "0.04290151596069336\n",
      "0.024815797805786133\n",
      "0.028563499450683594\n",
      "0.01575493812561035\n",
      "0.016363143920898438\n",
      "0.03262948989868164\n",
      "0.015398263931274414\n",
      "0.01782703399658203\n",
      "0.014928340911865234\n",
      "0.01303410530090332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06371521949768066\n",
      "0.05131840705871582\n",
      "0.03843569755554199\n",
      "0.014810323715209961\n",
      "0.02761554718017578\n",
      "0.012833118438720703\n",
      "0.012442350387573242\n",
      "0.02368640899658203\n",
      "0.021667957305908203\n",
      "0.03663229942321777\n",
      "0.015869855880737305\n",
      "0.016068696975708008\n",
      "0.01753401756286621\n",
      "0.023042678833007812\n",
      "0.014765739440917969\n",
      "0.028501510620117188\n",
      "0.025823116302490234\n",
      "0.014516830444335938\n",
      "0.02416706085205078\n",
      "0.020163774490356445\n",
      "0.012816667556762695\n",
      "0.01602792739868164\n",
      "0.021846532821655273\n",
      "0.013501882553100586\n",
      "0.027643918991088867\n",
      "0.023738861083984375\n",
      "0.018512487411499023\n",
      "0.02137899398803711\n",
      "0.015130043029785156\n",
      "0.021465063095092773\n",
      "0.02170109748840332\n",
      "0.04655790328979492\n",
      "0.014817953109741211\n",
      "0.01321268081665039\n",
      "0.01347041130065918\n",
      "0.012141942977905273\n",
      "0.008195638656616211\n",
      "0.025912046432495117\n",
      "0.08602046966552734\n",
      "0.029409170150756836\n",
      "0.03990650177001953\n",
      "0.028842687606811523\n",
      "0.024647951126098633\n",
      "0.10697770118713379\n",
      "0.019201278686523438\n",
      "0.08666682243347168\n",
      "0.04427647590637207\n",
      "0.026543855667114258\n",
      "0.02839350700378418\n",
      "0.045594215393066406\n",
      "0.01597452163696289\n",
      "0.05323219299316406\n",
      "0.01836395263671875\n",
      "0.017480134963989258\n",
      "0.01810908317565918\n",
      "0.014941930770874023\n",
      "0.030114173889160156\n",
      "0.09663558006286621\n",
      "0.01445317268371582\n",
      "0.02607440948486328\n",
      "0.08387875556945801\n",
      "0.02831745147705078\n",
      "0.02945113182067871\n",
      "0.030002355575561523\n",
      "0.02254462242126465\n",
      "0.0219724178314209\n",
      "0.04714202880859375\n",
      "0.013619661331176758\n",
      "0.028209209442138672\n",
      "0.01916790008544922\n",
      "0.014945030212402344\n",
      "0.06359267234802246\n",
      "0.044692277908325195\n",
      "0.1131901741027832\n",
      "0.05171465873718262\n",
      "0.049300432205200195\n",
      "0.029665470123291016\n",
      "0.02850794792175293\n",
      "0.02938365936279297\n",
      "0.014736413955688477\n",
      "0.03303813934326172\n",
      "0.02369403839111328\n",
      "0.012053728103637695\n",
      "0.05531954765319824\n",
      "0.034102678298950195\n",
      "0.06557655334472656\n",
      "0.020619630813598633\n",
      "0.04508042335510254\n",
      "0.014137744903564453\n",
      "0.012511968612670898\n",
      "0.012789726257324219\n",
      "0.02039313316345215\n",
      "0.01684737205505371\n",
      "0.012865781784057617\n",
      "0.01873946189880371\n",
      "0.018590450286865234\n",
      "0.016449689865112305\n",
      "0.0217440128326416\n",
      "0.02080821990966797\n",
      "0.029759883880615234\n",
      "0.012211084365844727\n",
      "0.01673102378845215\n",
      "0.01702570915222168\n",
      "0.04506278038024902\n",
      "0.027933359146118164\n",
      "0.04219937324523926\n",
      "0.0166776180267334\n",
      "0.013483285903930664\n",
      "0.033530235290527344\n",
      "0.014110326766967773\n",
      "0.023059844970703125\n",
      "0.015801429748535156\n",
      "0.01244044303894043\n",
      "0.02108001708984375\n",
      "0.0270993709564209\n",
      "0.05061817169189453\n",
      "0.018118619918823242\n",
      "0.011660099029541016\n",
      "0.014348268508911133\n",
      "0.014622211456298828\n",
      "0.02178215980529785\n",
      "0.00905609130859375\n",
      "0.00861048698425293\n",
      "0.01077580451965332\n",
      "0.02234029769897461\n",
      "0.011097431182861328\n",
      "0.008931398391723633\n",
      "0.008142232894897461\n",
      "0.01113581657409668\n",
      "0.02309441566467285\n",
      "0.015082359313964844\n",
      "0.019238948822021484\n",
      "0.013510704040527344\n",
      "0.015728235244750977\n",
      "0.011687517166137695\n",
      "0.008344173431396484\n",
      "0.021848440170288086\n",
      "0.009140729904174805\n",
      "0.010524272918701172\n",
      "0.014946699142456055\n",
      "0.010017871856689453\n",
      "0.022014379501342773\n",
      "0.013829469680786133\n",
      "0.019921064376831055\n",
      "0.009587287902832031\n",
      "0.008323907852172852\n",
      "0.007576942443847656\n",
      "0.012218475341796875\n",
      "0.010675430297851562\n",
      "0.01184844970703125\n",
      "0.00809168815612793\n",
      "0.014978408813476562\n",
      "0.015450000762939453\n",
      "0.013851165771484375\n",
      "0.032692670822143555\n",
      "0.014443635940551758\n",
      "0.01948833465576172\n",
      "0.0192108154296875\n",
      "0.023772001266479492\n",
      "0.04751014709472656\n",
      "0.026531219482421875\n",
      "0.027009010314941406\n",
      "0.0344853401184082\n",
      "0.02846693992614746\n",
      "0.024355411529541016\n",
      "0.013453960418701172\n",
      "0.017342329025268555\n",
      "0.03943157196044922\n",
      "0.024222373962402344\n",
      "0.014744281768798828\n",
      "0.014323949813842773\n",
      "0.020093441009521484\n",
      "0.032515764236450195\n",
      "0.013497114181518555\n",
      "0.032532453536987305\n",
      "0.016623258590698242\n",
      "0.01804637908935547\n",
      "0.025305509567260742\n",
      "0.014867782592773438\n",
      "0.019565582275390625\n",
      "0.051880836486816406\n",
      "0.016686439514160156\n",
      "0.018419265747070312\n",
      "0.021396398544311523\n",
      "0.026167869567871094\n",
      "0.020027875900268555\n",
      "0.01273488998413086\n",
      "0.02687358856201172\n",
      "0.05060887336730957\n",
      "0.04640603065490723\n",
      "0.04119682312011719\n",
      "0.022493839263916016\n",
      "0.013291120529174805\n",
      "0.03541135787963867\n",
      "0.01590275764465332\n",
      "0.01643681526184082\n",
      "0.026175975799560547\n",
      "0.01499485969543457\n",
      "0.031054973602294922\n",
      "0.01705622673034668\n",
      "0.014647483825683594\n",
      "0.014704704284667969\n",
      "0.012647151947021484\n",
      "0.03961014747619629\n",
      "0.03231310844421387\n",
      "0.026517391204833984\n",
      "0.0649559497833252\n",
      "0.02202463150024414\n",
      "0.030795574188232422\n",
      "0.02260899543762207\n",
      "0.03980684280395508\n",
      "0.02733588218688965\n",
      "0.02338576316833496\n",
      "0.0195772647857666\n",
      "0.026866912841796875\n",
      "0.02248525619506836\n",
      "0.01608872413635254\n",
      "0.012938499450683594\n",
      "0.023216962814331055\n",
      "0.0323328971862793\n",
      "0.023749351501464844\n",
      "0.021368026733398438\n",
      "0.03424501419067383\n",
      "0.013699531555175781\n",
      "0.021198749542236328\n",
      "0.013346433639526367\n",
      "0.05297446250915527\n",
      "0.02097320556640625\n",
      "0.041074514389038086\n",
      "0.04364466667175293\n",
      "0.02432727813720703\n",
      "0.014525413513183594\n",
      "0.022545814514160156\n",
      "0.03990602493286133\n",
      "0.0664973258972168\n",
      "0.0223081111907959\n",
      "0.021476268768310547\n",
      "0.03508496284484863\n",
      "0.032708168029785156\n",
      "0.059206485748291016\n",
      "0.01879286766052246\n",
      "0.06572294235229492\n",
      "0.023616313934326172\n",
      "0.015840768814086914\n",
      "0.013315200805664062\n",
      "0.05217695236206055\n",
      "0.01900959014892578\n",
      "0.014951705932617188\n",
      "0.02397918701171875\n",
      "0.017676830291748047\n",
      "0.04372835159301758\n",
      "0.022756338119506836\n",
      "0.037285804748535156\n",
      "0.028229475021362305\n",
      "0.03297901153564453\n",
      "0.042943477630615234\n",
      "0.014197826385498047\n",
      "0.02031993865966797\n",
      "0.014640331268310547\n",
      "0.011416912078857422\n",
      "0.028797626495361328\n",
      "0.009124517440795898\n",
      "0.014111518859863281\n",
      "0.009226560592651367\n",
      "0.007854223251342773\n",
      "0.016554594039916992\n",
      "0.01200556755065918\n",
      "0.00933980941772461\n",
      "0.01952838897705078\n",
      "0.027390718460083008\n",
      "0.008815288543701172\n",
      "0.014095544815063477\n",
      "0.02445530891418457\n",
      "0.014629125595092773\n",
      "0.01492619514465332\n",
      "0.011852502822875977\n",
      "0.011983156204223633\n",
      "0.010345220565795898\n",
      "0.016801834106445312\n",
      "0.007458209991455078\n",
      "0.008063793182373047\n",
      "0.010920286178588867\n",
      "0.01690196990966797\n",
      "0.013451576232910156\n",
      "0.027889251708984375\n",
      "0.014035940170288086\n",
      "0.007920265197753906\n",
      "0.00824427604675293\n",
      "0.010254621505737305\n",
      "0.010743379592895508\n",
      "0.008016347885131836\n",
      "0.014389276504516602\n",
      "0.0119781494140625\n",
      "0.008235931396484375\n",
      "0.012578964233398438\n",
      "0.009493350982666016\n",
      "0.022910594940185547\n",
      "0.013785123825073242\n",
      "0.03530406951904297\n",
      "0.018723249435424805\n",
      "0.015156745910644531\n",
      "0.03465127944946289\n",
      "0.023391008377075195\n",
      "0.01987767219543457\n",
      "0.008001089096069336\n",
      "0.015912532806396484\n",
      "0.010443687438964844\n",
      "0.012345552444458008\n",
      "0.008530378341674805\n",
      "0.022113561630249023\n",
      "0.045003414154052734\n",
      "0.008142232894897461\n",
      "0.08212018013000488\n",
      "0.015172958374023438\n",
      "0.017395973205566406\n",
      "0.03267669677734375\n",
      "0.05211973190307617\n",
      "0.017190217971801758\n",
      "0.01777505874633789\n",
      "0.023216962814331055\n",
      "0.021451473236083984\n",
      "0.03408026695251465\n",
      "0.016541004180908203\n",
      "0.030106306076049805\n",
      "0.0265505313873291\n",
      "0.015729665756225586\n",
      "0.017312288284301758\n",
      "0.01726508140563965\n",
      "0.020373821258544922\n",
      "0.02547287940979004\n",
      "0.016258716583251953\n",
      "0.02122640609741211\n",
      "0.02770256996154785\n",
      "0.01994776725769043\n",
      "0.024222135543823242\n",
      "0.0294644832611084\n",
      "0.0364069938659668\n",
      "0.023483991622924805\n",
      "0.0320892333984375\n",
      "0.021684646606445312\n",
      "0.017229795455932617\n",
      "0.023107290267944336\n",
      "0.03710746765136719\n",
      "0.029813528060913086\n",
      "0.02618885040283203\n",
      "0.04021477699279785\n",
      "0.02153325080871582\n",
      "0.04208731651306152\n",
      "0.019281387329101562\n",
      "0.023385047912597656\n",
      "0.015397787094116211\n",
      "0.02757096290588379\n",
      "0.0198209285736084\n",
      "0.019951343536376953\n",
      "0.04213261604309082\n",
      "0.06680822372436523\n",
      "0.052371978759765625\n",
      "0.05131649971008301\n",
      "0.022166728973388672\n",
      "0.017597436904907227\n",
      "0.038919925689697266\n",
      "0.029384374618530273\n",
      "0.034950971603393555\n",
      "0.0507204532623291\n",
      "0.020099163055419922\n",
      "0.03047037124633789\n",
      "0.02362513542175293\n",
      "0.029915571212768555\n",
      "0.025328397750854492\n",
      "0.024943828582763672\n",
      "0.07501745223999023\n",
      "0.022992849349975586\n",
      "0.056260108947753906\n",
      "0.02756357192993164\n",
      "0.05083274841308594\n",
      "0.03675723075866699\n",
      "0.0209043025970459\n",
      "0.03026604652404785\n",
      "0.029630661010742188\n",
      "0.035623788833618164\n",
      "0.0210723876953125\n",
      "0.054355621337890625\n",
      "0.015503644943237305\n",
      "0.04306960105895996\n",
      "0.02438497543334961\n",
      "0.021458864212036133\n",
      "0.01636481285095215\n",
      "0.018486499786376953\n",
      "0.02967095375061035\n",
      "0.025859594345092773\n",
      "0.045562744140625\n",
      "0.06611514091491699\n",
      "0.07567548751831055\n",
      "0.016381263732910156\n",
      "0.020023107528686523\n",
      "0.04531741142272949\n",
      "0.04293084144592285\n",
      "0.020551443099975586\n",
      "0.046785831451416016\n",
      "0.059232234954833984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08216714859008789\n",
      "0.05129599571228027\n",
      "0.050977230072021484\n",
      "0.033893585205078125\n",
      "0.09801626205444336\n",
      "0.02569413185119629\n",
      "0.12413573265075684\n",
      "0.04647660255432129\n",
      "0.09634804725646973\n",
      "0.032402992248535156\n",
      "0.02441120147705078\n",
      "0.020857572555541992\n",
      "0.03323054313659668\n",
      "0.04268765449523926\n",
      "0.057228803634643555\n",
      "0.027840137481689453\n",
      "0.06336164474487305\n",
      "0.02483677864074707\n",
      "0.018707752227783203\n",
      "0.0383305549621582\n",
      "0.028452157974243164\n",
      "0.024735689163208008\n",
      "0.04900646209716797\n",
      "0.04793548583984375\n",
      "0.04253745079040527\n",
      "0.02677774429321289\n",
      "0.035401105880737305\n",
      "0.024541378021240234\n",
      "0.025503873825073242\n",
      "0.036878347396850586\n",
      "0.022688865661621094\n",
      "0.02305459976196289\n",
      "0.027027606964111328\n",
      "0.01900172233581543\n",
      "0.038512229919433594\n",
      "0.02403736114501953\n",
      "0.02490711212158203\n",
      "0.023688316345214844\n",
      "0.038759469985961914\n",
      "0.026224374771118164\n",
      "0.02048516273498535\n",
      "0.015273094177246094\n",
      "0.01764702796936035\n",
      "0.020224809646606445\n",
      "0.01542973518371582\n",
      "0.017786264419555664\n",
      "0.018315792083740234\n",
      "0.013355255126953125\n",
      "0.017240524291992188\n",
      "0.013763666152954102\n",
      "0.01483917236328125\n",
      "0.01674509048461914\n",
      "0.022165298461914062\n",
      "0.05378079414367676\n",
      "0.013616085052490234\n",
      "0.01671433448791504\n",
      "0.013887643814086914\n",
      "0.03158140182495117\n",
      "0.021299362182617188\n",
      "0.020664453506469727\n",
      "0.050279855728149414\n",
      "0.01621270179748535\n",
      "0.013593912124633789\n",
      "0.03141307830810547\n",
      "0.024023056030273438\n",
      "0.01265716552734375\n",
      "0.015279769897460938\n",
      "0.012470722198486328\n",
      "0.01873612403869629\n",
      "0.04198479652404785\n",
      "0.012372255325317383\n",
      "0.020401477813720703\n",
      "0.05337834358215332\n",
      "0.016300201416015625\n",
      "0.027638673782348633\n",
      "0.015374898910522461\n",
      "0.019966602325439453\n",
      "0.012714624404907227\n",
      "0.016476154327392578\n",
      "0.012811660766601562\n",
      "0.01600503921508789\n",
      "0.0180203914642334\n",
      "0.014111757278442383\n",
      "0.01695084571838379\n",
      "0.0456845760345459\n",
      "0.013942241668701172\n",
      "0.019601821899414062\n",
      "0.013426542282104492\n",
      "0.025861263275146484\n",
      "0.02522873878479004\n",
      "0.013152360916137695\n",
      "0.016718387603759766\n",
      "0.013150930404663086\n",
      "0.015370845794677734\n",
      "0.01425027847290039\n",
      "0.013796329498291016\n",
      "0.01288294792175293\n",
      "0.026039600372314453\n",
      "0.025919437408447266\n",
      "0.017117738723754883\n",
      "0.013424396514892578\n",
      "0.013283014297485352\n",
      "0.016488313674926758\n",
      "0.016389846801757812\n",
      "0.02720355987548828\n",
      "0.01641845703125\n",
      "0.01877880096435547\n",
      "0.014402627944946289\n",
      "0.030185222625732422\n",
      "0.02807927131652832\n",
      "0.017178773880004883\n",
      "0.014778375625610352\n",
      "0.015668153762817383\n",
      "0.011971712112426758\n",
      "0.023378610610961914\n",
      "0.011380434036254883\n",
      "0.010048389434814453\n",
      "0.011277198791503906\n",
      "0.010579824447631836\n",
      "0.027332067489624023\n",
      "0.010355710983276367\n",
      "0.019783496856689453\n",
      "0.010525941848754883\n",
      "0.020437240600585938\n",
      "0.00960993766784668\n",
      "0.014969348907470703\n",
      "0.02775740623474121\n",
      "0.03272819519042969\n",
      "0.012746810913085938\n",
      "0.034012556076049805\n",
      "0.019725799560546875\n",
      "0.009152889251708984\n",
      "0.012564897537231445\n",
      "0.012969970703125\n",
      "0.007935285568237305\n",
      "0.012743473052978516\n",
      "0.025951385498046875\n",
      "0.020960092544555664\n",
      "0.03412175178527832\n",
      "0.027611494064331055\n",
      "0.07226109504699707\n",
      "0.030344247817993164\n",
      "0.039404869079589844\n",
      "0.028777360916137695\n",
      "0.04178905487060547\n",
      "0.02297186851501465\n",
      "0.03385496139526367\n",
      "0.007982969284057617\n",
      "0.016526222229003906\n",
      "0.014056682586669922\n",
      "0.012385368347167969\n",
      "0.00831747055053711\n",
      "0.009315729141235352\n",
      "0.007993698120117188\n",
      "0.010314464569091797\n",
      "0.025975704193115234\n",
      "0.011847496032714844\n",
      "0.013321876525878906\n",
      "0.018763303756713867\n",
      "0.02615499496459961\n",
      "0.05405235290527344\n",
      "0.018871545791625977\n",
      "0.012816190719604492\n",
      "0.03422379493713379\n",
      "0.014083385467529297\n",
      "0.017808198928833008\n",
      "0.03670811653137207\n",
      "0.016666412353515625\n",
      "0.05871152877807617\n",
      "0.01356649398803711\n",
      "0.009534597396850586\n",
      "0.01328587532043457\n",
      "0.013215780258178711\n",
      "0.031494140625\n",
      "0.032503366470336914\n",
      "0.08945393562316895\n",
      "0.049048423767089844\n",
      "0.015565872192382812\n",
      "0.01924300193786621\n",
      "0.025385141372680664\n",
      "0.06673312187194824\n",
      "0.04811978340148926\n",
      "0.023546695709228516\n",
      "0.012575626373291016\n",
      "0.013538599014282227\n",
      "0.03209233283996582\n",
      "0.017595291137695312\n",
      "0.013167858123779297\n",
      "0.012705802917480469\n",
      "0.021591901779174805\n",
      "0.014605998992919922\n",
      "0.023732662200927734\n",
      "0.01359868049621582\n",
      "0.015553712844848633\n",
      "0.01962590217590332\n",
      "0.027416467666625977\n",
      "0.019382238388061523\n",
      "0.022446632385253906\n",
      "0.01954054832458496\n",
      "0.022864341735839844\n",
      "0.01506662368774414\n",
      "0.012738466262817383\n",
      "0.019063472747802734\n",
      "0.01909780502319336\n",
      "0.018469572067260742\n",
      "0.016180038452148438\n",
      "0.017575979232788086\n",
      "0.015541315078735352\n",
      "0.013641119003295898\n",
      "0.015540361404418945\n",
      "0.014192342758178711\n",
      "0.13165020942687988\n",
      "0.03204059600830078\n",
      "0.028876304626464844\n",
      "0.015300273895263672\n",
      "0.018493175506591797\n",
      "0.01257634162902832\n",
      "0.012853145599365234\n",
      "0.012729644775390625\n",
      "0.03782057762145996\n",
      "0.048029422760009766\n",
      "0.017429351806640625\n",
      "0.013084888458251953\n",
      "0.01723957061767578\n",
      "0.012543678283691406\n",
      "0.07183718681335449\n",
      "0.0172116756439209\n",
      "0.01255941390991211\n",
      "0.02272820472717285\n",
      "0.018194198608398438\n",
      "0.017571210861206055\n",
      "0.030192136764526367\n",
      "0.01674962043762207\n",
      "0.014780282974243164\n",
      "0.016227245330810547\n",
      "0.02243494987487793\n",
      "0.019750356674194336\n",
      "0.019939184188842773\n",
      "0.022454500198364258\n",
      "0.017042160034179688\n",
      "0.02031564712524414\n",
      "0.01768040657043457\n",
      "0.012551307678222656\n",
      "0.021579265594482422\n",
      "0.019860029220581055\n",
      "0.02675914764404297\n",
      "0.012876749038696289\n",
      "0.01916027069091797\n",
      "0.014427423477172852\n",
      "0.013513565063476562\n",
      "0.03756833076477051\n",
      "0.022499799728393555\n",
      "0.015044212341308594\n",
      "0.03544497489929199\n",
      "0.018304109573364258\n",
      "0.013147830963134766\n",
      "0.030675649642944336\n",
      "0.014725923538208008\n",
      "0.01757979393005371\n",
      "0.015080928802490234\n",
      "0.02125716209411621\n",
      "0.034587860107421875\n",
      "0.01955699920654297\n",
      "0.023300647735595703\n",
      "0.023213863372802734\n",
      "0.01686239242553711\n",
      "0.012520313262939453\n",
      "0.01282501220703125\n",
      "0.03424334526062012\n",
      "0.01566600799560547\n",
      "0.014603614807128906\n",
      "0.031144142150878906\n",
      "0.017811059951782227\n",
      "0.020201444625854492\n",
      "0.014485597610473633\n",
      "0.014887094497680664\n",
      "0.026460647583007812\n",
      "0.01424717903137207\n",
      "0.0228729248046875\n",
      "0.014805316925048828\n",
      "0.026906490325927734\n",
      "0.02340412139892578\n",
      "0.039681196212768555\n",
      "0.01833367347717285\n",
      "0.013201475143432617\n",
      "0.012625455856323242\n",
      "0.015618085861206055\n",
      "0.02383279800415039\n",
      "0.01243448257446289\n",
      "0.01594376564025879\n",
      "0.023967981338500977\n",
      "0.015461206436157227\n",
      "0.02687811851501465\n",
      "0.01777505874633789\n",
      "0.015084266662597656\n",
      "0.014986276626586914\n",
      "0.06480050086975098\n",
      "0.028331518173217773\n",
      "0.036852359771728516\n",
      "0.07215762138366699\n",
      "0.013841867446899414\n",
      "0.06016397476196289\n",
      "0.030545473098754883\n",
      "0.017913818359375\n",
      "0.012993097305297852\n",
      "0.038802146911621094\n",
      "0.015404462814331055\n",
      "0.03393983840942383\n",
      "0.02397632598876953\n",
      "0.03811240196228027\n",
      "0.019305944442749023\n",
      "0.012901067733764648\n",
      "0.019839763641357422\n",
      "0.013202190399169922\n",
      "0.01551198959350586\n",
      "0.01321864128112793\n",
      "0.012714147567749023\n",
      "0.01827836036682129\n",
      "0.025612831115722656\n",
      "0.024184226989746094\n",
      "0.018039941787719727\n",
      "0.013154745101928711\n",
      "0.0332491397857666\n",
      "0.0205686092376709\n",
      "0.014930963516235352\n",
      "0.032242536544799805\n",
      "0.015449762344360352\n",
      "0.020646095275878906\n",
      "0.01679849624633789\n",
      "0.02162933349609375\n",
      "0.01877450942993164\n",
      "0.013473987579345703\n",
      "0.016518592834472656\n",
      "0.012321949005126953\n",
      "0.015166521072387695\n",
      "0.02033090591430664\n",
      "0.022374391555786133\n",
      "0.01593923568725586\n",
      "0.013293027877807617\n",
      "0.01290440559387207\n",
      "0.017186403274536133\n",
      "0.013393163681030273\n",
      "0.022405624389648438\n",
      "0.014681816101074219\n",
      "0.014554500579833984\n",
      "0.02014470100402832\n",
      "0.06139659881591797\n",
      "0.020987987518310547\n",
      "0.029900074005126953\n",
      "0.01878643035888672\n",
      "0.015504121780395508\n",
      "0.03174948692321777\n",
      "0.01353001594543457\n",
      "0.02648472785949707\n",
      "0.016676902770996094\n",
      "0.014619112014770508\n",
      "0.020000219345092773\n",
      "0.014364242553710938\n",
      "0.021463632583618164\n",
      "0.07884383201599121\n",
      "0.02197575569152832\n",
      "0.022835493087768555\n",
      "0.013903617858886719\n",
      "0.01698446273803711\n",
      "0.02845311164855957\n",
      "0.02825307846069336\n",
      "0.014638185501098633\n",
      "0.0411224365234375\n",
      "0.015051126480102539\n",
      "0.023842573165893555\n",
      "0.017064571380615234\n",
      "0.016510725021362305\n",
      "0.026418447494506836\n",
      "0.028099536895751953\n",
      "0.021142005920410156\n",
      "0.028299808502197266\n",
      "0.06638693809509277\n",
      "0.053229331970214844\n",
      "0.09251070022583008\n",
      "0.044319868087768555\n",
      "0.017246246337890625\n",
      "0.041673898696899414\n",
      "0.009033679962158203\n",
      "0.014740705490112305\n",
      "0.01789546012878418\n",
      "0.00973200798034668\n",
      "0.010257720947265625\n",
      "0.01661396026611328\n",
      "0.00774383544921875\n",
      "0.00795435905456543\n",
      "0.02960348129272461\n",
      "0.013207674026489258\n",
      "0.011251688003540039\n",
      "0.026007652282714844\n",
      "0.01954054832458496\n",
      "0.008214473724365234\n",
      "0.023639917373657227\n",
      "0.013266324996948242\n",
      "0.010462522506713867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053217411041259766\n",
      "0.02496051788330078\n",
      "0.0201113224029541\n",
      "0.031171560287475586\n",
      "0.014505624771118164\n",
      "0.013560295104980469\n",
      "0.025372028350830078\n",
      "0.01784968376159668\n",
      "0.04081439971923828\n",
      "0.09158587455749512\n",
      "0.1921522617340088\n",
      "0.10605859756469727\n",
      "0.08393025398254395\n",
      "0.051552772521972656\n",
      "0.169447660446167\n",
      "0.015107393264770508\n",
      "0.033272743225097656\n",
      "0.016323566436767578\n",
      "0.016351938247680664\n",
      "0.044704437255859375\n",
      "0.019791126251220703\n",
      "0.01630568504333496\n",
      "0.03844046592712402\n",
      "0.025049448013305664\n",
      "0.017630815505981445\n",
      "0.04152631759643555\n",
      "0.07598161697387695\n",
      "0.017459392547607422\n",
      "0.04120016098022461\n",
      "0.015336990356445312\n",
      "0.03148627281188965\n",
      "0.055496931076049805\n",
      "0.021466970443725586\n",
      "0.03230142593383789\n",
      "0.015720367431640625\n",
      "0.025008201599121094\n",
      "0.02513909339904785\n",
      "0.03523731231689453\n",
      "0.013658285140991211\n",
      "0.018561840057373047\n",
      "0.01932811737060547\n",
      "0.02373671531677246\n",
      "0.03586149215698242\n",
      "0.04403090476989746\n",
      "0.01306605339050293\n",
      "0.016216278076171875\n",
      "0.05469465255737305\n",
      "0.013733148574829102\n",
      "0.022946834564208984\n",
      "0.01612544059753418\n",
      "0.03890728950500488\n",
      "0.04379606246948242\n",
      "0.023752927780151367\n",
      "0.03341865539550781\n",
      "0.0323178768157959\n",
      "0.013595819473266602\n",
      "0.022304534912109375\n",
      "0.014176130294799805\n",
      "0.012320280075073242\n",
      "0.03929710388183594\n",
      "0.031225919723510742\n",
      "0.05626225471496582\n",
      "0.012331485748291016\n",
      "0.013693809509277344\n",
      "0.022525787353515625\n",
      "0.01359248161315918\n",
      "0.03898334503173828\n",
      "0.013200044631958008\n",
      "0.014119148254394531\n",
      "0.023505687713623047\n",
      "0.012277603149414062\n",
      "0.021521329879760742\n",
      "0.06308841705322266\n",
      "0.0368194580078125\n",
      "0.013700008392333984\n",
      "0.048467397689819336\n",
      "0.018852710723876953\n",
      "0.012671947479248047\n",
      "0.017382144927978516\n",
      "0.01938152313232422\n",
      "0.013846397399902344\n",
      "0.01674485206604004\n",
      "0.01777815818786621\n",
      "0.05574607849121094\n",
      "0.033315181732177734\n",
      "0.013292074203491211\n",
      "0.023593664169311523\n",
      "0.043723106384277344\n",
      "0.02400970458984375\n",
      "0.015371084213256836\n",
      "0.04919075965881348\n",
      "0.03137969970703125\n",
      "0.01346898078918457\n",
      "0.015917062759399414\n",
      "0.018412351608276367\n",
      "0.012563467025756836\n",
      "0.02212691307067871\n",
      "0.013430118560791016\n",
      "0.01889801025390625\n",
      "0.015773296356201172\n",
      "0.03835654258728027\n",
      "0.02585458755493164\n",
      "0.022905349731445312\n",
      "0.02327752113342285\n",
      "0.016587495803833008\n",
      "0.013329267501831055\n",
      "0.014173746109008789\n",
      "0.016737937927246094\n",
      "0.012312173843383789\n",
      "0.02125072479248047\n",
      "0.018004417419433594\n",
      "0.022546768188476562\n",
      "0.013831853866577148\n",
      "0.014264822006225586\n",
      "0.01366114616394043\n",
      "0.024915456771850586\n",
      "0.024960041046142578\n",
      "0.012525558471679688\n",
      "0.019700288772583008\n",
      "0.018483638763427734\n",
      "0.016079425811767578\n",
      "0.01799631118774414\n",
      "0.015055179595947266\n",
      "0.01668834686279297\n",
      "0.013880729675292969\n",
      "0.020416259765625\n",
      "0.02346181869506836\n",
      "0.012275457382202148\n",
      "0.05943894386291504\n",
      "0.0490725040435791\n",
      "0.022525787353515625\n",
      "0.018009662628173828\n",
      "0.016560792922973633\n",
      "0.030193567276000977\n",
      "0.01953721046447754\n",
      "0.03568124771118164\n",
      "0.018210411071777344\n",
      "0.029790163040161133\n",
      "0.046021223068237305\n",
      "0.019572019577026367\n",
      "0.01622152328491211\n",
      "0.012609243392944336\n",
      "0.04943680763244629\n",
      "0.04661822319030762\n",
      "0.03846621513366699\n",
      "0.0214540958404541\n",
      "0.022885560989379883\n",
      "0.0227358341217041\n",
      "0.03628087043762207\n",
      "0.0157015323638916\n",
      "0.01761317253112793\n",
      "0.015332698822021484\n",
      "0.017547130584716797\n",
      "0.01436758041381836\n",
      "0.012391090393066406\n",
      "0.019333362579345703\n",
      "0.014091014862060547\n",
      "0.016364336013793945\n",
      "0.013191938400268555\n",
      "0.021173477172851562\n",
      "0.022206783294677734\n",
      "0.015446186065673828\n",
      "0.01235342025756836\n",
      "0.03650045394897461\n",
      "0.026639938354492188\n",
      "0.04054546356201172\n",
      "0.014711380004882812\n",
      "0.013123035430908203\n",
      "0.023873567581176758\n",
      "0.05884099006652832\n",
      "0.024922847747802734\n",
      "0.01622605323791504\n",
      "0.014162063598632812\n",
      "0.01768326759338379\n",
      "0.01177668571472168\n",
      "0.008349418640136719\n",
      "0.012052297592163086\n",
      "0.00872945785522461\n",
      "0.0075969696044921875\n",
      "0.010209083557128906\n",
      "0.007936239242553711\n",
      "0.011169910430908203\n",
      "0.007567644119262695\n",
      "0.012319087982177734\n",
      "0.008498668670654297\n",
      "0.01289224624633789\n",
      "0.007668018341064453\n",
      "0.007772684097290039\n",
      "0.011328458786010742\n",
      "0.007753610610961914\n",
      "0.011261940002441406\n",
      "0.016833066940307617\n",
      "0.0074863433837890625\n",
      "0.007765531539916992\n",
      "0.011101722717285156\n",
      "0.024135351181030273\n",
      "0.023350000381469727\n",
      "0.01404714584350586\n",
      "0.013420343399047852\n",
      "0.015033245086669922\n",
      "0.012542724609375\n",
      "0.016390323638916016\n",
      "0.016982078552246094\n",
      "0.01979684829711914\n",
      "0.017389535903930664\n",
      "0.02847766876220703\n",
      "0.013572931289672852\n",
      "0.014274835586547852\n",
      "0.01539468765258789\n",
      "0.013878822326660156\n",
      "0.0422368049621582\n",
      "0.01648879051208496\n",
      "0.02420353889465332\n",
      "0.04423809051513672\n",
      "0.012483596801757812\n",
      "0.05922865867614746\n",
      "0.05010652542114258\n",
      "0.035399675369262695\n",
      "0.024637222290039062\n",
      "0.015466690063476562\n",
      "0.012690305709838867\n",
      "0.013857364654541016\n",
      "0.013813495635986328\n",
      "0.021785259246826172\n",
      "0.10029458999633789\n",
      "0.030703067779541016\n",
      "0.06786513328552246\n",
      "0.026948213577270508\n",
      "0.028148412704467773\n",
      "0.0427241325378418\n",
      "0.024977922439575195\n",
      "0.039011240005493164\n",
      "0.017665624618530273\n",
      "0.03013467788696289\n",
      "0.05461382865905762\n",
      "0.034821271896362305\n",
      "0.05764007568359375\n",
      "0.03223752975463867\n",
      "0.025612592697143555\n",
      "0.018492460250854492\n",
      "0.15560293197631836\n",
      "0.08666229248046875\n",
      "0.032483577728271484\n",
      "0.05131697654724121\n",
      "0.08021879196166992\n",
      "0.062445640563964844\n",
      "0.036046504974365234\n",
      "0.024415254592895508\n",
      "0.03032374382019043\n",
      "0.015915393829345703\n",
      "0.015393733978271484\n",
      "0.029592514038085938\n",
      "0.033013343811035156\n",
      "0.020743608474731445\n",
      "0.021478891372680664\n",
      "0.020130634307861328\n",
      "0.026590585708618164\n",
      "0.01753377914428711\n",
      "0.018509387969970703\n",
      "0.017064332962036133\n",
      "0.01757526397705078\n",
      "0.03477168083190918\n",
      "0.03523755073547363\n",
      "0.016874313354492188\n",
      "0.017909765243530273\n",
      "0.024934768676757812\n",
      "0.01835799217224121\n",
      "0.01638054847717285\n",
      "0.02524423599243164\n",
      "0.03516960144042969\n",
      "0.036769866943359375\n",
      "0.020381927490234375\n",
      "0.02459263801574707\n",
      "0.06134223937988281\n",
      "0.017054080963134766\n",
      "0.03229856491088867\n",
      "0.04691481590270996\n",
      "0.02073502540588379\n",
      "0.016509294509887695\n",
      "0.03464555740356445\n",
      "0.04203343391418457\n",
      "0.06211376190185547\n",
      "0.019989013671875\n",
      "0.010851383209228516\n",
      "0.02455878257751465\n",
      "0.008606195449829102\n",
      "0.017294645309448242\n",
      "0.024571895599365234\n",
      "0.012123584747314453\n",
      "0.02785515785217285\n",
      "0.008568286895751953\n",
      "0.018330097198486328\n",
      "0.007896184921264648\n",
      "0.014164447784423828\n",
      "0.03455615043640137\n",
      "0.023551225662231445\n",
      "0.025864362716674805\n",
      "0.012793302536010742\n",
      "0.02876567840576172\n",
      "0.018360137939453125\n",
      "0.02108907699584961\n",
      "0.04016828536987305\n",
      "0.06928706169128418\n",
      "0.050955772399902344\n",
      "0.029579639434814453\n",
      "0.024997234344482422\n",
      "0.020086288452148438\n",
      "0.02440643310546875\n",
      "0.0312802791595459\n",
      "0.016892671585083008\n",
      "0.021530866622924805\n",
      "0.019170761108398438\n",
      "0.028975248336791992\n",
      "0.027874231338500977\n",
      "0.13031601905822754\n",
      "0.032653093338012695\n",
      "0.021976709365844727\n",
      "0.04739856719970703\n",
      "0.03174114227294922\n",
      "0.029460906982421875\n",
      "0.038819074630737305\n",
      "0.01359248161315918\n",
      "0.014366626739501953\n",
      "0.020534515380859375\n",
      "0.022197484970092773\n",
      "0.015280485153198242\n",
      "0.01439213752746582\n",
      "0.05308866500854492\n",
      "0.11077737808227539\n",
      "0.030542850494384766\n",
      "0.026906967163085938\n",
      "0.04925227165222168\n",
      "0.05348062515258789\n",
      "0.04021024703979492\n",
      "0.017383337020874023\n",
      "0.02031230926513672\n",
      "0.019920825958251953\n",
      "0.01900482177734375\n",
      "0.035494089126586914\n",
      "0.07050466537475586\n",
      "0.01803302764892578\n",
      "0.03357362747192383\n",
      "0.017671585083007812\n",
      "0.026074647903442383\n",
      "0.01656961441040039\n",
      "0.04485130310058594\n",
      "0.03679776191711426\n",
      "0.04061079025268555\n",
      "0.04933929443359375\n",
      "0.0157470703125\n",
      "0.028772354125976562\n",
      "0.026017427444458008\n",
      "0.015869140625\n",
      "0.1221623420715332\n",
      "0.01584315299987793\n",
      "0.0355226993560791\n",
      "0.025191068649291992\n",
      "0.03247952461242676\n",
      "0.049402475357055664\n",
      "0.04301333427429199\n",
      "0.09716010093688965\n",
      "0.018466711044311523\n",
      "0.011452674865722656\n",
      "0.009510278701782227\n",
      "0.02331233024597168\n",
      "0.016466617584228516\n",
      "0.011893510818481445\n",
      "0.02841663360595703\n",
      "0.009557962417602539\n",
      "0.020587921142578125\n",
      "0.0279693603515625\n",
      "0.010728120803833008\n",
      "0.013817310333251953\n",
      "0.017126798629760742\n",
      "0.01638936996459961\n",
      "0.011631488800048828\n",
      "0.013016462326049805\n",
      "0.04224061965942383\n",
      "0.01690363883972168\n",
      "0.01758599281311035\n",
      "0.022014617919921875\n",
      "0.03903818130493164\n",
      "0.009181022644042969\n",
      "0.01695537567138672\n",
      "0.01385188102722168\n",
      "0.009540796279907227\n",
      "0.01228475570678711\n",
      "0.015720367431640625\n",
      "0.010474681854248047\n",
      "0.011163949966430664\n",
      "0.011075496673583984\n",
      "0.029271602630615234\n",
      "0.012142658233642578\n",
      "0.012661933898925781\n",
      "0.015166997909545898\n",
      "0.010140657424926758\n",
      "0.009437084197998047\n",
      "0.018717527389526367\n",
      "0.01586461067199707\n",
      "0.028110027313232422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013722658157348633\n",
      "0.01834702491760254\n",
      "0.011969804763793945\n",
      "0.010563850402832031\n",
      "0.009041070938110352\n",
      "0.010549545288085938\n",
      "0.011244535446166992\n",
      "0.012410879135131836\n",
      "0.010156869888305664\n",
      "0.011409282684326172\n",
      "0.0122528076171875\n",
      "0.017477989196777344\n",
      "0.01249837875366211\n",
      "0.012037515640258789\n",
      "0.011112451553344727\n",
      "0.020714521408081055\n",
      "0.01798105239868164\n",
      "0.009097099304199219\n",
      "0.010295391082763672\n",
      "0.0445256233215332\n",
      "0.015491724014282227\n",
      "0.010635614395141602\n",
      "0.01579594612121582\n",
      "0.009485721588134766\n",
      "0.022374391555786133\n",
      "0.029430150985717773\n",
      "0.014901161193847656\n",
      "0.012743234634399414\n",
      "0.0442507266998291\n",
      "0.01768183708190918\n",
      "0.04480743408203125\n",
      "0.016997337341308594\n",
      "0.013050079345703125\n",
      "0.01374673843383789\n",
      "0.03744864463806152\n",
      "0.03409314155578613\n",
      "0.015576839447021484\n",
      "0.03244209289550781\n",
      "0.06143021583557129\n",
      "0.023857593536376953\n",
      "0.04358959197998047\n",
      "0.08221960067749023\n",
      "0.04497337341308594\n",
      "0.028023719787597656\n",
      "0.013585329055786133\n",
      "0.02058243751525879\n",
      "0.013297080993652344\n",
      "0.01874542236328125\n",
      "0.1163642406463623\n",
      "0.018868446350097656\n",
      "0.03136301040649414\n",
      "0.02205371856689453\n",
      "0.020984649658203125\n",
      "0.013961076736450195\n",
      "0.027098894119262695\n",
      "0.08495688438415527\n",
      "0.053807973861694336\n",
      "0.022717952728271484\n",
      "0.10106635093688965\n",
      "0.019271373748779297\n",
      "0.017499446868896484\n",
      "0.02257394790649414\n",
      "0.02315497398376465\n",
      "0.052068233489990234\n",
      "0.04903554916381836\n",
      "0.0347437858581543\n",
      "0.17737054824829102\n",
      "0.025470495223999023\n",
      "0.07177495956420898\n",
      "0.03005075454711914\n",
      "0.05796098709106445\n",
      "0.03728151321411133\n",
      "0.03584098815917969\n",
      "0.015114307403564453\n",
      "0.02340841293334961\n",
      "0.019351959228515625\n",
      "0.01718592643737793\n",
      "0.03516030311584473\n",
      "0.0455479621887207\n",
      "0.11667084693908691\n",
      "0.08610796928405762\n",
      "0.025338411331176758\n",
      "0.07126426696777344\n",
      "0.02472853660583496\n",
      "0.12272953987121582\n",
      "0.033410072326660156\n",
      "0.1510012149810791\n",
      "0.09937453269958496\n",
      "0.025705337524414062\n",
      "0.20647001266479492\n",
      "0.06861567497253418\n",
      "0.019827842712402344\n",
      "0.050875186920166016\n",
      "0.11300230026245117\n",
      "0.04778313636779785\n",
      "0.07320427894592285\n",
      "0.05402684211730957\n",
      "0.01987457275390625\n",
      "0.01830267906188965\n",
      "0.01528167724609375\n",
      "0.014138460159301758\n",
      "0.016190767288208008\n",
      "0.027369976043701172\n",
      "0.018512248992919922\n",
      "0.015696287155151367\n",
      "0.04667043685913086\n",
      "0.015339851379394531\n",
      "0.18335342407226562\n",
      "0.02736687660217285\n",
      "0.06397557258605957\n",
      "0.04271554946899414\n",
      "0.03591299057006836\n",
      "0.013068199157714844\n",
      "0.15655851364135742\n",
      "0.12664341926574707\n",
      "0.1470952033996582\n",
      "0.045789480209350586\n",
      "0.0537571907043457\n",
      "0.03330111503601074\n",
      "0.017943143844604492\n",
      "0.06346964836120605\n",
      "0.012408971786499023\n",
      "0.19306683540344238\n",
      "0.055944204330444336\n",
      "0.01712942123413086\n",
      "0.027872323989868164\n",
      "0.013061285018920898\n",
      "0.023000717163085938\n",
      "0.021612167358398438\n",
      "0.013439416885375977\n",
      "0.017537832260131836\n",
      "0.018044233322143555\n",
      "0.014937877655029297\n",
      "0.035505056381225586\n",
      "0.07807183265686035\n",
      "0.03429150581359863\n",
      "0.027848005294799805\n",
      "0.013060569763183594\n",
      "0.020974397659301758\n",
      "0.049050092697143555\n",
      "0.030488014221191406\n",
      "0.021260738372802734\n",
      "0.016026973724365234\n",
      "0.07631278038024902\n",
      "0.01866006851196289\n",
      "0.012974262237548828\n",
      "0.06747579574584961\n",
      "0.04956865310668945\n",
      "0.026599884033203125\n",
      "0.07059645652770996\n",
      "0.13297629356384277\n",
      "0.022101879119873047\n",
      "0.04450082778930664\n",
      "0.015270471572875977\n",
      "0.0329434871673584\n",
      "0.02393198013305664\n",
      "0.09202885627746582\n",
      "0.0436711311340332\n",
      "0.08959484100341797\n",
      "0.012870073318481445\n",
      "0.08516836166381836\n",
      "0.01592254638671875\n",
      "0.018729448318481445\n",
      "0.022492647171020508\n",
      "0.0717935562133789\n",
      "0.02878880500793457\n",
      "0.024637460708618164\n",
      "0.01479339599609375\n",
      "0.012494087219238281\n",
      "0.06497621536254883\n",
      "0.016875505447387695\n",
      "0.020345211029052734\n",
      "0.041785478591918945\n",
      "0.035230159759521484\n",
      "0.022668838500976562\n",
      "0.013013362884521484\n",
      "0.032259225845336914\n",
      "0.025510549545288086\n",
      "0.01246500015258789\n",
      "0.029644250869750977\n",
      "0.0157318115234375\n",
      "0.0342864990234375\n",
      "0.08844876289367676\n",
      "0.019178390502929688\n",
      "0.013201475143432617\n",
      "0.02532029151916504\n",
      "0.013659238815307617\n",
      "0.03981637954711914\n",
      "0.01366734504699707\n",
      "0.01951122283935547\n",
      "0.020241260528564453\n",
      "0.03078627586364746\n",
      "0.015921354293823242\n",
      "0.058924198150634766\n",
      "0.02308177947998047\n",
      "0.04524350166320801\n",
      "0.0327296257019043\n",
      "0.03036022186279297\n",
      "0.024410009384155273\n",
      "0.01825261116027832\n",
      "0.02000594139099121\n",
      "0.014437198638916016\n",
      "0.016755342483520508\n",
      "0.01871967315673828\n",
      "0.012723207473754883\n",
      "0.017997264862060547\n",
      "0.0517420768737793\n",
      "0.016211271286010742\n",
      "0.1943361759185791\n",
      "0.04483842849731445\n",
      "0.05265927314758301\n",
      "0.14431142807006836\n",
      "0.022133350372314453\n",
      "0.018493175506591797\n",
      "0.01242208480834961\n",
      "0.06203627586364746\n",
      "0.02239680290222168\n",
      "0.0514986515045166\n",
      "0.06362557411193848\n",
      "0.09059309959411621\n",
      "0.014685630798339844\n",
      "0.07185029983520508\n",
      "0.018639802932739258\n",
      "0.028687238693237305\n",
      "0.019049406051635742\n",
      "0.017657756805419922\n",
      "0.029397010803222656\n",
      "0.021826505661010742\n",
      "0.06394147872924805\n",
      "0.052977561950683594\n",
      "0.029694557189941406\n",
      "0.06586837768554688\n",
      "0.02782297134399414\n",
      "0.020368576049804688\n",
      "0.03818082809448242\n",
      "0.13823437690734863\n",
      "0.09454965591430664\n",
      "0.021497726440429688\n",
      "0.04151463508605957\n",
      "0.0789334774017334\n",
      "0.05237841606140137\n",
      "0.022019386291503906\n",
      "0.02736496925354004\n",
      "0.010790348052978516\n",
      "0.0210263729095459\n",
      "0.020637035369873047\n",
      "0.016288042068481445\n",
      "0.012638330459594727\n",
      "0.016589879989624023\n",
      "0.0467379093170166\n",
      "0.03052997589111328\n",
      "0.014207124710083008\n",
      "0.05731487274169922\n",
      "0.04226970672607422\n",
      "0.026615619659423828\n",
      "0.013440608978271484\n",
      "0.021345853805541992\n",
      "0.020918846130371094\n",
      "0.024817466735839844\n",
      "0.015180110931396484\n",
      "0.0301358699798584\n",
      "0.022952795028686523\n",
      "0.02615213394165039\n",
      "0.039156436920166016\n",
      "0.01718759536743164\n",
      "0.04134988784790039\n",
      "0.032834768295288086\n",
      "0.027608156204223633\n",
      "0.012529850006103516\n",
      "0.04769611358642578\n",
      "0.024469375610351562\n",
      "0.05472064018249512\n",
      "0.04503822326660156\n",
      "0.03355669975280762\n",
      "0.028382539749145508\n",
      "0.038251638412475586\n",
      "0.0975644588470459\n",
      "0.055416107177734375\n",
      "0.04698014259338379\n",
      "0.046247243881225586\n",
      "0.012445449829101562\n",
      "0.013077497482299805\n",
      "0.012489795684814453\n",
      "0.015887975692749023\n",
      "0.01269221305847168\n",
      "0.040372610092163086\n",
      "0.030133962631225586\n",
      "0.0720663070678711\n",
      "0.016606569290161133\n",
      "0.04077720642089844\n",
      "0.025670766830444336\n",
      "0.027460575103759766\n",
      "0.017304420471191406\n",
      "0.03680086135864258\n",
      "0.0556187629699707\n",
      "0.048227548599243164\n",
      "0.0279541015625\n",
      "0.02725076675415039\n",
      "0.039998531341552734\n",
      "0.03293728828430176\n",
      "0.04000544548034668\n",
      "0.019344806671142578\n",
      "0.04149770736694336\n",
      "0.044112443923950195\n",
      "0.02312016487121582\n",
      "0.011728286743164062\n",
      "0.015718936920166016\n",
      "0.007815837860107422\n",
      "0.04285860061645508\n",
      "0.02084827423095703\n",
      "0.014247655868530273\n",
      "0.016484975814819336\n",
      "0.04992556571960449\n",
      "0.031484365463256836\n",
      "0.0587003231048584\n",
      "0.020041465759277344\n",
      "0.021674156188964844\n",
      "0.021399259567260742\n",
      "0.01772785186767578\n",
      "0.025801420211791992\n",
      "0.028166770935058594\n",
      "0.027363300323486328\n",
      "0.0234682559967041\n",
      "0.014132976531982422\n",
      "0.02527308464050293\n",
      "0.02039051055908203\n",
      "0.017965078353881836\n",
      "0.03355884552001953\n",
      "0.05440783500671387\n",
      "0.01996445655822754\n",
      "0.05134749412536621\n",
      "0.03960132598876953\n",
      "0.013641357421875\n",
      "0.02838134765625\n",
      "0.07163286209106445\n",
      "0.012366771697998047\n",
      "0.023674726486206055\n",
      "0.013957977294921875\n",
      "0.040915727615356445\n",
      "0.04315614700317383\n",
      "0.029037952423095703\n",
      "0.04442882537841797\n",
      "0.015004158020019531\n",
      "0.023651599884033203\n",
      "0.023961544036865234\n",
      "0.014061689376831055\n",
      "0.022585153579711914\n",
      "0.018046855926513672\n",
      "0.01897740364074707\n",
      "0.02008223533630371\n",
      "0.023662805557250977\n",
      "0.039554595947265625\n",
      "0.03008556365966797\n",
      "0.018735408782958984\n",
      "0.01320338249206543\n",
      "0.03546762466430664\n",
      "0.012907981872558594\n",
      "0.029276371002197266\n",
      "0.031089067459106445\n",
      "0.020337820053100586\n",
      "0.01641535758972168\n",
      "0.014422893524169922\n",
      "0.013377666473388672\n",
      "0.06118321418762207\n",
      "0.015811681747436523\n",
      "0.013191699981689453\n",
      "0.027643918991088867\n",
      "0.016704797744750977\n",
      "0.02746415138244629\n",
      "0.013948440551757812\n",
      "0.01354074478149414\n",
      "0.015988826751708984\n",
      "0.012480735778808594\n",
      "0.014304876327514648\n",
      "0.04325437545776367\n",
      "0.012892484664916992\n",
      "0.022014379501342773\n",
      "0.02456808090209961\n",
      "0.019102811813354492\n",
      "0.020551204681396484\n",
      "0.047481536865234375\n",
      "0.014124870300292969\n",
      "0.025365591049194336\n",
      "0.016057252883911133\n",
      "0.014563322067260742\n",
      "0.014943838119506836\n",
      "0.025243043899536133\n",
      "0.015883684158325195\n",
      "0.015051603317260742\n",
      "0.01275944709777832\n",
      "0.027899742126464844\n",
      "0.016966819763183594\n",
      "0.017410755157470703\n",
      "0.023837804794311523\n",
      "0.019690275192260742\n",
      "0.061409950256347656\n",
      "0.05703282356262207\n",
      "0.028790712356567383\n",
      "0.01250147819519043\n",
      "0.01985621452331543\n",
      "0.015168190002441406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030003070831298828\n",
      "0.009113073348999023\n",
      "0.008814334869384766\n",
      "0.008750677108764648\n",
      "0.01336812973022461\n",
      "0.028085947036743164\n",
      "0.014708280563354492\n",
      "0.012800216674804688\n",
      "0.028926372528076172\n",
      "0.03655409812927246\n",
      "0.012627601623535156\n",
      "0.05137968063354492\n",
      "0.018085718154907227\n",
      "0.012510299682617188\n",
      "0.053586483001708984\n",
      "0.013750314712524414\n",
      "0.01463937759399414\n",
      "0.017873764038085938\n",
      "0.01710820198059082\n",
      "0.09186244010925293\n",
      "0.019006013870239258\n",
      "0.019779443740844727\n",
      "0.02227473258972168\n",
      "0.015143632888793945\n",
      "0.027673006057739258\n",
      "0.03350496292114258\n",
      "0.013923406600952148\n",
      "0.028300762176513672\n",
      "0.04403853416442871\n",
      "0.030381202697753906\n",
      "0.013073444366455078\n",
      "0.025289058685302734\n",
      "0.017628192901611328\n",
      "0.020587682723999023\n",
      "0.023946046829223633\n",
      "0.030036211013793945\n",
      "0.03718900680541992\n",
      "0.0205075740814209\n",
      "0.04190945625305176\n",
      "0.02985405921936035\n",
      "0.02062511444091797\n",
      "0.02466273307800293\n",
      "0.03313755989074707\n",
      "0.03986978530883789\n",
      "0.03859543800354004\n",
      "0.07130575180053711\n",
      "0.02069997787475586\n",
      "0.013449430465698242\n",
      "0.011462211608886719\n",
      "0.013613462448120117\n",
      "0.010767221450805664\n",
      "0.010559558868408203\n",
      "0.015967607498168945\n",
      "0.011929750442504883\n",
      "0.013138771057128906\n",
      "0.009654760360717773\n",
      "0.008361577987670898\n",
      "0.030872344970703125\n",
      "0.01133871078491211\n",
      "0.02429485321044922\n",
      "0.01976323127746582\n",
      "0.013648509979248047\n",
      "0.008882999420166016\n",
      "0.012549400329589844\n",
      "0.01402902603149414\n",
      "0.02584099769592285\n",
      "0.015162467956542969\n",
      "0.022491931915283203\n",
      "0.03380274772644043\n",
      "0.031015872955322266\n",
      "0.02737140655517578\n",
      "0.014388799667358398\n",
      "0.019937753677368164\n",
      "0.03471565246582031\n",
      "0.016136884689331055\n",
      "0.017467021942138672\n",
      "0.021113872528076172\n",
      "0.014854669570922852\n",
      "0.018125295639038086\n",
      "0.01830458641052246\n",
      "0.012844562530517578\n",
      "0.014414787292480469\n",
      "0.02409505844116211\n",
      "0.016928434371948242\n",
      "0.03818392753601074\n",
      "0.030213594436645508\n",
      "0.027153730392456055\n",
      "0.023879051208496094\n",
      "0.04011392593383789\n",
      "0.018782615661621094\n",
      "0.02646923065185547\n",
      "0.012441158294677734\n",
      "0.015703201293945312\n",
      "0.024281024932861328\n",
      "0.016126155853271484\n",
      "0.014820337295532227\n",
      "0.02605438232421875\n",
      "0.017427444458007812\n",
      "0.020722389221191406\n",
      "0.016097068786621094\n",
      "0.013507366180419922\n",
      "0.013042211532592773\n",
      "0.024164438247680664\n",
      "0.01390218734741211\n",
      "0.014681577682495117\n",
      "0.013414859771728516\n",
      "0.012653350830078125\n",
      "0.016268014907836914\n",
      "0.020549535751342773\n",
      "0.013449907302856445\n",
      "0.015182971954345703\n",
      "0.015476465225219727\n",
      "0.012515068054199219\n",
      "0.020409345626831055\n",
      "0.01638054847717285\n",
      "0.013204813003540039\n",
      "0.02571249008178711\n",
      "0.027816057205200195\n",
      "0.029606103897094727\n",
      "0.023185253143310547\n",
      "0.012710809707641602\n",
      "0.012705326080322266\n",
      "0.024573326110839844\n",
      "0.013721942901611328\n",
      "0.023301362991333008\n",
      "0.01757192611694336\n",
      "0.03213024139404297\n",
      "0.012572765350341797\n",
      "0.018065452575683594\n",
      "0.01796436309814453\n",
      "0.05820322036743164\n",
      "0.014412164688110352\n",
      "0.014330148696899414\n",
      "0.05193066596984863\n",
      "0.01271510124206543\n",
      "0.01878213882446289\n",
      "0.01584792137145996\n",
      "0.01478266716003418\n",
      "0.016474008560180664\n",
      "0.017706871032714844\n",
      "0.0217282772064209\n",
      "0.01331329345703125\n",
      "0.0233919620513916\n",
      "0.05894184112548828\n",
      "0.01257777214050293\n",
      "0.015385627746582031\n",
      "0.013509988784790039\n",
      "0.019927501678466797\n",
      "0.01970815658569336\n",
      "0.027378082275390625\n",
      "0.014091730117797852\n",
      "0.014404773712158203\n",
      "0.022439956665039062\n",
      "0.01953577995300293\n",
      "0.01297140121459961\n",
      "0.013814926147460938\n",
      "0.01772451400756836\n",
      "0.018046140670776367\n",
      "0.018768310546875\n",
      "0.01961350440979004\n",
      "0.020925521850585938\n",
      "0.01889324188232422\n",
      "0.012522697448730469\n",
      "0.0313570499420166\n",
      "0.018853425979614258\n",
      "0.01357412338256836\n",
      "0.019654035568237305\n",
      "0.013548612594604492\n",
      "0.021883487701416016\n",
      "0.015929222106933594\n",
      "0.014444351196289062\n",
      "0.017728328704833984\n",
      "0.013684272766113281\n",
      "0.01619100570678711\n",
      "0.01409006118774414\n",
      "0.01397252082824707\n",
      "0.017941951751708984\n",
      "0.020794153213500977\n",
      "0.014883041381835938\n",
      "0.013821601867675781\n",
      "0.015370845794677734\n",
      "0.012505769729614258\n",
      "0.05990481376647949\n",
      "0.017380475997924805\n",
      "0.014616250991821289\n",
      "0.017955780029296875\n",
      "0.021673917770385742\n",
      "0.015349388122558594\n",
      "0.01801609992980957\n",
      "0.01338815689086914\n",
      "0.01706695556640625\n",
      "0.02005934715270996\n",
      "0.016160249710083008\n",
      "0.021461009979248047\n",
      "0.010233402252197266\n",
      "0.03516960144042969\n",
      "0.008012533187866211\n",
      "0.011159420013427734\n",
      "0.009530782699584961\n",
      "0.010833740234375\n",
      "0.01613640785217285\n",
      "0.011192798614501953\n",
      "0.03005838394165039\n",
      "0.024991750717163086\n",
      "0.012614727020263672\n",
      "0.014110326766967773\n",
      "0.022147417068481445\n",
      "0.021048545837402344\n",
      "0.09021210670471191\n",
      "0.013115882873535156\n",
      "0.022588491439819336\n",
      "0.0179750919342041\n",
      "0.016211271286010742\n",
      "0.03649115562438965\n",
      "0.016219377517700195\n",
      "0.013048887252807617\n",
      "0.016545772552490234\n",
      "0.017536401748657227\n",
      "0.022145509719848633\n",
      "0.034316062927246094\n",
      "0.01705193519592285\n",
      "0.03256082534790039\n",
      "0.015358686447143555\n",
      "0.025558948516845703\n",
      "0.04117989540100098\n",
      "0.017512798309326172\n",
      "0.016354084014892578\n",
      "0.01633286476135254\n",
      "0.012592554092407227\n",
      "0.017617464065551758\n",
      "0.0191957950592041\n",
      "0.012749195098876953\n",
      "0.014336347579956055\n",
      "0.016117095947265625\n",
      "0.01243281364440918\n",
      "0.013952255249023438\n",
      "0.012878894805908203\n",
      "0.0182340145111084\n",
      "0.017313480377197266\n",
      "0.014912128448486328\n",
      "0.021544218063354492\n",
      "0.019241809844970703\n",
      "0.03265190124511719\n",
      "0.04552340507507324\n",
      "0.017270565032958984\n",
      "0.025956153869628906\n",
      "0.013313055038452148\n",
      "0.026775836944580078\n",
      "0.0380253791809082\n",
      "0.0131378173828125\n",
      "0.026180028915405273\n",
      "0.012881994247436523\n",
      "0.02609992027282715\n",
      "0.015395879745483398\n",
      "0.012768030166625977\n",
      "0.02441573143005371\n",
      "0.03145003318786621\n",
      "0.014536142349243164\n",
      "0.02408766746520996\n",
      "0.022211790084838867\n",
      "0.02690887451171875\n",
      "0.015401363372802734\n",
      "0.0126953125\n",
      "0.02542424201965332\n",
      "0.022571802139282227\n",
      "0.014407873153686523\n",
      "0.014979124069213867\n",
      "0.02224898338317871\n",
      "0.015124320983886719\n",
      "0.013625144958496094\n",
      "0.016648054122924805\n",
      "0.023678064346313477\n",
      "0.026777029037475586\n",
      "0.012972831726074219\n",
      "0.017092227935791016\n",
      "0.02405238151550293\n",
      "0.012491703033447266\n",
      "0.013848304748535156\n",
      "0.024024009704589844\n",
      "0.02380061149597168\n",
      "0.015973806381225586\n",
      "0.02156352996826172\n",
      "0.013170480728149414\n",
      "0.014273881912231445\n",
      "0.012544631958007812\n",
      "0.013109683990478516\n",
      "0.012356281280517578\n",
      "0.01993083953857422\n",
      "0.01600933074951172\n",
      "0.0175628662109375\n",
      "0.03915214538574219\n",
      "0.015511512756347656\n",
      "0.013435840606689453\n",
      "0.016384601593017578\n",
      "0.034445762634277344\n",
      "0.021628856658935547\n",
      "0.019446372985839844\n",
      "0.016291141510009766\n",
      "0.021161556243896484\n",
      "0.02041792869567871\n",
      "0.0210878849029541\n",
      "0.02032017707824707\n",
      "0.01574420928955078\n",
      "0.014105558395385742\n",
      "0.055107831954956055\n",
      "0.023410797119140625\n",
      "0.01750469207763672\n",
      "0.07609701156616211\n",
      "0.019222497940063477\n",
      "0.017612934112548828\n",
      "0.02642512321472168\n",
      "0.013690471649169922\n",
      "0.012558221817016602\n",
      "0.025283336639404297\n",
      "0.016155481338500977\n",
      "0.013159990310668945\n",
      "0.02290201187133789\n",
      "0.028969287872314453\n",
      "0.02145695686340332\n",
      "0.02074146270751953\n",
      "0.01683640480041504\n",
      "0.016162633895874023\n",
      "0.03807377815246582\n",
      "0.024489641189575195\n",
      "0.022287368774414062\n",
      "0.04316306114196777\n",
      "0.03920865058898926\n",
      "0.03851628303527832\n",
      "0.030933856964111328\n",
      "0.03468632698059082\n",
      "0.0336611270904541\n",
      "0.017538070678710938\n",
      "0.018395662307739258\n",
      "0.021991729736328125\n",
      "0.030746936798095703\n",
      "0.01709461212158203\n",
      "0.01889824867248535\n",
      "0.02028512954711914\n",
      "0.017038583755493164\n",
      "0.05331110954284668\n",
      "0.02534651756286621\n",
      "0.015791654586791992\n",
      "0.02666640281677246\n",
      "0.01628422737121582\n",
      "0.0157470703125\n",
      "0.019306421279907227\n",
      "0.02147531509399414\n",
      "0.01624751091003418\n",
      "0.015370845794677734\n",
      "0.0359339714050293\n",
      "0.02143383026123047\n",
      "0.01980113983154297\n",
      "0.0172274112701416\n",
      "0.023435115814208984\n",
      "0.01065683364868164\n",
      "0.008905887603759766\n",
      "0.027118921279907227\n",
      "0.009723424911499023\n",
      "0.007842540740966797\n",
      "0.007872343063354492\n",
      "0.013142108917236328\n",
      "0.007439374923706055\n",
      "0.010611772537231445\n",
      "0.01506662368774414\n",
      "0.013081550598144531\n",
      "0.012170791625976562\n",
      "0.012894868850708008\n",
      "0.010135650634765625\n",
      "0.016457796096801758\n",
      "0.011187553405761719\n",
      "0.010324478149414062\n",
      "0.011093378067016602\n",
      "0.008280754089355469\n",
      "0.008529901504516602\n",
      "0.010540485382080078\n",
      "0.010626792907714844\n",
      "0.009463310241699219\n",
      "0.01346898078918457\n",
      "0.011586427688598633\n",
      "0.009865522384643555\n",
      "0.00876760482788086\n",
      "0.008881568908691406\n",
      "0.008359909057617188\n",
      "0.011797666549682617\n",
      "0.009917259216308594\n",
      "0.007582664489746094\n",
      "0.009092330932617188\n",
      "0.011821746826171875\n",
      "0.007572650909423828\n",
      "0.008750677108764648\n",
      "0.009190797805786133\n",
      "0.012545347213745117\n",
      "0.023514509201049805\n",
      "0.008237123489379883\n",
      "0.008676528930664062\n",
      "0.015221118927001953\n",
      "0.017930030822753906\n",
      "0.04054689407348633\n",
      "0.013006210327148438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014484643936157227\n",
      "0.008175134658813477\n",
      "0.016806364059448242\n",
      "0.014342784881591797\n",
      "0.00942683219909668\n",
      "0.009820222854614258\n",
      "0.012914896011352539\n",
      "0.011742830276489258\n",
      "0.016219377517700195\n",
      "0.01873779296875\n",
      "0.019175052642822266\n",
      "0.029824495315551758\n",
      "0.017229080200195312\n",
      "0.021924495697021484\n",
      "0.02479696273803711\n",
      "0.015429496765136719\n",
      "0.030822038650512695\n",
      "0.012513160705566406\n",
      "0.032344818115234375\n",
      "0.023973941802978516\n",
      "0.012398481369018555\n",
      "0.04993486404418945\n",
      "0.014546632766723633\n",
      "0.013065814971923828\n",
      "0.02096867561340332\n",
      "0.020741701126098633\n",
      "0.026541948318481445\n",
      "0.012352466583251953\n",
      "0.024150371551513672\n",
      "0.03346729278564453\n",
      "0.02159571647644043\n",
      "0.0556337833404541\n",
      "0.029448509216308594\n",
      "0.012563705444335938\n",
      "0.016297340393066406\n",
      "0.012530803680419922\n",
      "0.021334409713745117\n",
      "0.022617578506469727\n",
      "0.014428377151489258\n",
      "0.01294851303100586\n",
      "0.015323162078857422\n",
      "0.023638010025024414\n",
      "0.014261960983276367\n",
      "0.015328168869018555\n",
      "0.024859905242919922\n",
      "0.02049708366394043\n",
      "0.02735447883605957\n",
      "0.021831750869750977\n",
      "0.019468069076538086\n",
      "0.016540050506591797\n",
      "0.02613043785095215\n",
      "0.016770124435424805\n",
      "0.019957780838012695\n",
      "0.028859853744506836\n",
      "0.017953157424926758\n",
      "0.014586210250854492\n",
      "0.012030363082885742\n",
      "0.015101432800292969\n",
      "0.012556076049804688\n",
      "0.011775016784667969\n",
      "0.01634669303894043\n",
      "0.03308391571044922\n",
      "0.023923635482788086\n",
      "0.008283376693725586\n",
      "0.008308172225952148\n",
      "0.012952327728271484\n",
      "0.007513999938964844\n",
      "0.009051084518432617\n",
      "0.0076198577880859375\n",
      "0.00808858871459961\n",
      "0.007369041442871094\n",
      "0.009097099304199219\n",
      "0.029877662658691406\n",
      "0.0134124755859375\n",
      "0.022008895874023438\n",
      "0.014780044555664062\n",
      "0.009150981903076172\n",
      "0.009896516799926758\n",
      "0.011179685592651367\n",
      "0.008034229278564453\n",
      "0.014446735382080078\n",
      "0.015847444534301758\n",
      "0.01050567626953125\n",
      "0.012464046478271484\n",
      "0.02146744728088379\n",
      "0.01123809814453125\n",
      "0.015558242797851562\n",
      "0.009415149688720703\n",
      "0.02332329750061035\n",
      "0.011989831924438477\n",
      "0.013561487197875977\n",
      "0.012407302856445312\n",
      "0.012521982192993164\n",
      "0.013205766677856445\n",
      "0.012287139892578125\n",
      "0.02031421661376953\n",
      "0.020128488540649414\n",
      "0.021031856536865234\n",
      "0.021796226501464844\n",
      "0.012286901473999023\n",
      "0.02943563461303711\n",
      "0.03300738334655762\n",
      "0.015001058578491211\n",
      "0.021495342254638672\n",
      "0.015439510345458984\n",
      "0.014372110366821289\n",
      "0.01841259002685547\n",
      "0.01777052879333496\n",
      "0.04180169105529785\n",
      "0.020904541015625\n",
      "0.02219867706298828\n",
      "0.032486915588378906\n",
      "0.014120101928710938\n",
      "0.014221906661987305\n",
      "0.012567758560180664\n",
      "0.027326583862304688\n",
      "0.02093648910522461\n",
      "0.01252293586730957\n",
      "0.019539594650268555\n",
      "0.014982223510742188\n",
      "0.0206756591796875\n",
      "0.08140683174133301\n",
      "0.021600723266601562\n",
      "0.01250147819519043\n",
      "0.04786968231201172\n",
      "0.01812291145324707\n",
      "0.02136540412902832\n",
      "0.009975194931030273\n",
      "0.007875204086303711\n",
      "0.0102386474609375\n",
      "0.012510299682617188\n",
      "0.009784936904907227\n",
      "0.017873287200927734\n",
      "0.007454872131347656\n",
      "0.01268911361694336\n",
      "0.00865316390991211\n",
      "0.016017913818359375\n",
      "0.02007293701171875\n",
      "0.012158393859863281\n",
      "0.010365724563598633\n",
      "0.018275976181030273\n",
      "0.02458953857421875\n",
      "0.013554811477661133\n",
      "0.014777660369873047\n",
      "0.03991079330444336\n",
      "0.01409912109375\n",
      "0.039063215255737305\n",
      "0.012673377990722656\n",
      "0.03207850456237793\n",
      "0.017935991287231445\n",
      "0.019432783126831055\n",
      "0.04319596290588379\n",
      "0.01712965965270996\n",
      "0.016906023025512695\n",
      "0.012778997421264648\n",
      "0.015250444412231445\n",
      "0.018428802490234375\n",
      "0.01772284507751465\n",
      "0.027290821075439453\n",
      "0.022584199905395508\n",
      "0.01631641387939453\n",
      "0.022231340408325195\n",
      "0.02498340606689453\n",
      "0.021352291107177734\n",
      "0.014974594116210938\n",
      "0.01646256446838379\n",
      "0.018241167068481445\n",
      "0.013359308242797852\n",
      "0.03682398796081543\n",
      "0.04474759101867676\n",
      "0.017937660217285156\n",
      "0.030736446380615234\n",
      "0.013648509979248047\n",
      "0.025696277618408203\n",
      "0.026645898818969727\n",
      "0.014251470565795898\n",
      "0.06550335884094238\n",
      "0.050017595291137695\n",
      "0.018653154373168945\n",
      "0.025776147842407227\n",
      "0.024525165557861328\n",
      "0.02126908302307129\n",
      "0.014316320419311523\n",
      "0.012950897216796875\n",
      "0.025174856185913086\n",
      "0.014924764633178711\n",
      "0.022050857543945312\n",
      "0.016271352767944336\n",
      "0.013203620910644531\n",
      "0.03607892990112305\n",
      "0.0394587516784668\n",
      "0.028572797775268555\n",
      "0.02930283546447754\n",
      "0.03262615203857422\n",
      "0.01234292984008789\n",
      "0.017415761947631836\n",
      "0.02267599105834961\n",
      "0.01532125473022461\n",
      "0.02226877212524414\n",
      "0.02408313751220703\n",
      "0.01762700080871582\n",
      "0.016418933868408203\n",
      "0.021434307098388672\n",
      "0.018271446228027344\n",
      "0.037537574768066406\n",
      "0.020599842071533203\n",
      "0.04354262351989746\n",
      "0.027191877365112305\n",
      "0.0196840763092041\n",
      "0.019208431243896484\n",
      "0.03902912139892578\n",
      "0.012564897537231445\n",
      "0.012699604034423828\n",
      "0.039307594299316406\n",
      "0.014050483703613281\n",
      "0.020139694213867188\n",
      "0.013176918029785156\n",
      "0.020154714584350586\n",
      "0.013801813125610352\n",
      "0.016344308853149414\n",
      "0.013068437576293945\n",
      "0.016030550003051758\n",
      "0.015896320343017578\n",
      "0.013797521591186523\n",
      "0.021304845809936523\n",
      "0.026528358459472656\n",
      "0.020742177963256836\n",
      "0.028261899948120117\n",
      "0.018094301223754883\n",
      "0.026578664779663086\n",
      "0.016464948654174805\n",
      "0.012424468994140625\n",
      "0.017391443252563477\n",
      "0.017803192138671875\n",
      "0.020291805267333984\n",
      "0.016518354415893555\n",
      "0.042647361755371094\n",
      "0.019785165786743164\n",
      "0.013612985610961914\n",
      "0.01298975944519043\n",
      "0.012861490249633789\n",
      "0.011355161666870117\n",
      "0.016236066818237305\n",
      "0.011990070343017578\n",
      "0.061506032943725586\n",
      "0.02139425277709961\n",
      "0.012538433074951172\n",
      "0.022225141525268555\n",
      "0.03182864189147949\n",
      "0.01434469223022461\n",
      "0.012956380844116211\n",
      "0.07758092880249023\n",
      "0.1115562915802002\n",
      "0.0272371768951416\n",
      "0.008430719375610352\n",
      "0.008484601974487305\n",
      "0.012789487838745117\n",
      "0.02113795280456543\n",
      "0.021395206451416016\n",
      "0.025981903076171875\n",
      "0.008689641952514648\n",
      "0.008732795715332031\n",
      "0.017019033432006836\n",
      "0.027176618576049805\n",
      "0.014198780059814453\n",
      "0.008307456970214844\n",
      "0.01906108856201172\n",
      "0.018454313278198242\n",
      "0.011184930801391602\n",
      "0.012027502059936523\n",
      "0.016418933868408203\n",
      "0.021792173385620117\n",
      "0.016019344329833984\n",
      "0.030932188034057617\n",
      "0.011977195739746094\n",
      "0.009714365005493164\n",
      "0.016170263290405273\n",
      "0.012071371078491211\n",
      "0.011902093887329102\n",
      "0.014765501022338867\n",
      "0.008852720260620117\n",
      "0.014180421829223633\n",
      "0.00785517692565918\n",
      "0.012943506240844727\n",
      "0.009633541107177734\n",
      "0.020232200622558594\n",
      "0.008110761642456055\n",
      "0.04058122634887695\n",
      "0.01411747932434082\n",
      "0.013413667678833008\n",
      "0.015037298202514648\n",
      "0.020482540130615234\n",
      "0.0404512882232666\n",
      "0.03342700004577637\n",
      "0.018180131912231445\n",
      "0.02173590660095215\n",
      "0.04136037826538086\n",
      "0.02337026596069336\n",
      "0.01662135124206543\n",
      "0.013792753219604492\n",
      "0.02654552459716797\n",
      "0.04558300971984863\n",
      "0.02053213119506836\n",
      "0.03257107734680176\n",
      "0.022179365158081055\n",
      "0.015148401260375977\n",
      "0.045932769775390625\n",
      "0.012589454650878906\n",
      "0.01309347152709961\n",
      "0.012598752975463867\n",
      "0.020926475524902344\n",
      "0.012263774871826172\n",
      "0.03989458084106445\n",
      "0.02272200584411621\n",
      "0.01593637466430664\n",
      "0.01958632469177246\n",
      "0.01670980453491211\n",
      "0.014596939086914062\n",
      "0.012976408004760742\n",
      "0.013140678405761719\n",
      "0.015722990036010742\n",
      "0.012709379196166992\n",
      "0.01865363121032715\n",
      "0.01633906364440918\n",
      "0.041686296463012695\n",
      "0.015440702438354492\n",
      "0.01780533790588379\n",
      "0.014878034591674805\n",
      "0.02779102325439453\n",
      "0.014899730682373047\n",
      "0.014739513397216797\n",
      "0.015567779541015625\n",
      "0.018661975860595703\n",
      "0.015894412994384766\n",
      "0.013343334197998047\n",
      "0.013893365859985352\n",
      "0.018475055694580078\n",
      "0.01639080047607422\n",
      "0.01692056655883789\n",
      "0.012538909912109375\n",
      "0.01433706283569336\n",
      "0.020841360092163086\n",
      "0.014622211456298828\n",
      "0.028238773345947266\n",
      "0.025805234909057617\n",
      "0.012628316879272461\n",
      "0.016089677810668945\n",
      "0.01643657684326172\n",
      "0.015370368957519531\n",
      "0.014767885208129883\n",
      "0.024050474166870117\n",
      "0.013365745544433594\n",
      "0.013051271438598633\n",
      "0.014398574829101562\n",
      "0.012878656387329102\n",
      "0.0214383602142334\n",
      "0.01477670669555664\n",
      "0.01653122901916504\n",
      "0.02264690399169922\n",
      "0.014750957489013672\n",
      "0.013344526290893555\n",
      "0.013337373733520508\n",
      "0.03317737579345703\n",
      "0.020534038543701172\n",
      "0.03309369087219238\n",
      "0.013709783554077148\n",
      "0.019878625869750977\n",
      "0.017254114151000977\n",
      "0.01656055450439453\n",
      "0.01782679557800293\n",
      "0.020833730697631836\n",
      "0.03532099723815918\n",
      "0.015793561935424805\n",
      "0.02225184440612793\n",
      "0.02840900421142578\n",
      "0.01947498321533203\n",
      "0.012484550476074219\n",
      "0.01704859733581543\n",
      "0.019161701202392578\n",
      "0.013005971908569336\n",
      "0.016488313674926758\n",
      "0.02252936363220215\n",
      "0.016530275344848633\n",
      "0.017308950424194336\n",
      "0.02904677391052246\n",
      "0.012311220169067383\n",
      "0.018444538116455078\n",
      "0.013939380645751953\n",
      "0.013917922973632812\n",
      "0.013181686401367188\n",
      "0.017223596572875977\n",
      "0.03571033477783203\n",
      "0.013687372207641602\n",
      "0.026540517807006836\n",
      "0.04419231414794922\n",
      "0.016546964645385742\n",
      "0.021537303924560547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01779341697692871\n",
      "0.04741406440734863\n",
      "0.022950410842895508\n",
      "0.021553754806518555\n",
      "0.014911413192749023\n",
      "0.022769927978515625\n",
      "0.05577445030212402\n",
      "0.04092097282409668\n",
      "0.035112619400024414\n",
      "0.01647353172302246\n",
      "0.02602696418762207\n",
      "0.01828789710998535\n",
      "0.03457140922546387\n",
      "0.016360998153686523\n",
      "0.01477503776550293\n",
      "0.025612592697143555\n",
      "0.03476452827453613\n",
      "0.017386913299560547\n",
      "0.04560112953186035\n",
      "0.028133392333984375\n",
      "0.03404951095581055\n",
      "0.03560972213745117\n",
      "0.02205801010131836\n",
      "0.05791926383972168\n",
      "0.020664453506469727\n",
      "0.015633106231689453\n",
      "0.0388031005859375\n",
      "0.02399468421936035\n",
      "0.032187700271606445\n",
      "0.013055562973022461\n",
      "0.043715715408325195\n",
      "0.01747441291809082\n",
      "0.012763023376464844\n",
      "0.013087272644042969\n",
      "0.032958269119262695\n",
      "0.028151273727416992\n",
      "0.03212571144104004\n",
      "0.0203397274017334\n",
      "0.05665135383605957\n",
      "0.0297696590423584\n",
      "0.07439398765563965\n",
      "0.01578378677368164\n",
      "0.0375370979309082\n",
      "0.012744903564453125\n",
      "0.04756641387939453\n",
      "0.07330799102783203\n",
      "0.1005716323852539\n",
      "0.06286287307739258\n",
      "0.037529945373535156\n",
      "0.0622868537902832\n",
      "0.1023871898651123\n",
      "0.021096229553222656\n",
      "0.037688493728637695\n",
      "0.018090248107910156\n",
      "0.05448555946350098\n",
      "0.02999567985534668\n",
      "0.03327012062072754\n",
      "0.021647214889526367\n",
      "0.043912649154663086\n",
      "0.08930492401123047\n",
      "0.09057927131652832\n",
      "0.052017927169799805\n",
      "0.02014470100402832\n",
      "0.016956329345703125\n",
      "0.019327878952026367\n",
      "0.0779426097869873\n",
      "0.031862497329711914\n",
      "0.030876874923706055\n",
      "0.06635379791259766\n",
      "0.023490190505981445\n",
      "0.06935286521911621\n",
      "0.043229103088378906\n",
      "0.030118942260742188\n",
      "0.022759437561035156\n",
      "0.012514114379882812\n",
      "0.12816977500915527\n",
      "0.04973459243774414\n",
      "0.021171092987060547\n",
      "0.07207846641540527\n",
      "0.028179168701171875\n",
      "0.013642311096191406\n",
      "0.02943134307861328\n",
      "0.016442060470581055\n",
      "0.016178607940673828\n",
      "0.02001166343688965\n",
      "0.0320281982421875\n",
      "0.027471065521240234\n",
      "0.0453343391418457\n",
      "0.024593114852905273\n",
      "0.12926268577575684\n",
      "0.07253098487854004\n",
      "0.06720328330993652\n",
      "0.015269756317138672\n",
      "0.04414868354797363\n",
      "0.028971433639526367\n",
      "0.17127680778503418\n",
      "0.031645774841308594\n",
      "0.0361790657043457\n",
      "0.02146148681640625\n",
      "0.01629805564880371\n",
      "0.014705419540405273\n",
      "0.02711033821105957\n",
      "0.01875591278076172\n",
      "0.026175737380981445\n",
      "0.035993099212646484\n",
      "0.03692317008972168\n",
      "0.03083181381225586\n",
      "0.04287147521972656\n",
      "0.02425551414489746\n",
      "0.022773265838623047\n",
      "0.07741880416870117\n",
      "0.04228615760803223\n",
      "0.02122807502746582\n",
      "0.015858888626098633\n",
      "0.033902883529663086\n",
      "0.022440195083618164\n",
      "0.017472267150878906\n",
      "0.06385040283203125\n",
      "0.026491641998291016\n",
      "0.022867918014526367\n",
      "0.02071666717529297\n",
      "0.02392864227294922\n",
      "0.03986930847167969\n",
      "0.017952680587768555\n",
      "0.022351980209350586\n",
      "0.01934337615966797\n",
      "0.03715205192565918\n",
      "0.014796257019042969\n",
      "0.018962383270263672\n",
      "0.1584463119506836\n",
      "0.025875329971313477\n",
      "0.0249330997467041\n",
      "0.033550262451171875\n",
      "0.026615619659423828\n",
      "0.021976470947265625\n",
      "0.09883761405944824\n",
      "0.030135154724121094\n",
      "0.03216195106506348\n",
      "0.04089236259460449\n",
      "0.019374847412109375\n",
      "0.015484094619750977\n",
      "0.01825857162475586\n",
      "0.016567707061767578\n",
      "0.021063566207885742\n",
      "0.016768217086791992\n",
      "0.015865325927734375\n",
      "0.01528477668762207\n",
      "0.01987147331237793\n",
      "0.018238067626953125\n",
      "0.01725006103515625\n",
      "0.018546581268310547\n",
      "0.015731096267700195\n",
      "0.019255399703979492\n",
      "0.046077728271484375\n",
      "0.021708011627197266\n",
      "0.023020029067993164\n",
      "0.026469707489013672\n",
      "0.015695571899414062\n",
      "0.013837099075317383\n",
      "0.02338719367980957\n",
      "0.01854991912841797\n",
      "0.011281728744506836\n",
      "0.033829689025878906\n",
      "0.016899585723876953\n",
      "0.015139341354370117\n",
      "0.019204139709472656\n",
      "0.016399383544921875\n",
      "0.0248868465423584\n",
      "0.01375126838684082\n",
      "0.01796889305114746\n",
      "0.017171382904052734\n",
      "0.02480173110961914\n",
      "0.018450498580932617\n",
      "0.025555849075317383\n",
      "0.01357412338256836\n",
      "0.02105879783630371\n",
      "0.014374971389770508\n",
      "0.008391380310058594\n",
      "0.008775472640991211\n",
      "0.021910429000854492\n",
      "0.01023721694946289\n",
      "0.019107818603515625\n",
      "0.02520442008972168\n",
      "0.013640642166137695\n",
      "0.01507115364074707\n",
      "0.028348207473754883\n",
      "0.02794933319091797\n",
      "0.018299102783203125\n",
      "0.012778043746948242\n",
      "0.0194399356842041\n",
      "0.01451873779296875\n",
      "0.018232345581054688\n",
      "0.017671585083007812\n",
      "0.01987147331237793\n",
      "0.017600297927856445\n",
      "0.02482461929321289\n",
      "0.016469717025756836\n",
      "0.014306306838989258\n",
      "0.024306774139404297\n",
      "0.014665365219116211\n",
      "0.024596691131591797\n",
      "0.027051925659179688\n",
      "0.019568443298339844\n",
      "0.012413740158081055\n",
      "0.01452016830444336\n",
      "0.012994050979614258\n",
      "0.01361083984375\n",
      "0.012657880783081055\n",
      "0.028772830963134766\n",
      "0.020282268524169922\n",
      "0.018199443817138672\n",
      "0.02457737922668457\n",
      "0.02597522735595703\n",
      "0.015134096145629883\n",
      "0.02431511878967285\n",
      "0.034561872482299805\n",
      "0.018999814987182617\n",
      "0.016989946365356445\n",
      "0.027419328689575195\n",
      "0.01673293113708496\n",
      "0.028939485549926758\n",
      "0.03363990783691406\n",
      "0.028575897216796875\n",
      "0.01806330680847168\n",
      "0.013215780258178711\n",
      "0.01203465461730957\n",
      "0.03297829627990723\n",
      "0.027641773223876953\n",
      "0.014461755752563477\n",
      "0.029644489288330078\n",
      "0.018930912017822266\n",
      "0.019819259643554688\n",
      "0.04035019874572754\n",
      "0.018907785415649414\n",
      "0.04054760932922363\n",
      "0.01501774787902832\n",
      "0.038503408432006836\n",
      "0.013749837875366211\n",
      "0.014380216598510742\n",
      "0.015015363693237305\n",
      "0.014228582382202148\n",
      "0.013468742370605469\n",
      "0.02133941650390625\n",
      "0.014669179916381836\n",
      "0.021250486373901367\n",
      "0.01799941062927246\n",
      "0.01334071159362793\n",
      "0.01737689971923828\n",
      "0.012638568878173828\n",
      "0.028408527374267578\n",
      "0.021137475967407227\n",
      "0.023532390594482422\n",
      "0.016687870025634766\n",
      "0.04003643989562988\n",
      "0.014667749404907227\n",
      "0.015585899353027344\n",
      "0.013432979583740234\n",
      "0.012674331665039062\n",
      "0.014911651611328125\n",
      "0.017228126525878906\n",
      "0.02959299087524414\n",
      "0.014058113098144531\n",
      "0.031279802322387695\n",
      "0.02335357666015625\n",
      "0.020258188247680664\n",
      "0.020972728729248047\n",
      "0.043358564376831055\n",
      "0.025660276412963867\n",
      "0.022608041763305664\n",
      "0.019486665725708008\n",
      "0.020281314849853516\n",
      "0.016704797744750977\n",
      "0.018392562866210938\n",
      "0.024576187133789062\n",
      "0.042894601821899414\n",
      "0.021075010299682617\n",
      "0.015899658203125\n",
      "0.015571355819702148\n",
      "0.01245260238647461\n",
      "0.02576279640197754\n",
      "0.02738499641418457\n",
      "0.0255429744720459\n",
      "0.026122331619262695\n",
      "0.02848219871520996\n",
      "0.01940011978149414\n",
      "0.01238107681274414\n",
      "0.01458883285522461\n",
      "0.018369436264038086\n",
      "0.012790441513061523\n",
      "0.027504682540893555\n",
      "0.01671743392944336\n",
      "0.012610912322998047\n",
      "0.02146625518798828\n",
      "0.013421297073364258\n",
      "0.013184309005737305\n",
      "0.012689590454101562\n",
      "0.01909494400024414\n",
      "0.0239412784576416\n",
      "0.014550209045410156\n",
      "0.03971552848815918\n",
      "0.01812434196472168\n",
      "0.014468908309936523\n",
      "0.016856670379638672\n",
      "0.022049903869628906\n",
      "0.015364885330200195\n",
      "0.017370939254760742\n",
      "0.017751693725585938\n",
      "0.03477025032043457\n",
      "0.03329896926879883\n",
      "0.015479326248168945\n",
      "0.033859968185424805\n",
      "0.023653507232666016\n",
      "0.012595653533935547\n",
      "0.01748347282409668\n",
      "0.013859033584594727\n",
      "0.013586044311523438\n",
      "0.0172421932220459\n",
      "0.012508869171142578\n",
      "0.012333869934082031\n",
      "0.027328968048095703\n",
      "0.023712873458862305\n",
      "0.014530658721923828\n",
      "0.017080068588256836\n",
      "0.021315574645996094\n",
      "0.013281583786010742\n",
      "0.016231298446655273\n",
      "0.012784004211425781\n",
      "0.012603759765625\n",
      "0.013586282730102539\n",
      "0.019146442413330078\n",
      "0.020898818969726562\n",
      "0.02179431915283203\n",
      "0.024536848068237305\n",
      "0.015863895416259766\n",
      "0.01582646369934082\n",
      "0.02104926109313965\n",
      "0.015651941299438477\n",
      "0.01919412612915039\n",
      "0.013748645782470703\n",
      "0.02246236801147461\n",
      "0.012527227401733398\n",
      "0.02036452293395996\n",
      "0.012607097625732422\n",
      "0.0162503719329834\n",
      "0.03206348419189453\n",
      "0.01957416534423828\n",
      "0.013910531997680664\n",
      "0.014850854873657227\n",
      "0.017318010330200195\n",
      "0.019275665283203125\n",
      "0.013322591781616211\n",
      "0.044377803802490234\n",
      "0.03401684761047363\n",
      "0.016150951385498047\n",
      "0.013931035995483398\n",
      "0.01801156997680664\n",
      "0.023607730865478516\n",
      "0.008851289749145508\n",
      "0.010778427124023438\n",
      "0.007505655288696289\n",
      "0.010286569595336914\n",
      "0.010095357894897461\n",
      "0.01467752456665039\n",
      "0.009284496307373047\n",
      "0.013016700744628906\n",
      "0.012315034866333008\n",
      "0.012515068054199219\n",
      "0.010365486145019531\n",
      "0.008484601974487305\n",
      "0.03373551368713379\n",
      "0.01103830337524414\n",
      "0.009044170379638672\n",
      "0.00831151008605957\n",
      "0.007889032363891602\n",
      "0.01198124885559082\n",
      "0.007930755615234375\n",
      "0.011839866638183594\n",
      "0.013230562210083008\n",
      "0.007727861404418945\n",
      "0.015522003173828125\n",
      "0.008288145065307617\n",
      "0.008584022521972656\n",
      "0.020952224731445312\n",
      "0.008106231689453125\n",
      "0.010453224182128906\n",
      "0.008022069931030273\n",
      "0.007989645004272461\n",
      "0.00759577751159668\n",
      "0.014237642288208008\n",
      "0.008530139923095703\n",
      "0.012062549591064453\n",
      "0.007646799087524414\n",
      "0.011073827743530273\n",
      "0.008937597274780273\n",
      "0.01620006561279297\n",
      "0.010958671569824219\n",
      "0.009751081466674805\n",
      "0.008781671524047852\n",
      "0.00751805305480957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013020753860473633\n",
      "0.012336492538452148\n",
      "0.0075571537017822266\n",
      "0.01329183578491211\n",
      "0.007775783538818359\n",
      "0.012459754943847656\n",
      "0.01592230796813965\n",
      "0.012757301330566406\n",
      "0.007819652557373047\n",
      "0.00877833366394043\n",
      "0.00915217399597168\n",
      "0.013603448867797852\n",
      "0.008455991744995117\n",
      "0.020301103591918945\n",
      "0.020557165145874023\n",
      "0.012262821197509766\n",
      "0.009631872177124023\n",
      "0.008740425109863281\n",
      "0.011198997497558594\n",
      "0.015882253646850586\n",
      "0.00813746452331543\n",
      "0.017527103424072266\n",
      "0.015496969223022461\n",
      "0.015604734420776367\n",
      "0.007626056671142578\n",
      "0.010302066802978516\n",
      "0.012313127517700195\n",
      "0.009665250778198242\n",
      "0.024631977081298828\n",
      "0.019566059112548828\n",
      "0.007767200469970703\n",
      "0.0077114105224609375\n",
      "0.02915191650390625\n",
      "0.01859760284423828\n",
      "0.035521507263183594\n",
      "0.017155885696411133\n",
      "0.013559341430664062\n",
      "0.013555765151977539\n",
      "0.013937950134277344\n",
      "0.02116560935974121\n",
      "0.012603282928466797\n",
      "0.013136148452758789\n",
      "0.02286076545715332\n",
      "0.013257265090942383\n",
      "0.016905784606933594\n",
      "0.04301619529724121\n",
      "0.0175018310546875\n",
      "0.01627206802368164\n",
      "0.0242154598236084\n",
      "0.021959781646728516\n",
      "0.016816377639770508\n",
      "0.019765377044677734\n",
      "0.01503300666809082\n",
      "0.01621532440185547\n",
      "0.013691425323486328\n",
      "0.03258991241455078\n",
      "0.0376279354095459\n",
      "0.027411699295043945\n",
      "0.08760714530944824\n",
      "0.009898662567138672\n",
      "0.01940321922302246\n",
      "0.016984939575195312\n",
      "0.020733356475830078\n",
      "0.010249137878417969\n",
      "0.016988754272460938\n",
      "0.02010035514831543\n",
      "0.012938499450683594\n",
      "0.007607936859130859\n",
      "0.04524064064025879\n",
      "0.02048349380493164\n",
      "0.011371374130249023\n",
      "0.025818824768066406\n",
      "0.014064311981201172\n",
      "0.011385917663574219\n",
      "0.010755300521850586\n",
      "0.011038064956665039\n",
      "0.010874032974243164\n",
      "0.0076830387115478516\n",
      "0.02127385139465332\n",
      "0.016254186630249023\n",
      "0.03232073783874512\n",
      "0.018613576889038086\n",
      "0.028641223907470703\n",
      "0.017089366912841797\n",
      "0.016963720321655273\n",
      "0.02003931999206543\n",
      "0.020470619201660156\n",
      "0.028203725814819336\n",
      "0.05926680564880371\n",
      "0.023041963577270508\n",
      "0.0368044376373291\n",
      "0.013618707656860352\n",
      "0.013324975967407227\n",
      "0.016462326049804688\n",
      "0.02926015853881836\n",
      "0.044393062591552734\n",
      "0.028054475784301758\n",
      "0.034818172454833984\n",
      "0.016347169876098633\n",
      "0.03031325340270996\n",
      "0.013353824615478516\n",
      "0.014255523681640625\n",
      "0.014484643936157227\n",
      "0.03391385078430176\n",
      "0.03300929069519043\n",
      "0.05382204055786133\n",
      "0.013076066970825195\n",
      "0.013800621032714844\n",
      "0.01448822021484375\n",
      "0.019926071166992188\n",
      "0.014255523681640625\n",
      "0.017641305923461914\n",
      "0.014691829681396484\n",
      "0.023354768753051758\n",
      "0.020801305770874023\n",
      "0.018531322479248047\n",
      "0.0226743221282959\n",
      "0.015762805938720703\n",
      "0.02247309684753418\n",
      "0.03975987434387207\n",
      "0.01643228530883789\n",
      "0.03657722473144531\n",
      "0.01822066307067871\n",
      "0.014324188232421875\n",
      "0.01280522346496582\n",
      "0.015425443649291992\n",
      "0.01282954216003418\n",
      "0.01250910758972168\n",
      "0.01995229721069336\n",
      "0.012358903884887695\n",
      "0.018969297409057617\n",
      "0.015948772430419922\n",
      "0.022569894790649414\n",
      "0.014451026916503906\n",
      "0.02132105827331543\n",
      "0.023406505584716797\n",
      "0.014918088912963867\n",
      "0.03040599822998047\n",
      "0.037436485290527344\n",
      "0.03697061538696289\n",
      "0.027956724166870117\n",
      "0.014134645462036133\n",
      "0.01283717155456543\n",
      "0.020177841186523438\n",
      "0.03868842124938965\n",
      "0.016329288482666016\n",
      "0.012734174728393555\n",
      "0.015389204025268555\n",
      "0.013422012329101562\n",
      "0.014005184173583984\n",
      "0.01848578453063965\n",
      "0.013584613800048828\n",
      "0.012290477752685547\n",
      "0.03786277770996094\n",
      "0.014491558074951172\n",
      "0.028710603713989258\n",
      "0.012244939804077148\n",
      "0.04232501983642578\n",
      "0.018537044525146484\n",
      "0.014982938766479492\n",
      "0.040192604064941406\n",
      "0.017414093017578125\n",
      "0.013316154479980469\n",
      "0.04519057273864746\n",
      "0.02144169807434082\n",
      "0.021594762802124023\n",
      "0.01399087905883789\n",
      "0.014311552047729492\n",
      "0.01850438117980957\n",
      "0.021229982376098633\n",
      "0.038877248764038086\n",
      "0.013000965118408203\n",
      "0.01651287078857422\n",
      "0.014917850494384766\n",
      "0.01767706871032715\n",
      "0.01619267463684082\n",
      "0.02602529525756836\n",
      "0.014989614486694336\n",
      "0.036157846450805664\n",
      "0.02103567123413086\n",
      "0.0440065860748291\n",
      "0.021915435791015625\n",
      "0.024111270904541016\n",
      "0.03356170654296875\n",
      "0.0145111083984375\n",
      "0.030022621154785156\n",
      "0.024166107177734375\n",
      "0.02226090431213379\n",
      "0.01345372200012207\n",
      "0.018273115158081055\n",
      "0.02719402313232422\n",
      "0.015462636947631836\n",
      "0.013408660888671875\n",
      "0.022505998611450195\n",
      "0.014625310897827148\n",
      "0.01867055892944336\n",
      "0.023294448852539062\n",
      "0.01695847511291504\n",
      "0.013178586959838867\n",
      "0.02080059051513672\n",
      "0.022025108337402344\n",
      "0.022661924362182617\n",
      "0.03885316848754883\n",
      "0.012416839599609375\n",
      "0.013565301895141602\n",
      "0.015846967697143555\n",
      "0.026990413665771484\n",
      "0.02754521369934082\n",
      "0.03132963180541992\n",
      "0.024548053741455078\n",
      "0.013597726821899414\n",
      "0.012907743453979492\n",
      "0.026833772659301758\n",
      "0.023355960845947266\n",
      "0.025722742080688477\n",
      "0.024117708206176758\n",
      "0.04750347137451172\n",
      "0.022327423095703125\n",
      "0.015364885330200195\n",
      "0.022138357162475586\n",
      "0.023012638092041016\n",
      "0.03665518760681152\n",
      "0.027806758880615234\n",
      "0.019760608673095703\n",
      "0.018086671829223633\n",
      "0.019918441772460938\n",
      "0.015073060989379883\n",
      "0.014591693878173828\n",
      "0.014771461486816406\n",
      "0.027745723724365234\n",
      "0.053633928298950195\n",
      "0.04057502746582031\n",
      "0.024820566177368164\n",
      "0.01590251922607422\n",
      "0.10808300971984863\n",
      "0.04047083854675293\n",
      "0.018106937408447266\n",
      "0.04407024383544922\n",
      "0.1212465763092041\n",
      "0.04304146766662598\n",
      "0.020505189895629883\n",
      "0.013840913772583008\n",
      "0.02855825424194336\n",
      "0.04601645469665527\n",
      "0.015079975128173828\n",
      "0.031748294830322266\n",
      "0.021335840225219727\n",
      "0.016499996185302734\n",
      "0.01692938804626465\n",
      "0.01600050926208496\n",
      "0.0084991455078125\n",
      "0.04387617111206055\n",
      "0.04065513610839844\n",
      "0.06890392303466797\n",
      "0.0817406177520752\n",
      "0.0181734561920166\n",
      "0.07323122024536133\n",
      "0.014068126678466797\n",
      "0.00933527946472168\n",
      "0.021565914154052734\n",
      "0.008282661437988281\n",
      "0.007886648178100586\n",
      "0.01131749153137207\n",
      "0.012853145599365234\n",
      "0.011940240859985352\n",
      "0.013303518295288086\n",
      "0.014692306518554688\n",
      "0.04452848434448242\n",
      "0.03372788429260254\n",
      "0.028926372528076172\n",
      "0.018533706665039062\n",
      "0.03562664985656738\n",
      "0.013072967529296875\n",
      "0.04318094253540039\n",
      "0.013426542282104492\n",
      "0.019925832748413086\n",
      "0.02304863929748535\n",
      "0.04546761512756348\n",
      "0.04012799263000488\n",
      "0.028136491775512695\n",
      "0.013298273086547852\n",
      "0.023154258728027344\n",
      "0.018477678298950195\n",
      "0.018434762954711914\n",
      "0.014207839965820312\n",
      "0.03659176826477051\n",
      "0.01592254638671875\n",
      "0.022394418716430664\n",
      "0.01915264129638672\n",
      "0.026600122451782227\n",
      "0.01680731773376465\n",
      "0.02032780647277832\n",
      "0.0160064697265625\n",
      "0.04530620574951172\n",
      "0.014029741287231445\n",
      "0.019832134246826172\n",
      "0.015273571014404297\n",
      "0.03523969650268555\n",
      "0.02147531509399414\n",
      "0.04362154006958008\n",
      "0.017154455184936523\n",
      "0.03502321243286133\n",
      "0.015955448150634766\n",
      "0.02711033821105957\n",
      "0.03139138221740723\n",
      "0.03196239471435547\n",
      "0.02512812614440918\n",
      "0.01648235321044922\n",
      "0.035529375076293945\n",
      "0.01654648780822754\n",
      "0.01782083511352539\n",
      "0.05811190605163574\n",
      "0.016765594482421875\n",
      "0.019266605377197266\n",
      "0.026629209518432617\n",
      "0.013223648071289062\n",
      "0.019539356231689453\n",
      "0.014674663543701172\n",
      "0.02695322036743164\n",
      "0.017106294631958008\n",
      "0.014533042907714844\n",
      "0.013345003128051758\n",
      "0.03777146339416504\n",
      "0.01782059669494629\n",
      "0.01853013038635254\n",
      "0.03551626205444336\n",
      "0.013404130935668945\n",
      "0.01250600814819336\n",
      "0.015023231506347656\n",
      "0.03075408935546875\n",
      "0.013889551162719727\n",
      "0.014061212539672852\n",
      "0.012371301651000977\n",
      "0.023272991180419922\n",
      "0.03486180305480957\n",
      "0.018480300903320312\n",
      "0.0199737548828125\n",
      "0.053798675537109375\n",
      "0.02154374122619629\n",
      "0.03194475173950195\n",
      "0.016039133071899414\n",
      "0.01264190673828125\n",
      "0.0364377498626709\n",
      "0.013171672821044922\n",
      "0.01436614990234375\n",
      "0.020377635955810547\n",
      "0.016288042068481445\n",
      "0.052626848220825195\n",
      "0.01365518569946289\n",
      "0.06711888313293457\n",
      "0.05007290840148926\n",
      "0.021988630294799805\n",
      "0.040906429290771484\n",
      "0.06272363662719727\n",
      "0.020995140075683594\n",
      "0.024102210998535156\n",
      "0.017340898513793945\n",
      "0.02164745330810547\n",
      "0.013356447219848633\n",
      "0.015955209732055664\n",
      "0.031014204025268555\n",
      "0.018127918243408203\n",
      "0.008425235748291016\n",
      "0.024535655975341797\n",
      "0.007706880569458008\n",
      "0.010041475296020508\n",
      "0.017940282821655273\n",
      "0.013975143432617188\n",
      "0.008859634399414062\n",
      "0.008605718612670898\n",
      "0.009063243865966797\n",
      "0.007586002349853516\n",
      "0.01685023307800293\n",
      "0.03400754928588867\n",
      "0.011061668395996094\n",
      "0.009711265563964844\n",
      "0.02454400062561035\n",
      "0.008791685104370117\n",
      "0.008671283721923828\n",
      "0.011962175369262695\n",
      "0.031624555587768555\n",
      "0.015167474746704102\n",
      "0.008404970169067383\n",
      "0.016490936279296875\n",
      "0.012548446655273438\n",
      "0.011271476745605469\n",
      "0.03698849678039551\n",
      "0.01390385627746582\n",
      "0.010408639907836914\n",
      "0.017034530639648438\n",
      "0.009650468826293945\n",
      "0.022258281707763672\n",
      "0.02487015724182129\n",
      "0.011245489120483398\n",
      "0.008522987365722656\n",
      "0.007788896560668945\n",
      "0.00826406478881836\n",
      "0.007946491241455078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008137226104736328\n",
      "0.008273601531982422\n",
      "0.008854866027832031\n",
      "0.011574745178222656\n",
      "0.009765386581420898\n",
      "0.008453369140625\n",
      "0.025687217712402344\n",
      "0.011217832565307617\n",
      "0.009511947631835938\n",
      "0.010664224624633789\n",
      "0.021167993545532227\n",
      "0.008888006210327148\n",
      "0.01261591911315918\n",
      "0.00804281234741211\n",
      "0.01900506019592285\n",
      "0.012243509292602539\n",
      "0.021486759185791016\n",
      "0.012070417404174805\n",
      "0.010683536529541016\n",
      "0.021074295043945312\n",
      "0.008438587188720703\n",
      "0.012056112289428711\n",
      "0.010554790496826172\n",
      "0.022570371627807617\n",
      "0.008146047592163086\n",
      "0.01270294189453125\n",
      "0.018619537353515625\n",
      "0.008700847625732422\n",
      "0.010376453399658203\n",
      "0.023976802825927734\n",
      "0.03686094284057617\n",
      "0.03320956230163574\n",
      "0.018467187881469727\n",
      "0.019283771514892578\n",
      "0.018865108489990234\n",
      "0.02293992042541504\n",
      "0.02224278450012207\n",
      "0.02098369598388672\n",
      "0.023928165435791016\n",
      "0.015554666519165039\n",
      "0.01915884017944336\n",
      "0.02748847007751465\n",
      "0.029588937759399414\n",
      "0.016643285751342773\n",
      "0.01741623878479004\n",
      "0.04029035568237305\n",
      "0.046560049057006836\n",
      "0.10404658317565918\n",
      "0.027192115783691406\n",
      "0.034655094146728516\n",
      "0.021215438842773438\n",
      "0.00937342643737793\n",
      "0.008827924728393555\n",
      "0.023467063903808594\n",
      "0.013660907745361328\n",
      "0.010639429092407227\n",
      "0.012187480926513672\n",
      "0.010169267654418945\n",
      "0.03958630561828613\n",
      "0.025008678436279297\n",
      "0.011069059371948242\n",
      "0.010640382766723633\n",
      "0.01491236686706543\n",
      "0.015359163284301758\n",
      "0.016365528106689453\n",
      "0.01210641860961914\n",
      "0.009526252746582031\n",
      "0.020678043365478516\n",
      "0.02117300033569336\n",
      "0.013083934783935547\n",
      "0.022693395614624023\n",
      "0.025710582733154297\n",
      "0.020384550094604492\n",
      "0.013862133026123047\n",
      "0.026823997497558594\n",
      "0.017001628875732422\n",
      "0.01230478286743164\n",
      "0.01208806037902832\n",
      "0.010548114776611328\n",
      "0.015986919403076172\n",
      "0.00856328010559082\n",
      "0.009189605712890625\n",
      "0.00912165641784668\n",
      "0.014831066131591797\n",
      "0.008940696716308594\n",
      "0.013835668563842773\n",
      "0.025492191314697266\n",
      "0.008435249328613281\n",
      "0.010823488235473633\n",
      "0.008890390396118164\n",
      "0.01547384262084961\n",
      "0.00879979133605957\n",
      "0.009767293930053711\n",
      "0.025079011917114258\n",
      "0.010364532470703125\n",
      "0.008823156356811523\n",
      "0.012545585632324219\n",
      "0.013564586639404297\n",
      "0.021252155303955078\n",
      "0.01612997055053711\n",
      "0.010843992233276367\n",
      "0.008838176727294922\n",
      "0.008220195770263672\n",
      "0.013145685195922852\n",
      "0.01320648193359375\n",
      "0.010084152221679688\n",
      "0.015062570571899414\n",
      "0.008999109268188477\n",
      "0.016913414001464844\n",
      "0.049886465072631836\n",
      "0.040830135345458984\n",
      "0.013999700546264648\n",
      "0.01373434066772461\n",
      "0.14981293678283691\n",
      "0.02828216552734375\n",
      "0.039789676666259766\n",
      "0.05858588218688965\n",
      "0.03581404685974121\n",
      "0.07815694808959961\n",
      "0.04239773750305176\n",
      "0.05141925811767578\n",
      "0.027871370315551758\n",
      "0.019475936889648438\n",
      "0.02883625030517578\n",
      "0.0166475772857666\n",
      "0.06275105476379395\n",
      "0.012634754180908203\n",
      "0.015638351440429688\n",
      "0.015238761901855469\n",
      "0.031101703643798828\n",
      "0.020730018615722656\n",
      "0.01497340202331543\n",
      "0.01728343963623047\n",
      "0.011193990707397461\n",
      "0.00886225700378418\n",
      "0.010845184326171875\n",
      "0.020554542541503906\n",
      "0.015598773956298828\n",
      "0.0234220027923584\n",
      "0.013318777084350586\n",
      "0.021697044372558594\n",
      "0.02684330940246582\n",
      "0.021991252899169922\n",
      "0.0620574951171875\n",
      "0.011605978012084961\n",
      "0.017300128936767578\n",
      "0.024219274520874023\n",
      "0.018296241760253906\n",
      "0.020731687545776367\n",
      "0.011007308959960938\n",
      "0.011888742446899414\n",
      "0.01815342903137207\n",
      "0.018910884857177734\n",
      "0.00878453254699707\n",
      "0.01573967933654785\n",
      "0.013712167739868164\n",
      "0.008303403854370117\n",
      "0.01774311065673828\n",
      "0.018747806549072266\n",
      "0.025342941284179688\n",
      "0.011399030685424805\n",
      "0.009415149688720703\n",
      "0.012417078018188477\n",
      "0.020943880081176758\n",
      "0.009816408157348633\n",
      "0.021681785583496094\n",
      "0.021917104721069336\n",
      "0.015717267990112305\n",
      "0.02045607566833496\n",
      "0.009264945983886719\n",
      "0.012501716613769531\n",
      "0.013950109481811523\n",
      "0.02431035041809082\n",
      "0.026088476181030273\n",
      "0.02792048454284668\n",
      "0.020691633224487305\n",
      "0.02172398567199707\n",
      "0.015834331512451172\n",
      "0.02393960952758789\n",
      "0.01664423942565918\n",
      "0.019373416900634766\n",
      "0.01894354820251465\n",
      "0.02798175811767578\n",
      "0.024133682250976562\n",
      "0.015328168869018555\n",
      "0.018915414810180664\n",
      "0.025623559951782227\n",
      "0.02079916000366211\n",
      "0.01867961883544922\n",
      "0.04014229774475098\n",
      "0.020990610122680664\n",
      "0.018842697143554688\n",
      "0.018387556076049805\n",
      "0.01743173599243164\n",
      "0.04351949691772461\n",
      "0.01787590980529785\n",
      "0.01748967170715332\n",
      "0.012843132019042969\n",
      "0.013274192810058594\n",
      "0.03227591514587402\n",
      "0.024718046188354492\n",
      "0.010637521743774414\n",
      "0.02069878578186035\n",
      "0.014925956726074219\n",
      "0.03279709815979004\n",
      "0.013269186019897461\n",
      "0.009537458419799805\n",
      "0.01183462142944336\n",
      "0.008938074111938477\n",
      "0.02573561668395996\n",
      "0.012203454971313477\n",
      "0.021956920623779297\n",
      "0.06385993957519531\n",
      "0.008484840393066406\n",
      "0.00803065299987793\n",
      "0.008611679077148438\n",
      "0.026636838912963867\n",
      "0.01645350456237793\n",
      "0.021744966506958008\n",
      "0.01860642433166504\n",
      "0.01830458641052246\n",
      "0.021303176879882812\n",
      "0.03343915939331055\n",
      "0.0169069766998291\n",
      "0.05598092079162598\n",
      "0.018004179000854492\n",
      "0.02177143096923828\n",
      "0.029404640197753906\n",
      "0.021030187606811523\n",
      "0.020799636840820312\n",
      "0.015820026397705078\n",
      "0.02872323989868164\n",
      "0.016474485397338867\n",
      "0.026071548461914062\n",
      "0.03693962097167969\n",
      "0.015755414962768555\n",
      "0.0185239315032959\n",
      "0.02115011215209961\n",
      "0.06396627426147461\n",
      "0.014071941375732422\n",
      "0.019284486770629883\n",
      "0.015038728713989258\n",
      "0.012685775756835938\n",
      "0.029089689254760742\n",
      "0.02248692512512207\n",
      "0.020528554916381836\n",
      "0.014323949813842773\n",
      "0.02636885643005371\n",
      "0.016389131546020508\n",
      "0.015204906463623047\n",
      "0.04410290718078613\n",
      "0.05614519119262695\n",
      "0.02138686180114746\n",
      "0.06640005111694336\n",
      "0.0075836181640625\n",
      "0.021811246871948242\n",
      "0.01264333724975586\n",
      "0.009171247482299805\n",
      "0.01335597038269043\n",
      "0.011797189712524414\n",
      "0.018479347229003906\n",
      "0.017633438110351562\n",
      "0.01470947265625\n",
      "0.017758607864379883\n",
      "0.013432502746582031\n",
      "0.01802659034729004\n",
      "0.03186988830566406\n",
      "0.017818689346313477\n",
      "0.012617349624633789\n",
      "0.027910470962524414\n",
      "0.016259193420410156\n",
      "0.014078140258789062\n",
      "0.021252870559692383\n",
      "0.027298927307128906\n",
      "0.03456568717956543\n",
      "0.01339411735534668\n",
      "0.02077198028564453\n",
      "0.029511213302612305\n",
      "0.015849590301513672\n",
      "0.031931161880493164\n",
      "0.09795403480529785\n",
      "0.021309852600097656\n",
      "0.013874053955078125\n",
      "0.021072864532470703\n",
      "0.03913259506225586\n",
      "0.01926732063293457\n",
      "0.015147209167480469\n",
      "0.03261518478393555\n",
      "0.027240514755249023\n",
      "0.017377853393554688\n",
      "0.01870274543762207\n",
      "0.012805461883544922\n",
      "0.012388944625854492\n",
      "0.028630495071411133\n",
      "0.018448352813720703\n",
      "0.014213323593139648\n",
      "0.018286705017089844\n",
      "0.017914772033691406\n",
      "0.029214143753051758\n",
      "0.012616872787475586\n",
      "0.020740985870361328\n",
      "0.014000654220581055\n",
      "0.01313471794128418\n",
      "0.01531219482421875\n",
      "0.015377044677734375\n",
      "0.024528026580810547\n",
      "0.01434469223022461\n",
      "0.013266801834106445\n",
      "0.014370441436767578\n",
      "0.029917001724243164\n",
      "0.013189077377319336\n",
      "0.014767646789550781\n",
      "0.016083955764770508\n",
      "0.023655414581298828\n",
      "0.012923240661621094\n",
      "0.015583515167236328\n",
      "0.02929377555847168\n",
      "0.02559208869934082\n",
      "0.014919042587280273\n",
      "0.025713682174682617\n",
      "0.0427396297454834\n",
      "0.031235218048095703\n",
      "0.026682138442993164\n",
      "0.026407957077026367\n",
      "0.013178348541259766\n",
      "0.01447296142578125\n",
      "0.030276060104370117\n",
      "0.013908147811889648\n",
      "0.014315128326416016\n",
      "0.01271677017211914\n",
      "0.016261816024780273\n",
      "0.013551950454711914\n",
      "0.028935909271240234\n",
      "0.013731718063354492\n",
      "0.015050888061523438\n",
      "0.03009486198425293\n",
      "0.016627073287963867\n",
      "0.012993812561035156\n",
      "0.014543294906616211\n",
      "0.018207073211669922\n",
      "0.01961374282836914\n",
      "0.02349710464477539\n",
      "0.018818140029907227\n",
      "0.012502908706665039\n",
      "0.025533437728881836\n",
      "0.017624855041503906\n",
      "0.01929020881652832\n",
      "0.025467634201049805\n",
      "0.018581151962280273\n",
      "0.014937639236450195\n",
      "0.028127670288085938\n",
      "0.022444725036621094\n",
      "0.01912665367126465\n",
      "0.012826204299926758\n",
      "0.02988576889038086\n",
      "0.012963056564331055\n",
      "0.03384900093078613\n",
      "0.01766800880432129\n",
      "0.04155707359313965\n",
      "0.013733863830566406\n",
      "0.014100074768066406\n",
      "0.014822959899902344\n",
      "0.013951301574707031\n",
      "0.017943859100341797\n",
      "0.04537773132324219\n",
      "0.013974189758300781\n",
      "0.03915715217590332\n",
      "0.015903472900390625\n",
      "0.03601670265197754\n",
      "0.013788223266601562\n",
      "0.012301921844482422\n",
      "0.016017913818359375\n",
      "0.03151249885559082\n",
      "0.026515483856201172\n",
      "0.01683783531188965\n",
      "0.01797318458557129\n",
      "0.014153242111206055\n",
      "0.03173494338989258\n",
      "0.056427955627441406\n",
      "0.012921333312988281\n",
      "0.016502857208251953\n",
      "0.02666926383972168\n",
      "0.013984918594360352\n",
      "0.028833866119384766\n",
      "0.04187941551208496\n",
      "0.01238250732421875\n",
      "0.03109431266784668\n",
      "0.012704133987426758\n",
      "0.01650261878967285\n",
      "0.012347698211669922\n",
      "0.013611555099487305\n",
      "0.013449907302856445\n",
      "0.019588708877563477\n",
      "0.024707794189453125\n",
      "0.022650480270385742\n",
      "0.013804197311401367\n",
      "0.012827157974243164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019851207733154297\n",
      "0.027615070343017578\n",
      "0.016291141510009766\n",
      "0.02029252052307129\n",
      "0.015343904495239258\n",
      "0.020166635513305664\n",
      "0.014487266540527344\n",
      "0.02420639991760254\n",
      "0.013915538787841797\n",
      "0.02392435073852539\n",
      "0.013460159301757812\n",
      "0.02347564697265625\n",
      "0.012786149978637695\n",
      "0.012405872344970703\n",
      "0.03556060791015625\n",
      "0.012409210205078125\n",
      "0.01668572425842285\n",
      "0.02846240997314453\n",
      "0.02585911750793457\n",
      "0.013944149017333984\n",
      "0.030778884887695312\n",
      "0.04447293281555176\n",
      "0.03174233436584473\n",
      "0.05433344841003418\n",
      "0.019062280654907227\n",
      "0.016187429428100586\n",
      "0.08639788627624512\n",
      "0.028354644775390625\n",
      "0.01448965072631836\n",
      "0.03028583526611328\n",
      "0.0243682861328125\n",
      "0.020796537399291992\n",
      "0.02422499656677246\n",
      "0.053694963455200195\n",
      "0.01396799087524414\n",
      "0.015400409698486328\n",
      "0.012473583221435547\n",
      "0.013853073120117188\n",
      "0.014121055603027344\n",
      "0.023286104202270508\n",
      "0.014570474624633789\n",
      "0.024480342864990234\n",
      "0.028972387313842773\n",
      "0.015004634857177734\n",
      "0.014763593673706055\n",
      "0.025196313858032227\n",
      "0.02899312973022461\n",
      "0.04214811325073242\n",
      "0.013579607009887695\n",
      "0.02355194091796875\n",
      "0.01670360565185547\n",
      "0.027384519577026367\n",
      "0.01914691925048828\n",
      "0.03131270408630371\n",
      "0.024194955825805664\n",
      "0.035447120666503906\n",
      "0.024412870407104492\n",
      "0.024949073791503906\n",
      "0.0273129940032959\n",
      "0.026547670364379883\n",
      "0.014251708984375\n",
      "0.024276256561279297\n",
      "0.013520956039428711\n",
      "0.013024091720581055\n",
      "0.04636335372924805\n",
      "0.020885467529296875\n",
      "0.01618027687072754\n",
      "0.016682147979736328\n",
      "0.01567244529724121\n",
      "0.0396733283996582\n",
      "0.029334306716918945\n",
      "0.016196727752685547\n",
      "0.020396947860717773\n",
      "0.013212442398071289\n",
      "0.03544116020202637\n",
      "0.017895936965942383\n",
      "0.040010690689086914\n",
      "0.028482913970947266\n",
      "0.0238189697265625\n",
      "0.03097391128540039\n",
      "0.013311624526977539\n",
      "0.024265766143798828\n",
      "0.03242182731628418\n",
      "0.027638673782348633\n",
      "0.013238668441772461\n",
      "0.03636455535888672\n",
      "0.029929399490356445\n",
      "0.025347471237182617\n",
      "0.031047344207763672\n",
      "0.01243138313293457\n",
      "119.70079827308655\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = None\n",
    "config['batch_size'] = None\n",
    "config['extended_prefectch'] = None\n",
    "\n",
    "trial_dict_dir = '/Lun0/zhiyong/dataset/trial_dict'\n",
    "\n",
    "def trial_data_preload(dataset, i, trial_dict_dir):\n",
    "    with open(trial_dict_dir, 'rb') as handle:\n",
    "        trial_dict = pickle.load(handle)\n",
    "        \n",
    "    start_time = time.time()\n",
    "    for i in trial_dict:\n",
    "        data = dataset.process_one_utt(trial_dict[i])\n",
    "        lbpart = trial_dict[i].split('/')[-3:]\n",
    "        lbpart = lbpart[0]+'-'+lbpart[1]+'-'+lbpart[2]\n",
    "        label = lbpart[:-4]\n",
    "        with open('/Lun0/zhiyong/dataset/trial_data/'+str(i), 'wb') as handle:\n",
    "            pickle.dump((data.astype(np.float16), [label]), handle)\n",
    "        print(time.time()-start_time)\n",
    "        start_time = time.time()\n",
    "\n",
    "dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, trial_dict_dir)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trial index (Need only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "train_data_dir = os.path.join(OPT_INDEX, 'trial_data')\n",
    "expected_len = 4874\n",
    "workers = 1\n",
    "single_worker_len = int(expected_len / workers)\n",
    "output = os.path.join(OPT_INDEX, 'trial_data_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert expected_len == len(glob.glob(train_data_dir+'/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(output, 'w') as f:\n",
    "    for j in range(single_worker_len):\n",
    "        path = os.path.join(train_data_dir, str(j))\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4874"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make PLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fft = librosa.get_fftlib()\n",
    "class VoxIterableDataset(object):\n",
    "    def __init__(self, data_dir_dict, data_len_dict, config):        \n",
    "        with open(data_dir_dict['spk2utt_train_dict'], 'rb') as handle:\n",
    "            self.spk2utt_train_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['music_dict'], 'rb') as handle:\n",
    "            self.music_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['noise_dict'], 'rb') as handle:\n",
    "            self.noise_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['babble_dict'], 'rb') as handle:\n",
    "            self.babble_dict = pickle.load(handle)\n",
    "        with open(data_dir_dict['rir_dict'], 'rb') as handle:\n",
    "            self.rir_dict = pickle.load(handle)\n",
    "            \n",
    "        with open(data_len_dict['spk2utt_train_len'], 'rb') as handle:\n",
    "            self.spk2utt_train_len = pickle.load(handle)\n",
    "        with open(data_len_dict['music_len'], 'rb') as handle:\n",
    "            self.music_len = pickle.load(handle)\n",
    "        with open(data_len_dict['noise_len'], 'rb') as handle:\n",
    "            self.noise_len = pickle.load(handle)\n",
    "        with open(data_len_dict['babble_len'], 'rb') as handle:\n",
    "            self.babble_len = pickle.load(handle)\n",
    "        \n",
    "        \n",
    "        self.random_spkrs_batchlist = None\n",
    "        self.ramdom_batch_len = None\n",
    "        self.random_noise_type = None\n",
    "        \n",
    "        \n",
    "        self.possible_babble_num = [3, 4, 5, 6, 7]\n",
    "        self.possible_babble_snr = [13, 15, 17, 20]\n",
    "        self.possible_noise_snr = [0, 5, 10, 15]\n",
    "        self.possible_music_snr = [5, 8, 10, 15]\n",
    "        \n",
    "        self.sr = config['sr']\n",
    "        self.repeats = config['repeats']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.extended_prefectch = config['extended_prefectch']\n",
    "        \n",
    "        self.mfcc_dim = 30\n",
    "        \n",
    "        # Auxiliary paras\n",
    "        self.multi_read_count = 0\n",
    "        self.preload_mem = False\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        assert len(self.ramdom_batch_len) == len(self.random_spkrs_batchlist)\n",
    "        try:\n",
    "            batch_frame_len = self.ramdom_batch_len.pop(0)\n",
    "            batch_spkrs = self.random_spkrs_batchlist.pop(0)\n",
    "            batch_noise_type = self.random_noise_type.pop(0)\n",
    "            batched_feats = np.zeros([self.batch_size, batch_frame_len, self.mfcc_dim])\n",
    "            batched_labels = np.zeros(self.batch_size)\n",
    "            \n",
    "            for batch_index, (spkr, noise_type) in enumerate(zip(batch_spkrs, batch_noise_type)):\n",
    "                \n",
    "                concat_wav, VAD_result = self._colleting_and_slicing(spkr, batch_frame_len,\\\n",
    "                hop_len=160, extended_prefectch=self.extended_prefectch)\n",
    "            \n",
    "                \n",
    "                if noise_type == 0:\n",
    "                    aug_wav = concat_wav\n",
    "                \n",
    "                elif noise_type == 1:\n",
    "                    aug_wav = self._add_rebverb(concat_wav)\n",
    "                   \n",
    "                elif noise_type == 2:\n",
    "                    aug_wav = self._add_noise(concat_wav)\n",
    "                    \n",
    "                elif noise_type == 3:\n",
    "                    aug_wav = self._add_music(concat_wav)\n",
    "                  \n",
    "                elif noise_type == 4:\n",
    "                    aug_wav = self._add_babble(concat_wav)\n",
    "             \n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                    \n",
    "            \n",
    "                single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "                dct_type=2, n_fft=512, hop_length=160, \\\n",
    "                win_length=None, window='hann', power=2.0, \\\n",
    "                center=True, pad_mode='reflect', n_mels=30, \\\n",
    "                fmin=20, fmax=7600)\n",
    "                # Note single_feats needs transpose\n",
    "                out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "                # Apply VAD\n",
    "                assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "                out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "                batched_feats[batch_index] = out_feats[:batch_frame_len]\n",
    "                batched_labels[batch_index] = spkr\n",
    "                \n",
    "            return batched_feats, batched_labels\n",
    "        \n",
    "        except IndexError:\n",
    "            raise StopIteration\n",
    "\n",
    "    def process_one_utt(self, utt_dir):\n",
    "        try:\n",
    "            concat_wav, _ = librosa.load(utt_dir, sr=self.sr)\n",
    "            \n",
    "            VAD_result = self._VAD_detection(concat_wav)\n",
    "            \n",
    "            aug_wav = concat_wav\n",
    "\n",
    "            single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "            dct_type=2, n_fft=512, hop_length=160, \\\n",
    "            win_length=None, window='hann', power=2.0, \\\n",
    "            center=True, pad_mode='reflect', n_mels=30, \\\n",
    "            fmin=20, fmax=7600)\n",
    "            # Note single_feats needs transpose\n",
    "            out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "            # Apply VAD\n",
    "            assert out_feats.shape[0] == VAD_result.shape[0]\n",
    "            out_feats = out_feats[VAD_result.astype(np.bool)]\n",
    "            \n",
    "            batched_feats = out_feats[None, :, :]\n",
    "                \n",
    "            return batched_feats\n",
    "        \n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def process_one_utt_noVAD(self, utt_dir):\n",
    "        try:\n",
    "            concat_wav, _ = librosa.load(utt_dir, sr=self.sr)\n",
    "            \n",
    "            aug_wav = concat_wav\n",
    "\n",
    "            single_feats = librosa.feature.mfcc(y=aug_wav, sr=self.sr, n_mfcc=30, \\\n",
    "            dct_type=2, n_fft=512, hop_length=160, \\\n",
    "            win_length=None, window='hann', power=2.0, \\\n",
    "            center=True, pad_mode='reflect', n_mels=30, \\\n",
    "            fmin=20, fmax=7600)\n",
    "            # Note single_feats needs transpose\n",
    "            out_feats = self._CMVN(single_feats.T, cmn_window = 300, normalize_variance = False)\n",
    "            \n",
    "            batched_feats = out_feats[None, :, :]\n",
    "                \n",
    "            return batched_feats\n",
    "        \n",
    "        except Exception:\n",
    "            traceback.print_exc()            \n",
    "    \n",
    "    def noise_data_preload(self):\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            _, _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            _, _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            _, _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "    \n",
    "    def noise_data_preload2mem(self):\n",
    "        print('preloading to memory')\n",
    "        \n",
    "        self.music_preload_dict = {}\n",
    "        self.noise_preload_dict = {}\n",
    "        self.babble_preload_dict = {}\n",
    "        self.preload_mem = True\n",
    "        print('preloading music_dict')\n",
    "        for count, i in enumerate(self.music_dict):\n",
    "            self.music_preload_dict[i], _ = librosa.load(self.music_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading noise_dict')        \n",
    "        for count, i in enumerate(self.noise_dict):\n",
    "            self.noise_preload_dict[i], _ = librosa.load(self.noise_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)\n",
    "        print('preloading babble_dict')        \n",
    "        for count, i in enumerate(self.babble_dict):\n",
    "            self.babble_preload_dict[i], _ = librosa.load(self.babble_dict[i], sr=self.sr)\n",
    "            if (count+1)%100 == 0:\n",
    "                print(count+1)       \n",
    "        \n",
    "        \n",
    "    def get_random_list(self):\n",
    "        spkrs_list = self.repeats * list(self.spk2utt_train_dict.keys())\n",
    "        random.shuffle(spkrs_list)\n",
    "        len_spkrs_list = len(spkrs_list)\n",
    "        self.random_spkrs_batchlist = [spkrs_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        self.ramdom_batch_len = [random.randint(200, 400) for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        noise_type_list = [i%5 for i in range(len_spkrs_list)]\n",
    "\n",
    "        random.shuffle(noise_type_list)\n",
    "        self.random_noise_type = [noise_type_list[i*self.batch_size:i*self.batch_size+self.batch_size]\\\n",
    "        for i in range(len_spkrs_list // self.batch_size)]\n",
    "        \n",
    "        assert len(self.random_spkrs_batchlist) == len(self.ramdom_batch_len)\\\n",
    "        == len(self.random_noise_type)\n",
    "        \n",
    "    def _colleting_and_slicing(self, spkr, batch_frame_len, hop_len=160, extended_prefectch=2.0):\n",
    "        \n",
    "        least_wav_len = (batch_frame_len - 1) * hop_len\n",
    "        concat_utt = np.zeros(0)\n",
    "        valid_frames_len = 0\n",
    "        \n",
    "        # Use to count multi_read_count\n",
    "        get_count = 0\n",
    "\n",
    "        while valid_frames_len < batch_frame_len:\n",
    "            concat_utt = np.zeros(0)\n",
    "\n",
    "            utt_dir = self._get_random_spk_utt(spkr, self.spk2utt_train_dict)\n",
    "            utt_len = self.spk2utt_train_len[utt_dir]\n",
    "#             off = self._get_random_offset(least_wav_len, utt_len) / self.sr\n",
    "            off = self._get_random_offset(least_wav_len+extended_prefectch*self.sr, utt_len) / self.sr\n",
    "            dur = least_wav_len / self.sr + extended_prefectch\n",
    "            \n",
    "            utt_part, _ = librosa.load(utt_dir, sr=self.sr, offset=off, duration=dur)\n",
    "            \n",
    "            concat_utt = np.append(concat_utt, utt_part)\n",
    "            detected_frames = self._VAD_detection(concat_utt)\n",
    "            valid_frames_len = np.sum(detected_frames)\n",
    "\n",
    "            get_count += 1\n",
    "\n",
    "        if get_count > 1:\n",
    "            self.multi_read_count += 1\n",
    "\n",
    "        VAD_result = detected_frames\n",
    "        return concat_utt, VAD_result\n",
    "    \n",
    "    def _add_rebverb(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = in_wav\n",
    "        filter_dir = self._get_random_noise(self.rir_dict)\n",
    "        filter, _ = librosa.load(filter_dir, sr=self.sr)\n",
    "        \n",
    "        signal_length = len(signal)\n",
    "        filter_length = len(filter)\n",
    "        output_length = signal_length + filter_length - 1\n",
    "        output = np.zeros(output_length)\n",
    "\n",
    "        fft_length = 2**np.ceil(np.log2(4 * filter_length)).astype(np.int)\n",
    "        block_length = fft_length - filter_length + 1\n",
    "\n",
    "\n",
    "        filter_padded = np.zeros(fft_length)\n",
    "        filter_padded[0:filter_length] = filter\n",
    "        filter_padded = fft.rfft(filter_padded)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(signal_length//block_length + 1):\n",
    "            process_length = min(block_length, signal_length - i * block_length);\n",
    "            signal_block_padded = np.zeros(fft_length)\n",
    "            signal_block_padded[0:process_length] = signal[i * block_length : i * block_length + process_length]\n",
    "            signal_block_padded = fft.rfft(signal_block_padded)\n",
    "\n",
    "            signal_block_padded = filter_padded * signal_block_padded\n",
    "\n",
    "            signal_block_padded = fft.irfft(signal_block_padded, n=fft_length)\n",
    "\n",
    "            if (i*block_length + fft_length) <= output_length:\n",
    "                output[i*block_length : i*block_length + fft_length] += signal_block_padded\n",
    "            else:\n",
    "                output[i*block_length : output_length] += signal_block_padded[:output_length-i*block_length]\n",
    "        \n",
    "        # shift with max index of filter\n",
    "        shift_index = np.argmax(filter)\n",
    "        \n",
    "        final_out = output[shift_index:shift_index+signal_length]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_noise(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.noise_dict, return_index=True)\n",
    "            noise_len = self.noise_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "                \n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.noise_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_noise_snr[random.randint(0, len(self.possible_noise_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_music(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        total_noise_len = 0\n",
    "        signal_off = 0\n",
    "        while total_noise_len < signal_len:\n",
    "            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.music_dict, return_index=True)\n",
    "            noise_len = self.music_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                total_noise_len += signal_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                total_noise_len += noise_len\n",
    "                if self.preload_mem:\n",
    "                    noise = self.music_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_music_snr[random.randint(0, len(self.possible_music_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "            signal_off += len(noise)\n",
    "        \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_babble(self, in_wav):\n",
    "        power_before_reverb = in_wav.dot(in_wav) / len(in_wav)\n",
    "        shift_index = 0\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "        \n",
    "        signal_len = len(signal)\n",
    "        signal_off = 0\n",
    "        bg_spks_num = self.possible_babble_num[random.randint(0, len(self.possible_babble_num)-1)]    \n",
    "        for _ in range(bg_spks_num):            \n",
    "            noise_dir, noise_index = self._get_random_noise(self.babble_dict, return_index=True)\n",
    "            noise_len = self.babble_len[noise_index]\n",
    "            if noise_len > signal_len:\n",
    "                noise_off = self._get_random_offset(signal_len, noise_len)\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index][noise_off:noise_off+signal_len]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr, offset=noise_off/self.sr,\\\n",
    "                    duration=signal_len/self.sr)\n",
    "            else:\n",
    "                if self.preload_mem:\n",
    "                    noise = self.babble_preload_dict[noise_index]\n",
    "                else:\n",
    "                    noise, _ = librosa.load(noise_dir, sr=self.sr)\n",
    "                \n",
    "            snr_db = self.possible_babble_snr[random.randint(0, len(self.possible_babble_snr)-1)]\n",
    "        \n",
    "            signal = self._add_db(signal, noise, signal_off, snr_db, power_before_reverb)\n",
    "            \n",
    "        output = signal\n",
    "        final_out = output[shift_index:shift_index+signal_len]\n",
    "        power_after_reverb = final_out.dot(final_out) / len(final_out)\n",
    "        final_out = np.sqrt(power_before_reverb/power_after_reverb) * final_out\n",
    "        out_wav = final_out\n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _add_db(self, in_wav, noise, signal_off, snr_db, power_before_reverb):\n",
    "        signal = np.zeros(len(in_wav))\n",
    "        signal[:] = in_wav[:]\n",
    "\n",
    "        noise_power = noise.dot(noise) / len(noise)\n",
    "        scale_factor = np.sqrt(10**(-snr_db / 10) * power_before_reverb / noise_power)\n",
    "        noise = scale_factor * noise\n",
    "\n",
    "        add_length = min(len(noise), len(signal)-signal_off)\n",
    "        signal[signal_off:signal_off+add_length] += noise[:add_length]\n",
    "        out_wav = signal      \n",
    "        \n",
    "        return out_wav\n",
    "    \n",
    "    def _CMVN(self, in_feat, cmn_window = 300, normalize_variance = False):             \n",
    "        num_frames = in_feat.shape[0]\n",
    "        dim = in_feat.shape[1]\n",
    "        last_window_start = -1\n",
    "        last_window_end = -1\n",
    "        cur_sum = np.zeros(dim)\n",
    "        cur_sumsq = np.zeros(dim)\n",
    "\n",
    "        out_feat = np.zeros([num_frames, dim])\n",
    "\n",
    "        for t in range(num_frames):\n",
    "            window_start = 0\n",
    "            window_end = 0\n",
    "\n",
    "            window_start = t - int(cmn_window / 2)\n",
    "            window_end = window_start + cmn_window\n",
    "\n",
    "            if (window_start < 0):\n",
    "                window_end -= window_start\n",
    "                window_start = 0\n",
    "\n",
    "            if (window_end > num_frames):\n",
    "                window_start -= (window_end - num_frames)\n",
    "                window_end = num_frames\n",
    "                if (window_start < 0):\n",
    "                    window_start = 0\n",
    "\n",
    "            if (last_window_start == -1):\n",
    "                input_part = in_feat[window_start:window_end]\n",
    "                cur_sum = np.sum(input_part, axis=0, keepdims=False)\n",
    "                if normalize_variance:\n",
    "                    cur_sumsq = np.sum(input_part**2, axis=0, keepdims=False)\n",
    "            else:\n",
    "                if (window_start > last_window_start):\n",
    "                    frame_to_remove = in_feat[last_window_start]\n",
    "                    cur_sum -= frame_to_remove\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq -= frame_to_remove**2\n",
    "\n",
    "                if (window_end > last_window_end):\n",
    "                    frame_to_add = in_feat[last_window_end]\n",
    "                    cur_sum += frame_to_add\n",
    "                    if normalize_variance:\n",
    "                        cur_sumsq += frame_to_add**2\n",
    "\n",
    "            window_frames = window_end - window_start\n",
    "            last_window_start = window_start\n",
    "            last_window_end = window_end\n",
    "\n",
    "            out_feat[t] = in_feat[t] - (1.0 / window_frames) * cur_sum\n",
    "\n",
    "\n",
    "            if normalize_variance:\n",
    "                if (window_frames == 1):\n",
    "                    out_feat[t] = 0.0\n",
    "                else:\n",
    "                    variance = (1.0 / window_frames) * cur_sumsq - (1.0 / window_frames**2) * cur_sum**2\n",
    "                    variance = np.maximum(1.0e-10, variance)\n",
    "                    out_feat[t] /= variance**(0.5)\n",
    "                    \n",
    "        return out_feat\n",
    "\n",
    "    def _get_random_noise(self, noise_dict, return_index=False):\n",
    "        dict_len = len(noise_dict)\n",
    "        i = random.randint(0, dict_len-1)\n",
    "        noise_dir = noise_dict[i]\n",
    "        \n",
    "        if return_index:\n",
    "            return noise_dir, i\n",
    "        else:\n",
    "            return noise_dir\n",
    "    \n",
    "    def _get_random_spk_utt(self, spkr, spk2utt):\n",
    "        this_utts = spk2utt[spkr]\n",
    "        this_num_utts = len(this_utts)\n",
    "        i = random.randint(0, this_num_utts-1)\n",
    "        utt_dir = this_utts[i]\n",
    "        return utt_dir\n",
    "\n",
    "    def _get_random_offset(self, expected_length, utt_len):\n",
    "        if expected_length > utt_len:\n",
    "            return 0\n",
    "        \n",
    "        free_length = utt_len - expected_length\n",
    "        offset = random.randint(0, free_length)\n",
    "        return offset\n",
    "        \n",
    "    @property\n",
    "    def _VAD_config(self):\n",
    "        vad_energy_threshold = -3.0\n",
    "        vad_energy_mean_scale = 1.0\n",
    "        vad_frames_context = 0\n",
    "        vad_proportion_threshold = 0.12\n",
    "        \n",
    "        return vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold\n",
    "        \n",
    "        \n",
    "    def _VAD_detection(self, wav):\n",
    "        vad_energy_threshold, vad_energy_mean_scale,\\\n",
    "        vad_frames_context, vad_proportion_threshold = self._VAD_config\n",
    "        \n",
    "        y_tmp = np.pad(wav, int(512 // 2), mode='reflect')\n",
    "        y_tmp = librosa.util.frame(y_tmp, frame_length=512, hop_length=160)\n",
    "        y_log_energy = np.log(np.maximum(np.sum(y_tmp**2, axis=0), 1e-15))\n",
    "\n",
    "        T = len(y_log_energy)\n",
    "        output_voiced = np.zeros(T)\n",
    "        if (T == 0):\n",
    "            raise Exception(\"zero wave length\")\n",
    "\n",
    "        energy_threshold = vad_energy_threshold\n",
    "        if (vad_energy_mean_scale != 0.0):\n",
    "            assert(vad_energy_mean_scale > 0.0)\n",
    "            energy_threshold += vad_energy_mean_scale * np.sum(y_log_energy) / T\n",
    "\n",
    "\n",
    "        assert(vad_frames_context >= 0)\n",
    "        assert(vad_proportion_threshold > 0.0 and vad_proportion_threshold < 1.0);\n",
    "\n",
    "        for t in range(T):\n",
    "            num_count = 0\n",
    "            den_count = 0\n",
    "            context = vad_frames_context\n",
    "            for t2 in range(t - context, t + context+1):\n",
    "                if (t2 >= 0 and t2 < T):\n",
    "                    den_count+=1\n",
    "                    if (y_log_energy[t2] > energy_threshold):\n",
    "                        num_count+=1\n",
    "\n",
    "            if (num_count >= den_count * vad_proportion_threshold):\n",
    "                output_voiced[t] = 1.0\n",
    "            else:\n",
    "                output_voiced[t] = 0.0\n",
    "        \n",
    "        return output_voiced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "data_dir_dict = {}\n",
    "\n",
    "# val\n",
    "data_dir_dict['spk2utt_train_dict'] = os.path.join(OPT_INDEX, 'spk2utt_val_dict')\n",
    "data_dir_dict['music_dict'] = os.path.join(OPT_INDEX, 'music_dict')\n",
    "data_dir_dict['noise_dict'] = os.path.join(OPT_INDEX, 'noise_dict')\n",
    "data_dir_dict['babble_dict'] = os.path.join(OPT_INDEX, 'babble_dict')\n",
    "data_dir_dict['rir_dict'] = os.path.join(OPT_INDEX, 'rir_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len_dict = {}\n",
    "\n",
    "data_len_dict['spk2utt_train_len'] = os.path.join(OPT_INDEX, 'spk2utt_val_len')\n",
    "data_len_dict['music_len'] = os.path.join(OPT_INDEX, 'music_len')\n",
    "data_len_dict['noise_len'] = os.path.join(OPT_INDEX, 'noise_len')\n",
    "data_len_dict['babble_len'] = os.path.join(OPT_INDEX, 'babble_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spk2utt_dict = os.path.join(OPT_INDEX, 'spk2utt_dict')\n",
    "\n",
    "with open(spk2utt_dict, 'rb') as handle:\n",
    "    spk2utt_dict_data = pickle.load(handle)\n",
    "count = 0\n",
    "for i in spk2utt_dict_data:\n",
    "    count += len(spk2utt_dict_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "22095.06617307663\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = None\n",
    "config['batch_size'] = None\n",
    "config['extended_prefectch'] = None\n",
    "\n",
    "# trial_dict_dir = '/Lun0/zhiyong/dataset/trial_dict'\n",
    "\n",
    "def trial_data_preload(dataset, i, spk2utt_dict_data):\n",
    "        \n",
    "    for i in spk2utt_dict_data:\n",
    "        for j, line in enumerate(spk2utt_dict_data[i]):\n",
    "#             data = dataset.process_one_utt(line)\n",
    "            data = dataset.process_one_utt_noVAD(line)\n",
    "            lbpart = line.split('/')[-3:]\n",
    "            lbpart = lbpart[0]+'-'+lbpart[1]+'-'+lbpart[2]\n",
    "            label = lbpart[:-4]\n",
    "            with open('/Lun0/zhiyong/dataset/plda_full_data_noVAD/'+str(i)+'_'+str(j), 'wb') as handle:\n",
    "                pickle.dump((data.astype(np.float16), [label]), handle)\n",
    "        if ((i+1) % 100) == 0:    \n",
    "            print(i+1)\n",
    "\n",
    "dataset = VoxIterableDataset(data_dir_dict, data_len_dict, config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, spk2utt_dict_data)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make PLDA index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPT_INDEX = '/Lun0/zhiyong/dataset'\n",
    "train_data_dir = os.path.join(OPT_INDEX, 'plda_full_data_noVAD')\n",
    "expected_len = 1276888\n",
    "workers = 1\n",
    "single_worker_len = int(expected_len / workers)\n",
    "output = os.path.join(OPT_INDEX, 'plda_full_data_noVAD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spk2utt_dict = os.path.join(OPT_INDEX, 'spk2utt_dict')\n",
    "\n",
    "with open(spk2utt_dict, 'rb') as handle:\n",
    "    spk2utt_dict_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert expected_len == len(glob.glob(train_data_dir+'/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(output, 'w') as f:\n",
    "    for i in spk2utt_dict_data:\n",
    "        for j in range(len(spk2utt_dict_data[i])):\n",
    "            path = os.path.join(train_data_dir, str(i)+'_'+str(j))\n",
    "            assert os.path.isfile(path)\n",
    "            f.write(path+'\\n')\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276888"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
