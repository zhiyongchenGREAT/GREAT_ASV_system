{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import traceback\n",
    "import shutil\n",
    "\n",
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = '/workspace/GREAT_ASV_system/'\n",
    "sys.path.append(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPT_INDEX = '/workspace/DATASET/server9_ssd/STD_SRE_EGS'\n",
    "if not os.path.exists(OPT_INDEX):\n",
    "    os.mkdir(OPT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRE18_DEV_DIR = '/workspace/DATASET/server9/SRE18_DEV'\n",
    "SRE18_TEST_DIR = '/workspace/DATASET/server9/SRE18_TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO_DIR = os.path.join(OPT_INDEX, 'SRE18_TRIAL_INFO')\n",
    "if not os.path.exists(INFO_DIR):\n",
    "    os.mkdir(INFO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Trials dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/DATASET/server9/SRE18_DEV'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRE18_DEV_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial dict\n",
    "trial_dir = SRE18_DEV_DIR\n",
    "trial_dict_out = os.path.join(INFO_DIR, 'sre18_dev_trial_dict')\n",
    "trial_dict = {}\n",
    "\n",
    "tmp_dir_list = glob.glob(trial_dir+'/Enroll/*/*.wav') + glob.glob(trial_dir+'/Eval/*.wav')\n",
    "for count, this_dir in enumerate(tmp_dir_list):\n",
    "    trial_dict[count] = this_dir\n",
    "with open(trial_dict_out, 'wb') as handle:\n",
    "    pickle.dump(trial_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1741"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial dict\n",
    "trial_dir = SRE18_TEST_DIR\n",
    "trial_dict_out = os.path.join(INFO_DIR, 'sre18_test_trial_dict')\n",
    "trial_dict = {}\n",
    "\n",
    "tmp_dir_list = glob.glob(trial_dir+'/Enroll/*/*.wav') + glob.glob(trial_dir+'/Eval/*.wav')\n",
    "for count, this_dir in enumerate(tmp_dir_list):\n",
    "    trial_dict[count] = this_dir\n",
    "with open(trial_dict_out, 'wb') as handle:\n",
    "    pickle.dump(trial_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13451"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trials data for SRE18 DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.Utils.preprocessing_3type import ThreeTypes_IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC_O = os.path.join(OPT_INDEX, 'SRE18_DEV_TRIALS_MFCC')\n",
    "LOGMELFB_O = os.path.join(OPT_INDEX, 'SRE18_DEV_TRIALS_FB')\n",
    "RAWWAV_O = os.path.join(OPT_INDEX, 'SRE18_DEV_TRIALS_RAW')\n",
    "EER_LOG = os.path.join(OPT_INDEX, 'EER_LOG_SRE18_DEV_TRIAL')\n",
    "G_LOG = os.path.join(OPT_INDEX, 'G_LOG_SRE18_DEV_TRIAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MFCC_O):\n",
    "    os.mkdir(MFCC_O)\n",
    "else:\n",
    "    shutil.rmtree(MFCC_O)\n",
    "    \n",
    "if not os.path.exists(LOGMELFB_O):\n",
    "    os.mkdir(LOGMELFB_O)\n",
    "else:\n",
    "    shutil.rmtree(LOGMELFB_O)\n",
    "    \n",
    "if not os.path.exists(RAWWAV_O):\n",
    "    os.mkdir(RAWWAV_O)\n",
    "else:\n",
    "    shutil.rmtree(RAWWAV_O)\n",
    "\n",
    "with open(EER_LOG, 'w') as f:\n",
    "    pass\n",
    "\n",
    "with open(G_LOG, 'w') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = 1\n",
    "config['batch_size'] = 1\n",
    "\n",
    "trial_dict_dir = os.path.join(INFO_DIR, 'sre18_dev_trial_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_feats_rawwave, batched_feats_LogMelFB, batched_feats_MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "def trial_data_preload(dataset, i, trial_dict_dir):\n",
    "    with open(trial_dict_dir, 'rb') as handle:\n",
    "        trial_dict = pickle.load(handle)\n",
    "        \n",
    "    start_time = time.time()\n",
    "    for count, i in enumerate(trial_dict):\n",
    "        rw, fb, mfcc = dataset.process_one_utt(trial_dict[i])\n",
    "        lbpart = trial_dict[0].split('/')[-1]\n",
    "        label = lbpart[:-4]\n",
    "        \n",
    "        file_name = str(i)\n",
    "        with open(os.path.join(RAWWAV_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((rw.astype(np.float16), [label]), handle)\n",
    "        with open(os.path.join(LOGMELFB_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((fb.astype(np.float16), [label]), handle)\n",
    "        with open(os.path.join(MFCC_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((mfcc.astype(np.float16), [label]), handle)        \n",
    "        if (count+1) % 1000 == 0:\n",
    "            print(count+1)\n",
    "\n",
    "dataset = ThreeTypes_IterableDataset(config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, trial_dict_dir)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trials index SRE18 DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_mfcc_dir = os.path.join(INFO_DIR, 'sre18_dev_trials_mfcc.csv')\n",
    "trials_fb_dir = os.path.join(INFO_DIR, 'sre18_dev_trials_fb.csv')\n",
    "trials_rw_dir = os.path.join(INFO_DIR, 'sre18_dev_trials_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_len = glob.glob(MFCC_O+'/*')\n",
    "fb_len = glob.glob(LOGMELFB_O+'/*')\n",
    "raw_len = glob.glob(RAWWAV_O+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 1741\n",
      "fb 1741\n",
      "raw 1741\n"
     ]
    }
   ],
   "source": [
    "print('mfcc', len(mfcc_len))\n",
    "print('fb', len(fb_len))\n",
    "print('raw', len(raw_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 1741\n",
      "fb 1741\n",
      "raw 1741\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with open(trials_mfcc_dir, 'w') as f:\n",
    "    for path in mfcc_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('mfcc', count)\n",
    "\n",
    "count = 0\n",
    "with open(trials_fb_dir, 'w') as f:\n",
    "    for path in fb_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('fb', count)\n",
    "\n",
    "count = 0\n",
    "with open(trials_rw_dir, 'w') as f:\n",
    "    for path in raw_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('raw', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trials data for SRE18 DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.Utils.preprocessing_3type import ThreeTypes_IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC_O = os.path.join(OPT_INDEX, 'SRE18_TEST_TRIALS_MFCC')\n",
    "LOGMELFB_O = os.path.join(OPT_INDEX, 'SRE18_TEST_TRIALS_FB')\n",
    "RAWWAV_O = os.path.join(OPT_INDEX, 'SRE18_TEST_TRIALS_RAW')\n",
    "EER_LOG = os.path.join(OPT_INDEX, 'EER_LOG_SRE18_TEST_TRIAL')\n",
    "G_LOG = os.path.join(OPT_INDEX, 'G_LOG_SRE18_TEST_TRIAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MFCC_O):\n",
    "    os.mkdir(MFCC_O)\n",
    "else:\n",
    "    shutil.rmtree(MFCC_O)\n",
    "    \n",
    "if not os.path.exists(LOGMELFB_O):\n",
    "    os.mkdir(LOGMELFB_O)\n",
    "else:\n",
    "    shutil.rmtree(LOGMELFB_O)\n",
    "    \n",
    "if not os.path.exists(RAWWAV_O):\n",
    "    os.mkdir(RAWWAV_O)\n",
    "else:\n",
    "    shutil.rmtree(RAWWAV_O)\n",
    "\n",
    "with open(EER_LOG, 'w') as f:\n",
    "    pass\n",
    "\n",
    "with open(G_LOG, 'w') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['sr'] = 16000\n",
    "config['repeats'] = 1\n",
    "config['batch_size'] = 1\n",
    "\n",
    "trial_dict_dir = os.path.join(INFO_DIR, 'sre18_test_trial_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_feats_rawwave, batched_feats_LogMelFB, batched_feats_MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n"
     ]
    }
   ],
   "source": [
    "def trial_data_preload(dataset, i, trial_dict_dir):\n",
    "    with open(trial_dict_dir, 'rb') as handle:\n",
    "        trial_dict = pickle.load(handle)\n",
    "        \n",
    "    start_time = time.time()\n",
    "    for count, i in enumerate(trial_dict):\n",
    "        rw, fb, mfcc = dataset.process_one_utt(trial_dict[i])\n",
    "        lbpart = trial_dict[0].split('/')[-1]\n",
    "        label = lbpart[:-4]\n",
    "        \n",
    "        file_name = str(i)\n",
    "        with open(os.path.join(RAWWAV_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((rw.astype(np.float16), [label]), handle)\n",
    "        with open(os.path.join(LOGMELFB_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((fb.astype(np.float16), [label]), handle)\n",
    "        with open(os.path.join(MFCC_O, file_name), 'wb') as handle:\n",
    "            pickle.dump((mfcc.astype(np.float16), [label]), handle)        \n",
    "        if (count+1) % 1000 == 0:\n",
    "            print(count+1)\n",
    "\n",
    "dataset = ThreeTypes_IterableDataset(config)\n",
    "\n",
    "processes = [Process(target = trial_data_preload, args = (dataset, i, trial_dict_dir)) for i in range(1)]\n",
    "start_time = time.time()\n",
    "[p.start() for p in processes]\n",
    "joined = [p.join() for p in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trials index SRE18 TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_mfcc_dir = os.path.join(INFO_DIR, 'sre18_test_trials_mfcc.csv')\n",
    "trials_fb_dir = os.path.join(INFO_DIR, 'sre18_test_trials_fb.csv')\n",
    "trials_rw_dir = os.path.join(INFO_DIR, 'sre18_test_trials_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_len = glob.glob(MFCC_O+'/*')\n",
    "fb_len = glob.glob(LOGMELFB_O+'/*')\n",
    "raw_len = glob.glob(RAWWAV_O+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 13451\n",
      "fb 13451\n",
      "raw 13451\n"
     ]
    }
   ],
   "source": [
    "print('mfcc', len(mfcc_len))\n",
    "print('fb', len(fb_len))\n",
    "print('raw', len(raw_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc 13451\n",
      "fb 13451\n",
      "raw 13451\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with open(trials_mfcc_dir, 'w') as f:\n",
    "    for path in mfcc_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('mfcc', count)\n",
    "\n",
    "count = 0\n",
    "with open(trials_fb_dir, 'w') as f:\n",
    "    for path in fb_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('fb', count)\n",
    "\n",
    "count = 0\n",
    "with open(trials_rw_dir, 'w') as f:\n",
    "    for path in raw_len:\n",
    "        assert os.path.isfile(path)\n",
    "        f.write(path+'\\n')\n",
    "        count += 1\n",
    "print('raw', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make enroll model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/DATASET/server9/SRE18_DEV'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRE18_DEV_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "# trial dict\n",
    "trial_dir = SRE18_DEV_DIR\n",
    "enroll_model_out = os.path.join(INFO_DIR, 'sre18_dev_enroll_model')\n",
    "spk2utt = {}\n",
    "\n",
    "label_dir = glob.glob(trial_dir+'/Enroll/*')\n",
    "label = [i.split('/')[-1] for i in label_dir]\n",
    "\n",
    "for count, i in enumerate(label):\n",
    "    spk2utt[i] = glob.glob(os.path.join(trial_dir, 'Enroll', i)+'/*.wav')\n",
    "    \n",
    "print(len(spk2utt))\n",
    "\n",
    "with open(enroll_model_out, 'w') as f:\n",
    "    for label in spk2utt:\n",
    "        data = spk2utt[label]\n",
    "        line = label\n",
    "        for i in data:\n",
    "            line += ' '+i.split('/')[-1][:-4]\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/DATASET/server9/SRE18_TEST'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRE18_TEST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940\n"
     ]
    }
   ],
   "source": [
    "# trial dict\n",
    "trial_dir = SRE18_TEST_DIR\n",
    "enroll_model_out = os.path.join(INFO_DIR, 'sre18_test_enroll_model')\n",
    "spk2utt = {}\n",
    "\n",
    "label_dir = glob.glob(trial_dir+'/Enroll/*')\n",
    "label = [i.split('/')[-1] for i in label_dir]\n",
    "\n",
    "for count, i in enumerate(label):\n",
    "    spk2utt[i] = glob.glob(os.path.join(trial_dir, 'Enroll', i)+'/*.wav')\n",
    "    \n",
    "print(len(spk2utt))\n",
    "\n",
    "with open(enroll_model_out, 'w') as f:\n",
    "    for label in spk2utt:\n",
    "        data = spk2utt[label]\n",
    "        line = label\n",
    "        for i in data:\n",
    "            line += ' '+i.split('/')[-1][:-4]\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trial keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sre18_dev_trials_dir = os.path.join(INFO_DIR, 'sre18_dev_trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_sre18_dev_trials_dir = os.path.join(INFO_DIR, 'ori_sre18_dev_trial_key.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sre18_dev 108096\n"
     ]
    }
   ],
   "source": [
    "with open(ori_sre18_dev_trials_dir, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(sre18_dev_trials_dir, 'w') as f:\n",
    "    for count, line in enumerate(lines):\n",
    "        if count == 0:\n",
    "            continue\n",
    "        \n",
    "        cmp = line[:-1].split('\\t')\n",
    "        \n",
    "        if cmp[1].split('.')[1] == 'flac':\n",
    "            break\n",
    "        \n",
    "        if cmp[3] == 'nontarget':\n",
    "            out_1 = cmp[0]\n",
    "            out_2 = cmp[1].split('.')[0]\n",
    "            out_3 = cmp[3]\n",
    "            out = out_1+' '+out_2+' '+out_3+'\\n'\n",
    "        elif cmp[3] == 'target':\n",
    "            out_1 = cmp[0]\n",
    "            out_2 = cmp[1].split('.')[0]\n",
    "            out_3 = cmp[3]\n",
    "            out = out_1+' '+out_2+' '+out_3+'\\n'\n",
    "        else:\n",
    "            print('err')\n",
    "            \n",
    "        f.write(out)\n",
    "        \n",
    "print('sre18_dev', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sre18_test_trials_dir = os.path.join(INFO_DIR, 'sre18_test_trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_sre18_test_trials_dir = os.path.join(INFO_DIR, 'ori_sre18_eval_trial_key.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sre18_test 2063008\n"
     ]
    }
   ],
   "source": [
    "with open(ori_sre18_test_trials_dir, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(sre18_test_trials_dir, 'w') as f:\n",
    "    for count, line in enumerate(lines):\n",
    "        if count == 0:\n",
    "            continue\n",
    "        \n",
    "        cmp = line[:-1].split('\\t')\n",
    "        \n",
    "        if cmp[1].split('.')[1] == 'flac':\n",
    "            break\n",
    "        \n",
    "        if cmp[3] == 'nontarget':\n",
    "            out_1 = cmp[0]\n",
    "            out_2 = cmp[1].split('.')[0]\n",
    "            out_3 = cmp[3]\n",
    "            out = out_1+' '+out_2+' '+out_3+'\\n'\n",
    "        elif cmp[3] == 'target':\n",
    "            out_1 = cmp[0]\n",
    "            out_2 = cmp[1].split('.')[0]\n",
    "            out_3 = cmp[3]\n",
    "            out = out_1+' '+out_2+' '+out_3+'\\n'\n",
    "        else:\n",
    "            print('err')\n",
    "            \n",
    "        f.write(out)\n",
    "        \n",
    "print('sre18_test', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
